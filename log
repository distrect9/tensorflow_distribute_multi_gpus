train_step : 1, loss1 : 748.703613, loss2 : 676.448303
train_step : 2, loss1 : 1539.555664, loss2 : 3407.148193
train_step : 3, loss1 : 4654985.500000, loss2 : 4569825.000000
train_step : 4, loss1 : 224368.171875, loss2 : 230399.921875
train_step : 5, loss1 : 62297.578125, loss2 : 56407.656250
train_step : 6, loss1 : 813926016.000000, loss2 : 973564544.000000
train_step : 7, loss1 : 3900453888.000000, loss2 : 4476246016.000000
train_step : 8, loss1 : 898952064.000000, loss2 : 911577984.000000
train_step : 9, loss1 : 449837.812500, loss2 : 449428.687500
train_step : 10, loss1 : 289517.000000, loss2 : 286741.250000
train_step : 11, loss1 : 184159.875000, loss2 : 184405.468750
train_step : 12, loss1 : 116872.187500, loss2 : 117362.742188
train_step : 13, loss1 : 74418.515625, loss2 : 75159.343750
train_step : 14, loss1 : 48493.890625, loss2 : 48905.199219
train_step : 15, loss1 : 31411.957031, loss2 : 31380.050781
train_step : 16, loss1 : 9854.656250, loss2 : 10538.287109
train_step : 17, loss1 : 12717740.000000, loss2 : 13371388.000000
train_step : 18, loss1 : 701190.562500, loss2 : 703166.500000
train_step : 19, loss1 : 449310.531250, loss2 : 449112.000000
train_step : 20, loss1 : 285144.531250, loss2 : 285604.750000
train_step : 21, loss1 : 184297.781250, loss2 : 183860.281250
train_step : 22, loss1 : 118243.000000, loss2 : 117219.593750
train_step : 23, loss1 : 75279.031250, loss2 : 75354.234375
train_step : 24, loss1 : 48152.203125, loss2 : 48256.898438
train_step : 25, loss1 : 30788.355469, loss2 : 31022.890625
train_step : 26, loss1 : 20251.156250, loss2 : 19553.623047
train_step : 27, loss1 : 12092.013672, loss2 : 12877.900391
train_step : 28, loss1 : 8199.791016, loss2 : 7987.454590
train_step : 29, loss1 : 5171.916016, loss2 : 5172.772461
train_step : 30, loss1 : 3294.810547, loss2 : 3389.217529
train_step : 31, loss1 : 2134.677246, loss2 : 2095.488770
train_step : 32, loss1 : 1346.601807, loss2 : 1235.487671
train_step : 33, loss1 : 904.303711, loss2 : 880.925903
train_step : 34, loss1 : 573.790527, loss2 : 619.679321
train_step : 35, loss1 : 347.020020, loss2 : 377.716553
train_step : 36, loss1 : 235.095322, loss2 : 251.523926
train_step : 37, loss1 : 180.070801, loss2 : 153.325500
train_step : 38, loss1 : 107.056396, loss2 : 94.814590
train_step : 39, loss1 : 80.572449, loss2 : 86.265984
train_step : 40, loss1 : 69.382332, loss2 : 61.624638
train_step : 41, loss1 : 30.799744, loss2 : 21.636774
train_step : 42, loss1 : 44.624485, loss2 : 27.942137
train_step : 43, loss1 : 45.063290, loss2 : 20.917234
train_step : 44, loss1 : 33.699112, loss2 : 36.687500
train_step : 45, loss1 : 24.493181, loss2 : 14.774992
train_step : 46, loss1 : 19.720833, loss2 : 27.370110
train_step : 47, loss1 : 38.428665, loss2 : 21.927404
train_step : 48, loss1 : 11.360427, loss2 : 28.328205
train_step : 49, loss1 : 14.530201, loss2 : 10.629089
train_step : 50, loss1 : 10.672122, loss2 : 31.863895
train_step : 51, loss1 : 15.963854, loss2 : 11.959261
train_step : 52, loss1 : 12.581160, loss2 : 11.081319
train_step : 53, loss1 : 21.413166, loss2 : 21.170452
train_step : 54, loss1 : 11.924021, loss2 : 24.973068
train_step : 55, loss1 : 27.508423, loss2 : 24.482407
train_step : 56, loss1 : 16.311672, loss2 : 15.019455
train_step : 57, loss1 : 28.426048, loss2 : 12.688612
train_step : 58, loss1 : 15.022730, loss2 : 12.806206
train_step : 59, loss1 : 20.785284, loss2 : 16.757196
train_step : 60, loss1 : 10.781256, loss2 : 19.022030
train_step : 61, loss1 : 21.637489, loss2 : 6.430663
train_step : 62, loss1 : 16.624001, loss2 : 22.636217
train_step : 63, loss1 : 20.468540, loss2 : 13.471277
train_step : 64, loss1 : 25.985128, loss2 : 22.571941
train_step : 65, loss1 : 17.866028, loss2 : 17.153095
train_step : 66, loss1 : 23.205864, loss2 : 14.466388
train_step : 67, loss1 : 29.814211, loss2 : 15.297325
train_step : 68, loss1 : 19.904861, loss2 : 20.700296
train_step : 69, loss1 : 22.108448, loss2 : 12.494347
train_step : 70, loss1 : 10.784256, loss2 : 13.971555
train_step : 71, loss1 : 16.285021, loss2 : 19.668264
train_step : 72, loss1 : 21.779829, loss2 : 20.211786
train_step : 73, loss1 : 20.899487, loss2 : 9.903172
train_step : 74, loss1 : 15.460408, loss2 : 11.300850
train_step : 75, loss1 : 21.691078, loss2 : 17.388954
train_step : 76, loss1 : 19.741497, loss2 : 16.473843
train_step : 77, loss1 : 31.501659, loss2 : 23.530891
train_step : 78, loss1 : 10.067073, loss2 : 28.717094
train_step : 79, loss1 : 24.201387, loss2 : 12.768475
train_step : 80, loss1 : 20.597155, loss2 : 20.061823
train_step : 81, loss1 : 21.265511, loss2 : 14.617157
train_step : 82, loss1 : 14.282889, loss2 : 15.788322
train_step : 83, loss1 : 22.855162, loss2 : 19.262047
train_step : 84, loss1 : 25.721285, loss2 : 8.897423
train_step : 85, loss1 : 11.790480, loss2 : 29.131172
train_step : 86, loss1 : 21.560167, loss2 : 11.875337
train_step : 87, loss1 : 15.638608, loss2 : 10.620655
train_step : 88, loss1 : 22.204254, loss2 : 12.432655
train_step : 89, loss1 : 14.280373, loss2 : 21.142273
train_step : 90, loss1 : 23.666946, loss2 : 28.062086
train_step : 91, loss1 : 26.638775, loss2 : 24.278656
train_step : 92, loss1 : 12.994720, loss2 : 22.468250
train_step : 93, loss1 : 22.966555, loss2 : 14.967532
train_step : 94, loss1 : 12.014331, loss2 : 19.783602
train_step : 95, loss1 : 15.741554, loss2 : 8.201007
train_step : 96, loss1 : 12.576418, loss2 : 18.089096
train_step : 97, loss1 : 13.865149, loss2 : 14.763746
train_step : 98, loss1 : 18.289677, loss2 : 22.652710
train_step : 99, loss1 : 12.190778, loss2 : 15.726166
train_step : 100, loss1 : 7.272285, loss2 : 16.410957
train_step : 101, loss1 : 20.142620, loss2 : 16.155439
train_step : 102, loss1 : 25.734964, loss2 : 18.315197
train_step : 103, loss1 : 9.159107, loss2 : 13.273075
train_step : 104, loss1 : 10.933828, loss2 : 18.293156
train_step : 105, loss1 : 12.897151, loss2 : 22.334599
train_step : 106, loss1 : 17.060749, loss2 : 18.292461
train_step : 107, loss1 : 19.852512, loss2 : 19.628149
train_step : 108, loss1 : 16.560160, loss2 : 18.110500
train_step : 109, loss1 : 17.599346, loss2 : 14.837020
train_step : 110, loss1 : 19.687288, loss2 : 8.715088
train_step : 111, loss1 : 11.813438, loss2 : 19.706707
train_step : 112, loss1 : 26.392033, loss2 : 26.855309
train_step : 113, loss1 : 14.321676, loss2 : 15.736911
train_step : 114, loss1 : 14.704302, loss2 : 16.773445
train_step : 115, loss1 : 24.915886, loss2 : 21.911217
train_step : 116, loss1 : 17.751539, loss2 : 21.894581
train_step : 117, loss1 : 16.095455, loss2 : 25.208111
train_step : 118, loss1 : 25.683352, loss2 : 12.951869
train_step : 119, loss1 : 22.809862, loss2 : 11.081203
train_step : 120, loss1 : 25.773943, loss2 : 27.617332
train_step : 121, loss1 : 21.215885, loss2 : 24.565895
train_step : 122, loss1 : 16.134836, loss2 : 20.783907
train_step : 123, loss1 : 14.897770, loss2 : 34.023968
train_step : 124, loss1 : 12.400789, loss2 : 14.434181
train_step : 125, loss1 : 9.009613, loss2 : 10.396435
train_step : 126, loss1 : 12.561744, loss2 : 7.899375
train_step : 127, loss1 : 21.699282, loss2 : 13.482689
train_step : 128, loss1 : 22.086105, loss2 : 15.138430
train_step : 129, loss1 : 19.946754, loss2 : 20.162653
train_step : 130, loss1 : 21.963818, loss2 : 11.028852
train_step : 131, loss1 : 26.770895, loss2 : 17.897619
train_step : 132, loss1 : 12.543888, loss2 : 11.634651
train_step : 133, loss1 : 19.914108, loss2 : 13.527517
train_step : 134, loss1 : 16.465368, loss2 : 20.480133
train_step : 135, loss1 : 10.927442, loss2 : 16.960871
train_step : 136, loss1 : 21.677231, loss2 : 14.113979
train_step : 137, loss1 : 15.450390, loss2 : 20.711327
train_step : 138, loss1 : 26.814152, loss2 : 19.804209
train_step : 139, loss1 : 13.155662, loss2 : 14.915787
train_step : 140, loss1 : 14.506096, loss2 : 14.530876
train_step : 141, loss1 : 12.709149, loss2 : 16.691570
train_step : 142, loss1 : 13.601507, loss2 : 18.932602
train_step : 143, loss1 : 11.967948, loss2 : 29.259418
train_step : 144, loss1 : 19.489922, loss2 : 22.406658
train_step : 145, loss1 : 29.104033, loss2 : 16.458546
train_step : 146, loss1 : 10.646957, loss2 : 16.831657
train_step : 147, loss1 : 20.235285, loss2 : 15.726449
train_step : 148, loss1 : 19.868038, loss2 : 15.069468
train_step : 149, loss1 : 13.888107, loss2 : 17.248604
train_step : 150, loss1 : 26.896614, loss2 : 14.470456
train_step : 151, loss1 : 14.542187, loss2 : 19.833145
train_step : 152, loss1 : 15.416933, loss2 : 26.498787
train_step : 153, loss1 : 13.089406, loss2 : 8.744261
train_step : 154, loss1 : 26.656120, loss2 : 28.090826
train_step : 155, loss1 : 15.040122, loss2 : 17.598785
train_step : 156, loss1 : 15.428527, loss2 : 15.805302
train_step : 157, loss1 : 8.947552, loss2 : 14.371836
train_step : 158, loss1 : 22.408833, loss2 : 19.450670
train_step : 159, loss1 : 15.808688, loss2 : 16.871044
train_step : 160, loss1 : 15.460543, loss2 : 15.192533
train_step : 161, loss1 : 12.449347, loss2 : 27.066219
train_step : 162, loss1 : 19.494129, loss2 : 16.055275
train_step : 163, loss1 : 14.759417, loss2 : 16.321007
train_step : 164, loss1 : 13.430708, loss2 : 8.258511
train_step : 165, loss1 : 16.349754, loss2 : 22.352747
train_step : 166, loss1 : 14.012543, loss2 : 31.108307
train_step : 167, loss1 : 12.876204, loss2 : 20.022516
train_step : 168, loss1 : 11.334036, loss2 : 18.494335
train_step : 169, loss1 : 22.032696, loss2 : 27.365629
train_step : 170, loss1 : 8.084129, loss2 : 13.970318
train_step : 171, loss1 : 16.848286, loss2 : 12.649626
train_step : 172, loss1 : 23.882257, loss2 : 19.784708
train_step : 173, loss1 : 32.723606, loss2 : 15.762201
train_step : 174, loss1 : 18.520317, loss2 : 15.941660
train_step : 175, loss1 : 9.045912, loss2 : 12.322491
train_step : 176, loss1 : 11.081330, loss2 : 19.584419
train_step : 177, loss1 : 16.733131, loss2 : 16.093208
train_step : 178, loss1 : 17.167511, loss2 : 16.580189
train_step : 179, loss1 : 20.000050, loss2 : 17.462719
train_step : 180, loss1 : 25.721481, loss2 : 16.870667
train_step : 181, loss1 : 11.784725, loss2 : 11.490792
train_step : 182, loss1 : 14.259497, loss2 : 23.778944
train_step : 183, loss1 : 7.402715, loss2 : 30.164768
train_step : 184, loss1 : 18.630854, loss2 : 12.109631
train_step : 185, loss1 : 17.052298, loss2 : 14.132014
train_step : 186, loss1 : 7.661652, loss2 : 25.408102
train_step : 187, loss1 : 18.403847, loss2 : 8.870871
train_step : 188, loss1 : 13.582465, loss2 : 18.581556
train_step : 189, loss1 : 14.646944, loss2 : 16.750290
train_step : 190, loss1 : 22.665176, loss2 : 8.686953
train_step : 191, loss1 : 12.500807, loss2 : 11.946995
train_step : 192, loss1 : 14.242821, loss2 : 12.992719
train_step : 193, loss1 : 11.940012, loss2 : 9.466825
train_step : 194, loss1 : 20.269577, loss2 : 27.205242
train_step : 195, loss1 : 19.480612, loss2 : 13.104017
train_step : 196, loss1 : 6.217682, loss2 : 17.471928
train_step : 197, loss1 : 21.049637, loss2 : 9.105123
train_step : 198, loss1 : 17.833267, loss2 : 15.653787
train_step : 199, loss1 : 22.308985, loss2 : 17.090797
train_step : 200, loss1 : 11.591921, loss2 : 21.741699
train_step : 201, loss1 : 25.552280, loss2 : 13.769757
train_step : 202, loss1 : 29.092514, loss2 : 15.358605
train_step : 203, loss1 : 16.992573, loss2 : 14.231503
train_step : 204, loss1 : 17.584223, loss2 : 16.450611
train_step : 205, loss1 : 13.664534, loss2 : 18.279732
train_step : 206, loss1 : 21.897541, loss2 : 19.850628
train_step : 207, loss1 : 16.635693, loss2 : 17.159439
train_step : 208, loss1 : 21.036354, loss2 : 7.947959
train_step : 209, loss1 : 16.029324, loss2 : 15.252524
train_step : 210, loss1 : 18.273018, loss2 : 12.298382
train_step : 211, loss1 : 18.546101, loss2 : 30.310762
train_step : 212, loss1 : 16.022627, loss2 : 12.942298
train_step : 213, loss1 : 14.703684, loss2 : 9.183249
train_step : 214, loss1 : 13.587090, loss2 : 20.321644
train_step : 215, loss1 : 12.064933, loss2 : 17.258385
train_step : 216, loss1 : 15.022585, loss2 : 17.577145
train_step : 217, loss1 : 10.290737, loss2 : 17.367352
train_step : 218, loss1 : 18.619930, loss2 : 18.846832
train_step : 219, loss1 : 15.544096, loss2 : 13.522768
train_step : 220, loss1 : 19.317120, loss2 : 16.065659
train_step : 221, loss1 : 16.505152, loss2 : 14.115231
train_step : 222, loss1 : 14.260637, loss2 : 19.200336
train_step : 223, loss1 : 15.728079, loss2 : 23.847034
train_step : 224, loss1 : 16.343647, loss2 : 9.654369
train_step : 225, loss1 : 16.913313, loss2 : 21.813393
train_step : 226, loss1 : 22.826578, loss2 : 20.558914
train_step : 227, loss1 : 19.433304, loss2 : 12.809889
train_step : 228, loss1 : 9.712083, loss2 : 18.506046
train_step : 229, loss1 : 21.203892, loss2 : 12.202299
train_step : 230, loss1 : 26.970337, loss2 : 18.847919
train_step : 231, loss1 : 8.431870, loss2 : 23.848309
train_step : 232, loss1 : 24.770775, loss2 : 13.119841
train_step : 233, loss1 : 15.280784, loss2 : 16.390947
train_step : 234, loss1 : 10.549078, loss2 : 14.650484
train_step : 235, loss1 : 13.850166, loss2 : 13.898479
train_step : 236, loss1 : 13.342733, loss2 : 21.750818
train_step : 237, loss1 : 17.644297, loss2 : 28.742935
train_step : 238, loss1 : 27.563282, loss2 : 13.905348
train_step : 239, loss1 : 19.781738, loss2 : 19.780174
train_step : 240, loss1 : 26.857056, loss2 : 14.414234
train_step : 241, loss1 : 17.531155, loss2 : 18.891918
train_step : 242, loss1 : 24.282749, loss2 : 18.822899
train_step : 243, loss1 : 20.590275, loss2 : 13.812132
train_step : 244, loss1 : 16.892567, loss2 : 18.617100
train_step : 245, loss1 : 17.720852, loss2 : 19.913403
train_step : 246, loss1 : 22.622801, loss2 : 9.856014
train_step : 247, loss1 : 27.675154, loss2 : 9.476027
train_step : 248, loss1 : 12.121996, loss2 : 20.549122
train_step : 249, loss1 : 15.215530, loss2 : 15.137457
train_step : 250, loss1 : 11.011232, loss2 : 10.260242
train_step : 251, loss1 : 13.109624, loss2 : 11.812966
train_step : 252, loss1 : 14.355755, loss2 : 14.449123
train_step : 253, loss1 : 12.948093, loss2 : 20.588388
train_step : 254, loss1 : 20.025450, loss2 : 10.236178
train_step : 255, loss1 : 22.855442, loss2 : 15.366173
train_step : 256, loss1 : 24.823721, loss2 : 20.939415
train_step : 257, loss1 : 13.460192, loss2 : 26.906139
train_step : 258, loss1 : 18.641304, loss2 : 17.961433
train_step : 259, loss1 : 12.577227, loss2 : 12.943982
train_step : 260, loss1 : 14.690810, loss2 : 25.383862
train_step : 261, loss1 : 10.666001, loss2 : 23.939405
train_step : 262, loss1 : 20.028698, loss2 : 18.128975
train_step : 263, loss1 : 22.129833, loss2 : 11.113342
train_step : 264, loss1 : 16.521561, loss2 : 17.881775
train_step : 265, loss1 : 22.814583, loss2 : 13.455152
train_step : 266, loss1 : 22.323900, loss2 : 17.986656
train_step : 267, loss1 : 18.907549, loss2 : 13.099334
train_step : 268, loss1 : 12.446278, loss2 : 20.559738
train_step : 269, loss1 : 19.376556, loss2 : 14.886643
train_step : 270, loss1 : 10.096828, loss2 : 12.908474
train_step : 271, loss1 : 29.178104, loss2 : 14.433400
train_step : 272, loss1 : 12.454718, loss2 : 25.433048
train_step : 273, loss1 : 15.057283, loss2 : 24.309324
train_step : 274, loss1 : 11.540316, loss2 : 13.956345
train_step : 275, loss1 : 17.352043, loss2 : 17.363377
train_step : 276, loss1 : 17.700851, loss2 : 19.763731
train_step : 277, loss1 : 19.036053, loss2 : 17.529278
train_step : 278, loss1 : 18.653677, loss2 : 15.636934
train_step : 279, loss1 : 24.786877, loss2 : 18.746618
train_step : 280, loss1 : 18.358995, loss2 : 34.749207
train_step : 281, loss1 : 11.091424, loss2 : 11.444711
train_step : 282, loss1 : 26.181990, loss2 : 18.374092
train_step : 283, loss1 : 16.975706, loss2 : 16.883869
train_step : 284, loss1 : 19.005096, loss2 : 10.894248
train_step : 285, loss1 : 15.164627, loss2 : 18.777615
train_step : 286, loss1 : 14.296791, loss2 : 10.778711
train_step : 287, loss1 : 22.600147, loss2 : 17.540237
train_step : 288, loss1 : 14.135147, loss2 : 18.134972
train_step : 289, loss1 : 18.350897, loss2 : 21.784113
train_step : 290, loss1 : 14.763054, loss2 : 18.400536
train_step : 291, loss1 : 18.022896, loss2 : 15.621016
train_step : 292, loss1 : 21.904755, loss2 : 11.648277
train_step : 293, loss1 : 14.884424, loss2 : 20.598804
train_step : 294, loss1 : 17.987951, loss2 : 25.338074
train_step : 295, loss1 : 13.418009, loss2 : 21.253208
train_step : 296, loss1 : 21.282589, loss2 : 17.416183
train_step : 297, loss1 : 19.232746, loss2 : 19.039827
train_step : 298, loss1 : 18.425877, loss2 : 12.446089
train_step : 299, loss1 : 17.046766, loss2 : 17.100100
train_step : 300, loss1 : 15.579064, loss2 : 21.845867
train_step : 301, loss1 : 21.581280, loss2 : 12.733320
train_step : 302, loss1 : 18.073164, loss2 : 9.743350
train_step : 303, loss1 : 12.028431, loss2 : 12.412031
train_step : 304, loss1 : 31.729813, loss2 : 16.001968
train_step : 305, loss1 : 13.705282, loss2 : 23.164909
train_step : 306, loss1 : 16.578535, loss2 : 13.209916
train_step : 307, loss1 : 14.805516, loss2 : 21.124800
train_step : 308, loss1 : 19.031706, loss2 : 18.482908
train_step : 309, loss1 : 15.616943, loss2 : 33.445992
train_step : 310, loss1 : 16.110657, loss2 : 14.107212
train_step : 311, loss1 : 14.858829, loss2 : 22.776955
train_step : 312, loss1 : 23.587551, loss2 : 10.584359
train_step : 313, loss1 : 7.593455, loss2 : 17.666813
train_step : 314, loss1 : 16.580400, loss2 : 26.779869
train_step : 315, loss1 : 16.552814, loss2 : 21.554785
train_step : 316, loss1 : 26.684248, loss2 : 10.879576
train_step : 317, loss1 : 12.565281, loss2 : 25.098974
train_step : 318, loss1 : 27.940453, loss2 : 18.199997
train_step : 319, loss1 : 13.270978, loss2 : 9.260894
train_step : 320, loss1 : 31.119591, loss2 : 27.671646
train_step : 321, loss1 : 10.676825, loss2 : 26.978287
train_step : 322, loss1 : 21.140137, loss2 : 19.319118
train_step : 323, loss1 : 18.883926, loss2 : 24.834614
train_step : 324, loss1 : 8.993393, loss2 : 21.788311
train_step : 325, loss1 : 20.207863, loss2 : 15.422911
train_step : 326, loss1 : 21.085402, loss2 : 9.618849
train_step : 327, loss1 : 17.900476, loss2 : 12.773125
train_step : 328, loss1 : 10.960406, loss2 : 18.859358
train_step : 329, loss1 : 15.543500, loss2 : 15.262637
train_step : 330, loss1 : 12.821291, loss2 : 19.049763
train_step : 331, loss1 : 15.674465, loss2 : 22.982491
train_step : 332, loss1 : 17.196518, loss2 : 18.690956
train_step : 333, loss1 : 15.352711, loss2 : 18.314692
train_step : 334, loss1 : 22.137028, loss2 : 14.465348
train_step : 335, loss1 : 27.431669, loss2 : 18.348076
train_step : 336, loss1 : 22.438862, loss2 : 13.396402
train_step : 337, loss1 : 8.117470, loss2 : 18.700855
train_step : 338, loss1 : 14.224257, loss2 : 13.285084
train_step : 339, loss1 : 14.663075, loss2 : 33.309242
train_step : 340, loss1 : 11.383286, loss2 : 15.639849
train_step : 341, loss1 : 19.442650, loss2 : 14.804068
train_step : 342, loss1 : 17.702972, loss2 : 25.919273
train_step : 343, loss1 : 18.523144, loss2 : 20.870275
train_step : 344, loss1 : 14.215763, loss2 : 11.813542
train_step : 345, loss1 : 11.531263, loss2 : 12.880339
train_step : 346, loss1 : 18.987431, loss2 : 10.773679
train_step : 347, loss1 : 20.641983, loss2 : 17.403408
train_step : 348, loss1 : 13.348746, loss2 : 30.595016
train_step : 349, loss1 : 27.737869, loss2 : 9.286633
train_step : 350, loss1 : 12.015976, loss2 : 19.719093
train_step : 351, loss1 : 15.807098, loss2 : 24.610622
train_step : 352, loss1 : 12.876874, loss2 : 12.311052
train_step : 353, loss1 : 18.036156, loss2 : 21.500443
train_step : 354, loss1 : 12.620845, loss2 : 17.604038
train_step : 355, loss1 : 10.629398, loss2 : 18.462608
train_step : 356, loss1 : 12.488228, loss2 : 22.908466
train_step : 357, loss1 : 18.141293, loss2 : 18.800415
train_step : 358, loss1 : 21.930908, loss2 : 23.371754
train_step : 359, loss1 : 19.527351, loss2 : 16.340933
train_step : 360, loss1 : 23.103477, loss2 : 21.109892
train_step : 361, loss1 : 23.054710, loss2 : 23.150143
train_step : 362, loss1 : 19.283409, loss2 : 23.997684
train_step : 363, loss1 : 21.321970, loss2 : 23.094862
train_step : 364, loss1 : 18.344553, loss2 : 15.371071
train_step : 365, loss1 : 25.443810, loss2 : 26.897091
train_step : 366, loss1 : 17.654108, loss2 : 9.417934
train_step : 367, loss1 : 14.774243, loss2 : 16.497343
train_step : 368, loss1 : 16.188345, loss2 : 10.793679
train_step : 369, loss1 : 15.944989, loss2 : 10.642855
train_step : 370, loss1 : 19.675741, loss2 : 22.816666
train_step : 371, loss1 : 16.417976, loss2 : 22.591291
train_step : 372, loss1 : 12.479853, loss2 : 20.523697
train_step : 373, loss1 : 14.130931, loss2 : 24.339653
train_step : 374, loss1 : 17.064003, loss2 : 8.472384
train_step : 375, loss1 : 8.900752, loss2 : 23.081783
train_step : 376, loss1 : 15.245133, loss2 : 14.952248
train_step : 377, loss1 : 22.958597, loss2 : 15.713877
train_step : 378, loss1 : 13.744841, loss2 : 13.543935
train_step : 379, loss1 : 10.525631, loss2 : 26.393551
train_step : 380, loss1 : 7.908779, loss2 : 13.888365
train_step : 381, loss1 : 17.493011, loss2 : 18.263269
train_step : 382, loss1 : 11.704842, loss2 : 27.892080
train_step : 383, loss1 : 21.476168, loss2 : 21.253073
train_step : 384, loss1 : 14.985408, loss2 : 17.750168
train_step : 385, loss1 : 16.448326, loss2 : 27.408960
train_step : 386, loss1 : 13.548717, loss2 : 27.782316
train_step : 387, loss1 : 17.922697, loss2 : 14.839450
train_step : 388, loss1 : 22.563519, loss2 : 19.796129
train_step : 389, loss1 : 15.253477, loss2 : 12.128254
train_step : 390, loss1 : 22.048321, loss2 : 17.954679
train_step : 391, loss1 : 23.646049, loss2 : 14.737827
train_step : 392, loss1 : 17.132547, loss2 : 12.921907
train_step : 393, loss1 : 28.884329, loss2 : 19.278099
train_step : 394, loss1 : 22.070101, loss2 : 15.011460
train_step : 395, loss1 : 26.966606, loss2 : 21.691046
train_step : 396, loss1 : 15.554018, loss2 : 17.685577
train_step : 397, loss1 : 19.255451, loss2 : 13.649432
train_step : 398, loss1 : 16.171597, loss2 : 12.530729
train_step : 399, loss1 : 12.823991, loss2 : 11.960629
train_step : 400, loss1 : 16.753195, loss2 : 23.584524
train_step : 401, loss1 : 13.943206, loss2 : 25.128349
train_step : 402, loss1 : 31.440578, loss2 : 22.876247
train_step : 403, loss1 : 21.825207, loss2 : 9.657337
train_step : 404, loss1 : 23.375786, loss2 : 24.445633
train_step : 405, loss1 : 15.391024, loss2 : 16.631611
train_step : 406, loss1 : 19.133335, loss2 : 17.818604
train_step : 407, loss1 : 25.920391, loss2 : 23.502579
train_step : 408, loss1 : 21.785416, loss2 : 11.751434
train_step : 409, loss1 : 24.965967, loss2 : 36.671192
train_step : 410, loss1 : 10.776155, loss2 : 11.976389
train_step : 411, loss1 : 18.739365, loss2 : 16.013569
train_step : 412, loss1 : 16.514597, loss2 : 30.420160
train_step : 413, loss1 : 13.015695, loss2 : 13.771696
train_step : 414, loss1 : 13.245737, loss2 : 17.152287
train_step : 415, loss1 : 21.617985, loss2 : 22.328255
train_step : 416, loss1 : 11.972120, loss2 : 12.534490
train_step : 417, loss1 : 13.328270, loss2 : 27.656132
train_step : 418, loss1 : 12.835546, loss2 : 13.226732
train_step : 419, loss1 : 13.967256, loss2 : 16.155506
train_step : 420, loss1 : 12.331669, loss2 : 30.516838
train_step : 421, loss1 : 18.831310, loss2 : 10.372127
train_step : 422, loss1 : 20.102180, loss2 : 17.311531
train_step : 423, loss1 : 16.770447, loss2 : 12.910199
train_step : 424, loss1 : 31.340366, loss2 : 13.133228
train_step : 425, loss1 : 18.583969, loss2 : 16.007317
train_step : 426, loss1 : 15.973920, loss2 : 18.874739
train_step : 427, loss1 : 18.948051, loss2 : 18.321583
train_step : 428, loss1 : 18.263674, loss2 : 26.732679
train_step : 429, loss1 : 14.752045, loss2 : 20.869194
train_step : 430, loss1 : 18.824909, loss2 : 10.798988
train_step : 431, loss1 : 19.085060, loss2 : 8.801430
train_step : 432, loss1 : 13.771615, loss2 : 12.023420
train_step : 433, loss1 : 12.001989, loss2 : 22.073570
train_step : 434, loss1 : 12.865406, loss2 : 35.141502
train_step : 435, loss1 : 16.771925, loss2 : 17.201624
train_step : 436, loss1 : 12.083254, loss2 : 11.361790
train_step : 437, loss1 : 13.577961, loss2 : 22.466948
train_step : 438, loss1 : 15.108134, loss2 : 13.478864
train_step : 439, loss1 : 21.796982, loss2 : 12.423387
train_step : 440, loss1 : 16.292419, loss2 : 26.448055
train_step : 441, loss1 : 20.671741, loss2 : 22.989605
train_step : 442, loss1 : 17.289696, loss2 : 25.364050
train_step : 443, loss1 : 24.390114, loss2 : 17.967396
train_step : 444, loss1 : 23.578859, loss2 : 14.142020
train_step : 445, loss1 : 16.048195, loss2 : 17.912849
train_step : 446, loss1 : 13.068110, loss2 : 19.753120
train_step : 447, loss1 : 12.918302, loss2 : 25.752308
train_step : 448, loss1 : 18.224247, loss2 : 14.563557
train_step : 449, loss1 : 13.280523, loss2 : 31.171368
train_step : 450, loss1 : 11.100796, loss2 : 10.910854
train_step : 451, loss1 : 19.022770, loss2 : 9.285521
train_step : 452, loss1 : 13.374393, loss2 : 7.789244
train_step : 453, loss1 : 13.583817, loss2 : 16.340481
train_step : 454, loss1 : 17.821125, loss2 : 19.398569
train_step : 455, loss1 : 17.618952, loss2 : 24.143887
train_step : 456, loss1 : 14.625070, loss2 : 20.687572
train_step : 457, loss1 : 18.564104, loss2 : 26.521374
train_step : 458, loss1 : 15.028325, loss2 : 24.079033
train_step : 459, loss1 : 16.766531, loss2 : 22.102528
train_step : 460, loss1 : 18.702755, loss2 : 31.375086
train_step : 461, loss1 : 9.988557, loss2 : 19.574144
train_step : 462, loss1 : 22.274696, loss2 : 6.960760
train_step : 463, loss1 : 17.301420, loss2 : 15.379610
train_step : 464, loss1 : 19.215729, loss2 : 18.705376
train_step : 465, loss1 : 19.124369, loss2 : 16.605743
train_step : 466, loss1 : 18.758575, loss2 : 19.891216
train_step : 467, loss1 : 15.366106, loss2 : 13.671629
train_step : 468, loss1 : 14.019638, loss2 : 21.624695
train_step : 469, loss1 : 10.422854, loss2 : 13.767611
train_step : 470, loss1 : 7.889177, loss2 : 31.133011
train_step : 471, loss1 : 27.925236, loss2 : 21.417604
train_step : 472, loss1 : 14.761429, loss2 : 11.041177
train_step : 473, loss1 : 19.941969, loss2 : 18.908634
train_step : 474, loss1 : 16.236603, loss2 : 19.735727
train_step : 475, loss1 : 13.373295, loss2 : 14.589565
train_step : 476, loss1 : 20.553774, loss2 : 18.508484
train_step : 477, loss1 : 16.652325, loss2 : 15.691576
train_step : 478, loss1 : 20.221539, loss2 : 11.853426
train_step : 479, loss1 : 16.443020, loss2 : 15.147911
train_step : 480, loss1 : 9.983084, loss2 : 18.070818
train_step : 481, loss1 : 16.396057, loss2 : 14.649190
train_step : 482, loss1 : 11.643686, loss2 : 20.627705
train_step : 483, loss1 : 16.169508, loss2 : 21.178787
train_step : 484, loss1 : 13.304354, loss2 : 22.200813
train_step : 485, loss1 : 19.465399, loss2 : 18.761515
train_step : 486, loss1 : 9.954224, loss2 : 16.340094
train_step : 487, loss1 : 17.101252, loss2 : 7.756894
train_step : 488, loss1 : 10.696325, loss2 : 28.388248
train_step : 489, loss1 : 27.507832, loss2 : 17.025608
train_step : 490, loss1 : 15.225515, loss2 : 21.881191
train_step : 491, loss1 : 8.733006, loss2 : 27.491585
train_step : 492, loss1 : 15.554303, loss2 : 12.128282
train_step : 493, loss1 : 19.730236, loss2 : 12.147636
train_step : 494, loss1 : 11.595933, loss2 : 17.901304
train_step : 495, loss1 : 8.027026, loss2 : 19.956867
train_step : 496, loss1 : 21.593109, loss2 : 15.971469
train_step : 497, loss1 : 16.593748, loss2 : 19.692295
train_step : 498, loss1 : 20.781620, loss2 : 18.926620
train_step : 499, loss1 : 16.077120, loss2 : 27.921171
train_step : 500, loss1 : 12.316342, loss2 : 18.382973
train_step : 501, loss1 : 26.352684, loss2 : 17.070820
train_step : 502, loss1 : 17.606134, loss2 : 21.565556
train_step : 503, loss1 : 22.813564, loss2 : 22.012480
train_step : 504, loss1 : 15.396106, loss2 : 11.516396
train_step : 505, loss1 : 10.502596, loss2 : 17.811211
train_step : 506, loss1 : 16.766930, loss2 : 16.394222
train_step : 507, loss1 : 17.892689, loss2 : 15.408778
train_step : 508, loss1 : 35.278141, loss2 : 24.754349
train_step : 509, loss1 : 15.916043, loss2 : 16.892361
train_step : 510, loss1 : 16.913269, loss2 : 17.005531
train_step : 511, loss1 : 25.064459, loss2 : 19.172535
train_step : 512, loss1 : 16.781948, loss2 : 10.834556
train_step : 513, loss1 : 13.560035, loss2 : 17.173210
train_step : 514, loss1 : 23.729258, loss2 : 16.331898
train_step : 515, loss1 : 18.992376, loss2 : 16.859566
train_step : 516, loss1 : 15.443398, loss2 : 18.807327
train_step : 517, loss1 : 16.492180, loss2 : 17.117834
train_step : 518, loss1 : 27.294952, loss2 : 18.159466
train_step : 519, loss1 : 20.399010, loss2 : 29.793705
train_step : 520, loss1 : 14.725952, loss2 : 18.978035
train_step : 521, loss1 : 20.852217, loss2 : 25.508270
train_step : 522, loss1 : 11.942608, loss2 : 19.737755
train_step : 523, loss1 : 8.499363, loss2 : 17.802691
train_step : 524, loss1 : 21.679405, loss2 : 19.933758
train_step : 525, loss1 : 14.461626, loss2 : 23.404385
train_step : 526, loss1 : 21.420624, loss2 : 14.487061
train_step : 527, loss1 : 18.496883, loss2 : 17.787853
train_step : 528, loss1 : 33.143646, loss2 : 24.911337
train_step : 529, loss1 : 16.738756, loss2 : 11.462667
train_step : 530, loss1 : 15.831274, loss2 : 19.777758
train_step : 531, loss1 : 15.467670, loss2 : 16.458588
train_step : 532, loss1 : 23.438274, loss2 : 24.325712
train_step : 533, loss1 : 12.559488, loss2 : 14.584110
train_step : 534, loss1 : 26.994350, loss2 : 21.327442
train_step : 535, loss1 : 23.648857, loss2 : 17.000523
train_step : 536, loss1 : 24.774879, loss2 : 13.590334
train_step : 537, loss1 : 19.729515, loss2 : 19.336515
train_step : 538, loss1 : 11.787748, loss2 : 21.437990
train_step : 539, loss1 : 10.375987, loss2 : 19.312574
train_step : 540, loss1 : 18.447796, loss2 : 15.243347
train_step : 541, loss1 : 24.140316, loss2 : 26.357521
train_step : 542, loss1 : 36.199471, loss2 : 20.805569
train_step : 543, loss1 : 19.099483, loss2 : 11.090649
train_step : 544, loss1 : 18.225517, loss2 : 14.292566
train_step : 545, loss1 : 13.141492, loss2 : 18.511536
train_step : 546, loss1 : 18.858347, loss2 : 13.748098
train_step : 547, loss1 : 19.472706, loss2 : 9.642672
train_step : 548, loss1 : 16.025864, loss2 : 10.877863
train_step : 549, loss1 : 15.734452, loss2 : 18.209080
train_step : 550, loss1 : 30.047432, loss2 : 11.689143
train_step : 551, loss1 : 13.077786, loss2 : 20.398067
train_step : 552, loss1 : 21.906397, loss2 : 22.578428
train_step : 553, loss1 : 12.838547, loss2 : 30.080072
train_step : 554, loss1 : 30.914032, loss2 : 13.550744
train_step : 555, loss1 : 14.257262, loss2 : 14.315328
train_step : 556, loss1 : 20.944101, loss2 : 22.633322
train_step : 557, loss1 : 12.587408, loss2 : 9.309390
train_step : 558, loss1 : 17.430588, loss2 : 32.485199
train_step : 559, loss1 : 15.404513, loss2 : 23.641167
train_step : 560, loss1 : 19.978691, loss2 : 20.235542
train_step : 561, loss1 : 12.251642, loss2 : 26.230923
train_step : 562, loss1 : 20.356995, loss2 : 22.312462
train_step : 563, loss1 : 15.534415, loss2 : 19.908911
train_step : 564, loss1 : 25.304232, loss2 : 22.273172
train_step : 565, loss1 : 16.179619, loss2 : 9.430584
train_step : 566, loss1 : 23.510372, loss2 : 14.175394
train_step : 567, loss1 : 17.999294, loss2 : 9.389793
train_step : 568, loss1 : 15.549145, loss2 : 17.520426
train_step : 569, loss1 : 17.121037, loss2 : 11.816279
train_step : 570, loss1 : 16.183430, loss2 : 14.280518
train_step : 571, loss1 : 16.958296, loss2 : 23.585587
train_step : 572, loss1 : 10.468475, loss2 : 13.021118
train_step : 573, loss1 : 22.751335, loss2 : 15.639364
train_step : 574, loss1 : 15.765173, loss2 : 10.384398
train_step : 575, loss1 : 22.534462, loss2 : 15.822105
train_step : 576, loss1 : 10.020621, loss2 : 21.168503
train_step : 577, loss1 : 11.722225, loss2 : 14.831757
train_step : 578, loss1 : 21.973520, loss2 : 14.593029
train_step : 579, loss1 : 12.946741, loss2 : 30.630413
train_step : 580, loss1 : 12.843308, loss2 : 10.640478
train_step : 581, loss1 : 18.608833, loss2 : 19.955570
train_step : 582, loss1 : 14.012818, loss2 : 12.148695
train_step : 583, loss1 : 22.962852, loss2 : 13.788989
train_step : 584, loss1 : 29.802683, loss2 : 21.515770
train_step : 585, loss1 : 17.658951, loss2 : 14.539739
train_step : 586, loss1 : 23.795725, loss2 : 13.737881
train_step : 587, loss1 : 15.555934, loss2 : 11.747402
train_step : 588, loss1 : 20.639679, loss2 : 10.552970
train_step : 589, loss1 : 21.793716, loss2 : 31.829472
train_step : 590, loss1 : 9.189236, loss2 : 15.163642
train_step : 591, loss1 : 17.844433, loss2 : 13.821486
train_step : 592, loss1 : 15.761316, loss2 : 22.124723
train_step : 593, loss1 : 21.561247, loss2 : 16.432341
train_step : 594, loss1 : 10.392237, loss2 : 16.103333
train_step : 595, loss1 : 17.086493, loss2 : 19.682972
train_step : 596, loss1 : 19.254566, loss2 : 18.244459
train_step : 597, loss1 : 14.961815, loss2 : 12.671568
train_step : 598, loss1 : 20.241716, loss2 : 17.266783
train_step : 599, loss1 : 13.669994, loss2 : 19.546652
train_step : 600, loss1 : 13.325371, loss2 : 14.272415
train_step : 601, loss1 : 13.598169, loss2 : 12.025681
train_step : 602, loss1 : 15.660993, loss2 : 18.914917
train_step : 603, loss1 : 9.513812, loss2 : 24.771242
train_step : 604, loss1 : 15.800125, loss2 : 19.046589
train_step : 605, loss1 : 11.758530, loss2 : 17.889074
train_step : 606, loss1 : 31.458229, loss2 : 18.010555
train_step : 607, loss1 : 19.013767, loss2 : 24.321262
train_step : 608, loss1 : 15.977777, loss2 : 6.901275
train_step : 609, loss1 : 22.498613, loss2 : 16.012714
train_step : 610, loss1 : 15.156885, loss2 : 19.223181
train_step : 611, loss1 : 18.286713, loss2 : 27.345419
train_step : 612, loss1 : 20.845785, loss2 : 16.856739
train_step : 613, loss1 : 13.115378, loss2 : 17.990623
train_step : 614, loss1 : 12.435856, loss2 : 14.800097
train_step : 615, loss1 : 18.789633, loss2 : 17.767467
train_step : 616, loss1 : 19.672987, loss2 : 18.446026
train_step : 617, loss1 : 12.838932, loss2 : 14.377723
train_step : 618, loss1 : 20.591385, loss2 : 31.791080
train_step : 619, loss1 : 23.157455, loss2 : 25.611004
train_step : 620, loss1 : 11.321514, loss2 : 16.722412
train_step : 621, loss1 : 11.453432, loss2 : 20.017391
train_step : 622, loss1 : 16.729069, loss2 : 15.493695
train_step : 623, loss1 : 17.363289, loss2 : 24.903965
train_step : 624, loss1 : 13.055203, loss2 : 23.081203
train_step : 625, loss1 : 22.388416, loss2 : 11.215850
train_step : 626, loss1 : 22.236519, loss2 : 29.494205
train_step : 627, loss1 : 11.001833, loss2 : 19.153355
train_step : 628, loss1 : 19.130495, loss2 : 21.481615
train_step : 629, loss1 : 28.219013, loss2 : 15.651122
train_step : 630, loss1 : 17.299694, loss2 : 13.536551
train_step : 631, loss1 : 9.672531, loss2 : 22.110691
train_step : 632, loss1 : 14.539962, loss2 : 14.924257
train_step : 633, loss1 : 12.488859, loss2 : 18.154716
train_step : 634, loss1 : 19.956005, loss2 : 22.569626
train_step : 635, loss1 : 29.679146, loss2 : 13.524240
train_step : 636, loss1 : 21.628906, loss2 : 26.087387
train_step : 637, loss1 : 11.247561, loss2 : 18.490356
train_step : 638, loss1 : 22.690405, loss2 : 24.906399
train_step : 639, loss1 : 18.335352, loss2 : 9.880762
train_step : 640, loss1 : 20.986025, loss2 : 14.752520
train_step : 641, loss1 : 13.646367, loss2 : 13.237042
train_step : 642, loss1 : 14.264763, loss2 : 16.295717
train_step : 643, loss1 : 16.706743, loss2 : 16.843771
train_step : 644, loss1 : 8.481520, loss2 : 15.360390
train_step : 645, loss1 : 16.047985, loss2 : 10.155018
train_step : 646, loss1 : 8.746387, loss2 : 27.718395
train_step : 647, loss1 : 13.055528, loss2 : 20.470001
train_step : 648, loss1 : 25.140400, loss2 : 22.650879
train_step : 649, loss1 : 6.780580, loss2 : 15.573492
train_step : 650, loss1 : 23.872894, loss2 : 10.017307
train_step : 651, loss1 : 18.218880, loss2 : 22.989277
train_step : 652, loss1 : 25.257471, loss2 : 25.211597
train_step : 653, loss1 : 14.950185, loss2 : 29.497944
train_step : 654, loss1 : 11.445471, loss2 : 20.982027
train_step : 655, loss1 : 24.674706, loss2 : 30.209093
train_step : 656, loss1 : 24.644070, loss2 : 8.964504
train_step : 657, loss1 : 21.611362, loss2 : 19.133232
train_step : 658, loss1 : 22.160774, loss2 : 16.035923
train_step : 659, loss1 : 13.554390, loss2 : 17.021158
train_step : 660, loss1 : 20.605600, loss2 : 27.362926
train_step : 661, loss1 : 25.226021, loss2 : 19.705915
train_step : 662, loss1 : 18.900578, loss2 : 23.840975
train_step : 663, loss1 : 19.380150, loss2 : 12.019005
train_step : 664, loss1 : 12.863378, loss2 : 16.891798
train_step : 665, loss1 : 14.951975, loss2 : 35.534031
train_step : 666, loss1 : 14.741244, loss2 : 28.608307
train_step : 667, loss1 : 13.644863, loss2 : 10.708351
train_step : 668, loss1 : 16.004662, loss2 : 15.607997
train_step : 669, loss1 : 18.275597, loss2 : 19.593063
train_step : 670, loss1 : 15.736582, loss2 : 15.420423
train_step : 671, loss1 : 16.314903, loss2 : 13.415627
train_step : 672, loss1 : 21.469925, loss2 : 10.961486
train_step : 673, loss1 : 24.059900, loss2 : 13.869610
train_step : 674, loss1 : 24.465424, loss2 : 14.250020
train_step : 675, loss1 : 16.335768, loss2 : 20.475733
train_step : 676, loss1 : 17.343021, loss2 : 13.734430
train_step : 677, loss1 : 17.116829, loss2 : 29.928856
train_step : 678, loss1 : 35.085537, loss2 : 14.869356
train_step : 679, loss1 : 20.293980, loss2 : 10.768841
train_step : 680, loss1 : 10.504328, loss2 : 13.833714
train_step : 681, loss1 : 24.903339, loss2 : 17.258831
train_step : 682, loss1 : 12.541759, loss2 : 17.248217
train_step : 683, loss1 : 13.533821, loss2 : 15.533491
train_step : 684, loss1 : 20.603233, loss2 : 22.789034
train_step : 685, loss1 : 18.645882, loss2 : 12.425009
train_step : 686, loss1 : 7.826453, loss2 : 12.553394
train_step : 687, loss1 : 17.627636, loss2 : 14.132557
train_step : 688, loss1 : 15.914045, loss2 : 22.417938
train_step : 689, loss1 : 20.180555, loss2 : 20.639053
train_step : 690, loss1 : 19.879997, loss2 : 12.209949
train_step : 691, loss1 : 10.771214, loss2 : 24.364233
train_step : 692, loss1 : 14.136437, loss2 : 12.107447
train_step : 693, loss1 : 22.560104, loss2 : 13.312914
train_step : 694, loss1 : 25.953827, loss2 : 14.043185
train_step : 695, loss1 : 16.621647, loss2 : 18.615915
train_step : 696, loss1 : 27.948250, loss2 : 26.280487
train_step : 697, loss1 : 13.894577, loss2 : 23.776794
train_step : 698, loss1 : 13.912493, loss2 : 13.410809
train_step : 699, loss1 : 16.396095, loss2 : 16.382271
train_step : 700, loss1 : 28.857058, loss2 : 20.478106
train_step : 701, loss1 : 22.189779, loss2 : 10.705962
train_step : 702, loss1 : 12.293043, loss2 : 14.534341
train_step : 703, loss1 : 11.960016, loss2 : 16.219685
train_step : 704, loss1 : 12.046747, loss2 : 23.694099
train_step : 705, loss1 : 9.659378, loss2 : 17.117172
train_step : 706, loss1 : 13.899159, loss2 : 18.058138
train_step : 707, loss1 : 11.030471, loss2 : 12.274242
train_step : 708, loss1 : 17.615822, loss2 : 17.955362
train_step : 709, loss1 : 25.700539, loss2 : 26.733305
train_step : 710, loss1 : 16.980146, loss2 : 12.945246
train_step : 711, loss1 : 13.611980, loss2 : 24.347599
train_step : 712, loss1 : 24.849247, loss2 : 8.047908
train_step : 713, loss1 : 8.201604, loss2 : 24.213680
train_step : 714, loss1 : 21.703674, loss2 : 19.294807
train_step : 715, loss1 : 12.310809, loss2 : 19.441854
train_step : 716, loss1 : 14.068387, loss2 : 17.204384
train_step : 717, loss1 : 22.363396, loss2 : 23.369200
train_step : 718, loss1 : 21.018349, loss2 : 11.822948
train_step : 719, loss1 : 15.224624, loss2 : 19.967798
train_step : 720, loss1 : 17.592451, loss2 : 18.761314
train_step : 721, loss1 : 15.556398, loss2 : 18.063110
train_step : 722, loss1 : 10.334944, loss2 : 15.844063
train_step : 723, loss1 : 11.740255, loss2 : 32.370842
train_step : 724, loss1 : 12.221643, loss2 : 14.244398
train_step : 725, loss1 : 24.741631, loss2 : 16.532856
train_step : 726, loss1 : 29.443739, loss2 : 27.713213
train_step : 727, loss1 : 28.545317, loss2 : 10.685282
train_step : 728, loss1 : 25.104206, loss2 : 23.448566
train_step : 729, loss1 : 16.838291, loss2 : 27.759113
train_step : 730, loss1 : 31.137310, loss2 : 16.760456
train_step : 731, loss1 : 11.018346, loss2 : 18.666637
train_step : 732, loss1 : 16.528744, loss2 : 16.560345
train_step : 733, loss1 : 27.461353, loss2 : 17.090796
train_step : 734, loss1 : 14.503620, loss2 : 24.674480
train_step : 735, loss1 : 16.400221, loss2 : 22.616947
train_step : 736, loss1 : 15.009268, loss2 : 18.264366
train_step : 737, loss1 : 17.634205, loss2 : 19.588209
train_step : 738, loss1 : 11.744865, loss2 : 24.610149
train_step : 739, loss1 : 20.917755, loss2 : 22.381832
train_step : 740, loss1 : 26.006824, loss2 : 16.154877
train_step : 741, loss1 : 12.557479, loss2 : 27.527315
train_step : 742, loss1 : 9.077687, loss2 : 22.654531
train_step : 743, loss1 : 12.962437, loss2 : 15.943363
train_step : 744, loss1 : 13.658855, loss2 : 11.294605
train_step : 745, loss1 : 19.746376, loss2 : 11.768708
train_step : 746, loss1 : 16.109047, loss2 : 9.580660
train_step : 747, loss1 : 12.989178, loss2 : 25.440849
train_step : 748, loss1 : 22.603100, loss2 : 33.516479
train_step : 749, loss1 : 20.074503, loss2 : 12.851268
train_step : 750, loss1 : 20.285828, loss2 : 14.023408
train_step : 751, loss1 : 24.252338, loss2 : 20.198437
train_step : 752, loss1 : 12.770926, loss2 : 16.160280
train_step : 753, loss1 : 13.504430, loss2 : 17.564949
train_step : 754, loss1 : 23.246557, loss2 : 18.953066
train_step : 755, loss1 : 17.354393, loss2 : 18.246880
train_step : 756, loss1 : 13.997368, loss2 : 36.094795
train_step : 757, loss1 : 18.073881, loss2 : 20.231808
train_step : 758, loss1 : 16.353758, loss2 : 14.157635
train_step : 759, loss1 : 19.087622, loss2 : 25.684162
train_step : 760, loss1 : 8.287725, loss2 : 18.528072
train_step : 761, loss1 : 19.688896, loss2 : 19.824987
train_step : 762, loss1 : 10.857913, loss2 : 18.662605
train_step : 763, loss1 : 24.885887, loss2 : 17.634720
train_step : 764, loss1 : 31.281818, loss2 : 22.652611
train_step : 765, loss1 : 15.531143, loss2 : 19.361496
train_step : 766, loss1 : 23.870277, loss2 : 21.085402
train_step : 767, loss1 : 14.859009, loss2 : 9.331749
train_step : 768, loss1 : 17.148460, loss2 : 12.338457
train_step : 769, loss1 : 21.512218, loss2 : 19.488094
train_step : 770, loss1 : 13.117710, loss2 : 17.878046
train_step : 771, loss1 : 24.847122, loss2 : 14.520647
train_step : 772, loss1 : 25.126253, loss2 : 21.208187
train_step : 773, loss1 : 11.808055, loss2 : 15.700755
train_step : 774, loss1 : 17.471272, loss2 : 34.452377
train_step : 775, loss1 : 14.995792, loss2 : 11.865589
train_step : 776, loss1 : 20.575464, loss2 : 7.628564
train_step : 777, loss1 : 18.656641, loss2 : 25.239647
train_step : 778, loss1 : 14.937414, loss2 : 14.980701
train_step : 779, loss1 : 12.876522, loss2 : 14.536941
train_step : 780, loss1 : 17.219330, loss2 : 15.203821
train_step : 781, loss1 : 11.078628, loss2 : 12.964890
train_step : 782, loss1 : 7.969682, loss2 : 9.973893
train_step : 783, loss1 : 24.753965, loss2 : 14.036925
train_step : 784, loss1 : 8.736872, loss2 : 19.759956
train_step : 785, loss1 : 11.761210, loss2 : 12.726622
train_step : 786, loss1 : 26.504108, loss2 : 21.982685
train_step : 787, loss1 : 18.912941, loss2 : 32.626877
train_step : 788, loss1 : 11.945377, loss2 : 23.215040
train_step : 789, loss1 : 14.137502, loss2 : 16.401649
train_step : 790, loss1 : 19.722946, loss2 : 12.702478
train_step : 791, loss1 : 25.793222, loss2 : 24.341330
train_step : 792, loss1 : 12.573376, loss2 : 12.395273
train_step : 793, loss1 : 13.226325, loss2 : 6.248717
train_step : 794, loss1 : 21.899212, loss2 : 13.604313
train_step : 795, loss1 : 12.262736, loss2 : 10.734987
train_step : 796, loss1 : 36.281071, loss2 : 16.225149
train_step : 797, loss1 : 10.802509, loss2 : 20.489231
train_step : 798, loss1 : 15.749913, loss2 : 8.385846
train_step : 799, loss1 : 20.146959, loss2 : 17.249538
train_step : 800, loss1 : 24.558510, loss2 : 17.059753
train_step : 801, loss1 : 8.670979, loss2 : 22.079273
train_step : 802, loss1 : 16.965395, loss2 : 15.833732
train_step : 803, loss1 : 18.158409, loss2 : 13.863741
train_step : 804, loss1 : 14.853315, loss2 : 18.352291
train_step : 805, loss1 : 12.919300, loss2 : 21.031012
train_step : 806, loss1 : 14.011550, loss2 : 22.808453
train_step : 807, loss1 : 14.227504, loss2 : 20.066589
train_step : 808, loss1 : 12.517867, loss2 : 21.759022
train_step : 809, loss1 : 10.772205, loss2 : 17.153770
train_step : 810, loss1 : 28.675304, loss2 : 19.594616
train_step : 811, loss1 : 20.987787, loss2 : 16.190865
train_step : 812, loss1 : 30.414425, loss2 : 14.667333
train_step : 813, loss1 : 10.920468, loss2 : 20.939396
train_step : 814, loss1 : 13.036674, loss2 : 13.513031
train_step : 815, loss1 : 9.356337, loss2 : 16.711773
train_step : 816, loss1 : 13.824299, loss2 : 13.062634
train_step : 817, loss1 : 7.584854, loss2 : 14.091434
train_step : 818, loss1 : 11.510128, loss2 : 10.354622
train_step : 819, loss1 : 33.982868, loss2 : 14.594730
train_step : 820, loss1 : 16.655624, loss2 : 14.760025
train_step : 821, loss1 : 7.500359, loss2 : 21.791502
train_step : 822, loss1 : 14.108448, loss2 : 14.312132
train_step : 823, loss1 : 13.976337, loss2 : 8.492513
train_step : 824, loss1 : 21.246208, loss2 : 16.667706
train_step : 825, loss1 : 18.418175, loss2 : 14.265598
train_step : 826, loss1 : 12.492609, loss2 : 14.473984
train_step : 827, loss1 : 18.426716, loss2 : 17.502680
train_step : 828, loss1 : 7.333838, loss2 : 17.861950
train_step : 829, loss1 : 27.747013, loss2 : 16.573486
train_step : 830, loss1 : 16.989943, loss2 : 16.419376
train_step : 831, loss1 : 31.404648, loss2 : 13.296993
train_step : 832, loss1 : 11.146514, loss2 : 13.528852
train_step : 833, loss1 : 11.217071, loss2 : 22.263260
train_step : 834, loss1 : 29.260508, loss2 : 16.564270
train_step : 835, loss1 : 13.824177, loss2 : 15.001266
train_step : 836, loss1 : 13.823601, loss2 : 19.239355
train_step : 837, loss1 : 19.587275, loss2 : 23.201815
train_step : 838, loss1 : 13.579071, loss2 : 16.110271
train_step : 839, loss1 : 19.265804, loss2 : 25.180817
train_step : 840, loss1 : 21.784760, loss2 : 24.979437
train_step : 841, loss1 : 35.118340, loss2 : 18.636494
train_step : 842, loss1 : 13.010805, loss2 : 26.504915
train_step : 843, loss1 : 22.470568, loss2 : 12.373219
train_step : 844, loss1 : 16.121880, loss2 : 18.103245
train_step : 845, loss1 : 10.228970, loss2 : 20.543144
train_step : 846, loss1 : 21.022316, loss2 : 12.618712
train_step : 847, loss1 : 19.153969, loss2 : 15.624591
train_step : 848, loss1 : 16.635504, loss2 : 7.403082
train_step : 849, loss1 : 22.726940, loss2 : 15.162071
train_step : 850, loss1 : 9.699986, loss2 : 30.045784
train_step : 851, loss1 : 9.710890, loss2 : 18.396976
train_step : 852, loss1 : 16.867615, loss2 : 21.626297
train_step : 853, loss1 : 19.149288, loss2 : 19.088078
train_step : 854, loss1 : 11.974998, loss2 : 24.216112
train_step : 855, loss1 : 17.120443, loss2 : 16.042427
train_step : 856, loss1 : 22.454187, loss2 : 15.814049
train_step : 857, loss1 : 18.563362, loss2 : 14.496572
train_step : 858, loss1 : 12.411289, loss2 : 19.040936
train_step : 859, loss1 : 10.195200, loss2 : 10.770277
train_step : 860, loss1 : 17.584270, loss2 : 20.320562
train_step : 861, loss1 : 15.167649, loss2 : 17.345453
train_step : 862, loss1 : 29.421701, loss2 : 22.177053
train_step : 863, loss1 : 27.931204, loss2 : 24.901836
train_step : 864, loss1 : 18.826344, loss2 : 16.273338
train_step : 865, loss1 : 13.800983, loss2 : 11.979998
train_step : 866, loss1 : 23.755348, loss2 : 7.653561
train_step : 867, loss1 : 17.479429, loss2 : 15.408350
train_step : 868, loss1 : 15.117904, loss2 : 12.891331
train_step : 869, loss1 : 28.346272, loss2 : 11.821816
train_step : 870, loss1 : 16.830355, loss2 : 11.612639
train_step : 871, loss1 : 16.386288, loss2 : 19.965912
train_step : 872, loss1 : 16.591400, loss2 : 15.674253
train_step : 873, loss1 : 10.494356, loss2 : 9.734155
train_step : 874, loss1 : 15.393476, loss2 : 24.195755
train_step : 875, loss1 : 23.350861, loss2 : 23.279253
train_step : 876, loss1 : 18.159290, loss2 : 17.229555
train_step : 877, loss1 : 24.257301, loss2 : 16.694454
train_step : 878, loss1 : 18.473282, loss2 : 21.606012
train_step : 879, loss1 : 13.788698, loss2 : 17.326664
train_step : 880, loss1 : 12.748165, loss2 : 10.958189
train_step : 881, loss1 : 22.458084, loss2 : 14.277575
train_step : 882, loss1 : 29.648304, loss2 : 19.975063
train_step : 883, loss1 : 27.061480, loss2 : 16.267469
train_step : 884, loss1 : 20.480610, loss2 : 15.424545
train_step : 885, loss1 : 12.728791, loss2 : 26.708704
train_step : 886, loss1 : 13.197026, loss2 : 12.252338
train_step : 887, loss1 : 21.901287, loss2 : 20.068245
train_step : 888, loss1 : 13.315762, loss2 : 15.231731
train_step : 889, loss1 : 12.863613, loss2 : 7.578010
train_step : 890, loss1 : 12.704611, loss2 : 28.595959
train_step : 891, loss1 : 28.290497, loss2 : 11.388147
train_step : 892, loss1 : 24.379959, loss2 : 34.726871
train_step : 893, loss1 : 13.479528, loss2 : 18.222944
train_step : 894, loss1 : 22.444286, loss2 : 17.198141
train_step : 895, loss1 : 22.684776, loss2 : 16.317383
train_step : 896, loss1 : 13.233458, loss2 : 22.903334
train_step : 897, loss1 : 27.688606, loss2 : 13.960669
train_step : 898, loss1 : 18.575102, loss2 : 17.970310
train_step : 899, loss1 : 13.132075, loss2 : 18.221552
train_step : 900, loss1 : 9.336039, loss2 : 26.883472
train_step : 901, loss1 : 16.938133, loss2 : 11.259907
train_step : 902, loss1 : 20.828815, loss2 : 20.390945
train_step : 903, loss1 : 19.275841, loss2 : 10.781275
train_step : 904, loss1 : 23.322899, loss2 : 18.063732
train_step : 905, loss1 : 15.214872, loss2 : 12.457923
train_step : 906, loss1 : 22.003090, loss2 : 37.415993
train_step : 907, loss1 : 25.426556, loss2 : 12.937210
train_step : 908, loss1 : 16.633808, loss2 : 13.547434
train_step : 909, loss1 : 16.912258, loss2 : 10.184806
train_step : 910, loss1 : 15.838072, loss2 : 15.606907
train_step : 911, loss1 : 22.010159, loss2 : 10.143557
train_step : 912, loss1 : 15.213651, loss2 : 9.524053
train_step : 913, loss1 : 19.536274, loss2 : 7.957324
train_step : 914, loss1 : 14.971025, loss2 : 23.705200
train_step : 915, loss1 : 28.709911, loss2 : 31.113668
train_step : 916, loss1 : 5.917349, loss2 : 15.922217
train_step : 917, loss1 : 17.411682, loss2 : 18.585632
train_step : 918, loss1 : 18.998150, loss2 : 13.739331
train_step : 919, loss1 : 11.852116, loss2 : 14.845706
train_step : 920, loss1 : 13.287926, loss2 : 13.862727
train_step : 921, loss1 : 15.813982, loss2 : 14.770672
train_step : 922, loss1 : 15.893161, loss2 : 21.426088
train_step : 923, loss1 : 16.424007, loss2 : 18.426537
train_step : 924, loss1 : 13.799896, loss2 : 13.426713
train_step : 925, loss1 : 20.823351, loss2 : 8.723379
train_step : 926, loss1 : 19.377190, loss2 : 11.290089
train_step : 927, loss1 : 12.840926, loss2 : 17.875704
train_step : 928, loss1 : 28.123329, loss2 : 28.677837
train_step : 929, loss1 : 10.229792, loss2 : 16.425587
train_step : 930, loss1 : 24.136627, loss2 : 13.484315
train_step : 931, loss1 : 9.452467, loss2 : 21.223152
train_step : 932, loss1 : 22.359184, loss2 : 24.442711
train_step : 933, loss1 : 13.254795, loss2 : 13.676827
train_step : 934, loss1 : 18.583447, loss2 : 16.722710
train_step : 935, loss1 : 10.925911, loss2 : 16.799316
train_step : 936, loss1 : 20.144379, loss2 : 17.302410
train_step : 937, loss1 : 10.307492, loss2 : 13.290010
train_step : 938, loss1 : 10.712435, loss2 : 10.450094
train_step : 939, loss1 : 14.619895, loss2 : 9.740122
train_step : 940, loss1 : 16.404751, loss2 : 10.475090
train_step : 941, loss1 : 13.748735, loss2 : 14.794760
train_step : 942, loss1 : 20.798580, loss2 : 12.442776
train_step : 943, loss1 : 20.634060, loss2 : 15.321692
train_step : 944, loss1 : 11.044340, loss2 : 17.850300
train_step : 945, loss1 : 26.157602, loss2 : 15.016857
train_step : 946, loss1 : 18.011818, loss2 : 15.409170
train_step : 947, loss1 : 7.414113, loss2 : 33.735031
train_step : 948, loss1 : 16.380398, loss2 : 38.321758
train_step : 949, loss1 : 13.826357, loss2 : 17.937284
train_step : 950, loss1 : 16.594219, loss2 : 8.116915
train_step : 951, loss1 : 13.475708, loss2 : 19.429171
train_step : 952, loss1 : 10.100513, loss2 : 11.968054
train_step : 953, loss1 : 13.206379, loss2 : 30.599699
train_step : 954, loss1 : 28.903446, loss2 : 19.822498
train_step : 955, loss1 : 15.501997, loss2 : 22.723326
train_step : 956, loss1 : 12.540607, loss2 : 26.041985
train_step : 957, loss1 : 19.622835, loss2 : 25.133476
train_step : 958, loss1 : 17.665436, loss2 : 20.278114
train_step : 959, loss1 : 20.124733, loss2 : 13.214430
train_step : 960, loss1 : 17.448400, loss2 : 21.952362
train_step : 961, loss1 : 22.982155, loss2 : 18.220064
train_step : 962, loss1 : 14.668474, loss2 : 22.042694
train_step : 963, loss1 : 11.463148, loss2 : 16.829062
train_step : 964, loss1 : 26.089157, loss2 : 21.968407
train_step : 965, loss1 : 15.009577, loss2 : 15.826509
train_step : 966, loss1 : 15.258003, loss2 : 20.144958
train_step : 967, loss1 : 17.443886, loss2 : 12.666437
train_step : 968, loss1 : 12.474993, loss2 : 16.226528
train_step : 969, loss1 : 21.153755, loss2 : 14.896866
train_step : 970, loss1 : 20.920425, loss2 : 16.339081
train_step : 971, loss1 : 6.633145, loss2 : 10.994445
train_step : 972, loss1 : 22.187149, loss2 : 16.852451
train_step : 973, loss1 : 9.761478, loss2 : 21.743393
train_step : 974, loss1 : 24.872168, loss2 : 13.910608
train_step : 975, loss1 : 18.789268, loss2 : 16.343628
train_step : 976, loss1 : 29.760662, loss2 : 12.293193
train_step : 977, loss1 : 18.301849, loss2 : 19.459671
train_step : 978, loss1 : 20.035971, loss2 : 20.050152
train_step : 979, loss1 : 25.633429, loss2 : 27.747320
train_step : 980, loss1 : 13.423035, loss2 : 21.240562
train_step : 981, loss1 : 16.155838, loss2 : 16.657135
train_step : 982, loss1 : 14.856632, loss2 : 12.294651
train_step : 983, loss1 : 23.585505, loss2 : 21.462643
train_step : 984, loss1 : 34.806057, loss2 : 11.624941
train_step : 985, loss1 : 11.518057, loss2 : 7.956496
train_step : 986, loss1 : 10.578547, loss2 : 24.574890
train_step : 987, loss1 : 19.325153, loss2 : 23.095263
train_step : 988, loss1 : 16.596855, loss2 : 11.759695
train_step : 989, loss1 : 25.780964, loss2 : 19.770054
train_step : 990, loss1 : 15.037888, loss2 : 16.202267
train_step : 991, loss1 : 14.181127, loss2 : 18.942627
train_step : 992, loss1 : 24.174273, loss2 : 19.313633
train_step : 993, loss1 : 14.671158, loss2 : 12.751024
train_step : 994, loss1 : 22.306623, loss2 : 13.697300
train_step : 995, loss1 : 9.506365, loss2 : 20.143682
train_step : 996, loss1 : 15.099497, loss2 : 14.147541
train_step : 997, loss1 : 17.312759, loss2 : 17.895424
train_step : 998, loss1 : 25.879688, loss2 : 8.532166
train_step : 999, loss1 : 11.568873, loss2 : 14.100700
train_step : 1000, loss1 : 18.040087, loss2 : 16.541414
train_step : 1001, loss1 : 27.580591, loss2 : 11.127302
train_step : 1002, loss1 : 17.006767, loss2 : 28.816807
train_step : 1003, loss1 : 20.674950, loss2 : 11.287832
train_step : 1004, loss1 : 15.612902, loss2 : 11.813240
train_step : 1005, loss1 : 18.789158, loss2 : 24.454439
train_step : 1006, loss1 : 19.596775, loss2 : 19.305958
train_step : 1007, loss1 : 24.659233, loss2 : 10.101171
train_step : 1008, loss1 : 18.326097, loss2 : 13.830456
train_step : 1009, loss1 : 12.353766, loss2 : 15.297889
train_step : 1010, loss1 : 26.470537, loss2 : 25.050390
train_step : 1011, loss1 : 20.406286, loss2 : 11.956777
train_step : 1012, loss1 : 13.940777, loss2 : 22.420200
train_step : 1013, loss1 : 14.345882, loss2 : 15.218044
train_step : 1014, loss1 : 13.884777, loss2 : 19.740278
train_step : 1015, loss1 : 19.273653, loss2 : 13.108355
train_step : 1016, loss1 : 17.993883, loss2 : 15.220184
train_step : 1017, loss1 : 17.294235, loss2 : 21.655987
train_step : 1018, loss1 : 21.567053, loss2 : 18.406994
train_step : 1019, loss1 : 28.735271, loss2 : 12.559277
train_step : 1020, loss1 : 27.036289, loss2 : 18.004496
train_step : 1021, loss1 : 32.851147, loss2 : 19.826519
train_step : 1022, loss1 : 8.912706, loss2 : 17.733822
train_step : 1023, loss1 : 21.051403, loss2 : 16.540665
train_step : 1024, loss1 : 16.352551, loss2 : 19.095526
train_step : 1025, loss1 : 11.252798, loss2 : 18.823730
train_step : 1026, loss1 : 18.299793, loss2 : 22.911900
train_step : 1027, loss1 : 18.903257, loss2 : 41.420872
train_step : 1028, loss1 : 15.983976, loss2 : 23.778545
train_step : 1029, loss1 : 14.818224, loss2 : 18.452160
train_step : 1030, loss1 : 20.083237, loss2 : 16.536428
train_step : 1031, loss1 : 30.369732, loss2 : 15.657293
train_step : 1032, loss1 : 8.168312, loss2 : 14.269513
train_step : 1033, loss1 : 21.067474, loss2 : 16.746632
train_step : 1034, loss1 : 16.128672, loss2 : 19.647568
train_step : 1035, loss1 : 13.153321, loss2 : 19.947071
train_step : 1036, loss1 : 15.593225, loss2 : 21.706997
train_step : 1037, loss1 : 14.951616, loss2 : 26.046268
train_step : 1038, loss1 : 11.384706, loss2 : 24.729218
train_step : 1039, loss1 : 22.609955, loss2 : 9.682392
train_step : 1040, loss1 : 23.485537, loss2 : 18.262894
train_step : 1041, loss1 : 24.022610, loss2 : 12.709827
train_step : 1042, loss1 : 12.100311, loss2 : 14.007701
train_step : 1043, loss1 : 15.349541, loss2 : 18.360218
train_step : 1044, loss1 : 13.690720, loss2 : 9.790489
train_step : 1045, loss1 : 17.446638, loss2 : 18.497353
train_step : 1046, loss1 : 13.048378, loss2 : 18.536732
train_step : 1047, loss1 : 15.065191, loss2 : 17.466452
train_step : 1048, loss1 : 18.715784, loss2 : 10.462845
train_step : 1049, loss1 : 9.731894, loss2 : 23.645226
train_step : 1050, loss1 : 20.591059, loss2 : 13.723457
train_step : 1051, loss1 : 14.445939, loss2 : 16.344875
train_step : 1052, loss1 : 26.050083, loss2 : 17.732784
train_step : 1053, loss1 : 11.267235, loss2 : 14.636303
train_step : 1054, loss1 : 18.864956, loss2 : 16.917212
train_step : 1055, loss1 : 21.799419, loss2 : 18.188082
train_step : 1056, loss1 : 21.483395, loss2 : 6.738958
train_step : 1057, loss1 : 21.888414, loss2 : 9.651941
train_step : 1058, loss1 : 15.290564, loss2 : 20.050411
train_step : 1059, loss1 : 18.115097, loss2 : 14.732199
train_step : 1060, loss1 : 15.001763, loss2 : 14.036626
train_step : 1061, loss1 : 16.723667, loss2 : 12.804171
train_step : 1062, loss1 : 18.637730, loss2 : 17.225294
train_step : 1063, loss1 : 18.873055, loss2 : 11.767668
train_step : 1064, loss1 : 14.761244, loss2 : 13.772150
train_step : 1065, loss1 : 19.634487, loss2 : 17.571377
train_step : 1066, loss1 : 22.716644, loss2 : 15.163345
train_step : 1067, loss1 : 12.085732, loss2 : 16.520798
train_step : 1068, loss1 : 11.171869, loss2 : 9.326623
train_step : 1069, loss1 : 31.936718, loss2 : 14.514010
train_step : 1070, loss1 : 15.357590, loss2 : 13.018711
train_step : 1071, loss1 : 16.794167, loss2 : 12.927626
train_step : 1072, loss1 : 12.594612, loss2 : 15.110632
train_step : 1073, loss1 : 15.400697, loss2 : 15.449072
train_step : 1074, loss1 : 17.390797, loss2 : 14.020703
train_step : 1075, loss1 : 21.052479, loss2 : 16.095135
train_step : 1076, loss1 : 12.275780, loss2 : 27.006248
train_step : 1077, loss1 : 14.557615, loss2 : 17.954227
train_step : 1078, loss1 : 14.503171, loss2 : 17.876640
train_step : 1079, loss1 : 16.210220, loss2 : 18.149435
train_step : 1080, loss1 : 13.916182, loss2 : 20.863785
train_step : 1081, loss1 : 22.650869, loss2 : 17.428196
train_step : 1082, loss1 : 14.285448, loss2 : 19.665730
train_step : 1083, loss1 : 18.228313, loss2 : 18.511696
train_step : 1084, loss1 : 11.923645, loss2 : 12.497031
train_step : 1085, loss1 : 14.019190, loss2 : 19.120861
train_step : 1086, loss1 : 16.698154, loss2 : 25.681545
train_step : 1087, loss1 : 16.233789, loss2 : 22.489513
train_step : 1088, loss1 : 15.276637, loss2 : 13.734587
train_step : 1089, loss1 : 19.638266, loss2 : 14.457798
train_step : 1090, loss1 : 15.707412, loss2 : 13.290665
train_step : 1091, loss1 : 18.444527, loss2 : 17.781446
train_step : 1092, loss1 : 10.397695, loss2 : 25.896378
train_step : 1093, loss1 : 22.576012, loss2 : 28.962523
train_step : 1094, loss1 : 13.140366, loss2 : 15.361203
train_step : 1095, loss1 : 30.378872, loss2 : 8.075850
train_step : 1096, loss1 : 23.161661, loss2 : 18.350733
train_step : 1097, loss1 : 11.004785, loss2 : 18.023151
train_step : 1098, loss1 : 13.326368, loss2 : 11.479527
train_step : 1099, loss1 : 11.218042, loss2 : 11.565006
train_step : 1100, loss1 : 15.491250, loss2 : 16.585350
train_step : 1101, loss1 : 15.703862, loss2 : 19.278830
train_step : 1102, loss1 : 18.555786, loss2 : 27.423002
train_step : 1103, loss1 : 14.060344, loss2 : 20.186842
train_step : 1104, loss1 : 24.445026, loss2 : 27.917015
train_step : 1105, loss1 : 18.949970, loss2 : 23.109825
train_step : 1106, loss1 : 30.258072, loss2 : 18.295551
train_step : 1107, loss1 : 14.414764, loss2 : 21.798737
train_step : 1108, loss1 : 20.197365, loss2 : 22.179768
train_step : 1109, loss1 : 26.635307, loss2 : 32.854683
train_step : 1110, loss1 : 10.520386, loss2 : 11.956938
train_step : 1111, loss1 : 23.234453, loss2 : 18.058783
train_step : 1112, loss1 : 22.069494, loss2 : 11.217745
train_step : 1113, loss1 : 16.841295, loss2 : 14.940264
train_step : 1114, loss1 : 15.915429, loss2 : 14.811886
train_step : 1115, loss1 : 18.162251, loss2 : 22.525854
train_step : 1116, loss1 : 17.007002, loss2 : 15.637994
train_step : 1117, loss1 : 17.381287, loss2 : 16.414997
train_step : 1118, loss1 : 7.404768, loss2 : 19.955034
train_step : 1119, loss1 : 27.778978, loss2 : 28.592028
train_step : 1120, loss1 : 21.673559, loss2 : 24.473370
train_step : 1121, loss1 : 19.299732, loss2 : 20.234169
train_step : 1122, loss1 : 14.031936, loss2 : 13.274530
train_step : 1123, loss1 : 22.726793, loss2 : 16.664730
train_step : 1124, loss1 : 9.913868, loss2 : 19.417122
train_step : 1125, loss1 : 17.383434, loss2 : 17.314941
train_step : 1126, loss1 : 19.295172, loss2 : 21.756273
train_step : 1127, loss1 : 11.794250, loss2 : 16.440491
train_step : 1128, loss1 : 11.218445, loss2 : 21.498125
train_step : 1129, loss1 : 13.387972, loss2 : 10.872583
train_step : 1130, loss1 : 11.543102, loss2 : 14.872463
train_step : 1131, loss1 : 20.662954, loss2 : 19.232801
train_step : 1132, loss1 : 18.311934, loss2 : 23.422573
train_step : 1133, loss1 : 15.421869, loss2 : 20.314747
train_step : 1134, loss1 : 20.706448, loss2 : 12.458939
train_step : 1135, loss1 : 16.898640, loss2 : 16.184481
train_step : 1136, loss1 : 19.072998, loss2 : 15.225133
train_step : 1137, loss1 : 26.180590, loss2 : 16.278721
train_step : 1138, loss1 : 15.970707, loss2 : 10.210489
train_step : 1139, loss1 : 19.384045, loss2 : 20.950363
train_step : 1140, loss1 : 18.625132, loss2 : 14.288982
train_step : 1141, loss1 : 18.982204, loss2 : 16.800476
train_step : 1142, loss1 : 10.683817, loss2 : 18.826517
train_step : 1143, loss1 : 19.672291, loss2 : 13.560153
train_step : 1144, loss1 : 20.519657, loss2 : 18.750118
train_step : 1145, loss1 : 24.465622, loss2 : 22.086288
train_step : 1146, loss1 : 22.421646, loss2 : 24.865700
train_step : 1147, loss1 : 16.086311, loss2 : 22.372711
train_step : 1148, loss1 : 15.584553, loss2 : 24.904831
train_step : 1149, loss1 : 16.690605, loss2 : 17.669674
train_step : 1150, loss1 : 11.699281, loss2 : 12.887830
train_step : 1151, loss1 : 16.648424, loss2 : 26.329952
train_step : 1152, loss1 : 19.025118, loss2 : 29.702398
train_step : 1153, loss1 : 29.163498, loss2 : 11.808893
train_step : 1154, loss1 : 23.438461, loss2 : 22.808117
train_step : 1155, loss1 : 20.247044, loss2 : 18.467386
train_step : 1156, loss1 : 11.549200, loss2 : 10.734108
train_step : 1157, loss1 : 10.499777, loss2 : 21.436378
train_step : 1158, loss1 : 18.487377, loss2 : 17.907906
train_step : 1159, loss1 : 32.955109, loss2 : 12.355301
train_step : 1160, loss1 : 30.124058, loss2 : 19.975634
train_step : 1161, loss1 : 16.897484, loss2 : 19.837692
train_step : 1162, loss1 : 17.626740, loss2 : 17.220837
train_step : 1163, loss1 : 17.335516, loss2 : 27.594082
train_step : 1164, loss1 : 12.575151, loss2 : 18.525787
train_step : 1165, loss1 : 16.126402, loss2 : 17.216906
train_step : 1166, loss1 : 11.991312, loss2 : 19.641052
train_step : 1167, loss1 : 15.776700, loss2 : 21.300549
train_step : 1168, loss1 : 19.684544, loss2 : 18.751257
train_step : 1169, loss1 : 15.341097, loss2 : 13.634823
train_step : 1170, loss1 : 24.764538, loss2 : 8.055204
train_step : 1171, loss1 : 26.881641, loss2 : 15.266802
train_step : 1172, loss1 : 21.903843, loss2 : 26.954163
train_step : 1173, loss1 : 15.146088, loss2 : 24.080074
train_step : 1174, loss1 : 17.715199, loss2 : 17.111706
train_step : 1175, loss1 : 15.469206, loss2 : 27.514442
train_step : 1176, loss1 : 17.387054, loss2 : 16.051764
train_step : 1177, loss1 : 9.904013, loss2 : 16.066854
train_step : 1178, loss1 : 15.808223, loss2 : 16.289415
train_step : 1179, loss1 : 17.757790, loss2 : 12.604210
train_step : 1180, loss1 : 11.828058, loss2 : 17.305235
train_step : 1181, loss1 : 13.022637, loss2 : 11.322261
train_step : 1182, loss1 : 13.191981, loss2 : 24.237053
train_step : 1183, loss1 : 19.002611, loss2 : 25.947691
train_step : 1184, loss1 : 21.977455, loss2 : 16.747349
train_step : 1185, loss1 : 17.487082, loss2 : 12.258953
train_step : 1186, loss1 : 28.468649, loss2 : 18.945089
train_step : 1187, loss1 : 19.314457, loss2 : 6.052463
train_step : 1188, loss1 : 21.502251, loss2 : 24.430893
train_step : 1189, loss1 : 17.565712, loss2 : 27.787209
train_step : 1190, loss1 : 14.152171, loss2 : 17.143709
train_step : 1191, loss1 : 22.323595, loss2 : 27.621815
train_step : 1192, loss1 : 24.172146, loss2 : 18.933945
train_step : 1193, loss1 : 13.652819, loss2 : 14.600218
train_step : 1194, loss1 : 17.634094, loss2 : 13.452983
train_step : 1195, loss1 : 17.281086, loss2 : 13.617876
train_step : 1196, loss1 : 14.506017, loss2 : 21.364172
train_step : 1197, loss1 : 13.562445, loss2 : 17.909224
train_step : 1198, loss1 : 13.143251, loss2 : 22.648338
train_step : 1199, loss1 : 12.618465, loss2 : 25.992151
train_step : 1200, loss1 : 15.612775, loss2 : 15.749298
train_step : 1201, loss1 : 17.539753, loss2 : 13.216366
train_step : 1202, loss1 : 19.049192, loss2 : 16.580238
train_step : 1203, loss1 : 18.359566, loss2 : 10.009945
train_step : 1204, loss1 : 15.765780, loss2 : 19.185802
train_step : 1205, loss1 : 26.927147, loss2 : 15.457773
train_step : 1206, loss1 : 15.424931, loss2 : 32.983673
train_step : 1207, loss1 : 18.447552, loss2 : 24.367060
train_step : 1208, loss1 : 6.447244, loss2 : 9.706858
train_step : 1209, loss1 : 23.475531, loss2 : 16.189522
train_step : 1210, loss1 : 15.671206, loss2 : 25.205357
train_step : 1211, loss1 : 22.212620, loss2 : 11.854889
train_step : 1212, loss1 : 18.729454, loss2 : 20.941814
train_step : 1213, loss1 : 17.762260, loss2 : 16.215441
train_step : 1214, loss1 : 12.750811, loss2 : 12.738179
train_step : 1215, loss1 : 26.750071, loss2 : 11.253032
train_step : 1216, loss1 : 31.830471, loss2 : 17.687832
train_step : 1217, loss1 : 19.718609, loss2 : 14.008480
train_step : 1218, loss1 : 11.867445, loss2 : 29.999060
train_step : 1219, loss1 : 21.575676, loss2 : 24.315685
train_step : 1220, loss1 : 16.104443, loss2 : 13.920109
train_step : 1221, loss1 : 25.146622, loss2 : 17.613361
train_step : 1222, loss1 : 11.231497, loss2 : 7.099247
train_step : 1223, loss1 : 31.026392, loss2 : 21.976162
train_step : 1224, loss1 : 9.962916, loss2 : 11.162655
train_step : 1225, loss1 : 14.566202, loss2 : 26.687094
train_step : 1226, loss1 : 21.291824, loss2 : 12.318407
train_step : 1227, loss1 : 16.559875, loss2 : 20.048218
train_step : 1228, loss1 : 12.823606, loss2 : 15.406323
train_step : 1229, loss1 : 19.802597, loss2 : 12.620190
train_step : 1230, loss1 : 20.639307, loss2 : 23.400839
train_step : 1231, loss1 : 23.990330, loss2 : 23.699837
train_step : 1232, loss1 : 18.751709, loss2 : 9.566705
train_step : 1233, loss1 : 16.111010, loss2 : 38.383461
train_step : 1234, loss1 : 10.806430, loss2 : 9.744037
train_step : 1235, loss1 : 16.067419, loss2 : 17.219271
train_step : 1236, loss1 : 12.868220, loss2 : 18.273205
train_step : 1237, loss1 : 30.821383, loss2 : 18.578354
train_step : 1238, loss1 : 16.469574, loss2 : 31.429466
train_step : 1239, loss1 : 15.152231, loss2 : 15.907761
train_step : 1240, loss1 : 20.561697, loss2 : 16.261894
train_step : 1241, loss1 : 23.478695, loss2 : 30.028091
train_step : 1242, loss1 : 16.577490, loss2 : 20.175510
train_step : 1243, loss1 : 12.384729, loss2 : 21.117374
train_step : 1244, loss1 : 18.405058, loss2 : 13.814354
train_step : 1245, loss1 : 13.841050, loss2 : 15.447569
train_step : 1246, loss1 : 12.469579, loss2 : 20.794617
train_step : 1247, loss1 : 16.785429, loss2 : 26.556522
train_step : 1248, loss1 : 28.194115, loss2 : 26.428101
train_step : 1249, loss1 : 15.552500, loss2 : 17.083553
train_step : 1250, loss1 : 15.902906, loss2 : 13.923794
train_step : 1251, loss1 : 30.877922, loss2 : 16.263119
train_step : 1252, loss1 : 16.854504, loss2 : 21.135994
train_step : 1253, loss1 : 21.304470, loss2 : 29.478230
train_step : 1254, loss1 : 22.595573, loss2 : 22.599506
train_step : 1255, loss1 : 18.702021, loss2 : 23.713820
train_step : 1256, loss1 : 9.772522, loss2 : 27.659060
train_step : 1257, loss1 : 14.487432, loss2 : 10.869759
train_step : 1258, loss1 : 17.446220, loss2 : 18.651764
train_step : 1259, loss1 : 11.035481, loss2 : 12.604762
train_step : 1260, loss1 : 25.318169, loss2 : 21.168890
train_step : 1261, loss1 : 12.809586, loss2 : 13.589462
train_step : 1262, loss1 : 12.925018, loss2 : 13.412516
train_step : 1263, loss1 : 23.327181, loss2 : 9.131603
train_step : 1264, loss1 : 19.057873, loss2 : 11.855606
train_step : 1265, loss1 : 22.913837, loss2 : 20.298071
train_step : 1266, loss1 : 20.007332, loss2 : 14.023027
train_step : 1267, loss1 : 22.006119, loss2 : 19.438614
train_step : 1268, loss1 : 22.272764, loss2 : 14.701980
train_step : 1269, loss1 : 16.268772, loss2 : 18.308800
train_step : 1270, loss1 : 18.451530, loss2 : 18.361334
train_step : 1271, loss1 : 11.089134, loss2 : 14.876460
train_step : 1272, loss1 : 10.891176, loss2 : 14.544675
train_step : 1273, loss1 : 23.480797, loss2 : 21.103592
train_step : 1274, loss1 : 15.263008, loss2 : 16.593006
train_step : 1275, loss1 : 23.958294, loss2 : 32.819729
train_step : 1276, loss1 : 15.805306, loss2 : 22.614758
train_step : 1277, loss1 : 29.956011, loss2 : 8.925438
train_step : 1278, loss1 : 13.805357, loss2 : 12.257992
train_step : 1279, loss1 : 14.309196, loss2 : 16.938404
train_step : 1280, loss1 : 25.733513, loss2 : 12.189075
train_step : 1281, loss1 : 16.234812, loss2 : 19.348705
train_step : 1282, loss1 : 25.177065, loss2 : 12.137033
train_step : 1283, loss1 : 18.098209, loss2 : 10.607877
train_step : 1284, loss1 : 19.139862, loss2 : 19.761284
train_step : 1285, loss1 : 12.438451, loss2 : 16.739908
train_step : 1286, loss1 : 15.123687, loss2 : 21.584791
train_step : 1287, loss1 : 8.859643, loss2 : 21.884277
train_step : 1288, loss1 : 6.397046, loss2 : 14.481777
train_step : 1289, loss1 : 25.220469, loss2 : 17.046144
train_step : 1290, loss1 : 27.179205, loss2 : 17.926275
train_step : 1291, loss1 : 24.127035, loss2 : 10.539296
train_step : 1292, loss1 : 16.151670, loss2 : 10.973714
train_step : 1293, loss1 : 20.257069, loss2 : 15.588964
train_step : 1294, loss1 : 20.655788, loss2 : 18.811569
train_step : 1295, loss1 : 15.733563, loss2 : 14.130135
train_step : 1296, loss1 : 14.743355, loss2 : 17.114277
train_step : 1297, loss1 : 17.440556, loss2 : 17.924341
train_step : 1298, loss1 : 13.485857, loss2 : 21.774069
train_step : 1299, loss1 : 25.712681, loss2 : 14.136383
train_step : 1300, loss1 : 18.874561, loss2 : 25.107880
train_step : 1301, loss1 : 12.397625, loss2 : 17.650211
train_step : 1302, loss1 : 32.558807, loss2 : 23.708975
train_step : 1303, loss1 : 19.083462, loss2 : 16.572691
train_step : 1304, loss1 : 22.284122, loss2 : 33.747395
train_step : 1305, loss1 : 12.286871, loss2 : 18.332941
train_step : 1306, loss1 : 17.536167, loss2 : 13.716249
train_step : 1307, loss1 : 11.692450, loss2 : 18.209482
train_step : 1308, loss1 : 19.487711, loss2 : 12.171511
train_step : 1309, loss1 : 19.312946, loss2 : 19.342049
train_step : 1310, loss1 : 13.122941, loss2 : 13.116838
train_step : 1311, loss1 : 10.816414, loss2 : 18.557020
train_step : 1312, loss1 : 14.109378, loss2 : 11.902531
train_step : 1313, loss1 : 29.267227, loss2 : 12.972305
train_step : 1314, loss1 : 22.529030, loss2 : 13.215866
train_step : 1315, loss1 : 19.545006, loss2 : 23.663795
train_step : 1316, loss1 : 10.671520, loss2 : 17.686380
train_step : 1317, loss1 : 12.769062, loss2 : 14.547863
train_step : 1318, loss1 : 23.730385, loss2 : 17.988466
train_step : 1319, loss1 : 25.949709, loss2 : 24.486286
train_step : 1320, loss1 : 11.148344, loss2 : 13.550287
train_step : 1321, loss1 : 20.563488, loss2 : 20.807686
train_step : 1322, loss1 : 13.362889, loss2 : 21.382179
train_step : 1323, loss1 : 10.591973, loss2 : 20.977921
train_step : 1324, loss1 : 8.772979, loss2 : 12.328726
train_step : 1325, loss1 : 11.787475, loss2 : 16.152981
train_step : 1326, loss1 : 20.264362, loss2 : 12.641377
train_step : 1327, loss1 : 10.970339, loss2 : 21.105381
train_step : 1328, loss1 : 27.080059, loss2 : 16.118053
train_step : 1329, loss1 : 21.682327, loss2 : 10.169544
train_step : 1330, loss1 : 16.727402, loss2 : 16.394053
train_step : 1331, loss1 : 16.044031, loss2 : 32.551586
train_step : 1332, loss1 : 14.279374, loss2 : 11.023521
train_step : 1333, loss1 : 8.848995, loss2 : 24.954039
train_step : 1334, loss1 : 22.089449, loss2 : 15.767432
train_step : 1335, loss1 : 13.249122, loss2 : 14.503307
train_step : 1336, loss1 : 22.483692, loss2 : 26.130518
train_step : 1337, loss1 : 11.828175, loss2 : 15.646984
train_step : 1338, loss1 : 10.311606, loss2 : 15.652971
train_step : 1339, loss1 : 14.979433, loss2 : 18.047724
train_step : 1340, loss1 : 15.250699, loss2 : 16.418541
train_step : 1341, loss1 : 30.439598, loss2 : 28.861618
train_step : 1342, loss1 : 14.487241, loss2 : 16.016178
train_step : 1343, loss1 : 26.769436, loss2 : 14.072213
train_step : 1344, loss1 : 15.457557, loss2 : 22.908371
train_step : 1345, loss1 : 16.500305, loss2 : 25.210098
train_step : 1346, loss1 : 14.731417, loss2 : 12.368423
train_step : 1347, loss1 : 29.180733, loss2 : 19.246981
train_step : 1348, loss1 : 13.172385, loss2 : 15.304858
train_step : 1349, loss1 : 13.105589, loss2 : 16.643208
train_step : 1350, loss1 : 11.845219, loss2 : 13.940634
train_step : 1351, loss1 : 6.313282, loss2 : 27.657042
train_step : 1352, loss1 : 12.170127, loss2 : 12.157364
train_step : 1353, loss1 : 19.169237, loss2 : 27.491846
train_step : 1354, loss1 : 23.556084, loss2 : 11.912886
train_step : 1355, loss1 : 16.468678, loss2 : 11.363769
train_step : 1356, loss1 : 12.700258, loss2 : 13.067444
train_step : 1357, loss1 : 31.088022, loss2 : 19.432259
train_step : 1358, loss1 : 13.905449, loss2 : 19.204975
train_step : 1359, loss1 : 17.760838, loss2 : 17.708771
train_step : 1360, loss1 : 17.487528, loss2 : 21.260403
train_step : 1361, loss1 : 30.313406, loss2 : 11.545182
train_step : 1362, loss1 : 14.168772, loss2 : 20.360279
train_step : 1363, loss1 : 12.527077, loss2 : 17.381651
train_step : 1364, loss1 : 18.239960, loss2 : 27.556492
train_step : 1365, loss1 : 21.901054, loss2 : 16.706200
train_step : 1366, loss1 : 9.718485, loss2 : 15.758042
train_step : 1367, loss1 : 18.031483, loss2 : 22.273319
train_step : 1368, loss1 : 11.550598, loss2 : 16.208656
train_step : 1369, loss1 : 11.329603, loss2 : 22.486511
train_step : 1370, loss1 : 13.724033, loss2 : 14.624178
train_step : 1371, loss1 : 21.094963, loss2 : 23.428083
train_step : 1372, loss1 : 12.223976, loss2 : 17.147043
train_step : 1373, loss1 : 12.255047, loss2 : 22.001644
train_step : 1374, loss1 : 14.577490, loss2 : 21.095510
train_step : 1375, loss1 : 21.282360, loss2 : 16.692514
train_step : 1376, loss1 : 21.782799, loss2 : 14.315440
train_step : 1377, loss1 : 18.156590, loss2 : 17.684818
train_step : 1378, loss1 : 14.781956, loss2 : 13.656802
train_step : 1379, loss1 : 12.148861, loss2 : 18.187500
train_step : 1380, loss1 : 28.279181, loss2 : 21.884037
train_step : 1381, loss1 : 11.120909, loss2 : 11.153009
train_step : 1382, loss1 : 17.722456, loss2 : 16.414774
train_step : 1383, loss1 : 10.232276, loss2 : 17.691339
train_step : 1384, loss1 : 14.638468, loss2 : 13.074574
train_step : 1385, loss1 : 7.703454, loss2 : 16.949369
train_step : 1386, loss1 : 17.044291, loss2 : 22.420704
train_step : 1387, loss1 : 15.292428, loss2 : 21.526550
train_step : 1388, loss1 : 9.952706, loss2 : 13.243559
train_step : 1389, loss1 : 21.622019, loss2 : 22.249409
train_step : 1390, loss1 : 16.531715, loss2 : 22.534605
train_step : 1391, loss1 : 21.890131, loss2 : 18.531336
train_step : 1392, loss1 : 10.584033, loss2 : 26.017157
train_step : 1393, loss1 : 16.886889, loss2 : 14.376101
train_step : 1394, loss1 : 10.853762, loss2 : 11.873383
train_step : 1395, loss1 : 10.639927, loss2 : 14.410702
train_step : 1396, loss1 : 14.458052, loss2 : 17.024002
train_step : 1397, loss1 : 16.620716, loss2 : 23.353823
train_step : 1398, loss1 : 13.896509, loss2 : 17.598877
train_step : 1399, loss1 : 19.867872, loss2 : 18.600853
train_step : 1400, loss1 : 17.210049, loss2 : 17.790928
train_step : 1401, loss1 : 11.566658, loss2 : 12.134974
train_step : 1402, loss1 : 25.470798, loss2 : 17.525475
train_step : 1403, loss1 : 13.851586, loss2 : 20.430010
train_step : 1404, loss1 : 12.158382, loss2 : 26.157209
train_step : 1405, loss1 : 18.237795, loss2 : 9.071747
train_step : 1406, loss1 : 14.514830, loss2 : 16.763456
train_step : 1407, loss1 : 11.321943, loss2 : 19.207966
train_step : 1408, loss1 : 24.153381, loss2 : 16.934078
train_step : 1409, loss1 : 21.441643, loss2 : 25.937019
train_step : 1410, loss1 : 14.612637, loss2 : 10.411335
train_step : 1411, loss1 : 22.901321, loss2 : 12.850841
train_step : 1412, loss1 : 18.101305, loss2 : 23.085917
train_step : 1413, loss1 : 8.953783, loss2 : 25.684700
train_step : 1414, loss1 : 13.361374, loss2 : 22.494427
train_step : 1415, loss1 : 13.872942, loss2 : 24.388458
train_step : 1416, loss1 : 18.019096, loss2 : 20.480747
train_step : 1417, loss1 : 26.339462, loss2 : 20.492640
train_step : 1418, loss1 : 15.778271, loss2 : 15.813416
train_step : 1419, loss1 : 25.729111, loss2 : 12.564730
train_step : 1420, loss1 : 27.947271, loss2 : 18.138168
train_step : 1421, loss1 : 10.074761, loss2 : 12.526489
train_step : 1422, loss1 : 17.375061, loss2 : 29.788462
train_step : 1423, loss1 : 18.998159, loss2 : 10.813873
train_step : 1424, loss1 : 14.703767, loss2 : 14.711151
train_step : 1425, loss1 : 8.726243, loss2 : 17.377005
train_step : 1426, loss1 : 24.306515, loss2 : 18.204212
train_step : 1427, loss1 : 12.288586, loss2 : 19.987986
train_step : 1428, loss1 : 11.947609, loss2 : 18.488625
train_step : 1429, loss1 : 17.438671, loss2 : 17.204372
train_step : 1430, loss1 : 22.821594, loss2 : 23.799967
train_step : 1431, loss1 : 10.778126, loss2 : 15.571110
train_step : 1432, loss1 : 23.848892, loss2 : 21.649679
train_step : 1433, loss1 : 16.904160, loss2 : 21.608385
train_step : 1434, loss1 : 22.343693, loss2 : 12.652489
train_step : 1435, loss1 : 23.661076, loss2 : 18.094368
train_step : 1436, loss1 : 15.906569, loss2 : 14.957386
train_step : 1437, loss1 : 10.065054, loss2 : 18.715071
train_step : 1438, loss1 : 21.383270, loss2 : 13.421863
train_step : 1439, loss1 : 13.168484, loss2 : 20.519077
train_step : 1440, loss1 : 26.683645, loss2 : 11.128538
train_step : 1441, loss1 : 14.248698, loss2 : 17.997200
train_step : 1442, loss1 : 16.863241, loss2 : 18.904648
train_step : 1443, loss1 : 13.372076, loss2 : 23.461605
train_step : 1444, loss1 : 18.579021, loss2 : 15.957293
train_step : 1445, loss1 : 16.321774, loss2 : 19.417233
train_step : 1446, loss1 : 14.954090, loss2 : 19.628160
train_step : 1447, loss1 : 14.377607, loss2 : 8.980158
train_step : 1448, loss1 : 11.422711, loss2 : 29.488852
train_step : 1449, loss1 : 8.801207, loss2 : 16.033354
train_step : 1450, loss1 : 16.090128, loss2 : 27.185989
train_step : 1451, loss1 : 13.460340, loss2 : 16.722614
train_step : 1452, loss1 : 18.029465, loss2 : 21.736248
train_step : 1453, loss1 : 15.006829, loss2 : 23.226677
train_step : 1454, loss1 : 13.277947, loss2 : 16.226082
train_step : 1455, loss1 : 17.067583, loss2 : 27.844297
train_step : 1456, loss1 : 13.915155, loss2 : 21.998434
train_step : 1457, loss1 : 10.932484, loss2 : 21.332607
train_step : 1458, loss1 : 10.135302, loss2 : 15.495105
train_step : 1459, loss1 : 18.658903, loss2 : 18.073124
train_step : 1460, loss1 : 16.831705, loss2 : 15.767253
train_step : 1461, loss1 : 16.727047, loss2 : 15.492296
train_step : 1462, loss1 : 14.967434, loss2 : 20.462337
train_step : 1463, loss1 : 17.076286, loss2 : 21.555023
train_step : 1464, loss1 : 22.709812, loss2 : 13.024979
train_step : 1465, loss1 : 11.608700, loss2 : 18.041756
train_step : 1466, loss1 : 21.125813, loss2 : 25.840576
train_step : 1467, loss1 : 16.031328, loss2 : 28.726421
train_step : 1468, loss1 : 19.990021, loss2 : 10.802368
train_step : 1469, loss1 : 16.043125, loss2 : 20.138649
train_step : 1470, loss1 : 21.901104, loss2 : 13.663474
train_step : 1471, loss1 : 14.794171, loss2 : 15.262808
train_step : 1472, loss1 : 14.050121, loss2 : 14.298700
train_step : 1473, loss1 : 13.158346, loss2 : 19.297367
train_step : 1474, loss1 : 17.631208, loss2 : 21.080397
train_step : 1475, loss1 : 25.326748, loss2 : 11.832304
train_step : 1476, loss1 : 17.343658, loss2 : 16.918274
train_step : 1477, loss1 : 34.819016, loss2 : 12.262904
train_step : 1478, loss1 : 8.553144, loss2 : 22.806479
train_step : 1479, loss1 : 17.070139, loss2 : 23.810499
train_step : 1480, loss1 : 19.355255, loss2 : 21.123909
train_step : 1481, loss1 : 17.640518, loss2 : 31.301344
train_step : 1482, loss1 : 17.982704, loss2 : 13.754496
train_step : 1483, loss1 : 22.017193, loss2 : 24.034451
train_step : 1484, loss1 : 29.622707, loss2 : 17.417049
train_step : 1485, loss1 : 20.712425, loss2 : 18.899422
train_step : 1486, loss1 : 18.716469, loss2 : 15.434107
train_step : 1487, loss1 : 13.213376, loss2 : 18.268799
train_step : 1488, loss1 : 14.684578, loss2 : 20.610773
train_step : 1489, loss1 : 13.764098, loss2 : 20.006813
train_step : 1490, loss1 : 26.044254, loss2 : 12.257213
train_step : 1491, loss1 : 22.333155, loss2 : 16.322205
train_step : 1492, loss1 : 14.234691, loss2 : 10.574882
train_step : 1493, loss1 : 15.813875, loss2 : 13.435432
train_step : 1494, loss1 : 16.822449, loss2 : 11.625361
train_step : 1495, loss1 : 24.741844, loss2 : 13.107151
train_step : 1496, loss1 : 12.568212, loss2 : 16.770424
train_step : 1497, loss1 : 12.854530, loss2 : 19.147461
train_step : 1498, loss1 : 19.478939, loss2 : 10.309290
train_step : 1499, loss1 : 21.340893, loss2 : 21.021526
train_step : 1500, loss1 : 36.695095, loss2 : 12.540610
train_step : 1501, loss1 : 25.738556, loss2 : 19.603714
train_step : 1502, loss1 : 21.270771, loss2 : 16.980486
train_step : 1503, loss1 : 13.636711, loss2 : 20.084185
train_step : 1504, loss1 : 18.486357, loss2 : 17.939213
train_step : 1505, loss1 : 17.551411, loss2 : 21.706779
train_step : 1506, loss1 : 15.140692, loss2 : 16.030844
train_step : 1507, loss1 : 15.743196, loss2 : 15.245358
train_step : 1508, loss1 : 20.645687, loss2 : 15.572306
train_step : 1509, loss1 : 15.953854, loss2 : 18.131578
train_step : 1510, loss1 : 16.979403, loss2 : 14.210233
train_step : 1511, loss1 : 22.954876, loss2 : 17.056206
train_step : 1512, loss1 : 12.441004, loss2 : 11.526503
train_step : 1513, loss1 : 7.338797, loss2 : 30.406067
train_step : 1514, loss1 : 24.721783, loss2 : 16.469296
train_step : 1515, loss1 : 16.992588, loss2 : 12.807449
train_step : 1516, loss1 : 17.723536, loss2 : 13.119557
train_step : 1517, loss1 : 16.636242, loss2 : 16.697559
train_step : 1518, loss1 : 9.240251, loss2 : 13.121060
train_step : 1519, loss1 : 15.003878, loss2 : 16.940479
train_step : 1520, loss1 : 19.162476, loss2 : 15.923453
train_step : 1521, loss1 : 24.771355, loss2 : 25.700115
train_step : 1522, loss1 : 14.829544, loss2 : 23.112547
train_step : 1523, loss1 : 12.934351, loss2 : 14.909591
train_step : 1524, loss1 : 11.098091, loss2 : 18.072994
train_step : 1525, loss1 : 25.731615, loss2 : 21.511429
train_step : 1526, loss1 : 17.524055, loss2 : 9.818879
train_step : 1527, loss1 : 22.267746, loss2 : 19.113823
train_step : 1528, loss1 : 23.512295, loss2 : 15.252312
train_step : 1529, loss1 : 13.708605, loss2 : 31.667496
train_step : 1530, loss1 : 20.764473, loss2 : 28.138483
train_step : 1531, loss1 : 27.705540, loss2 : 17.052816
train_step : 1532, loss1 : 14.318622, loss2 : 17.103579
train_step : 1533, loss1 : 26.753616, loss2 : 11.511244
train_step : 1534, loss1 : 8.147243, loss2 : 12.187408
train_step : 1535, loss1 : 18.341576, loss2 : 21.218620
train_step : 1536, loss1 : 12.241944, loss2 : 14.570711
train_step : 1537, loss1 : 14.962900, loss2 : 21.142946
train_step : 1538, loss1 : 13.545965, loss2 : 16.823494
train_step : 1539, loss1 : 21.303198, loss2 : 17.902298
train_step : 1540, loss1 : 6.303707, loss2 : 14.163725
train_step : 1541, loss1 : 17.253990, loss2 : 16.030186
train_step : 1542, loss1 : 19.548359, loss2 : 19.993095
train_step : 1543, loss1 : 16.519150, loss2 : 14.380253
train_step : 1544, loss1 : 19.117596, loss2 : 16.781954
train_step : 1545, loss1 : 16.456947, loss2 : 11.084341
train_step : 1546, loss1 : 15.600586, loss2 : 14.208613
train_step : 1547, loss1 : 20.662537, loss2 : 22.808468
train_step : 1548, loss1 : 22.384232, loss2 : 13.324044
train_step : 1549, loss1 : 20.617508, loss2 : 18.885111
train_step : 1550, loss1 : 15.679701, loss2 : 13.357887
train_step : 1551, loss1 : 20.063803, loss2 : 23.258533
train_step : 1552, loss1 : 15.768341, loss2 : 15.127144
train_step : 1553, loss1 : 12.760307, loss2 : 13.319651
train_step : 1554, loss1 : 32.886024, loss2 : 14.220251
train_step : 1555, loss1 : 19.395864, loss2 : 20.122654
train_step : 1556, loss1 : 31.996227, loss2 : 8.572095
train_step : 1557, loss1 : 16.499769, loss2 : 19.589130
train_step : 1558, loss1 : 20.871042, loss2 : 20.021093
train_step : 1559, loss1 : 22.500969, loss2 : 26.268093
train_step : 1560, loss1 : 12.514280, loss2 : 27.116518
train_step : 1561, loss1 : 17.546400, loss2 : 12.944367
train_step : 1562, loss1 : 20.618788, loss2 : 16.108419
train_step : 1563, loss1 : 14.862843, loss2 : 15.801796
train_step : 1564, loss1 : 6.911679, loss2 : 20.387547
train_step : 1565, loss1 : 17.531261, loss2 : 9.378716
train_step : 1566, loss1 : 11.627495, loss2 : 15.630777
train_step : 1567, loss1 : 19.888512, loss2 : 22.598228
train_step : 1568, loss1 : 14.379751, loss2 : 19.166943
train_step : 1569, loss1 : 17.267746, loss2 : 9.129548
train_step : 1570, loss1 : 16.841442, loss2 : 22.143303
train_step : 1571, loss1 : 15.685133, loss2 : 23.888186
train_step : 1572, loss1 : 19.377819, loss2 : 17.964203
train_step : 1573, loss1 : 16.550993, loss2 : 14.133634
train_step : 1574, loss1 : 17.755476, loss2 : 14.641381
train_step : 1575, loss1 : 17.161684, loss2 : 22.489155
train_step : 1576, loss1 : 14.822121, loss2 : 19.700539
train_step : 1577, loss1 : 12.540592, loss2 : 27.448814
train_step : 1578, loss1 : 24.796703, loss2 : 17.712090
train_step : 1579, loss1 : 12.021297, loss2 : 17.342163
train_step : 1580, loss1 : 12.850880, loss2 : 16.469778
train_step : 1581, loss1 : 10.246613, loss2 : 13.121885
train_step : 1582, loss1 : 10.582037, loss2 : 19.203056
train_step : 1583, loss1 : 24.670540, loss2 : 22.752007
train_step : 1584, loss1 : 12.294971, loss2 : 15.703024
train_step : 1585, loss1 : 19.689060, loss2 : 26.900711
train_step : 1586, loss1 : 7.325748, loss2 : 16.331955
train_step : 1587, loss1 : 19.211926, loss2 : 16.055050
train_step : 1588, loss1 : 19.051178, loss2 : 18.056538
train_step : 1589, loss1 : 23.184559, loss2 : 14.965941
train_step : 1590, loss1 : 16.126858, loss2 : 15.532597
train_step : 1591, loss1 : 11.711842, loss2 : 13.832678
train_step : 1592, loss1 : 12.778035, loss2 : 28.155510
train_step : 1593, loss1 : 17.850233, loss2 : 15.577209
train_step : 1594, loss1 : 29.424534, loss2 : 14.979206
train_step : 1595, loss1 : 29.616869, loss2 : 9.534362
train_step : 1596, loss1 : 21.341553, loss2 : 15.851709
train_step : 1597, loss1 : 13.329698, loss2 : 17.298885
train_step : 1598, loss1 : 20.784536, loss2 : 28.076073
train_step : 1599, loss1 : 15.919573, loss2 : 13.037621
train_step : 1600, loss1 : 28.999405, loss2 : 23.179150
train_step : 1601, loss1 : 26.684490, loss2 : 15.336351
train_step : 1602, loss1 : 13.822023, loss2 : 17.890261
train_step : 1603, loss1 : 15.231066, loss2 : 18.310631
train_step : 1604, loss1 : 16.077932, loss2 : 25.647186
train_step : 1605, loss1 : 28.978857, loss2 : 17.897982
train_step : 1606, loss1 : 21.764969, loss2 : 16.825615
train_step : 1607, loss1 : 26.320961, loss2 : 13.497774
train_step : 1608, loss1 : 19.066929, loss2 : 16.985588
train_step : 1609, loss1 : 10.830458, loss2 : 25.524046
train_step : 1610, loss1 : 11.126223, loss2 : 17.956179
train_step : 1611, loss1 : 14.792418, loss2 : 17.976345
train_step : 1612, loss1 : 15.069738, loss2 : 8.694402
train_step : 1613, loss1 : 12.965009, loss2 : 18.692127
train_step : 1614, loss1 : 12.383995, loss2 : 13.869540
train_step : 1615, loss1 : 19.021265, loss2 : 16.879515
train_step : 1616, loss1 : 18.545887, loss2 : 15.006622
train_step : 1617, loss1 : 12.721449, loss2 : 24.277971
train_step : 1618, loss1 : 20.216696, loss2 : 24.522451
train_step : 1619, loss1 : 13.280370, loss2 : 19.140886
train_step : 1620, loss1 : 26.925327, loss2 : 14.839650
train_step : 1621, loss1 : 9.561119, loss2 : 22.964773
train_step : 1622, loss1 : 21.432587, loss2 : 18.337917
train_step : 1623, loss1 : 17.233955, loss2 : 16.188366
train_step : 1624, loss1 : 17.562069, loss2 : 9.498852
train_step : 1625, loss1 : 16.741163, loss2 : 22.845184
train_step : 1626, loss1 : 22.158840, loss2 : 18.236773
train_step : 1627, loss1 : 27.041557, loss2 : 18.315475
train_step : 1628, loss1 : 15.757015, loss2 : 24.485603
train_step : 1629, loss1 : 13.794057, loss2 : 14.690407
train_step : 1630, loss1 : 13.495764, loss2 : 7.926549
train_step : 1631, loss1 : 20.712395, loss2 : 15.551478
train_step : 1632, loss1 : 26.270510, loss2 : 13.411128
train_step : 1633, loss1 : 16.498325, loss2 : 11.038698
train_step : 1634, loss1 : 16.100712, loss2 : 9.194239
train_step : 1635, loss1 : 10.542398, loss2 : 15.521207
train_step : 1636, loss1 : 18.312590, loss2 : 26.183620
train_step : 1637, loss1 : 16.848656, loss2 : 9.986735
train_step : 1638, loss1 : 10.208759, loss2 : 13.696198
train_step : 1639, loss1 : 11.582403, loss2 : 16.628536
train_step : 1640, loss1 : 19.007347, loss2 : 10.902521
train_step : 1641, loss1 : 12.329421, loss2 : 13.922134
train_step : 1642, loss1 : 18.602444, loss2 : 13.568602
train_step : 1643, loss1 : 15.390583, loss2 : 19.629404
train_step : 1644, loss1 : 16.127907, loss2 : 15.164541
train_step : 1645, loss1 : 10.110796, loss2 : 26.890884
train_step : 1646, loss1 : 12.103852, loss2 : 19.615944
train_step : 1647, loss1 : 27.340532, loss2 : 13.366006
train_step : 1648, loss1 : 10.219214, loss2 : 6.757142
train_step : 1649, loss1 : 16.698921, loss2 : 31.140024
train_step : 1650, loss1 : 16.882626, loss2 : 11.073113
train_step : 1651, loss1 : 16.061825, loss2 : 17.879694
train_step : 1652, loss1 : 19.383497, loss2 : 11.521099
train_step : 1653, loss1 : 15.451301, loss2 : 21.651569
train_step : 1654, loss1 : 16.225245, loss2 : 17.193420
train_step : 1655, loss1 : 16.135077, loss2 : 20.679493
train_step : 1656, loss1 : 22.658318, loss2 : 10.506445
train_step : 1657, loss1 : 20.002285, loss2 : 8.709237
train_step : 1658, loss1 : 12.675398, loss2 : 20.676941
train_step : 1659, loss1 : 18.983902, loss2 : 16.035429
train_step : 1660, loss1 : 15.583515, loss2 : 34.050331
train_step : 1661, loss1 : 38.758591, loss2 : 19.423672
train_step : 1662, loss1 : 19.077698, loss2 : 21.430000
train_step : 1663, loss1 : 12.919690, loss2 : 14.396726
train_step : 1664, loss1 : 13.184298, loss2 : 19.631977
train_step : 1665, loss1 : 17.491745, loss2 : 19.103931
train_step : 1666, loss1 : 15.967715, loss2 : 14.163118
train_step : 1667, loss1 : 19.629599, loss2 : 32.210342
train_step : 1668, loss1 : 15.857859, loss2 : 21.280651
train_step : 1669, loss1 : 22.252275, loss2 : 14.064418
train_step : 1670, loss1 : 13.015387, loss2 : 14.690175
train_step : 1671, loss1 : 24.620226, loss2 : 20.066452
train_step : 1672, loss1 : 13.810303, loss2 : 16.009871
train_step : 1673, loss1 : 12.423668, loss2 : 20.273008
train_step : 1674, loss1 : 17.769659, loss2 : 22.052856
train_step : 1675, loss1 : 20.294428, loss2 : 20.364292
train_step : 1676, loss1 : 10.170690, loss2 : 17.438477
train_step : 1677, loss1 : 14.449593, loss2 : 13.122361
train_step : 1678, loss1 : 23.665318, loss2 : 17.526491
train_step : 1679, loss1 : 17.858725, loss2 : 24.761051
train_step : 1680, loss1 : 25.162392, loss2 : 15.866365
train_step : 1681, loss1 : 15.917919, loss2 : 17.553635
train_step : 1682, loss1 : 16.869078, loss2 : 14.536606
train_step : 1683, loss1 : 18.514671, loss2 : 21.667803
train_step : 1684, loss1 : 23.345530, loss2 : 26.837269
train_step : 1685, loss1 : 11.294253, loss2 : 23.992683
train_step : 1686, loss1 : 17.733852, loss2 : 15.189326
train_step : 1687, loss1 : 19.799856, loss2 : 22.566954
train_step : 1688, loss1 : 21.226088, loss2 : 18.545830
train_step : 1689, loss1 : 23.908318, loss2 : 24.660906
train_step : 1690, loss1 : 27.012156, loss2 : 17.172611
train_step : 1691, loss1 : 14.401291, loss2 : 10.725018
train_step : 1692, loss1 : 13.886154, loss2 : 9.934961
train_step : 1693, loss1 : 10.501305, loss2 : 16.659111
train_step : 1694, loss1 : 17.807789, loss2 : 27.590693
train_step : 1695, loss1 : 10.938833, loss2 : 26.385355
train_step : 1696, loss1 : 18.321941, loss2 : 19.038235
train_step : 1697, loss1 : 18.235931, loss2 : 12.581861
train_step : 1698, loss1 : 15.077039, loss2 : 15.143276
train_step : 1699, loss1 : 16.005505, loss2 : 22.720005
train_step : 1700, loss1 : 18.710743, loss2 : 15.430211
train_step : 1701, loss1 : 15.422287, loss2 : 26.477303
train_step : 1702, loss1 : 13.385521, loss2 : 13.185101
train_step : 1703, loss1 : 15.792286, loss2 : 21.400719
train_step : 1704, loss1 : 15.284697, loss2 : 21.945793
train_step : 1705, loss1 : 18.271955, loss2 : 19.391657
train_step : 1706, loss1 : 12.999980, loss2 : 24.040751
train_step : 1707, loss1 : 13.660805, loss2 : 27.672714
train_step : 1708, loss1 : 21.779385, loss2 : 18.773228
train_step : 1709, loss1 : 21.534075, loss2 : 27.635536
train_step : 1710, loss1 : 19.115520, loss2 : 18.353067
train_step : 1711, loss1 : 26.408218, loss2 : 23.905140
train_step : 1712, loss1 : 23.323151, loss2 : 30.708435
train_step : 1713, loss1 : 25.369223, loss2 : 18.248230
train_step : 1714, loss1 : 15.472742, loss2 : 15.409551
train_step : 1715, loss1 : 22.916643, loss2 : 14.525610
train_step : 1716, loss1 : 32.612427, loss2 : 16.961185
train_step : 1717, loss1 : 12.592503, loss2 : 27.352703
train_step : 1718, loss1 : 20.669540, loss2 : 23.527910
train_step : 1719, loss1 : 21.080826, loss2 : 20.177691
train_step : 1720, loss1 : 15.396679, loss2 : 13.267783
train_step : 1721, loss1 : 20.432209, loss2 : 18.105814
train_step : 1722, loss1 : 17.574295, loss2 : 18.135208
train_step : 1723, loss1 : 13.015854, loss2 : 22.917086
train_step : 1724, loss1 : 19.235239, loss2 : 17.735584
train_step : 1725, loss1 : 17.848579, loss2 : 12.719796
train_step : 1726, loss1 : 13.549326, loss2 : 20.052778
train_step : 1727, loss1 : 18.357651, loss2 : 15.965354
train_step : 1728, loss1 : 22.096008, loss2 : 12.933990
train_step : 1729, loss1 : 17.621801, loss2 : 16.284586
train_step : 1730, loss1 : 22.257084, loss2 : 24.034698
train_step : 1731, loss1 : 17.165058, loss2 : 21.963596
train_step : 1732, loss1 : 22.260220, loss2 : 11.562931
train_step : 1733, loss1 : 24.555176, loss2 : 19.663836
train_step : 1734, loss1 : 25.224010, loss2 : 15.591457
train_step : 1735, loss1 : 15.517745, loss2 : 27.704762
train_step : 1736, loss1 : 17.250050, loss2 : 16.532619
train_step : 1737, loss1 : 21.372816, loss2 : 11.947011
train_step : 1738, loss1 : 16.049696, loss2 : 18.267397
train_step : 1739, loss1 : 18.370346, loss2 : 13.840830
train_step : 1740, loss1 : 22.328133, loss2 : 20.875053
train_step : 1741, loss1 : 26.261536, loss2 : 11.580973
train_step : 1742, loss1 : 16.514088, loss2 : 21.571274
train_step : 1743, loss1 : 16.721928, loss2 : 18.604057
train_step : 1744, loss1 : 13.623678, loss2 : 24.373055
train_step : 1745, loss1 : 12.412580, loss2 : 29.011339
train_step : 1746, loss1 : 27.091381, loss2 : 23.591152
train_step : 1747, loss1 : 17.532463, loss2 : 31.961517
train_step : 1748, loss1 : 14.585960, loss2 : 16.705658
train_step : 1749, loss1 : 25.296154, loss2 : 20.946693
train_step : 1750, loss1 : 17.896183, loss2 : 17.666559
train_step : 1751, loss1 : 12.439196, loss2 : 14.134752
train_step : 1752, loss1 : 14.431772, loss2 : 26.868732
train_step : 1753, loss1 : 23.271732, loss2 : 21.194368
train_step : 1754, loss1 : 15.596058, loss2 : 23.650030
train_step : 1755, loss1 : 15.131218, loss2 : 22.430548
train_step : 1756, loss1 : 12.352018, loss2 : 11.461206
train_step : 1757, loss1 : 18.942017, loss2 : 12.612313
train_step : 1758, loss1 : 13.944943, loss2 : 19.276531
train_step : 1759, loss1 : 18.398544, loss2 : 20.906273
train_step : 1760, loss1 : 18.015314, loss2 : 14.541195
train_step : 1761, loss1 : 17.463243, loss2 : 12.734018
train_step : 1762, loss1 : 25.083321, loss2 : 23.434956
train_step : 1763, loss1 : 15.867072, loss2 : 18.975492
train_step : 1764, loss1 : 28.855598, loss2 : 21.462133
train_step : 1765, loss1 : 12.801562, loss2 : 12.907457
train_step : 1766, loss1 : 16.237535, loss2 : 11.110798
train_step : 1767, loss1 : 13.707502, loss2 : 19.593246
train_step : 1768, loss1 : 18.308846, loss2 : 13.446959
train_step : 1769, loss1 : 12.536290, loss2 : 16.274490
train_step : 1770, loss1 : 14.273823, loss2 : 22.194799
train_step : 1771, loss1 : 11.100878, loss2 : 16.468189
train_step : 1772, loss1 : 26.383379, loss2 : 14.116615
train_step : 1773, loss1 : 26.894197, loss2 : 14.903227
train_step : 1774, loss1 : 12.393552, loss2 : 14.441647
train_step : 1775, loss1 : 11.716002, loss2 : 15.303788
train_step : 1776, loss1 : 13.119571, loss2 : 10.455107
train_step : 1777, loss1 : 17.154053, loss2 : 13.444189
train_step : 1778, loss1 : 7.538165, loss2 : 10.910238
train_step : 1779, loss1 : 23.393259, loss2 : 15.249667
train_step : 1780, loss1 : 16.258205, loss2 : 11.497575
train_step : 1781, loss1 : 18.838795, loss2 : 13.410959
train_step : 1782, loss1 : 13.887484, loss2 : 15.702927
train_step : 1783, loss1 : 10.059771, loss2 : 18.347435
train_step : 1784, loss1 : 11.162327, loss2 : 19.403479
train_step : 1785, loss1 : 13.922228, loss2 : 23.113983
train_step : 1786, loss1 : 17.942413, loss2 : 15.866913
train_step : 1787, loss1 : 20.376015, loss2 : 9.686276
train_step : 1788, loss1 : 17.105896, loss2 : 15.145826
train_step : 1789, loss1 : 13.456498, loss2 : 22.883759
train_step : 1790, loss1 : 20.590935, loss2 : 17.056999
train_step : 1791, loss1 : 18.154230, loss2 : 23.778099
train_step : 1792, loss1 : 24.859051, loss2 : 17.991365
train_step : 1793, loss1 : 17.574810, loss2 : 20.059616
train_step : 1794, loss1 : 14.243758, loss2 : 16.866224
train_step : 1795, loss1 : 20.712242, loss2 : 10.263661
train_step : 1796, loss1 : 15.880529, loss2 : 13.902145
train_step : 1797, loss1 : 17.777332, loss2 : 18.875801
train_step : 1798, loss1 : 23.253056, loss2 : 22.683050
train_step : 1799, loss1 : 14.829039, loss2 : 15.088915
train_step : 1800, loss1 : 28.822670, loss2 : 15.592533
train_step : 1801, loss1 : 17.322943, loss2 : 18.314415
train_step : 1802, loss1 : 13.033234, loss2 : 17.420504
train_step : 1803, loss1 : 14.127394, loss2 : 19.641045
train_step : 1804, loss1 : 16.021111, loss2 : 12.901325
train_step : 1805, loss1 : 18.948896, loss2 : 19.490112
train_step : 1806, loss1 : 10.333517, loss2 : 19.631802
train_step : 1807, loss1 : 12.870599, loss2 : 18.802731
train_step : 1808, loss1 : 18.621054, loss2 : 19.665455
train_step : 1809, loss1 : 21.011246, loss2 : 10.023317
train_step : 1810, loss1 : 10.238205, loss2 : 18.192078
train_step : 1811, loss1 : 22.694149, loss2 : 12.736258
train_step : 1812, loss1 : 6.772786, loss2 : 20.130264
train_step : 1813, loss1 : 16.359041, loss2 : 10.758564
train_step : 1814, loss1 : 12.019899, loss2 : 20.029196
train_step : 1815, loss1 : 9.649290, loss2 : 18.053467
train_step : 1816, loss1 : 10.896802, loss2 : 26.191502
train_step : 1817, loss1 : 16.771130, loss2 : 12.061354
train_step : 1818, loss1 : 19.583416, loss2 : 14.823895
train_step : 1819, loss1 : 18.274876, loss2 : 11.647871
train_step : 1820, loss1 : 17.307039, loss2 : 23.232019
train_step : 1821, loss1 : 20.873800, loss2 : 19.926491
train_step : 1822, loss1 : 14.572560, loss2 : 20.290453
train_step : 1823, loss1 : 14.073908, loss2 : 11.684212
train_step : 1824, loss1 : 14.937672, loss2 : 15.856240
train_step : 1825, loss1 : 14.523548, loss2 : 21.783833
train_step : 1826, loss1 : 14.755472, loss2 : 14.565581
train_step : 1827, loss1 : 23.412867, loss2 : 25.616995
train_step : 1828, loss1 : 17.717588, loss2 : 13.899611
train_step : 1829, loss1 : 11.965248, loss2 : 31.478811
train_step : 1830, loss1 : 18.013847, loss2 : 23.937000
train_step : 1831, loss1 : 17.721073, loss2 : 8.754219
train_step : 1832, loss1 : 22.468620, loss2 : 17.835796
train_step : 1833, loss1 : 23.879875, loss2 : 15.185865
train_step : 1834, loss1 : 16.771908, loss2 : 24.432705
train_step : 1835, loss1 : 17.119457, loss2 : 11.964968
train_step : 1836, loss1 : 11.084301, loss2 : 14.128122
train_step : 1837, loss1 : 27.095520, loss2 : 17.250202
train_step : 1838, loss1 : 20.639717, loss2 : 17.887508
train_step : 1839, loss1 : 19.908325, loss2 : 24.542587
train_step : 1840, loss1 : 13.880716, loss2 : 18.188698
train_step : 1841, loss1 : 13.865389, loss2 : 13.434977
train_step : 1842, loss1 : 13.636285, loss2 : 4.987912
train_step : 1843, loss1 : 18.495632, loss2 : 11.134905
train_step : 1844, loss1 : 6.557792, loss2 : 17.734814
train_step : 1845, loss1 : 32.196781, loss2 : 23.120558
train_step : 1846, loss1 : 14.043880, loss2 : 15.827955
train_step : 1847, loss1 : 13.390229, loss2 : 8.809689
train_step : 1848, loss1 : 15.557466, loss2 : 13.585663
train_step : 1849, loss1 : 27.566208, loss2 : 8.045164
train_step : 1850, loss1 : 24.031025, loss2 : 20.214935
train_step : 1851, loss1 : 33.221294, loss2 : 13.094227
train_step : 1852, loss1 : 14.746103, loss2 : 12.990709
train_step : 1853, loss1 : 17.732834, loss2 : 40.259884
train_step : 1854, loss1 : 26.761564, loss2 : 19.482002
train_step : 1855, loss1 : 12.249006, loss2 : 18.016752
train_step : 1856, loss1 : 14.672899, loss2 : 15.121137
train_step : 1857, loss1 : 13.423225, loss2 : 16.980227
train_step : 1858, loss1 : 17.848385, loss2 : 17.973568
train_step : 1859, loss1 : 14.165462, loss2 : 18.275728
train_step : 1860, loss1 : 11.366305, loss2 : 17.018608
train_step : 1861, loss1 : 10.684633, loss2 : 23.820820
train_step : 1862, loss1 : 24.286335, loss2 : 12.134642
train_step : 1863, loss1 : 15.715981, loss2 : 11.284657
train_step : 1864, loss1 : 14.512042, loss2 : 11.554562
train_step : 1865, loss1 : 17.499981, loss2 : 15.879047
train_step : 1866, loss1 : 13.443283, loss2 : 23.013559
train_step : 1867, loss1 : 23.212652, loss2 : 16.146561
train_step : 1868, loss1 : 18.987959, loss2 : 8.392556
train_step : 1869, loss1 : 15.370569, loss2 : 26.533152
train_step : 1870, loss1 : 19.997839, loss2 : 14.330408
train_step : 1871, loss1 : 21.011108, loss2 : 20.982426
train_step : 1872, loss1 : 39.306461, loss2 : 27.477821
train_step : 1873, loss1 : 6.945135, loss2 : 17.042759
train_step : 1874, loss1 : 26.933079, loss2 : 22.463371
train_step : 1875, loss1 : 25.566414, loss2 : 15.119522
train_step : 1876, loss1 : 22.064034, loss2 : 17.884296
train_step : 1877, loss1 : 7.321965, loss2 : 14.332635
train_step : 1878, loss1 : 13.242584, loss2 : 16.733776
train_step : 1879, loss1 : 25.608929, loss2 : 12.304930
train_step : 1880, loss1 : 20.604801, loss2 : 28.307129
train_step : 1881, loss1 : 15.195981, loss2 : 16.054298
train_step : 1882, loss1 : 24.996372, loss2 : 14.581717
train_step : 1883, loss1 : 24.873280, loss2 : 22.229345
train_step : 1884, loss1 : 17.054811, loss2 : 21.265144
train_step : 1885, loss1 : 30.973461, loss2 : 21.612518
train_step : 1886, loss1 : 9.765558, loss2 : 12.665231
train_step : 1887, loss1 : 14.105110, loss2 : 16.717215
train_step : 1888, loss1 : 25.792562, loss2 : 10.069937
train_step : 1889, loss1 : 15.655137, loss2 : 19.721390
train_step : 1890, loss1 : 9.251512, loss2 : 14.611607
train_step : 1891, loss1 : 12.559750, loss2 : 10.215717
train_step : 1892, loss1 : 18.294601, loss2 : 18.559971
train_step : 1893, loss1 : 15.739366, loss2 : 16.343601
train_step : 1894, loss1 : 20.712870, loss2 : 11.372765
train_step : 1895, loss1 : 24.397161, loss2 : 26.766958
train_step : 1896, loss1 : 15.718140, loss2 : 17.331009
train_step : 1897, loss1 : 16.674509, loss2 : 18.166817
train_step : 1898, loss1 : 14.935608, loss2 : 16.076790
train_step : 1899, loss1 : 11.512069, loss2 : 15.980008
train_step : 1900, loss1 : 12.350447, loss2 : 19.793415
train_step : 1901, loss1 : 12.044991, loss2 : 25.473692
train_step : 1902, loss1 : 25.975327, loss2 : 15.105671
train_step : 1903, loss1 : 10.398891, loss2 : 13.944378
train_step : 1904, loss1 : 17.142076, loss2 : 17.472231
train_step : 1905, loss1 : 23.917961, loss2 : 20.749321
train_step : 1906, loss1 : 22.855980, loss2 : 9.756482
train_step : 1907, loss1 : 21.882412, loss2 : 17.522242
train_step : 1908, loss1 : 14.056503, loss2 : 18.572926
train_step : 1909, loss1 : 15.174896, loss2 : 28.326771
train_step : 1910, loss1 : 13.883964, loss2 : 11.658569
train_step : 1911, loss1 : 26.371136, loss2 : 18.159910
train_step : 1912, loss1 : 12.903622, loss2 : 21.281614
train_step : 1913, loss1 : 22.705620, loss2 : 22.352055
train_step : 1914, loss1 : 14.822736, loss2 : 21.337740
train_step : 1915, loss1 : 12.467227, loss2 : 14.794703
train_step : 1916, loss1 : 11.860041, loss2 : 19.499922
train_step : 1917, loss1 : 16.132702, loss2 : 19.431950
train_step : 1918, loss1 : 14.013800, loss2 : 17.363361
train_step : 1919, loss1 : 16.593302, loss2 : 17.803820
train_step : 1920, loss1 : 14.417603, loss2 : 18.228878
train_step : 1921, loss1 : 15.352748, loss2 : 11.750828
train_step : 1922, loss1 : 17.868752, loss2 : 15.740433
train_step : 1923, loss1 : 21.420223, loss2 : 15.395044
train_step : 1924, loss1 : 15.014014, loss2 : 29.854847
train_step : 1925, loss1 : 13.625504, loss2 : 25.753635
train_step : 1926, loss1 : 11.363373, loss2 : 19.271887
train_step : 1927, loss1 : 13.309017, loss2 : 12.364824
train_step : 1928, loss1 : 14.546569, loss2 : 21.544117
train_step : 1929, loss1 : 15.693549, loss2 : 15.155393
train_step : 1930, loss1 : 18.467535, loss2 : 17.464333
train_step : 1931, loss1 : 19.739498, loss2 : 11.328281
train_step : 1932, loss1 : 23.456404, loss2 : 12.384880
train_step : 1933, loss1 : 29.918179, loss2 : 29.240305
train_step : 1934, loss1 : 23.815487, loss2 : 22.074928
train_step : 1935, loss1 : 12.941307, loss2 : 23.424137
train_step : 1936, loss1 : 17.337881, loss2 : 20.145889
train_step : 1937, loss1 : 13.887936, loss2 : 12.195900
train_step : 1938, loss1 : 9.058212, loss2 : 16.966555
train_step : 1939, loss1 : 12.380882, loss2 : 21.789764
train_step : 1940, loss1 : 26.953709, loss2 : 14.643091
train_step : 1941, loss1 : 17.746826, loss2 : 23.446836
train_step : 1942, loss1 : 17.704113, loss2 : 27.411304
train_step : 1943, loss1 : 20.591124, loss2 : 12.061921
train_step : 1944, loss1 : 10.411079, loss2 : 15.213964
train_step : 1945, loss1 : 15.657106, loss2 : 20.358107
train_step : 1946, loss1 : 16.009508, loss2 : 19.717960
train_step : 1947, loss1 : 22.077616, loss2 : 16.182388
train_step : 1948, loss1 : 22.625572, loss2 : 18.189676
train_step : 1949, loss1 : 23.035875, loss2 : 16.790512
train_step : 1950, loss1 : 12.650766, loss2 : 17.250679
train_step : 1951, loss1 : 11.613346, loss2 : 13.265129
train_step : 1952, loss1 : 21.630939, loss2 : 19.788633
train_step : 1953, loss1 : 19.416245, loss2 : 14.496944
train_step : 1954, loss1 : 20.505844, loss2 : 13.020595
train_step : 1955, loss1 : 22.061827, loss2 : 18.976538
train_step : 1956, loss1 : 15.948755, loss2 : 14.334988
train_step : 1957, loss1 : 15.982177, loss2 : 12.869778
train_step : 1958, loss1 : 23.362288, loss2 : 20.911081
train_step : 1959, loss1 : 11.616318, loss2 : 22.047035
train_step : 1960, loss1 : 20.892540, loss2 : 12.750241
train_step : 1961, loss1 : 7.891747, loss2 : 28.206888
train_step : 1962, loss1 : 8.047465, loss2 : 13.375183
train_step : 1963, loss1 : 17.455814, loss2 : 22.867313
train_step : 1964, loss1 : 17.193714, loss2 : 14.386168
train_step : 1965, loss1 : 18.088760, loss2 : 14.171036
train_step : 1966, loss1 : 7.034211, loss2 : 10.335198
train_step : 1967, loss1 : 16.156342, loss2 : 7.545925
train_step : 1968, loss1 : 24.146675, loss2 : 16.872137
train_step : 1969, loss1 : 13.258208, loss2 : 22.132759
train_step : 1970, loss1 : 9.071243, loss2 : 17.789345
train_step : 1971, loss1 : 22.961380, loss2 : 17.564222
train_step : 1972, loss1 : 18.679138, loss2 : 14.130871
train_step : 1973, loss1 : 20.124260, loss2 : 25.342503
train_step : 1974, loss1 : 8.213965, loss2 : 8.778557
train_step : 1975, loss1 : 22.472971, loss2 : 20.518099
train_step : 1976, loss1 : 14.256195, loss2 : 14.984654
train_step : 1977, loss1 : 16.945900, loss2 : 13.423502
train_step : 1978, loss1 : 20.616985, loss2 : 25.970144
train_step : 1979, loss1 : 17.405382, loss2 : 18.541157
train_step : 1980, loss1 : 14.001469, loss2 : 10.472082
train_step : 1981, loss1 : 21.559017, loss2 : 13.094454
train_step : 1982, loss1 : 15.725600, loss2 : 29.972713
train_step : 1983, loss1 : 13.131735, loss2 : 15.395597
train_step : 1984, loss1 : 23.343212, loss2 : 19.239948
train_step : 1985, loss1 : 9.175724, loss2 : 11.669270
train_step : 1986, loss1 : 14.485680, loss2 : 12.594158
train_step : 1987, loss1 : 19.376629, loss2 : 18.166891
train_step : 1988, loss1 : 14.330164, loss2 : 13.685511
train_step : 1989, loss1 : 14.719609, loss2 : 8.911305
train_step : 1990, loss1 : 20.638605, loss2 : 20.242096
train_step : 1991, loss1 : 11.467909, loss2 : 23.625494
train_step : 1992, loss1 : 16.212337, loss2 : 15.477712
train_step : 1993, loss1 : 29.224583, loss2 : 19.350821
train_step : 1994, loss1 : 10.068764, loss2 : 13.769646
train_step : 1995, loss1 : 24.550739, loss2 : 12.234524
train_step : 1996, loss1 : 13.468102, loss2 : 21.232225
train_step : 1997, loss1 : 18.028252, loss2 : 17.594849
train_step : 1998, loss1 : 29.991846, loss2 : 9.089874
train_step : 1999, loss1 : 22.975658, loss2 : 22.605373
train_step : 2000, loss1 : 17.237743, loss2 : 9.410440
train_step : 2001, loss1 : 17.737080, loss2 : 12.285064
train_step : 2002, loss1 : 18.139341, loss2 : 19.310993
train_step : 2003, loss1 : 21.517000, loss2 : 18.246902
train_step : 2004, loss1 : 15.386637, loss2 : 24.852564
train_step : 2005, loss1 : 24.924778, loss2 : 13.196569
train_step : 2006, loss1 : 19.359524, loss2 : 20.358412
train_step : 2007, loss1 : 20.496220, loss2 : 9.620784
train_step : 2008, loss1 : 22.941525, loss2 : 8.529085
train_step : 2009, loss1 : 16.108273, loss2 : 15.963814
train_step : 2010, loss1 : 14.158954, loss2 : 12.156298
train_step : 2011, loss1 : 14.898647, loss2 : 24.194668
train_step : 2012, loss1 : 17.320953, loss2 : 13.851315
train_step : 2013, loss1 : 13.973540, loss2 : 14.493579
train_step : 2014, loss1 : 27.323038, loss2 : 17.317938
train_step : 2015, loss1 : 16.707970, loss2 : 18.305681
train_step : 2016, loss1 : 20.445721, loss2 : 19.554615
train_step : 2017, loss1 : 22.142197, loss2 : 23.868176
train_step : 2018, loss1 : 25.170710, loss2 : 33.190418
train_step : 2019, loss1 : 16.142729, loss2 : 14.858715
train_step : 2020, loss1 : 19.720592, loss2 : 6.840654
train_step : 2021, loss1 : 9.554111, loss2 : 28.189850
train_step : 2022, loss1 : 24.819490, loss2 : 22.056416
train_step : 2023, loss1 : 14.920910, loss2 : 19.660849
train_step : 2024, loss1 : 16.795673, loss2 : 14.201683
train_step : 2025, loss1 : 20.330235, loss2 : 17.663998
train_step : 2026, loss1 : 17.271725, loss2 : 26.900621
train_step : 2027, loss1 : 13.105083, loss2 : 19.471092
train_step : 2028, loss1 : 15.638748, loss2 : 23.846737
train_step : 2029, loss1 : 20.548016, loss2 : 16.564949
train_step : 2030, loss1 : 19.892368, loss2 : 17.334831
train_step : 2031, loss1 : 16.497898, loss2 : 23.428545
train_step : 2032, loss1 : 18.119059, loss2 : 18.659828
train_step : 2033, loss1 : 12.653664, loss2 : 15.466707
train_step : 2034, loss1 : 21.551918, loss2 : 10.225086
train_step : 2035, loss1 : 22.547256, loss2 : 17.571829
train_step : 2036, loss1 : 26.601303, loss2 : 19.202721
train_step : 2037, loss1 : 26.180340, loss2 : 15.223501
train_step : 2038, loss1 : 12.793873, loss2 : 21.100822
train_step : 2039, loss1 : 14.816661, loss2 : 23.961430
train_step : 2040, loss1 : 21.310886, loss2 : 37.494385
train_step : 2041, loss1 : 23.362745, loss2 : 15.334691
train_step : 2042, loss1 : 13.330877, loss2 : 24.532993
train_step : 2043, loss1 : 20.536552, loss2 : 10.502278
train_step : 2044, loss1 : 13.133018, loss2 : 22.988066
train_step : 2045, loss1 : 20.409651, loss2 : 29.249130
train_step : 2046, loss1 : 19.887436, loss2 : 22.066792
train_step : 2047, loss1 : 7.807320, loss2 : 21.194637
train_step : 2048, loss1 : 22.300739, loss2 : 9.663225
train_step : 2049, loss1 : 6.404205, loss2 : 27.539185
train_step : 2050, loss1 : 21.067898, loss2 : 21.604605
train_step : 2051, loss1 : 23.159084, loss2 : 9.805466
train_step : 2052, loss1 : 25.443018, loss2 : 12.101852
train_step : 2053, loss1 : 58.165943, loss2 : 25.232548
train_step : 2054, loss1 : 28.811699, loss2 : 18.335016
train_step : 2055, loss1 : 21.653015, loss2 : 16.723530
train_step : 2056, loss1 : 20.705204, loss2 : 16.308430
train_step : 2057, loss1 : 8.701234, loss2 : 15.906537
train_step : 2058, loss1 : 19.212503, loss2 : 21.089081
train_step : 2059, loss1 : 28.841570, loss2 : 24.112505
train_step : 2060, loss1 : 20.159500, loss2 : 23.353535
train_step : 2061, loss1 : 15.050735, loss2 : 27.769171
train_step : 2062, loss1 : 20.837675, loss2 : 13.649267
train_step : 2063, loss1 : 26.202881, loss2 : 15.229374
train_step : 2064, loss1 : 13.832972, loss2 : 18.622723
train_step : 2065, loss1 : 28.619274, loss2 : 20.275002
train_step : 2066, loss1 : 25.202108, loss2 : 11.420546
train_step : 2067, loss1 : 8.550250, loss2 : 18.521053
train_step : 2068, loss1 : 12.296688, loss2 : 16.815863
train_step : 2069, loss1 : 10.280226, loss2 : 12.088240
train_step : 2070, loss1 : 24.878887, loss2 : 17.719910
train_step : 2071, loss1 : 31.039059, loss2 : 28.535862
train_step : 2072, loss1 : 14.788397, loss2 : 11.229199
train_step : 2073, loss1 : 16.953207, loss2 : 17.438980
train_step : 2074, loss1 : 12.123743, loss2 : 19.246462
train_step : 2075, loss1 : 24.055185, loss2 : 8.703772
train_step : 2076, loss1 : 15.251177, loss2 : 28.612110
train_step : 2077, loss1 : 16.012426, loss2 : 21.266079
train_step : 2078, loss1 : 13.550063, loss2 : 17.169865
train_step : 2079, loss1 : 11.281821, loss2 : 14.764057
train_step : 2080, loss1 : 14.684839, loss2 : 25.951267
train_step : 2081, loss1 : 9.845469, loss2 : 12.028151
train_step : 2082, loss1 : 11.708834, loss2 : 13.805717
train_step : 2083, loss1 : 9.718042, loss2 : 15.537417
train_step : 2084, loss1 : 9.967754, loss2 : 19.243879
train_step : 2085, loss1 : 24.880463, loss2 : 9.541183
train_step : 2086, loss1 : 6.849575, loss2 : 13.499624
train_step : 2087, loss1 : 21.140347, loss2 : 17.735254
train_step : 2088, loss1 : 24.561993, loss2 : 19.944286
train_step : 2089, loss1 : 20.776798, loss2 : 15.429914
train_step : 2090, loss1 : 28.338394, loss2 : 16.882645
train_step : 2091, loss1 : 22.158413, loss2 : 22.759308
train_step : 2092, loss1 : 26.041035, loss2 : 22.082809
train_step : 2093, loss1 : 18.720753, loss2 : 26.208921
train_step : 2094, loss1 : 16.681580, loss2 : 24.614750
train_step : 2095, loss1 : 21.717224, loss2 : 27.690863
train_step : 2096, loss1 : 15.437033, loss2 : 18.519751
train_step : 2097, loss1 : 30.780745, loss2 : 14.147586
train_step : 2098, loss1 : 16.660767, loss2 : 17.557213
train_step : 2099, loss1 : 21.760460, loss2 : 13.799088
train_step : 2100, loss1 : 11.522547, loss2 : 32.403858
train_step : 2101, loss1 : 24.476879, loss2 : 28.526028
train_step : 2102, loss1 : 22.919281, loss2 : 21.567106
train_step : 2103, loss1 : 22.842487, loss2 : 14.377095
train_step : 2104, loss1 : 10.402161, loss2 : 11.867988
train_step : 2105, loss1 : 11.390463, loss2 : 20.250076
train_step : 2106, loss1 : 18.110645, loss2 : 12.807989
train_step : 2107, loss1 : 14.486935, loss2 : 15.910602
train_step : 2108, loss1 : 34.801094, loss2 : 25.281357
train_step : 2109, loss1 : 20.579233, loss2 : 17.906796
train_step : 2110, loss1 : 16.472805, loss2 : 26.290348
train_step : 2111, loss1 : 14.239990, loss2 : 23.446060
train_step : 2112, loss1 : 14.625813, loss2 : 19.765564
train_step : 2113, loss1 : 32.222332, loss2 : 17.893559
train_step : 2114, loss1 : 13.642075, loss2 : 16.697731
train_step : 2115, loss1 : 18.685564, loss2 : 10.997501
train_step : 2116, loss1 : 22.560682, loss2 : 6.748307
train_step : 2117, loss1 : 28.461512, loss2 : 18.675171
train_step : 2118, loss1 : 16.036673, loss2 : 17.051861
train_step : 2119, loss1 : 22.489971, loss2 : 26.701977
train_step : 2120, loss1 : 13.948333, loss2 : 13.422001
train_step : 2121, loss1 : 13.593118, loss2 : 27.730267
train_step : 2122, loss1 : 11.689090, loss2 : 25.589378
train_step : 2123, loss1 : 23.575678, loss2 : 13.279661
train_step : 2124, loss1 : 15.909622, loss2 : 14.285312
train_step : 2125, loss1 : 19.149954, loss2 : 19.874472
train_step : 2126, loss1 : 17.322437, loss2 : 13.432305
train_step : 2127, loss1 : 14.457987, loss2 : 18.521585
train_step : 2128, loss1 : 19.896053, loss2 : 16.315403
train_step : 2129, loss1 : 24.174526, loss2 : 12.244281
train_step : 2130, loss1 : 15.179078, loss2 : 15.812555
train_step : 2131, loss1 : 19.027588, loss2 : 19.536829
train_step : 2132, loss1 : 10.509872, loss2 : 13.969765
train_step : 2133, loss1 : 14.335449, loss2 : 12.080099
train_step : 2134, loss1 : 20.470648, loss2 : 14.554245
train_step : 2135, loss1 : 21.556965, loss2 : 16.403112
train_step : 2136, loss1 : 17.917366, loss2 : 23.732962
train_step : 2137, loss1 : 13.964277, loss2 : 20.662756
train_step : 2138, loss1 : 4.992049, loss2 : 20.838963
train_step : 2139, loss1 : 11.730314, loss2 : 26.812422
train_step : 2140, loss1 : 13.233952, loss2 : 21.985981
train_step : 2141, loss1 : 27.266701, loss2 : 14.325486
train_step : 2142, loss1 : 17.106377, loss2 : 23.145437
train_step : 2143, loss1 : 10.559652, loss2 : 11.838517
train_step : 2144, loss1 : 16.857378, loss2 : 17.387299
train_step : 2145, loss1 : 19.016354, loss2 : 19.776356
train_step : 2146, loss1 : 27.089760, loss2 : 11.466516
train_step : 2147, loss1 : 22.160191, loss2 : 13.187767
train_step : 2148, loss1 : 8.621599, loss2 : 15.558649
train_step : 2149, loss1 : 13.672264, loss2 : 15.679713
train_step : 2150, loss1 : 19.802589, loss2 : 8.808016
train_step : 2151, loss1 : 19.794975, loss2 : 12.154152
train_step : 2152, loss1 : 16.159954, loss2 : 21.385624
train_step : 2153, loss1 : 30.107094, loss2 : 16.476032
train_step : 2154, loss1 : 16.317165, loss2 : 26.102135
train_step : 2155, loss1 : 10.601959, loss2 : 15.036475
train_step : 2156, loss1 : 15.967945, loss2 : 13.040474
train_step : 2157, loss1 : 11.526583, loss2 : 23.055220
train_step : 2158, loss1 : 15.853033, loss2 : 13.253874
train_step : 2159, loss1 : 11.497840, loss2 : 16.683886
train_step : 2160, loss1 : 17.734398, loss2 : 9.572869
train_step : 2161, loss1 : 17.483833, loss2 : 19.532928
train_step : 2162, loss1 : 21.415371, loss2 : 12.739061
train_step : 2163, loss1 : 17.397530, loss2 : 21.829565
train_step : 2164, loss1 : 17.898762, loss2 : 16.012920
train_step : 2165, loss1 : 11.596924, loss2 : 14.342100
train_step : 2166, loss1 : 8.835119, loss2 : 16.061518
train_step : 2167, loss1 : 18.869543, loss2 : 21.229248
train_step : 2168, loss1 : 20.077578, loss2 : 8.158782
train_step : 2169, loss1 : 17.048067, loss2 : 10.486931
train_step : 2170, loss1 : 16.199091, loss2 : 14.856137
train_step : 2171, loss1 : 16.925251, loss2 : 12.257151
train_step : 2172, loss1 : 12.040938, loss2 : 9.543924
train_step : 2173, loss1 : 11.447454, loss2 : 21.753458
train_step : 2174, loss1 : 18.960104, loss2 : 15.858985
train_step : 2175, loss1 : 27.379152, loss2 : 14.716186
train_step : 2176, loss1 : 19.455317, loss2 : 15.256407
train_step : 2177, loss1 : 9.206937, loss2 : 16.879604
train_step : 2178, loss1 : 14.623230, loss2 : 14.952281
train_step : 2179, loss1 : 20.666180, loss2 : 15.303391
train_step : 2180, loss1 : 9.034489, loss2 : 13.447025
train_step : 2181, loss1 : 14.612279, loss2 : 14.647799
train_step : 2182, loss1 : 23.084215, loss2 : 26.933125
train_step : 2183, loss1 : 21.010208, loss2 : 10.956748
train_step : 2184, loss1 : 28.324638, loss2 : 11.478312
train_step : 2185, loss1 : 10.286691, loss2 : 12.697830
train_step : 2186, loss1 : 23.399197, loss2 : 16.952435
train_step : 2187, loss1 : 13.320328, loss2 : 34.224575
train_step : 2188, loss1 : 9.985708, loss2 : 27.057289
train_step : 2189, loss1 : 22.482056, loss2 : 7.432772
train_step : 2190, loss1 : 17.440590, loss2 : 19.787701
train_step : 2191, loss1 : 13.876247, loss2 : 15.392666
train_step : 2192, loss1 : 29.101898, loss2 : 10.120806
train_step : 2193, loss1 : 22.233425, loss2 : 20.570047
train_step : 2194, loss1 : 23.941093, loss2 : 12.516914
train_step : 2195, loss1 : 24.508718, loss2 : 18.424171
train_step : 2196, loss1 : 21.767385, loss2 : 7.872837
train_step : 2197, loss1 : 16.433651, loss2 : 16.292061
train_step : 2198, loss1 : 16.639568, loss2 : 11.311913
train_step : 2199, loss1 : 9.627661, loss2 : 20.163576
train_step : 2200, loss1 : 11.138124, loss2 : 23.084435
train_step : 2201, loss1 : 18.550022, loss2 : 21.931866
train_step : 2202, loss1 : 10.363626, loss2 : 15.253857
train_step : 2203, loss1 : 13.053537, loss2 : 14.596834
train_step : 2204, loss1 : 22.909695, loss2 : 22.348209
train_step : 2205, loss1 : 12.001810, loss2 : 20.434254
train_step : 2206, loss1 : 28.865921, loss2 : 15.027594
train_step : 2207, loss1 : 21.324631, loss2 : 10.423742
train_step : 2208, loss1 : 13.534123, loss2 : 11.027485
train_step : 2209, loss1 : 16.632790, loss2 : 17.568768
train_step : 2210, loss1 : 12.565681, loss2 : 12.113747
train_step : 2211, loss1 : 20.813705, loss2 : 16.290085
train_step : 2212, loss1 : 18.349464, loss2 : 19.330622
train_step : 2213, loss1 : 13.051660, loss2 : 13.141511
train_step : 2214, loss1 : 14.013378, loss2 : 18.864225
train_step : 2215, loss1 : 12.649485, loss2 : 20.718605
train_step : 2216, loss1 : 25.925419, loss2 : 15.557027
train_step : 2217, loss1 : 24.867525, loss2 : 13.115721
train_step : 2218, loss1 : 20.964142, loss2 : 7.140103
train_step : 2219, loss1 : 7.245915, loss2 : 17.896343
train_step : 2220, loss1 : 12.798737, loss2 : 5.987875
train_step : 2221, loss1 : 9.751202, loss2 : 12.592270
train_step : 2222, loss1 : 20.503593, loss2 : 24.607347
train_step : 2223, loss1 : 23.256962, loss2 : 10.953238
train_step : 2224, loss1 : 19.738056, loss2 : 20.344803
train_step : 2225, loss1 : 10.021975, loss2 : 14.129093
train_step : 2226, loss1 : 13.751400, loss2 : 13.529718
train_step : 2227, loss1 : 12.708541, loss2 : 19.789982
train_step : 2228, loss1 : 18.348465, loss2 : 31.930382
train_step : 2229, loss1 : 12.228792, loss2 : 9.081320
train_step : 2230, loss1 : 18.105074, loss2 : 18.611900
train_step : 2231, loss1 : 19.626064, loss2 : 14.695273
train_step : 2232, loss1 : 13.533522, loss2 : 23.702913
train_step : 2233, loss1 : 16.457335, loss2 : 18.455040
train_step : 2234, loss1 : 26.511288, loss2 : 11.777840
train_step : 2235, loss1 : 17.374811, loss2 : 19.309856
train_step : 2236, loss1 : 29.140429, loss2 : 16.881113
train_step : 2237, loss1 : 7.955785, loss2 : 15.964349
train_step : 2238, loss1 : 23.756664, loss2 : 19.968227
train_step : 2239, loss1 : 14.727905, loss2 : 9.089142
train_step : 2240, loss1 : 15.904828, loss2 : 18.947067
train_step : 2241, loss1 : 28.055546, loss2 : 13.974783
train_step : 2242, loss1 : 15.087143, loss2 : 15.865579
train_step : 2243, loss1 : 10.624860, loss2 : 17.417793
train_step : 2244, loss1 : 19.741444, loss2 : 19.715483
train_step : 2245, loss1 : 21.192280, loss2 : 15.382219
train_step : 2246, loss1 : 25.746576, loss2 : 15.566820
train_step : 2247, loss1 : 30.521259, loss2 : 23.890709
train_step : 2248, loss1 : 13.403332, loss2 : 25.917368
train_step : 2249, loss1 : 26.579830, loss2 : 18.619171
train_step : 2250, loss1 : 26.133499, loss2 : 21.991400
train_step : 2251, loss1 : 23.831146, loss2 : 16.645977
train_step : 2252, loss1 : 17.567402, loss2 : 15.444995
train_step : 2253, loss1 : 15.446718, loss2 : 13.258899
train_step : 2254, loss1 : 33.713516, loss2 : 8.504511
train_step : 2255, loss1 : 15.777662, loss2 : 15.945272
train_step : 2256, loss1 : 9.955420, loss2 : 21.988358
train_step : 2257, loss1 : 15.575832, loss2 : 16.007065
train_step : 2258, loss1 : 15.404572, loss2 : 14.282516
train_step : 2259, loss1 : 24.781891, loss2 : 10.222252
train_step : 2260, loss1 : 14.907084, loss2 : 5.312481
train_step : 2261, loss1 : 19.053795, loss2 : 14.810985
train_step : 2262, loss1 : 19.430462, loss2 : 20.858540
train_step : 2263, loss1 : 24.870237, loss2 : 12.585981
train_step : 2264, loss1 : 18.054552, loss2 : 18.456852
train_step : 2265, loss1 : 11.680084, loss2 : 18.523205
train_step : 2266, loss1 : 17.564949, loss2 : 18.599806
train_step : 2267, loss1 : 14.352493, loss2 : 11.399235
train_step : 2268, loss1 : 10.078319, loss2 : 19.270735
train_step : 2269, loss1 : 9.874397, loss2 : 19.680456
train_step : 2270, loss1 : 14.754610, loss2 : 16.524519
train_step : 2271, loss1 : 18.311012, loss2 : 8.769966
train_step : 2272, loss1 : 10.950844, loss2 : 23.882578
train_step : 2273, loss1 : 23.021355, loss2 : 17.985443
train_step : 2274, loss1 : 22.646021, loss2 : 19.571966
train_step : 2275, loss1 : 20.784237, loss2 : 16.642954
train_step : 2276, loss1 : 18.176495, loss2 : 17.955406
train_step : 2277, loss1 : 21.696037, loss2 : 14.401184
train_step : 2278, loss1 : 15.036573, loss2 : 13.279886
train_step : 2279, loss1 : 27.409630, loss2 : 9.119595
train_step : 2280, loss1 : 14.335290, loss2 : 15.302024
train_step : 2281, loss1 : 14.576624, loss2 : 14.240030
train_step : 2282, loss1 : 20.357834, loss2 : 14.323849
train_step : 2283, loss1 : 23.503860, loss2 : 14.048628
train_step : 2284, loss1 : 15.995302, loss2 : 11.284687
train_step : 2285, loss1 : 11.847305, loss2 : 18.962524
train_step : 2286, loss1 : 9.034382, loss2 : 7.261601
train_step : 2287, loss1 : 17.109066, loss2 : 20.151878
train_step : 2288, loss1 : 22.747105, loss2 : 13.543101
train_step : 2289, loss1 : 18.851818, loss2 : 21.857861
train_step : 2290, loss1 : 20.084984, loss2 : 15.896847
train_step : 2291, loss1 : 26.900936, loss2 : 23.237129
train_step : 2292, loss1 : 13.014015, loss2 : 9.430878
train_step : 2293, loss1 : 15.407539, loss2 : 22.888390
train_step : 2294, loss1 : 15.179834, loss2 : 9.189768
train_step : 2295, loss1 : 12.581793, loss2 : 11.272220
train_step : 2296, loss1 : 16.619692, loss2 : 26.073803
train_step : 2297, loss1 : 19.296122, loss2 : 25.182472
train_step : 2298, loss1 : 18.847446, loss2 : 19.860794
train_step : 2299, loss1 : 17.643627, loss2 : 18.980167
train_step : 2300, loss1 : 16.288731, loss2 : 22.025557
train_step : 2301, loss1 : 27.893625, loss2 : 24.621227
train_step : 2302, loss1 : 18.554543, loss2 : 16.581200
train_step : 2303, loss1 : 9.464008, loss2 : 11.919641
train_step : 2304, loss1 : 21.457884, loss2 : 8.740675
train_step : 2305, loss1 : 10.694484, loss2 : 19.061596
train_step : 2306, loss1 : 15.875713, loss2 : 24.248795
train_step : 2307, loss1 : 15.847397, loss2 : 14.685260
train_step : 2308, loss1 : 25.110165, loss2 : 14.520610
train_step : 2309, loss1 : 17.617474, loss2 : 17.803165
train_step : 2310, loss1 : 16.762943, loss2 : 14.812022
train_step : 2311, loss1 : 21.300364, loss2 : 31.809147
train_step : 2312, loss1 : 18.919785, loss2 : 19.177288
train_step : 2313, loss1 : 28.754850, loss2 : 25.513189
train_step : 2314, loss1 : 24.002098, loss2 : 22.841404
train_step : 2315, loss1 : 21.186958, loss2 : 13.105404
train_step : 2316, loss1 : 21.160574, loss2 : 12.939375
train_step : 2317, loss1 : 30.146704, loss2 : 20.615480
train_step : 2318, loss1 : 30.485769, loss2 : 11.813111
train_step : 2319, loss1 : 14.567642, loss2 : 21.547142
train_step : 2320, loss1 : 31.684378, loss2 : 10.159260
train_step : 2321, loss1 : 17.956009, loss2 : 28.402603
train_step : 2322, loss1 : 14.022684, loss2 : 17.861263
train_step : 2323, loss1 : 18.547022, loss2 : 8.662087
train_step : 2324, loss1 : 14.665697, loss2 : 10.660433
train_step : 2325, loss1 : 17.736767, loss2 : 17.282988
train_step : 2326, loss1 : 12.642572, loss2 : 16.517591
train_step : 2327, loss1 : 18.377174, loss2 : 16.941422
train_step : 2328, loss1 : 15.855682, loss2 : 23.228880
train_step : 2329, loss1 : 13.268607, loss2 : 21.877243
train_step : 2330, loss1 : 18.983215, loss2 : 15.057215
train_step : 2331, loss1 : 14.999767, loss2 : 14.281114
train_step : 2332, loss1 : 11.614372, loss2 : 26.280684
train_step : 2333, loss1 : 13.586307, loss2 : 14.662341
train_step : 2334, loss1 : 23.265287, loss2 : 17.987354
train_step : 2335, loss1 : 10.574072, loss2 : 11.170736
train_step : 2336, loss1 : 9.562075, loss2 : 12.833579
train_step : 2337, loss1 : 20.486645, loss2 : 15.273108
train_step : 2338, loss1 : 18.311647, loss2 : 8.608592
train_step : 2339, loss1 : 17.033842, loss2 : 12.773718
train_step : 2340, loss1 : 20.116709, loss2 : 15.845407
train_step : 2341, loss1 : 20.963348, loss2 : 19.800240
train_step : 2342, loss1 : 20.330605, loss2 : 17.551609
train_step : 2343, loss1 : 22.301956, loss2 : 26.898085
train_step : 2344, loss1 : 20.816177, loss2 : 17.171780
train_step : 2345, loss1 : 18.330156, loss2 : 19.653278
train_step : 2346, loss1 : 20.405180, loss2 : 21.224804
train_step : 2347, loss1 : 15.247721, loss2 : 15.109746
train_step : 2348, loss1 : 11.271430, loss2 : 20.422802
train_step : 2349, loss1 : 18.653584, loss2 : 20.502859
train_step : 2350, loss1 : 12.011301, loss2 : 12.296277
train_step : 2351, loss1 : 17.977858, loss2 : 9.480590
train_step : 2352, loss1 : 13.589069, loss2 : 19.304356
train_step : 2353, loss1 : 15.393668, loss2 : 13.756020
train_step : 2354, loss1 : 20.910803, loss2 : 17.767056
train_step : 2355, loss1 : 15.120339, loss2 : 25.121433
train_step : 2356, loss1 : 18.879864, loss2 : 25.831287
train_step : 2357, loss1 : 9.506447, loss2 : 14.403479
train_step : 2358, loss1 : 20.438906, loss2 : 16.176773
train_step : 2359, loss1 : 25.845631, loss2 : 10.522125
train_step : 2360, loss1 : 29.617567, loss2 : 19.539129
train_step : 2361, loss1 : 18.668171, loss2 : 8.039604
train_step : 2362, loss1 : 12.604601, loss2 : 13.069857
train_step : 2363, loss1 : 17.745987, loss2 : 24.328796
train_step : 2364, loss1 : 13.596165, loss2 : 9.910934
train_step : 2365, loss1 : 15.596601, loss2 : 36.119030
train_step : 2366, loss1 : 9.043167, loss2 : 11.380909
train_step : 2367, loss1 : 28.362488, loss2 : 15.733447
train_step : 2368, loss1 : 15.199980, loss2 : 5.913494
train_step : 2369, loss1 : 19.924480, loss2 : 11.835770
train_step : 2370, loss1 : 25.079716, loss2 : 14.610268
train_step : 2371, loss1 : 23.809837, loss2 : 21.696939
train_step : 2372, loss1 : 20.075987, loss2 : 18.567760
train_step : 2373, loss1 : 9.762479, loss2 : 23.077127
train_step : 2374, loss1 : 10.857779, loss2 : 17.167377
train_step : 2375, loss1 : 12.998538, loss2 : 7.406140
train_step : 2376, loss1 : 17.696173, loss2 : 31.284409
train_step : 2377, loss1 : 11.111483, loss2 : 21.913868
train_step : 2378, loss1 : 20.039600, loss2 : 19.137871
train_step : 2379, loss1 : 10.560946, loss2 : 21.410305
train_step : 2380, loss1 : 13.301998, loss2 : 27.158100
train_step : 2381, loss1 : 17.239166, loss2 : 14.215292
train_step : 2382, loss1 : 18.515476, loss2 : 17.772869
train_step : 2383, loss1 : 23.807070, loss2 : 19.029957
train_step : 2384, loss1 : 22.463892, loss2 : 14.667965
train_step : 2385, loss1 : 16.939463, loss2 : 14.733437
train_step : 2386, loss1 : 14.694523, loss2 : 8.432251
train_step : 2387, loss1 : 13.683587, loss2 : 16.167442
train_step : 2388, loss1 : 16.645634, loss2 : 19.188049
train_step : 2389, loss1 : 18.044918, loss2 : 16.127111
train_step : 2390, loss1 : 25.641663, loss2 : 15.744924
train_step : 2391, loss1 : 27.165819, loss2 : 36.185776
train_step : 2392, loss1 : 18.652695, loss2 : 16.512394
train_step : 2393, loss1 : 20.252716, loss2 : 30.361736
train_step : 2394, loss1 : 20.143829, loss2 : 11.122002
train_step : 2395, loss1 : 20.464939, loss2 : 21.558456
train_step : 2396, loss1 : 12.120573, loss2 : 28.958458
train_step : 2397, loss1 : 15.487459, loss2 : 14.358955
train_step : 2398, loss1 : 22.957924, loss2 : 19.909771
train_step : 2399, loss1 : 14.980922, loss2 : 21.328827
train_step : 2400, loss1 : 6.833694, loss2 : 18.310177
train_step : 2401, loss1 : 19.674770, loss2 : 20.299042
train_step : 2402, loss1 : 14.405794, loss2 : 13.858131
train_step : 2403, loss1 : 21.635252, loss2 : 28.665565
train_step : 2404, loss1 : 19.267284, loss2 : 18.655197
train_step : 2405, loss1 : 15.234799, loss2 : 14.326343
train_step : 2406, loss1 : 19.683064, loss2 : 10.216846
train_step : 2407, loss1 : 15.192815, loss2 : 15.321798
train_step : 2408, loss1 : 14.934920, loss2 : 24.274639
train_step : 2409, loss1 : 14.860996, loss2 : 15.431930
train_step : 2410, loss1 : 17.803566, loss2 : 28.240952
train_step : 2411, loss1 : 15.809742, loss2 : 18.764256
train_step : 2412, loss1 : 22.190031, loss2 : 21.840862
train_step : 2413, loss1 : 15.925218, loss2 : 16.425966
train_step : 2414, loss1 : 31.121416, loss2 : 19.303118
train_step : 2415, loss1 : 18.422493, loss2 : 17.764473
train_step : 2416, loss1 : 11.467962, loss2 : 13.463272
train_step : 2417, loss1 : 19.548134, loss2 : 9.896749
train_step : 2418, loss1 : 17.639652, loss2 : 13.985174
train_step : 2419, loss1 : 12.663040, loss2 : 34.682022
train_step : 2420, loss1 : 16.807529, loss2 : 22.722258
train_step : 2421, loss1 : 23.707407, loss2 : 20.621387
train_step : 2422, loss1 : 29.122004, loss2 : 7.734599
train_step : 2423, loss1 : 16.490116, loss2 : 14.626327
train_step : 2424, loss1 : 28.012589, loss2 : 11.990102
train_step : 2425, loss1 : 18.133041, loss2 : 9.446391
train_step : 2426, loss1 : 24.646433, loss2 : 24.535015
train_step : 2427, loss1 : 19.287779, loss2 : 15.916324
train_step : 2428, loss1 : 14.892163, loss2 : 14.576407
train_step : 2429, loss1 : 23.684948, loss2 : 23.742170
train_step : 2430, loss1 : 20.754467, loss2 : 12.486967
train_step : 2431, loss1 : 11.606185, loss2 : 20.094177
train_step : 2432, loss1 : 19.991375, loss2 : 17.311010
train_step : 2433, loss1 : 14.112622, loss2 : 15.317127
train_step : 2434, loss1 : 12.940302, loss2 : 15.569242
train_step : 2435, loss1 : 20.217846, loss2 : 10.266655
train_step : 2436, loss1 : 35.018044, loss2 : 12.837105
train_step : 2437, loss1 : 42.077099, loss2 : 16.936258
train_step : 2438, loss1 : 8.236008, loss2 : 21.120266
train_step : 2439, loss1 : 25.198814, loss2 : 18.804699
train_step : 2440, loss1 : 25.923096, loss2 : 20.190502
train_step : 2441, loss1 : 16.017139, loss2 : 17.838261
train_step : 2442, loss1 : 31.569939, loss2 : 16.135612
train_step : 2443, loss1 : 16.589211, loss2 : 24.173019
train_step : 2444, loss1 : 19.112923, loss2 : 10.154915
train_step : 2445, loss1 : 8.626075, loss2 : 8.943733
train_step : 2446, loss1 : 16.038132, loss2 : 20.953949
train_step : 2447, loss1 : 13.581526, loss2 : 8.887139
train_step : 2448, loss1 : 15.302055, loss2 : 20.600449
train_step : 2449, loss1 : 17.463940, loss2 : 12.975303
train_step : 2450, loss1 : 15.921433, loss2 : 16.200113
train_step : 2451, loss1 : 9.276271, loss2 : 21.778347
train_step : 2452, loss1 : 13.938471, loss2 : 10.022816
train_step : 2453, loss1 : 19.623909, loss2 : 21.990887
train_step : 2454, loss1 : 14.820295, loss2 : 22.809500
train_step : 2455, loss1 : 11.608180, loss2 : 21.387913
train_step : 2456, loss1 : 23.031094, loss2 : 15.638641
train_step : 2457, loss1 : 8.265819, loss2 : 14.082732
train_step : 2458, loss1 : 19.450558, loss2 : 13.817852
train_step : 2459, loss1 : 16.219011, loss2 : 19.599348
train_step : 2460, loss1 : 12.135387, loss2 : 14.556743
train_step : 2461, loss1 : 18.673475, loss2 : 22.184120
train_step : 2462, loss1 : 16.625221, loss2 : 26.950525
train_step : 2463, loss1 : 23.582605, loss2 : 19.006811
train_step : 2464, loss1 : 23.237583, loss2 : 20.852383
train_step : 2465, loss1 : 13.805979, loss2 : 20.304531
train_step : 2466, loss1 : 20.228306, loss2 : 9.591146
train_step : 2467, loss1 : 29.097069, loss2 : 25.340305
train_step : 2468, loss1 : 7.605380, loss2 : 18.617680
train_step : 2469, loss1 : 9.296937, loss2 : 15.631880
train_step : 2470, loss1 : 13.717652, loss2 : 15.477764
train_step : 2471, loss1 : 16.339560, loss2 : 8.663340
train_step : 2472, loss1 : 29.042381, loss2 : 10.173885
train_step : 2473, loss1 : 20.797897, loss2 : 14.828823
train_step : 2474, loss1 : 11.248947, loss2 : 21.673542
train_step : 2475, loss1 : 11.532001, loss2 : 22.608553
train_step : 2476, loss1 : 8.949005, loss2 : 13.371494
train_step : 2477, loss1 : 10.081760, loss2 : 13.781738
train_step : 2478, loss1 : 20.518887, loss2 : 15.634731
train_step : 2479, loss1 : 23.671356, loss2 : 12.630526
train_step : 2480, loss1 : 14.020144, loss2 : 13.229714
train_step : 2481, loss1 : 18.324524, loss2 : 15.255488
train_step : 2482, loss1 : 7.666408, loss2 : 14.022610
train_step : 2483, loss1 : 12.667591, loss2 : 18.672020
train_step : 2484, loss1 : 19.055584, loss2 : 10.698137
train_step : 2485, loss1 : 16.991362, loss2 : 17.726421
train_step : 2486, loss1 : 19.578709, loss2 : 22.708469
train_step : 2487, loss1 : 14.742048, loss2 : 11.741912
train_step : 2488, loss1 : 12.208376, loss2 : 15.906192
train_step : 2489, loss1 : 12.413290, loss2 : 22.117418
train_step : 2490, loss1 : 15.003460, loss2 : 9.051103
train_step : 2491, loss1 : 21.138670, loss2 : 23.778843
train_step : 2492, loss1 : 9.007204, loss2 : 21.307064
train_step : 2493, loss1 : 11.059324, loss2 : 17.614077
train_step : 2494, loss1 : 18.321362, loss2 : 14.570452
train_step : 2495, loss1 : 21.409706, loss2 : 27.585064
train_step : 2496, loss1 : 24.902290, loss2 : 10.546030
train_step : 2497, loss1 : 17.142300, loss2 : 14.999587
train_step : 2498, loss1 : 10.907784, loss2 : 12.721357
train_step : 2499, loss1 : 11.336210, loss2 : 24.190384
train_step : 2500, loss1 : 13.331251, loss2 : 14.492323
train_step : 2501, loss1 : 23.661839, loss2 : 20.878057
train_step : 2502, loss1 : 10.375081, loss2 : 9.894056
train_step : 2503, loss1 : 12.578061, loss2 : 22.491451
train_step : 2504, loss1 : 12.776841, loss2 : 14.712001
train_step : 2505, loss1 : 9.352881, loss2 : 20.529293
train_step : 2506, loss1 : 28.130642, loss2 : 18.373236
train_step : 2507, loss1 : 6.802445, loss2 : 19.310644
train_step : 2508, loss1 : 19.010288, loss2 : 35.401878
train_step : 2509, loss1 : 28.605259, loss2 : 17.301506
train_step : 2510, loss1 : 15.335835, loss2 : 22.878660
train_step : 2511, loss1 : 21.806896, loss2 : 16.757349
train_step : 2512, loss1 : 15.116433, loss2 : 17.936714
train_step : 2513, loss1 : 23.264805, loss2 : 22.947853
train_step : 2514, loss1 : 11.965369, loss2 : 21.679970
train_step : 2515, loss1 : 20.335579, loss2 : 16.576294
train_step : 2516, loss1 : 18.225063, loss2 : 13.822943
train_step : 2517, loss1 : 17.382931, loss2 : 12.485075
train_step : 2518, loss1 : 11.244499, loss2 : 24.466530
train_step : 2519, loss1 : 20.703184, loss2 : 18.738747
train_step : 2520, loss1 : 24.546898, loss2 : 24.351362
train_step : 2521, loss1 : 12.150224, loss2 : 32.820419
train_step : 2522, loss1 : 11.422173, loss2 : 19.408478
train_step : 2523, loss1 : 20.596479, loss2 : 30.017296
train_step : 2524, loss1 : 11.314427, loss2 : 18.166151
train_step : 2525, loss1 : 19.561438, loss2 : 10.038939
train_step : 2526, loss1 : 24.362686, loss2 : 17.694695
train_step : 2527, loss1 : 11.770466, loss2 : 23.990463
train_step : 2528, loss1 : 12.295712, loss2 : 13.409780
train_step : 2529, loss1 : 24.119999, loss2 : 22.725113
train_step : 2530, loss1 : 15.225456, loss2 : 14.276267
train_step : 2531, loss1 : 13.191399, loss2 : 18.360691
train_step : 2532, loss1 : 14.903893, loss2 : 17.415279
train_step : 2533, loss1 : 14.836507, loss2 : 8.922496
train_step : 2534, loss1 : 19.420630, loss2 : 18.359320
train_step : 2535, loss1 : 15.655570, loss2 : 23.834421
train_step : 2536, loss1 : 13.805500, loss2 : 10.092188
train_step : 2537, loss1 : 22.190096, loss2 : 19.167713
train_step : 2538, loss1 : 16.696163, loss2 : 25.333755
train_step : 2539, loss1 : 17.573339, loss2 : 10.899593
train_step : 2540, loss1 : 8.447151, loss2 : 15.460584
train_step : 2541, loss1 : 19.082558, loss2 : 23.328247
train_step : 2542, loss1 : 15.016537, loss2 : 15.263642
train_step : 2543, loss1 : 12.559664, loss2 : 15.641598
train_step : 2544, loss1 : 8.269136, loss2 : 11.656507
train_step : 2545, loss1 : 15.625061, loss2 : 18.992155
train_step : 2546, loss1 : 16.218552, loss2 : 7.602897
train_step : 2547, loss1 : 7.736672, loss2 : 25.661919
train_step : 2548, loss1 : 13.431316, loss2 : 18.671736
train_step : 2549, loss1 : 11.605330, loss2 : 12.234878
train_step : 2550, loss1 : 17.834377, loss2 : 21.745903
train_step : 2551, loss1 : 17.351969, loss2 : 22.012768
train_step : 2552, loss1 : 19.001135, loss2 : 7.692830
train_step : 2553, loss1 : 11.065873, loss2 : 21.044302
train_step : 2554, loss1 : 12.456435, loss2 : 14.587961
train_step : 2555, loss1 : 29.394526, loss2 : 17.763369
train_step : 2556, loss1 : 8.282522, loss2 : 17.466236
train_step : 2557, loss1 : 14.182516, loss2 : 14.803447
train_step : 2558, loss1 : 8.657766, loss2 : 20.778694
train_step : 2559, loss1 : 12.059780, loss2 : 19.767483
train_step : 2560, loss1 : 12.709187, loss2 : 20.355450
train_step : 2561, loss1 : 17.200211, loss2 : 22.207737
train_step : 2562, loss1 : 17.667089, loss2 : 11.112843
train_step : 2563, loss1 : 12.897066, loss2 : 20.257805
train_step : 2564, loss1 : 23.704590, loss2 : 8.347686
train_step : 2565, loss1 : 16.099770, loss2 : 20.384785
train_step : 2566, loss1 : 14.458430, loss2 : 21.031595
train_step : 2567, loss1 : 23.240078, loss2 : 9.681206
train_step : 2568, loss1 : 14.370699, loss2 : 26.440781
train_step : 2569, loss1 : 17.382986, loss2 : 20.670097
train_step : 2570, loss1 : 7.279708, loss2 : 16.567753
train_step : 2571, loss1 : 17.124096, loss2 : 13.339036
train_step : 2572, loss1 : 11.944231, loss2 : 18.516701
train_step : 2573, loss1 : 27.461842, loss2 : 12.807732
train_step : 2574, loss1 : 26.304886, loss2 : 15.098775
train_step : 2575, loss1 : 17.495085, loss2 : 15.054274
train_step : 2576, loss1 : 17.896425, loss2 : 9.411278
train_step : 2577, loss1 : 23.385225, loss2 : 21.641768
train_step : 2578, loss1 : 21.070732, loss2 : 14.145522
train_step : 2579, loss1 : 17.814631, loss2 : 16.119253
train_step : 2580, loss1 : 10.476017, loss2 : 25.297508
train_step : 2581, loss1 : 9.932878, loss2 : 14.170349
train_step : 2582, loss1 : 16.427809, loss2 : 18.764267
train_step : 2583, loss1 : 15.858416, loss2 : 16.906837
train_step : 2584, loss1 : 7.188143, loss2 : 14.545898
train_step : 2585, loss1 : 20.474033, loss2 : 17.652033
train_step : 2586, loss1 : 29.985668, loss2 : 13.259729
train_step : 2587, loss1 : 14.227214, loss2 : 19.070492
train_step : 2588, loss1 : 22.260286, loss2 : 15.769853
train_step : 2589, loss1 : 18.825806, loss2 : 9.558172
train_step : 2590, loss1 : 11.889794, loss2 : 13.163677
train_step : 2591, loss1 : 20.873608, loss2 : 15.238035
train_step : 2592, loss1 : 14.245487, loss2 : 22.996344
train_step : 2593, loss1 : 4.890217, loss2 : 19.167919
train_step : 2594, loss1 : 12.871444, loss2 : 18.431309
train_step : 2595, loss1 : 14.130416, loss2 : 22.557062
train_step : 2596, loss1 : 20.484116, loss2 : 17.104996
train_step : 2597, loss1 : 9.087776, loss2 : 12.948909
train_step : 2598, loss1 : 27.190666, loss2 : 14.493559
train_step : 2599, loss1 : 20.171560, loss2 : 13.571213
train_step : 2600, loss1 : 10.506948, loss2 : 24.529926
train_step : 2601, loss1 : 16.340425, loss2 : 12.359159
train_step : 2602, loss1 : 19.350775, loss2 : 13.084655
train_step : 2603, loss1 : 11.242294, loss2 : 9.929203
train_step : 2604, loss1 : 21.152332, loss2 : 25.654507
train_step : 2605, loss1 : 15.088369, loss2 : 12.343642
train_step : 2606, loss1 : 27.792133, loss2 : 18.790356
train_step : 2607, loss1 : 11.352098, loss2 : 10.958059
train_step : 2608, loss1 : 10.795959, loss2 : 22.368475
train_step : 2609, loss1 : 17.440531, loss2 : 22.484892
train_step : 2610, loss1 : 11.813586, loss2 : 12.526576
train_step : 2611, loss1 : 20.496170, loss2 : 17.842859
train_step : 2612, loss1 : 15.053380, loss2 : 9.132778
train_step : 2613, loss1 : 13.077745, loss2 : 11.194529
train_step : 2614, loss1 : 15.958025, loss2 : 17.487619
train_step : 2615, loss1 : 12.835987, loss2 : 9.114922
train_step : 2616, loss1 : 27.604919, loss2 : 19.325779
train_step : 2617, loss1 : 27.543425, loss2 : 14.529226
train_step : 2618, loss1 : 19.199734, loss2 : 9.911472
train_step : 2619, loss1 : 15.660004, loss2 : 13.671270
train_step : 2620, loss1 : 14.950052, loss2 : 9.232837
train_step : 2621, loss1 : 14.623041, loss2 : 15.787704
train_step : 2622, loss1 : 18.376463, loss2 : 13.875036
train_step : 2623, loss1 : 16.777542, loss2 : 34.857101
train_step : 2624, loss1 : 17.486488, loss2 : 11.657795
train_step : 2625, loss1 : 9.102402, loss2 : 8.609338
train_step : 2626, loss1 : 21.157125, loss2 : 22.214195
train_step : 2627, loss1 : 16.164787, loss2 : 10.831987
train_step : 2628, loss1 : 20.303112, loss2 : 14.378269
train_step : 2629, loss1 : 14.611353, loss2 : 14.804590
train_step : 2630, loss1 : 19.325230, loss2 : 19.440662
train_step : 2631, loss1 : 9.826157, loss2 : 19.620197
train_step : 2632, loss1 : 9.581697, loss2 : 16.315975
train_step : 2633, loss1 : 23.627056, loss2 : 16.958546
train_step : 2634, loss1 : 18.985622, loss2 : 17.296259
train_step : 2635, loss1 : 30.108269, loss2 : 12.018787
train_step : 2636, loss1 : 13.361033, loss2 : 9.527061
train_step : 2637, loss1 : 10.316193, loss2 : 23.201641
train_step : 2638, loss1 : 20.459457, loss2 : 22.043743
train_step : 2639, loss1 : 15.988344, loss2 : 16.903316
train_step : 2640, loss1 : 10.595547, loss2 : 11.853842
train_step : 2641, loss1 : 25.781643, loss2 : 16.517139
train_step : 2642, loss1 : 16.684238, loss2 : 10.163435
train_step : 2643, loss1 : 15.226225, loss2 : 14.549572
train_step : 2644, loss1 : 15.728161, loss2 : 23.065540
train_step : 2645, loss1 : 18.991709, loss2 : 17.181047
train_step : 2646, loss1 : 20.191607, loss2 : 14.925448
train_step : 2647, loss1 : 15.049157, loss2 : 20.036510
train_step : 2648, loss1 : 17.694668, loss2 : 18.080641
train_step : 2649, loss1 : 12.702686, loss2 : 21.734425
train_step : 2650, loss1 : 15.528924, loss2 : 18.116203
train_step : 2651, loss1 : 7.209741, loss2 : 15.837656
train_step : 2652, loss1 : 15.434484, loss2 : 22.503429
train_step : 2653, loss1 : 17.747000, loss2 : 13.694501
train_step : 2654, loss1 : 16.386959, loss2 : 18.892517
train_step : 2655, loss1 : 17.705847, loss2 : 31.524513
train_step : 2656, loss1 : 19.169352, loss2 : 7.223984
train_step : 2657, loss1 : 18.320496, loss2 : 15.032588
train_step : 2658, loss1 : 8.556238, loss2 : 17.610828
train_step : 2659, loss1 : 12.047009, loss2 : 17.993053
train_step : 2660, loss1 : 18.477577, loss2 : 20.291580
train_step : 2661, loss1 : 13.447536, loss2 : 18.578812
train_step : 2662, loss1 : 15.788945, loss2 : 16.164948
train_step : 2663, loss1 : 19.656239, loss2 : 19.283289
train_step : 2664, loss1 : 18.088448, loss2 : 23.419758
train_step : 2665, loss1 : 27.175053, loss2 : 10.671202
train_step : 2666, loss1 : 28.118757, loss2 : 15.512777
train_step : 2667, loss1 : 12.689264, loss2 : 11.477200
train_step : 2668, loss1 : 11.102654, loss2 : 12.358408
train_step : 2669, loss1 : 13.855581, loss2 : 13.690889
train_step : 2670, loss1 : 19.524183, loss2 : 14.248821
train_step : 2671, loss1 : 10.008881, loss2 : 27.645096
train_step : 2672, loss1 : 14.651608, loss2 : 16.825775
train_step : 2673, loss1 : 9.414417, loss2 : 9.796165
train_step : 2674, loss1 : 12.297894, loss2 : 12.147948
train_step : 2675, loss1 : 15.814318, loss2 : 18.065384
train_step : 2676, loss1 : 13.433636, loss2 : 18.782217
train_step : 2677, loss1 : 17.075401, loss2 : 8.429795
train_step : 2678, loss1 : 20.093479, loss2 : 12.438589
train_step : 2679, loss1 : 13.325171, loss2 : 19.360678
train_step : 2680, loss1 : 22.774418, loss2 : 14.765894
train_step : 2681, loss1 : 13.976076, loss2 : 21.932133
train_step : 2682, loss1 : 13.703420, loss2 : 10.038742
train_step : 2683, loss1 : 10.304707, loss2 : 7.391666
train_step : 2684, loss1 : 14.401888, loss2 : 20.825073
train_step : 2685, loss1 : 15.895535, loss2 : 16.990295
train_step : 2686, loss1 : 19.660828, loss2 : 12.120026
train_step : 2687, loss1 : 18.310642, loss2 : 17.786604
train_step : 2688, loss1 : 7.760922, loss2 : 23.004997
train_step : 2689, loss1 : 22.046597, loss2 : 15.366613
train_step : 2690, loss1 : 15.975079, loss2 : 20.870903
train_step : 2691, loss1 : 18.350895, loss2 : 15.925218
train_step : 2692, loss1 : 10.989969, loss2 : 18.259968
train_step : 2693, loss1 : 21.240383, loss2 : 25.323982
train_step : 2694, loss1 : 15.453362, loss2 : 19.364761
train_step : 2695, loss1 : 18.685993, loss2 : 20.664230
train_step : 2696, loss1 : 23.303251, loss2 : 23.030689
train_step : 2697, loss1 : 13.083712, loss2 : 9.370344
train_step : 2698, loss1 : 9.424080, loss2 : 9.899761
train_step : 2699, loss1 : 20.056511, loss2 : 14.886813
train_step : 2700, loss1 : 24.296465, loss2 : 13.583376
train_step : 2701, loss1 : 14.258196, loss2 : 21.106117
train_step : 2702, loss1 : 9.258512, loss2 : 14.761570
train_step : 2703, loss1 : 22.456787, loss2 : 13.368771
train_step : 2704, loss1 : 4.439336, loss2 : 14.832411
train_step : 2705, loss1 : 9.150352, loss2 : 15.267482
train_step : 2706, loss1 : 14.917927, loss2 : 22.711542
train_step : 2707, loss1 : 24.656921, loss2 : 22.073751
train_step : 2708, loss1 : 18.586472, loss2 : 16.559349
train_step : 2709, loss1 : 26.131378, loss2 : 20.560591
train_step : 2710, loss1 : 19.600237, loss2 : 14.105005
train_step : 2711, loss1 : 22.559683, loss2 : 15.383429
train_step : 2712, loss1 : 14.680850, loss2 : 10.736576
train_step : 2713, loss1 : 13.648734, loss2 : 15.861054
train_step : 2714, loss1 : 20.034210, loss2 : 13.763578
train_step : 2715, loss1 : 12.319202, loss2 : 12.639446
train_step : 2716, loss1 : 18.221960, loss2 : 16.985077
train_step : 2717, loss1 : 12.975575, loss2 : 13.500455
train_step : 2718, loss1 : 14.242015, loss2 : 17.016401
train_step : 2719, loss1 : 13.467196, loss2 : 14.440956
train_step : 2720, loss1 : 20.199738, loss2 : 13.349417
train_step : 2721, loss1 : 21.583769, loss2 : 20.597416
train_step : 2722, loss1 : 15.147164, loss2 : 22.930149
train_step : 2723, loss1 : 18.341095, loss2 : 14.347927
train_step : 2724, loss1 : 11.609486, loss2 : 11.040999
train_step : 2725, loss1 : 14.136287, loss2 : 16.508923
train_step : 2726, loss1 : 15.379288, loss2 : 26.667431
train_step : 2727, loss1 : 16.494614, loss2 : 11.382685
train_step : 2728, loss1 : 14.912310, loss2 : 13.110455
train_step : 2729, loss1 : 26.128738, loss2 : 10.729986
train_step : 2730, loss1 : 15.590229, loss2 : 20.052223
train_step : 2731, loss1 : 9.874866, loss2 : 9.433958
train_step : 2732, loss1 : 11.451614, loss2 : 15.870951
train_step : 2733, loss1 : 14.033365, loss2 : 12.355914
train_step : 2734, loss1 : 21.392937, loss2 : 11.784510
train_step : 2735, loss1 : 6.554177, loss2 : 10.483455
train_step : 2736, loss1 : 12.402300, loss2 : 11.940109
train_step : 2737, loss1 : 9.902613, loss2 : 17.594624
train_step : 2738, loss1 : 17.585779, loss2 : 17.720203
train_step : 2739, loss1 : 14.822990, loss2 : 9.504343
train_step : 2740, loss1 : 18.447472, loss2 : 12.353243
train_step : 2741, loss1 : 14.326488, loss2 : 10.858885
train_step : 2742, loss1 : 17.080898, loss2 : 16.493088
train_step : 2743, loss1 : 19.161026, loss2 : 12.894535
train_step : 2744, loss1 : 25.212233, loss2 : 20.736755
train_step : 2745, loss1 : 11.647755, loss2 : 21.792313
train_step : 2746, loss1 : 15.612303, loss2 : 10.007360
train_step : 2747, loss1 : 12.326828, loss2 : 13.307087
train_step : 2748, loss1 : 21.009964, loss2 : 12.578053
train_step : 2749, loss1 : 12.953753, loss2 : 12.385550
train_step : 2750, loss1 : 10.109879, loss2 : 17.256147
train_step : 2751, loss1 : 19.222046, loss2 : 17.532078
train_step : 2752, loss1 : 18.978729, loss2 : 21.208216
train_step : 2753, loss1 : 10.638255, loss2 : 9.748220
train_step : 2754, loss1 : 8.692510, loss2 : 12.176967
train_step : 2755, loss1 : 16.884890, loss2 : 8.525476
train_step : 2756, loss1 : 7.556948, loss2 : 14.033661
train_step : 2757, loss1 : 20.848499, loss2 : 18.193041
train_step : 2758, loss1 : 14.069539, loss2 : 17.775009
train_step : 2759, loss1 : 9.938652, loss2 : 11.125217
train_step : 2760, loss1 : 20.131851, loss2 : 14.540509
train_step : 2761, loss1 : 16.662424, loss2 : 15.816921
train_step : 2762, loss1 : 18.429819, loss2 : 12.748078
train_step : 2763, loss1 : 13.084420, loss2 : 16.516472
train_step : 2764, loss1 : 10.968708, loss2 : 13.271532
train_step : 2765, loss1 : 12.748632, loss2 : 8.259335
train_step : 2766, loss1 : 16.468098, loss2 : 14.054300
train_step : 2767, loss1 : 18.178566, loss2 : 16.384062
train_step : 2768, loss1 : 21.834270, loss2 : 10.120858
train_step : 2769, loss1 : 13.573061, loss2 : 9.328476
train_step : 2770, loss1 : 14.050078, loss2 : 15.324347
train_step : 2771, loss1 : 14.343885, loss2 : 16.333010
train_step : 2772, loss1 : 12.879761, loss2 : 20.191235
train_step : 2773, loss1 : 12.842831, loss2 : 19.339249
train_step : 2774, loss1 : 10.077714, loss2 : 14.049510
train_step : 2775, loss1 : 16.066364, loss2 : 14.410984
train_step : 2776, loss1 : 12.213765, loss2 : 10.081058
train_step : 2777, loss1 : 13.404755, loss2 : 20.331848
train_step : 2778, loss1 : 6.957179, loss2 : 12.774805
train_step : 2779, loss1 : 14.146812, loss2 : 11.614027
train_step : 2780, loss1 : 15.375591, loss2 : 23.026337
train_step : 2781, loss1 : 14.902903, loss2 : 15.462606
train_step : 2782, loss1 : 11.993302, loss2 : 14.210769
train_step : 2783, loss1 : 13.868430, loss2 : 15.061024
train_step : 2784, loss1 : 13.958024, loss2 : 12.649842
train_step : 2785, loss1 : 10.538855, loss2 : 12.805947
train_step : 2786, loss1 : 9.823374, loss2 : 11.356270
train_step : 2787, loss1 : 16.092466, loss2 : 9.141214
train_step : 2788, loss1 : 8.029668, loss2 : 13.897422
train_step : 2789, loss1 : 11.638818, loss2 : 12.481425
train_step : 2790, loss1 : 5.528227, loss2 : 12.361225
train_step : 2791, loss1 : 5.047623, loss2 : 6.312555
train_step : 2792, loss1 : 11.626412, loss2 : 12.187262
train_step : 2793, loss1 : 16.282307, loss2 : 9.127917
train_step : 2794, loss1 : 16.456844, loss2 : 16.676205
train_step : 2795, loss1 : 10.545115, loss2 : 9.564528
train_step : 2796, loss1 : 6.113522, loss2 : 11.118547
train_step : 2797, loss1 : 10.669934, loss2 : 11.304434
train_step : 2798, loss1 : 9.187437, loss2 : 8.434570
train_step : 2799, loss1 : 5.110250, loss2 : 12.118986
train_step : 2800, loss1 : 8.651621, loss2 : 6.875139
train_step : 2801, loss1 : 7.154163, loss2 : 4.635136
train_step : 2802, loss1 : 6.245317, loss2 : 3.921503
train_step : 2803, loss1 : 4.582712, loss2 : 5.905231
train_step : 2804, loss1 : 5.071750, loss2 : 4.254076
train_step : 2805, loss1 : 3.638640, loss2 : 6.385066
train_step : 2806, loss1 : 6.037022, loss2 : 7.030468
train_step : 2807, loss1 : 10.501934, loss2 : 6.536498
train_step : 2808, loss1 : 9.783160, loss2 : 7.341084
train_step : 2809, loss1 : 9.643404, loss2 : 7.664392
train_step : 2810, loss1 : 12.138931, loss2 : 7.841497
train_step : 2811, loss1 : 9.274326, loss2 : 9.692323
train_step : 2812, loss1 : 6.620129, loss2 : 13.513256
train_step : 2813, loss1 : 5.542917, loss2 : 6.719151
train_step : 2814, loss1 : 5.196414, loss2 : 4.860468
train_step : 2815, loss1 : 7.757892, loss2 : 7.472506
train_step : 2816, loss1 : 4.892876, loss2 : 6.729133
train_step : 2817, loss1 : 4.911592, loss2 : 4.087749
train_step : 2818, loss1 : 4.398890, loss2 : 6.660556
train_step : 2819, loss1 : 6.039664, loss2 : 3.285746
train_step : 2820, loss1 : 3.215828, loss2 : 6.161283
train_step : 2821, loss1 : 6.004745, loss2 : 4.366032
train_step : 2822, loss1 : 5.119006, loss2 : 4.664544
train_step : 2823, loss1 : 5.725529, loss2 : 4.637311
train_step : 2824, loss1 : 4.768759, loss2 : 3.355827
train_step : 2825, loss1 : 3.377592, loss2 : 8.021797
train_step : 2826, loss1 : 7.116376, loss2 : 2.068234
train_step : 2827, loss1 : 3.486567, loss2 : 5.775537
train_step : 2828, loss1 : 2.646774, loss2 : 1.250077
train_step : 2829, loss1 : 2.379466, loss2 : 1.868982
train_step : 2830, loss1 : 7.303052, loss2 : 3.221098
train_step : 2831, loss1 : 4.404722, loss2 : 2.623568
train_step : 2832, loss1 : 3.376667, loss2 : 5.364481
train_step : 2833, loss1 : 3.079258, loss2 : 5.138433
train_step : 2834, loss1 : 4.229432, loss2 : 4.268383
train_step : 2835, loss1 : 1.829724, loss2 : 5.927707
train_step : 2836, loss1 : 2.758798, loss2 : 4.555423
train_step : 2837, loss1 : 2.923937, loss2 : 2.208868
train_step : 2838, loss1 : 2.846021, loss2 : 2.252713
train_step : 2839, loss1 : 6.106489, loss2 : 2.944849
train_step : 2840, loss1 : 4.152671, loss2 : 6.839857
train_step : 2841, loss1 : 3.686372, loss2 : 5.243667
train_step : 2842, loss1 : 3.506059, loss2 : 2.911103
train_step : 2843, loss1 : 1.684061, loss2 : 3.566954
train_step : 2844, loss1 : 1.518532, loss2 : 2.751455
train_step : 2845, loss1 : 2.939033, loss2 : 1.842328
train_step : 2846, loss1 : 2.170843, loss2 : 3.382808
train_step : 2847, loss1 : 2.466459, loss2 : 2.013725
train_step : 2848, loss1 : 1.524496, loss2 : 5.303905
train_step : 2849, loss1 : 2.394012, loss2 : 1.643076
train_step : 2850, loss1 : 2.923315, loss2 : 3.993299
train_step : 2851, loss1 : 2.291308, loss2 : 4.660779
train_step : 2852, loss1 : 3.415165, loss2 : 2.462935
train_step : 2853, loss1 : 5.000660, loss2 : 4.420969
train_step : 2854, loss1 : 4.674525, loss2 : 7.783148
train_step : 2855, loss1 : 3.787819, loss2 : 3.879789
train_step : 2856, loss1 : 2.101459, loss2 : 8.171108
train_step : 2857, loss1 : 5.200541, loss2 : 3.302792
train_step : 2858, loss1 : 2.911598, loss2 : 2.353868
train_step : 2859, loss1 : 3.643780, loss2 : 2.893148
train_step : 2860, loss1 : 4.421258, loss2 : 4.829508
train_step : 2861, loss1 : 6.313297, loss2 : 7.902954
train_step : 2862, loss1 : 5.513257, loss2 : 5.561852
train_step : 2863, loss1 : 11.631742, loss2 : 9.176148
train_step : 2864, loss1 : 10.148529, loss2 : 6.735414
train_step : 2865, loss1 : 11.016146, loss2 : 7.759025
train_step : 2866, loss1 : 4.082000, loss2 : 4.718154
train_step : 2867, loss1 : 11.381855, loss2 : 5.761238
train_step : 2868, loss1 : 3.796546, loss2 : 4.275745
train_step : 2869, loss1 : 5.763196, loss2 : 4.109359
train_step : 2870, loss1 : 2.606675, loss2 : 1.963343
train_step : 2871, loss1 : 1.655487, loss2 : 1.030599
train_step : 2872, loss1 : 2.154253, loss2 : 1.995590
train_step : 2873, loss1 : 4.380622, loss2 : 4.359773
train_step : 2874, loss1 : 5.013947, loss2 : 7.824933
train_step : 2875, loss1 : 2.356695, loss2 : 3.793923
train_step : 2876, loss1 : 2.000903, loss2 : 2.863482
train_step : 2877, loss1 : 1.307057, loss2 : 2.963146
train_step : 2878, loss1 : 5.955269, loss2 : 3.261473
train_step : 2879, loss1 : 3.969486, loss2 : 3.870786
train_step : 2880, loss1 : 4.998038, loss2 : 4.648387
train_step : 2881, loss1 : 3.450830, loss2 : 3.594494
train_step : 2882, loss1 : 5.270103, loss2 : 5.860248
train_step : 2883, loss1 : 6.184989, loss2 : 3.604039
train_step : 2884, loss1 : 9.884197, loss2 : 7.632180
train_step : 2885, loss1 : 6.067634, loss2 : 10.125296
train_step : 2886, loss1 : 7.187383, loss2 : 7.078218
train_step : 2887, loss1 : 4.043227, loss2 : 4.185334
train_step : 2888, loss1 : 10.286999, loss2 : 6.999683
train_step : 2889, loss1 : 5.585587, loss2 : 5.331802
train_step : 2890, loss1 : 6.117229, loss2 : 6.517614
train_step : 2891, loss1 : 5.010648, loss2 : 5.721659
train_step : 2892, loss1 : 6.008521, loss2 : 5.539501
train_step : 2893, loss1 : 2.404784, loss2 : 1.525513
train_step : 2894, loss1 : 3.293149, loss2 : 1.456956
train_step : 2895, loss1 : 1.383116, loss2 : 1.390078
train_step : 2896, loss1 : 1.819437, loss2 : 1.728787
train_step : 2897, loss1 : 0.830936, loss2 : 1.244038
train_step : 2898, loss1 : 2.033791, loss2 : 1.248120
train_step : 2899, loss1 : 2.482709, loss2 : 3.964767
train_step : 2900, loss1 : 1.747196, loss2 : 2.627548
train_step : 2901, loss1 : 5.029592, loss2 : 7.438320
train_step : 2902, loss1 : 5.078099, loss2 : 5.860395
train_step : 2903, loss1 : 3.990295, loss2 : 3.388144
train_step : 2904, loss1 : 5.798144, loss2 : 6.382204
train_step : 2905, loss1 : 8.695516, loss2 : 5.173083
train_step : 2906, loss1 : 3.989626, loss2 : 4.093836
train_step : 2907, loss1 : 9.357498, loss2 : 7.733739
train_step : 2908, loss1 : 4.988297, loss2 : 5.071895
train_step : 2909, loss1 : 2.350880, loss2 : 2.377033
train_step : 2910, loss1 : 2.913048, loss2 : 3.107399
train_step : 2911, loss1 : 3.030608, loss2 : 2.418632
train_step : 2912, loss1 : 4.738949, loss2 : 4.647431
train_step : 2913, loss1 : 8.561560, loss2 : 3.730845
train_step : 2914, loss1 : 8.935507, loss2 : 7.772623
train_step : 2915, loss1 : 8.536363, loss2 : 8.576056
train_step : 2916, loss1 : 10.426993, loss2 : 8.407183
train_step : 2917, loss1 : 11.200493, loss2 : 3.856767
train_step : 2918, loss1 : 4.671863, loss2 : 5.120961
train_step : 2919, loss1 : 5.447595, loss2 : 4.543190
train_step : 2920, loss1 : 7.957287, loss2 : 6.481117
train_step : 2921, loss1 : 4.731087, loss2 : 9.240959
train_step : 2922, loss1 : 5.138319, loss2 : 3.845391
train_step : 2923, loss1 : 1.808742, loss2 : 2.606281
train_step : 2924, loss1 : 2.529197, loss2 : 1.866518
train_step : 2925, loss1 : 1.713956, loss2 : 1.200064
train_step : 2926, loss1 : 2.476660, loss2 : 4.627971
train_step : 2927, loss1 : 2.471268, loss2 : 1.683380
train_step : 2928, loss1 : 1.426943, loss2 : 1.805179
train_step : 2929, loss1 : 1.636328, loss2 : 0.694753
train_step : 2930, loss1 : 5.535539, loss2 : 2.556907
train_step : 2931, loss1 : 0.892510, loss2 : 1.617447
train_step : 2932, loss1 : 10.751445, loss2 : 1.207620
train_step : 2933, loss1 : 2.035954, loss2 : 3.207803
train_step : 2934, loss1 : 2.070831, loss2 : 1.793590
train_step : 2935, loss1 : 1.418760, loss2 : 2.086670
train_step : 2936, loss1 : 2.026842, loss2 : 3.982345
train_step : 2937, loss1 : 6.103601, loss2 : 3.629846
train_step : 2938, loss1 : 4.578230, loss2 : 6.273669
train_step : 2939, loss1 : 4.296546, loss2 : 5.409910
train_step : 2940, loss1 : 5.516217, loss2 : 6.619398
train_step : 2941, loss1 : 4.616450, loss2 : 2.168779
train_step : 2942, loss1 : 3.928988, loss2 : 3.197902
train_step : 2943, loss1 : 2.873715, loss2 : 2.932020
train_step : 2944, loss1 : 3.490711, loss2 : 3.066877
train_step : 2945, loss1 : 2.814319, loss2 : 2.340322
train_step : 2946, loss1 : 2.568943, loss2 : 5.731728
train_step : 2947, loss1 : 4.211058, loss2 : 3.008670
train_step : 2948, loss1 : 2.774311, loss2 : 3.950876
train_step : 2949, loss1 : 2.411272, loss2 : 4.523954
train_step : 2950, loss1 : 2.934633, loss2 : 4.093181
train_step : 2951, loss1 : 2.390027, loss2 : 3.436222
train_step : 2952, loss1 : 3.442843, loss2 : 2.474121
train_step : 2953, loss1 : 2.229297, loss2 : 3.699238
train_step : 2954, loss1 : 2.471719, loss2 : 2.352008
train_step : 2955, loss1 : 2.434203, loss2 : 1.873822
train_step : 2956, loss1 : 5.777809, loss2 : 3.774147
train_step : 2957, loss1 : 1.353282, loss2 : 2.063365
train_step : 2958, loss1 : 2.489118, loss2 : 2.865292
train_step : 2959, loss1 : 4.015662, loss2 : 4.787647
train_step : 2960, loss1 : 7.685359, loss2 : 4.886983
train_step : 2961, loss1 : 3.274138, loss2 : 5.782998
train_step : 2962, loss1 : 6.003250, loss2 : 4.471468
train_step : 2963, loss1 : 2.163594, loss2 : 4.108541
train_step : 2964, loss1 : 4.438035, loss2 : 5.207047
train_step : 2965, loss1 : 2.638165, loss2 : 2.764816
train_step : 2966, loss1 : 2.538715, loss2 : 1.479158
train_step : 2967, loss1 : 3.628484, loss2 : 1.318586
train_step : 2968, loss1 : 2.064428, loss2 : 2.345584
train_step : 2969, loss1 : 2.933822, loss2 : 1.935443
train_step : 2970, loss1 : 4.477850, loss2 : 3.693848
train_step : 2971, loss1 : 5.366907, loss2 : 2.670527
train_step : 2972, loss1 : 2.914826, loss2 : 3.615552
train_step : 2973, loss1 : 3.448761, loss2 : 3.501710
train_step : 2974, loss1 : 4.003021, loss2 : 4.384552
train_step : 2975, loss1 : 3.212443, loss2 : 3.234483
train_step : 2976, loss1 : 4.061007, loss2 : 3.521203
train_step : 2977, loss1 : 4.208241, loss2 : 3.518804
train_step : 2978, loss1 : 4.862823, loss2 : 6.472883
train_step : 2979, loss1 : 6.607455, loss2 : 2.062550
train_step : 2980, loss1 : 4.030593, loss2 : 4.086145
train_step : 2981, loss1 : 2.290917, loss2 : 1.814422
train_step : 2982, loss1 : 3.448328, loss2 : 3.282829
train_step : 2983, loss1 : 1.907163, loss2 : 1.601710
train_step : 2984, loss1 : 1.629719, loss2 : 1.238410
train_step : 2985, loss1 : 1.984588, loss2 : 1.961305
train_step : 2986, loss1 : 2.554478, loss2 : 2.716053
train_step : 2987, loss1 : 2.036393, loss2 : 3.348157
train_step : 2988, loss1 : 4.638934, loss2 : 3.524097
train_step : 2989, loss1 : 3.282130, loss2 : 2.409237
train_step : 2990, loss1 : 3.397456, loss2 : 4.330155
train_step : 2991, loss1 : 4.058422, loss2 : 5.131209
train_step : 2992, loss1 : 4.514432, loss2 : 3.773379
train_step : 2993, loss1 : 4.402281, loss2 : 3.104073
train_step : 2994, loss1 : 3.604386, loss2 : 6.618996
train_step : 2995, loss1 : 4.424169, loss2 : 2.361372
train_step : 2996, loss1 : 3.995301, loss2 : 4.439747
train_step : 2997, loss1 : 4.625074, loss2 : 3.169100
train_step : 2998, loss1 : 3.533546, loss2 : 3.900358
train_step : 2999, loss1 : 3.411952, loss2 : 2.201771
train_step : 3000, loss1 : 1.623389, loss2 : 1.799444
train_step : 3001, loss1 : 3.048476, loss2 : 1.145313
train_step : 3002, loss1 : 2.837831, loss2 : 3.437589
train_step : 3003, loss1 : 3.099073, loss2 : 5.968102
train_step : 3004, loss1 : 4.996004, loss2 : 5.009318
train_step : 3005, loss1 : 3.569344, loss2 : 4.873735
train_step : 3006, loss1 : 5.518719, loss2 : 3.564940
train_step : 3007, loss1 : 2.782580, loss2 : 4.160088
train_step : 3008, loss1 : 4.537942, loss2 : 4.467385
train_step : 3009, loss1 : 2.319622, loss2 : 3.349792
train_step : 3010, loss1 : 3.051279, loss2 : 3.516872
train_step : 3011, loss1 : 4.075923, loss2 : 2.942539
train_step : 3012, loss1 : 3.252048, loss2 : 5.229746
train_step : 3013, loss1 : 2.290060, loss2 : 2.488509
train_step : 3014, loss1 : 2.937631, loss2 : 4.003962
train_step : 3015, loss1 : 3.536853, loss2 : 4.265019
train_step : 3016, loss1 : 3.105214, loss2 : 3.493008
train_step : 3017, loss1 : 2.876993, loss2 : 2.966704
train_step : 3018, loss1 : 2.251888, loss2 : 3.774354
train_step : 3019, loss1 : 1.610690, loss2 : 1.654477
train_step : 3020, loss1 : 7.277635, loss2 : 1.411626
train_step : 3021, loss1 : 1.539467, loss2 : 2.685521
train_step : 3022, loss1 : 2.102651, loss2 : 0.898774
train_step : 3023, loss1 : 1.393271, loss2 : 1.998838
train_step : 3024, loss1 : 1.514472, loss2 : 1.495682
train_step : 3025, loss1 : 2.563720, loss2 : 1.056576
train_step : 3026, loss1 : 2.031173, loss2 : 2.791471
train_step : 3027, loss1 : 2.887879, loss2 : 2.777307
train_step : 3028, loss1 : 4.523786, loss2 : 4.175887
train_step : 3029, loss1 : 2.638552, loss2 : 5.412623
train_step : 3030, loss1 : 5.466464, loss2 : 6.045470
train_step : 3031, loss1 : 3.445507, loss2 : 3.207301
train_step : 3032, loss1 : 4.462306, loss2 : 4.219697
train_step : 3033, loss1 : 5.209861, loss2 : 4.501946
train_step : 3034, loss1 : 6.041339, loss2 : 5.207512
train_step : 3035, loss1 : 5.204640, loss2 : 5.249047
train_step : 3036, loss1 : 5.338002, loss2 : 5.540909
train_step : 3037, loss1 : 7.045959, loss2 : 6.206600
train_step : 3038, loss1 : 7.380968, loss2 : 6.405690
train_step : 3039, loss1 : 5.285869, loss2 : 4.938190
train_step : 3040, loss1 : 4.386411, loss2 : 6.327168
train_step : 3041, loss1 : 3.933004, loss2 : 4.668979
train_step : 3042, loss1 : 8.940742, loss2 : 4.127229
train_step : 3043, loss1 : 4.277584, loss2 : 3.907532
train_step : 3044, loss1 : 3.333188, loss2 : 2.795702
train_step : 3045, loss1 : 3.441776, loss2 : 2.182087
train_step : 3046, loss1 : 5.709399, loss2 : 3.462558
train_step : 3047, loss1 : 2.989122, loss2 : 4.739676
train_step : 3048, loss1 : 3.838114, loss2 : 2.441238
train_step : 3049, loss1 : 4.041264, loss2 : 1.486177
train_step : 3050, loss1 : 1.985335, loss2 : 1.410466
train_step : 3051, loss1 : 2.564411, loss2 : 2.119985
train_step : 3052, loss1 : 4.636021, loss2 : 4.037627
train_step : 3053, loss1 : 2.018867, loss2 : 2.986853
train_step : 3054, loss1 : 2.026211, loss2 : 2.558174
train_step : 3055, loss1 : 2.516898, loss2 : 2.630779
train_step : 3056, loss1 : 6.363269, loss2 : 2.868567
train_step : 3057, loss1 : 2.599489, loss2 : 2.078217
train_step : 3058, loss1 : 2.087851, loss2 : 4.754714
train_step : 3059, loss1 : 1.106957, loss2 : 0.893690
train_step : 3060, loss1 : 2.192961, loss2 : 1.161371
train_step : 3061, loss1 : 0.683211, loss2 : 1.324954
train_step : 3062, loss1 : 3.050014, loss2 : 1.336460
train_step : 3063, loss1 : 1.146065, loss2 : 4.608349
train_step : 3064, loss1 : 1.915136, loss2 : 1.857513
train_step : 3065, loss1 : 2.295417, loss2 : 2.926641
train_step : 3066, loss1 : 3.366530, loss2 : 4.091726
train_step : 3067, loss1 : 3.476889, loss2 : 6.435411
train_step : 3068, loss1 : 4.203905, loss2 : 5.562772
train_step : 3069, loss1 : 2.150122, loss2 : 3.574892
train_step : 3070, loss1 : 2.658341, loss2 : 2.587196
train_step : 3071, loss1 : 2.083745, loss2 : 2.056170
train_step : 3072, loss1 : 2.597698, loss2 : 2.748701
train_step : 3073, loss1 : 1.011174, loss2 : 1.478768
train_step : 3074, loss1 : 2.308830, loss2 : 1.287076
train_step : 3075, loss1 : 1.195771, loss2 : 3.678013
train_step : 3076, loss1 : 2.209831, loss2 : 1.605286
train_step : 3077, loss1 : 1.426872, loss2 : 1.293380
train_step : 3078, loss1 : 1.732612, loss2 : 1.004536
train_step : 3079, loss1 : 2.055472, loss2 : 1.732018
train_step : 3080, loss1 : 1.744743, loss2 : 1.298576
train_step : 3081, loss1 : 1.309181, loss2 : 0.764331
train_step : 3082, loss1 : 1.007264, loss2 : 1.864140
train_step : 3083, loss1 : 1.379454, loss2 : 0.829568
train_step : 3084, loss1 : 0.930263, loss2 : 3.400900
train_step : 3085, loss1 : 0.644335, loss2 : 0.603233
train_step : 3086, loss1 : 0.893695, loss2 : 1.547117
train_step : 3087, loss1 : 1.162596, loss2 : 2.036364
train_step : 3088, loss1 : 3.509995, loss2 : 2.879240
train_step : 3089, loss1 : 5.088977, loss2 : 3.821760
train_step : 3090, loss1 : 4.618618, loss2 : 3.516590
train_step : 3091, loss1 : 4.381268, loss2 : 2.943681
train_step : 3092, loss1 : 4.711143, loss2 : 6.503311
train_step : 3093, loss1 : 4.351081, loss2 : 4.978669
train_step : 3094, loss1 : 4.807595, loss2 : 7.604894
train_step : 3095, loss1 : 5.399609, loss2 : 2.889412
train_step : 3096, loss1 : 4.606083, loss2 : 6.200593
train_step : 3097, loss1 : 2.968858, loss2 : 2.736752
train_step : 3098, loss1 : 1.989861, loss2 : 2.057334
train_step : 3099, loss1 : 2.255366, loss2 : 0.900110
train_step : 3100, loss1 : 2.304626, loss2 : 1.271439
train_step : 3101, loss1 : 2.863162, loss2 : 3.178153
train_step : 3102, loss1 : 1.702257, loss2 : 2.784865
train_step : 3103, loss1 : 2.012386, loss2 : 1.136957
train_step : 3104, loss1 : 1.797740, loss2 : 1.872033
train_step : 3105, loss1 : 1.487095, loss2 : 2.827414
train_step : 3106, loss1 : 2.548237, loss2 : 2.775093
train_step : 3107, loss1 : 1.553498, loss2 : 2.768851
train_step : 3108, loss1 : 2.524195, loss2 : 1.790579
train_step : 3109, loss1 : 2.523038, loss2 : 1.272802
train_step : 3110, loss1 : 1.248819, loss2 : 1.700002
train_step : 3111, loss1 : 0.848589, loss2 : 1.288791
train_step : 3112, loss1 : 1.229119, loss2 : 1.513357
train_step : 3113, loss1 : 1.227205, loss2 : 1.164960
train_step : 3114, loss1 : 0.782456, loss2 : 1.490508
train_step : 3115, loss1 : 1.195330, loss2 : 0.749771
train_step : 3116, loss1 : 0.559936, loss2 : 1.512680
train_step : 3117, loss1 : 1.735639, loss2 : 0.842689
train_step : 3118, loss1 : 0.927348, loss2 : 1.220305
train_step : 3119, loss1 : 0.693488, loss2 : 0.637535
train_step : 3120, loss1 : 2.137361, loss2 : 2.448848
train_step : 3121, loss1 : 0.463350, loss2 : 1.464199
train_step : 3122, loss1 : 2.227624, loss2 : 0.780725
train_step : 3123, loss1 : 0.782737, loss2 : 1.507682
train_step : 3124, loss1 : 1.519123, loss2 : 1.284263
train_step : 3125, loss1 : 1.420236, loss2 : 1.499793
train_step : 3126, loss1 : 1.148952, loss2 : 1.196383
train_step : 3127, loss1 : 0.992518, loss2 : 1.022592
train_step : 3128, loss1 : 2.323570, loss2 : 1.134104
train_step : 3129, loss1 : 1.409744, loss2 : 1.534442
train_step : 3130, loss1 : 0.881927, loss2 : 4.061547
train_step : 3131, loss1 : 0.724614, loss2 : 1.047483
train_step : 3132, loss1 : 1.485711, loss2 : 1.464136
train_step : 3133, loss1 : 2.347053, loss2 : 1.362862
train_step : 3134, loss1 : 1.938090, loss2 : 3.084645
train_step : 3135, loss1 : 2.169477, loss2 : 1.540643
train_step : 3136, loss1 : 2.961236, loss2 : 3.095082
train_step : 3137, loss1 : 3.197427, loss2 : 3.500352
train_step : 3138, loss1 : 3.740803, loss2 : 3.193368
train_step : 3139, loss1 : 3.450368, loss2 : 5.296778
train_step : 3140, loss1 : 1.943962, loss2 : 2.497317
train_step : 3141, loss1 : 3.080759, loss2 : 2.347563
train_step : 3142, loss1 : 3.559557, loss2 : 10.556232
train_step : 3143, loss1 : 2.874744, loss2 : 4.441248
train_step : 3144, loss1 : 3.796233, loss2 : 3.180661
train_step : 3145, loss1 : 3.388162, loss2 : 3.261922
train_step : 3146, loss1 : 3.365284, loss2 : 3.678046
train_step : 3147, loss1 : 1.823347, loss2 : 3.276717
train_step : 3148, loss1 : 4.547213, loss2 : 2.983827
train_step : 3149, loss1 : 3.051151, loss2 : 3.309009
train_step : 3150, loss1 : 2.429760, loss2 : 3.873987
train_step : 3151, loss1 : 4.013706, loss2 : 4.030702
train_step : 3152, loss1 : 4.102588, loss2 : 3.346211
train_step : 3153, loss1 : 7.132349, loss2 : 3.992361
train_step : 3154, loss1 : 8.127462, loss2 : 6.547878
train_step : 3155, loss1 : 2.499034, loss2 : 4.445846
train_step : 3156, loss1 : 5.817493, loss2 : 2.908743
train_step : 3157, loss1 : 3.122294, loss2 : 1.508345
train_step : 3158, loss1 : 3.345607, loss2 : 3.979034
train_step : 3159, loss1 : 3.489400, loss2 : 2.737400
train_step : 3160, loss1 : 4.388029, loss2 : 4.423214
train_step : 3161, loss1 : 4.439733, loss2 : 3.751348
train_step : 3162, loss1 : 5.025283, loss2 : 4.073334
train_step : 3163, loss1 : 4.423950, loss2 : 5.565569
train_step : 3164, loss1 : 3.633353, loss2 : 4.939949
train_step : 3165, loss1 : 2.572222, loss2 : 2.214590
train_step : 3166, loss1 : 3.935213, loss2 : 3.043868
train_step : 3167, loss1 : 3.994364, loss2 : 3.424275
train_step : 3168, loss1 : 2.822976, loss2 : 3.465032
train_step : 3169, loss1 : 2.215058, loss2 : 3.052630
train_step : 3170, loss1 : 2.898475, loss2 : 1.496414
train_step : 3171, loss1 : 1.470015, loss2 : 2.052953
train_step : 3172, loss1 : 1.842244, loss2 : 1.414791
train_step : 3173, loss1 : 0.890531, loss2 : 0.837480
train_step : 3174, loss1 : 0.826976, loss2 : 1.807274
train_step : 3175, loss1 : 2.490113, loss2 : 1.630070
train_step : 3176, loss1 : 0.699469, loss2 : 1.226100
train_step : 3177, loss1 : 1.057524, loss2 : 1.036469
train_step : 3178, loss1 : 3.260224, loss2 : 1.938892
train_step : 3179, loss1 : 0.571106, loss2 : 1.545137
train_step : 3180, loss1 : 1.195803, loss2 : 1.225834
train_step : 3181, loss1 : 1.035241, loss2 : 0.678415
train_step : 3182, loss1 : 1.520801, loss2 : 1.330832
train_step : 3183, loss1 : 2.322798, loss2 : 1.457483
train_step : 3184, loss1 : 0.742696, loss2 : 1.542374
train_step : 3185, loss1 : 1.131700, loss2 : 1.223992
train_step : 3186, loss1 : 1.601545, loss2 : 1.381451
train_step : 3187, loss1 : 4.820678, loss2 : 1.272033
train_step : 3188, loss1 : 1.426765, loss2 : 1.089493
train_step : 3189, loss1 : 1.060798, loss2 : 1.567973
train_step : 3190, loss1 : 1.403889, loss2 : 0.678084
train_step : 3191, loss1 : 2.019618, loss2 : 1.300084
train_step : 3192, loss1 : 1.531557, loss2 : 2.836482
train_step : 3193, loss1 : 1.761868, loss2 : 2.550330
train_step : 3194, loss1 : 4.242542, loss2 : 2.048484
train_step : 3195, loss1 : 2.992412, loss2 : 2.066632
train_step : 3196, loss1 : 4.073583, loss2 : 6.028937
train_step : 3197, loss1 : 3.289672, loss2 : 2.838338
train_step : 3198, loss1 : 3.226837, loss2 : 5.129898
train_step : 3199, loss1 : 3.623348, loss2 : 3.064985
train_step : 3200, loss1 : 3.973732, loss2 : 3.892182
train_step : 3201, loss1 : 3.620948, loss2 : 2.209922
train_step : 3202, loss1 : 4.280697, loss2 : 3.274862
train_step : 3203, loss1 : 4.660157, loss2 : 5.046497
train_step : 3204, loss1 : 5.179397, loss2 : 6.895761
train_step : 3205, loss1 : 4.436365, loss2 : 3.994264
train_step : 3206, loss1 : 3.959287, loss2 : 8.598593
train_step : 3207, loss1 : 3.194665, loss2 : 2.174535
train_step : 3208, loss1 : 2.565852, loss2 : 2.158488
train_step : 3209, loss1 : 1.669687, loss2 : 1.990627
train_step : 3210, loss1 : 1.211331, loss2 : 1.350755
train_step : 3211, loss1 : 0.908149, loss2 : 1.009128
train_step : 3212, loss1 : 0.966771, loss2 : 1.378792
train_step : 3213, loss1 : 0.596012, loss2 : 0.683276
train_step : 3214, loss1 : 1.084507, loss2 : 1.237499
train_step : 3215, loss1 : 1.340927, loss2 : 1.452072
train_step : 3216, loss1 : 0.657033, loss2 : 1.870234
train_step : 3217, loss1 : 0.710029, loss2 : 1.879305
train_step : 3218, loss1 : 1.213649, loss2 : 1.306554
train_step : 3219, loss1 : 1.602533, loss2 : 1.703279
train_step : 3220, loss1 : 1.336662, loss2 : 1.078198
train_step : 3221, loss1 : 1.420675, loss2 : 1.827188
train_step : 3222, loss1 : 1.108302, loss2 : 0.874091
train_step : 3223, loss1 : 1.890026, loss2 : 2.711740
train_step : 3224, loss1 : 1.811886, loss2 : 0.794709
train_step : 3225, loss1 : 1.654588, loss2 : 1.979484
train_step : 3226, loss1 : 1.620387, loss2 : 2.446741
train_step : 3227, loss1 : 3.184262, loss2 : 2.999068
train_step : 3228, loss1 : 4.879058, loss2 : 3.348231
train_step : 3229, loss1 : 4.259017, loss2 : 3.869468
train_step : 3230, loss1 : 3.085025, loss2 : 3.815617
train_step : 3231, loss1 : 3.855321, loss2 : 5.788609
train_step : 3232, loss1 : 2.383920, loss2 : 4.847927
train_step : 3233, loss1 : 2.127524, loss2 : 2.818638
train_step : 3234, loss1 : 2.274013, loss2 : 2.520680
train_step : 3235, loss1 : 2.599994, loss2 : 3.472530
train_step : 3236, loss1 : 2.908892, loss2 : 3.056880
train_step : 3237, loss1 : 3.490554, loss2 : 5.178474
train_step : 3238, loss1 : 4.539461, loss2 : 4.209642
train_step : 3239, loss1 : 2.956861, loss2 : 4.286405
train_step : 3240, loss1 : 3.034220, loss2 : 2.903434
train_step : 3241, loss1 : 2.706478, loss2 : 3.390766
train_step : 3242, loss1 : 2.414598, loss2 : 4.271691
train_step : 3243, loss1 : 2.465546, loss2 : 4.249069
train_step : 3244, loss1 : 3.778290, loss2 : 2.810253
train_step : 3245, loss1 : 3.954133, loss2 : 4.627219
train_step : 3246, loss1 : 3.775822, loss2 : 1.367620
train_step : 3247, loss1 : 1.421675, loss2 : 2.650322
train_step : 3248, loss1 : 1.983386, loss2 : 1.475951
train_step : 3249, loss1 : 2.243556, loss2 : 3.123397
train_step : 3250, loss1 : 2.795039, loss2 : 2.354607
train_step : 3251, loss1 : 2.776999, loss2 : 2.892119
train_step : 3252, loss1 : 2.891383, loss2 : 1.690123
train_step : 3253, loss1 : 2.715873, loss2 : 2.227166
train_step : 3254, loss1 : 1.881691, loss2 : 1.189224
train_step : 3255, loss1 : 0.821529, loss2 : 1.426298
train_step : 3256, loss1 : 2.256595, loss2 : 1.553060
train_step : 3257, loss1 : 2.095712, loss2 : 2.570602
train_step : 3258, loss1 : 1.467571, loss2 : 1.958371
train_step : 3259, loss1 : 1.538073, loss2 : 3.369616
train_step : 3260, loss1 : 2.944748, loss2 : 2.694041
train_step : 3261, loss1 : 2.274734, loss2 : 1.875341
train_step : 3262, loss1 : 2.277071, loss2 : 2.294233
train_step : 3263, loss1 : 2.273338, loss2 : 3.260900
train_step : 3264, loss1 : 2.984919, loss2 : 1.924372
train_step : 3265, loss1 : 1.566048, loss2 : 2.946200
train_step : 3266, loss1 : 2.046324, loss2 : 2.443569
train_step : 3267, loss1 : 1.992678, loss2 : 3.627250
train_step : 3268, loss1 : 1.532873, loss2 : 2.425401
train_step : 3269, loss1 : 1.722869, loss2 : 1.693260
train_step : 3270, loss1 : 2.226707, loss2 : 1.907248
train_step : 3271, loss1 : 1.332613, loss2 : 1.820849
train_step : 3272, loss1 : 0.992328, loss2 : 1.695055
train_step : 3273, loss1 : 0.619044, loss2 : 2.030391
train_step : 3274, loss1 : 0.717743, loss2 : 1.011186
train_step : 3275, loss1 : 1.097670, loss2 : 3.103386
train_step : 3276, loss1 : 1.148103, loss2 : 1.139219
train_step : 3277, loss1 : 0.835768, loss2 : 1.304379
train_step : 3278, loss1 : 1.503799, loss2 : 0.793784
train_step : 3279, loss1 : 2.784390, loss2 : 1.589437
train_step : 3280, loss1 : 0.952754, loss2 : 0.731573
train_step : 3281, loss1 : 1.326613, loss2 : 3.577880
train_step : 3282, loss1 : 1.327410, loss2 : 1.804294
train_step : 3283, loss1 : 1.851404, loss2 : 2.233909
train_step : 3284, loss1 : 2.646235, loss2 : 2.863020
train_step : 3285, loss1 : 3.233531, loss2 : 4.782956
train_step : 3286, loss1 : 4.375868, loss2 : 3.777978
train_step : 3287, loss1 : 3.743329, loss2 : 1.936884
train_step : 3288, loss1 : 3.265409, loss2 : 5.610622
train_step : 3289, loss1 : 2.908850, loss2 : 2.992570
train_step : 3290, loss1 : 3.511587, loss2 : 3.729876
train_step : 3291, loss1 : 3.751009, loss2 : 3.061831
train_step : 3292, loss1 : 3.365908, loss2 : 2.010532
train_step : 3293, loss1 : 2.695007, loss2 : 2.905418
train_step : 3294, loss1 : 3.859482, loss2 : 3.098074
train_step : 3295, loss1 : 3.628771, loss2 : 2.103185
train_step : 3296, loss1 : 3.241449, loss2 : 3.739749
train_step : 3297, loss1 : 3.269240, loss2 : 4.584898
train_step : 3298, loss1 : 2.984812, loss2 : 4.948539
train_step : 3299, loss1 : 3.653321, loss2 : 2.777342
train_step : 3300, loss1 : 3.830259, loss2 : 2.741687
train_step : 3301, loss1 : 2.027947, loss2 : 1.666603
train_step : 3302, loss1 : 2.451519, loss2 : 1.490804
train_step : 3303, loss1 : 1.284869, loss2 : 2.624298
train_step : 3304, loss1 : 2.224207, loss2 : 2.370959
train_step : 3305, loss1 : 1.342402, loss2 : 1.278793
train_step : 3306, loss1 : 1.681292, loss2 : 2.103668
train_step : 3307, loss1 : 0.614625, loss2 : 0.983183
train_step : 3308, loss1 : 1.399960, loss2 : 1.519089
train_step : 3309, loss1 : 0.357524, loss2 : 1.486305
train_step : 3310, loss1 : 1.855351, loss2 : 0.491400
train_step : 3311, loss1 : 1.280840, loss2 : 0.552840
train_step : 3312, loss1 : 0.630909, loss2 : 1.009137
train_step : 3313, loss1 : 0.922398, loss2 : 1.103985
train_step : 3314, loss1 : 1.139551, loss2 : 0.968450
train_step : 3315, loss1 : 0.969902, loss2 : 0.788646
train_step : 3316, loss1 : 0.867027, loss2 : 1.874508
train_step : 3317, loss1 : 3.284236, loss2 : 1.097311
train_step : 3318, loss1 : 1.067160, loss2 : 1.354087
train_step : 3319, loss1 : 2.255507, loss2 : 0.869031
train_step : 3320, loss1 : 4.205465, loss2 : 1.447670
train_step : 3321, loss1 : 1.171579, loss2 : 2.389730
train_step : 3322, loss1 : 2.116944, loss2 : 1.870402
train_step : 3323, loss1 : 2.660244, loss2 : 1.922914
train_step : 3324, loss1 : 2.650396, loss2 : 2.645463
train_step : 3325, loss1 : 2.432600, loss2 : 3.171318
train_step : 3326, loss1 : 4.944313, loss2 : 2.989228
train_step : 3327, loss1 : 3.101831, loss2 : 2.859206
train_step : 3328, loss1 : 4.434612, loss2 : 4.449737
train_step : 3329, loss1 : 2.852012, loss2 : 5.233146
train_step : 3330, loss1 : 4.932183, loss2 : 5.073250
train_step : 3331, loss1 : 3.847584, loss2 : 5.651960
train_step : 3332, loss1 : 7.053381, loss2 : 4.902543
train_step : 3333, loss1 : 3.944173, loss2 : 4.540586
train_step : 3334, loss1 : 3.047111, loss2 : 2.793482
train_step : 3335, loss1 : 1.406375, loss2 : 2.839850
train_step : 3336, loss1 : 1.068909, loss2 : 1.540624
train_step : 3337, loss1 : 1.384309, loss2 : 1.423152
train_step : 3338, loss1 : 3.304240, loss2 : 1.471271
train_step : 3339, loss1 : 1.207515, loss2 : 1.246283
train_step : 3340, loss1 : 1.357521, loss2 : 1.289203
train_step : 3341, loss1 : 1.495013, loss2 : 1.961106
train_step : 3342, loss1 : 1.159863, loss2 : 0.839322
train_step : 3343, loss1 : 1.839895, loss2 : 0.910729
train_step : 3344, loss1 : 1.286188, loss2 : 1.310664
train_step : 3345, loss1 : 0.980058, loss2 : 1.019178
train_step : 3346, loss1 : 1.904344, loss2 : 2.063988
train_step : 3347, loss1 : 4.165207, loss2 : 2.211731
train_step : 3348, loss1 : 3.134156, loss2 : 3.088674
train_step : 3349, loss1 : 3.128828, loss2 : 3.733098
train_step : 3350, loss1 : 2.436253, loss2 : 2.752815
train_step : 3351, loss1 : 2.002803, loss2 : 1.910453
train_step : 3352, loss1 : 1.542670, loss2 : 1.705322
train_step : 3353, loss1 : 1.932850, loss2 : 1.436656
train_step : 3354, loss1 : 1.948949, loss2 : 1.303516
train_step : 3355, loss1 : 1.686204, loss2 : 1.103679
train_step : 3356, loss1 : 1.395250, loss2 : 2.095619
train_step : 3357, loss1 : 1.297636, loss2 : 2.460495
train_step : 3358, loss1 : 1.982285, loss2 : 2.414888
train_step : 3359, loss1 : 2.929148, loss2 : 2.361837
train_step : 3360, loss1 : 0.778965, loss2 : 4.857361
train_step : 3361, loss1 : 0.997508, loss2 : 0.922141
train_step : 3362, loss1 : 1.609885, loss2 : 1.177223
train_step : 3363, loss1 : 2.670838, loss2 : 2.206359
train_step : 3364, loss1 : 3.209432, loss2 : 1.088819
train_step : 3365, loss1 : 0.985271, loss2 : 3.668523
train_step : 3366, loss1 : 2.231953, loss2 : 1.861624
train_step : 3367, loss1 : 1.140988, loss2 : 1.398301
train_step : 3368, loss1 : 1.155403, loss2 : 0.925163
train_step : 3369, loss1 : 1.874526, loss2 : 1.722778
train_step : 3370, loss1 : 1.879015, loss2 : 1.053301
train_step : 3371, loss1 : 1.230240, loss2 : 1.574505
train_step : 3372, loss1 : 1.788176, loss2 : 2.562112
train_step : 3373, loss1 : 2.668784, loss2 : 3.312970
train_step : 3374, loss1 : 3.066231, loss2 : 2.974162
train_step : 3375, loss1 : 2.421949, loss2 : 6.025703
train_step : 3376, loss1 : 2.532056, loss2 : 4.035341
train_step : 3377, loss1 : 1.601255, loss2 : 2.472385
train_step : 3378, loss1 : 2.773312, loss2 : 1.636678
train_step : 3379, loss1 : 1.445913, loss2 : 1.488328
train_step : 3380, loss1 : 3.685042, loss2 : 1.414199
train_step : 3381, loss1 : 0.894784, loss2 : 1.364544
train_step : 3382, loss1 : 1.492354, loss2 : 1.913136
train_step : 3383, loss1 : 3.084819, loss2 : 0.996513
train_step : 3384, loss1 : 2.693662, loss2 : 1.500308
train_step : 3385, loss1 : 1.498302, loss2 : 1.558360
train_step : 3386, loss1 : 0.839782, loss2 : 1.455959
train_step : 3387, loss1 : 0.662577, loss2 : 3.391564
train_step : 3388, loss1 : 1.836872, loss2 : 1.918592
train_step : 3389, loss1 : 3.491261, loss2 : 1.212493
train_step : 3390, loss1 : 2.935523, loss2 : 2.904618
train_step : 3391, loss1 : 2.242630, loss2 : 2.633895
train_step : 3392, loss1 : 3.074107, loss2 : 2.571171
train_step : 3393, loss1 : 5.077877, loss2 : 2.544502
train_step : 3394, loss1 : 4.142433, loss2 : 4.813404
train_step : 3395, loss1 : 2.644835, loss2 : 3.192332
train_step : 3396, loss1 : 4.623178, loss2 : 2.644825
train_step : 3397, loss1 : 3.480776, loss2 : 2.743687
train_step : 3398, loss1 : 5.738190, loss2 : 4.060222
train_step : 3399, loss1 : 5.570648, loss2 : 4.701424
train_step : 3400, loss1 : 5.676546, loss2 : 5.708565
train_step : 3401, loss1 : 4.821657, loss2 : 5.775223
train_step : 3402, loss1 : 6.236542, loss2 : 6.450568
train_step : 3403, loss1 : 5.719236, loss2 : 3.487990
train_step : 3404, loss1 : 3.747870, loss2 : 4.379096
train_step : 3405, loss1 : 2.205711, loss2 : 2.467686
train_step : 3406, loss1 : 2.790851, loss2 : 2.535261
train_step : 3407, loss1 : 3.420586, loss2 : 3.042650
train_step : 3408, loss1 : 3.040365, loss2 : 4.324865
train_step : 3409, loss1 : 2.682058, loss2 : 1.018531
train_step : 3410, loss1 : 1.182717, loss2 : 0.857222
train_step : 3411, loss1 : 1.010377, loss2 : 1.710794
train_step : 3412, loss1 : 0.726795, loss2 : 0.703336
train_step : 3413, loss1 : 1.790515, loss2 : 1.058008
train_step : 3414, loss1 : 1.925836, loss2 : 1.469693
train_step : 3415, loss1 : 1.978911, loss2 : 1.684272
train_step : 3416, loss1 : 1.892893, loss2 : 3.709712
train_step : 3417, loss1 : 1.281946, loss2 : 2.116249
train_step : 3418, loss1 : 1.134957, loss2 : 1.794467
train_step : 3419, loss1 : 1.876187, loss2 : 2.788171
train_step : 3420, loss1 : 1.092373, loss2 : 1.646983
train_step : 3421, loss1 : 0.813699, loss2 : 1.196245
train_step : 3422, loss1 : 0.839764, loss2 : 1.192144
train_step : 3423, loss1 : 1.352354, loss2 : 1.481303
train_step : 3424, loss1 : 1.194334, loss2 : 1.154643
train_step : 3425, loss1 : 1.765159, loss2 : 1.403632
train_step : 3426, loss1 : 1.132740, loss2 : 2.861435
train_step : 3427, loss1 : 2.114722, loss2 : 0.941804
train_step : 3428, loss1 : 2.313918, loss2 : 1.958807
train_step : 3429, loss1 : 1.945777, loss2 : 0.983116
train_step : 3430, loss1 : 1.046982, loss2 : 1.011327
train_step : 3431, loss1 : 1.146205, loss2 : 1.098965
train_step : 3432, loss1 : 1.791301, loss2 : 1.213850
train_step : 3433, loss1 : 2.985099, loss2 : 1.786704
train_step : 3434, loss1 : 2.424833, loss2 : 3.891043
train_step : 3435, loss1 : 3.315685, loss2 : 3.623006
train_step : 3436, loss1 : 3.397351, loss2 : 2.991425
train_step : 3437, loss1 : 3.150374, loss2 : 3.132864
train_step : 3438, loss1 : 3.199318, loss2 : 1.382714
train_step : 3439, loss1 : 2.331049, loss2 : 2.604615
train_step : 3440, loss1 : 2.891200, loss2 : 2.505731
train_step : 3441, loss1 : 1.929734, loss2 : 2.279250
train_step : 3442, loss1 : 2.171751, loss2 : 1.797036
train_step : 3443, loss1 : 2.055536, loss2 : 2.028478
train_step : 3444, loss1 : 2.057398, loss2 : 2.000804
train_step : 3445, loss1 : 0.879619, loss2 : 1.409861
train_step : 3446, loss1 : 1.628338, loss2 : 1.750661
train_step : 3447, loss1 : 1.280934, loss2 : 1.501486
train_step : 3448, loss1 : 1.491258, loss2 : 1.410648
train_step : 3449, loss1 : 1.037021, loss2 : 1.304774
train_step : 3450, loss1 : 1.094041, loss2 : 1.377837
train_step : 3451, loss1 : 2.195380, loss2 : 2.130789
train_step : 3452, loss1 : 2.415400, loss2 : 2.407887
train_step : 3453, loss1 : 4.403975, loss2 : 3.334255
train_step : 3454, loss1 : 2.289909, loss2 : 3.019762
train_step : 3455, loss1 : 2.741846, loss2 : 2.435014
train_step : 3456, loss1 : 1.367538, loss2 : 1.582277
train_step : 3457, loss1 : 1.480668, loss2 : 1.673452
train_step : 3458, loss1 : 1.083379, loss2 : 0.771311
train_step : 3459, loss1 : 0.748970, loss2 : 1.538819
train_step : 3460, loss1 : 1.324354, loss2 : 0.877659
train_step : 3461, loss1 : 1.340689, loss2 : 1.801130
train_step : 3462, loss1 : 1.941304, loss2 : 2.826984
train_step : 3463, loss1 : 2.437469, loss2 : 1.720942
train_step : 3464, loss1 : 1.917202, loss2 : 2.908680
train_step : 3465, loss1 : 2.591024, loss2 : 1.259962
train_step : 3466, loss1 : 1.075402, loss2 : 1.221678
train_step : 3467, loss1 : 1.160218, loss2 : 1.351615
train_step : 3468, loss1 : 1.139728, loss2 : 1.357509
train_step : 3469, loss1 : 2.487896, loss2 : 2.882926
train_step : 3470, loss1 : 2.971868, loss2 : 2.509340
train_step : 3471, loss1 : 1.574398, loss2 : 1.870506
train_step : 3472, loss1 : 1.336038, loss2 : 2.024442
train_step : 3473, loss1 : 1.964381, loss2 : 1.095752
train_step : 3474, loss1 : 2.269477, loss2 : 1.731799
train_step : 3475, loss1 : 0.906518, loss2 : 1.196564
train_step : 3476, loss1 : 0.994206, loss2 : 1.750028
train_step : 3477, loss1 : 0.870474, loss2 : 1.014045
train_step : 3478, loss1 : 0.312103, loss2 : 0.718257
train_step : 3479, loss1 : 1.346250, loss2 : 0.710792
train_step : 3480, loss1 : 0.624820, loss2 : 1.104252
train_step : 3481, loss1 : 1.424727, loss2 : 0.828128
train_step : 3482, loss1 : 0.853485, loss2 : 0.930344
train_step : 3483, loss1 : 0.915651, loss2 : 1.150782
train_step : 3484, loss1 : 1.126525, loss2 : 0.938408
train_step : 3485, loss1 : 1.168960, loss2 : 1.582006
train_step : 3486, loss1 : 1.769631, loss2 : 1.205713
train_step : 3487, loss1 : 2.445592, loss2 : 1.707871
train_step : 3488, loss1 : 2.710830, loss2 : 1.581847
train_step : 3489, loss1 : 1.276894, loss2 : 2.244399
train_step : 3490, loss1 : 0.795137, loss2 : 5.421597
train_step : 3491, loss1 : 1.233341, loss2 : 1.777544
train_step : 3492, loss1 : 0.780614, loss2 : 2.013247
train_step : 3493, loss1 : 1.484741, loss2 : 2.884106
train_step : 3494, loss1 : 2.051766, loss2 : 1.343809
train_step : 3495, loss1 : 1.722661, loss2 : 2.571214
train_step : 3496, loss1 : 2.086542, loss2 : 4.799332
train_step : 3497, loss1 : 2.296144, loss2 : 2.237009
train_step : 3498, loss1 : 3.279659, loss2 : 0.910843
train_step : 3499, loss1 : 2.217753, loss2 : 2.152096
train_step : 3500, loss1 : 1.423342, loss2 : 3.214846
train_step : 3501, loss1 : 2.831519, loss2 : 2.387010
train_step : 3502, loss1 : 4.072022, loss2 : 2.816086
train_step : 3503, loss1 : 3.483869, loss2 : 5.167427
train_step : 3504, loss1 : 3.269092, loss2 : 4.899217
train_step : 3505, loss1 : 3.834430, loss2 : 3.099925
train_step : 3506, loss1 : 4.552395, loss2 : 2.665151
train_step : 3507, loss1 : 3.630614, loss2 : 4.246400
train_step : 3508, loss1 : 2.551525, loss2 : 3.846237
train_step : 3509, loss1 : 2.691560, loss2 : 2.415409
train_step : 3510, loss1 : 4.279610, loss2 : 2.146967
train_step : 3511, loss1 : 4.103858, loss2 : 3.917516
train_step : 3512, loss1 : 3.018384, loss2 : 3.168692
train_step : 3513, loss1 : 5.504219, loss2 : 3.105502
train_step : 3514, loss1 : 3.333182, loss2 : 2.168950
train_step : 3515, loss1 : 3.867587, loss2 : 2.780454
train_step : 3516, loss1 : 2.386235, loss2 : 1.986865
train_step : 3517, loss1 : 3.689065, loss2 : 4.341387
train_step : 3518, loss1 : 1.263494, loss2 : 2.402930
train_step : 3519, loss1 : 1.810919, loss2 : 2.601836
train_step : 3520, loss1 : 2.530318, loss2 : 2.049134
train_step : 3521, loss1 : 3.130604, loss2 : 5.193569
train_step : 3522, loss1 : 2.634451, loss2 : 2.407245
train_step : 3523, loss1 : 2.303459, loss2 : 2.501643
train_step : 3524, loss1 : 1.655122, loss2 : 0.870959
train_step : 3525, loss1 : 1.634728, loss2 : 0.995219
train_step : 3526, loss1 : 0.992520, loss2 : 1.426284
train_step : 3527, loss1 : 1.515263, loss2 : 1.385137
train_step : 3528, loss1 : 1.325506, loss2 : 1.499070
train_step : 3529, loss1 : 1.413964, loss2 : 1.064044
train_step : 3530, loss1 : 2.678659, loss2 : 0.941232
train_step : 3531, loss1 : 1.363485, loss2 : 1.169831
train_step : 3532, loss1 : 1.485376, loss2 : 1.393355
train_step : 3533, loss1 : 1.649520, loss2 : 0.966382
train_step : 3534, loss1 : 1.554643, loss2 : 3.347007
train_step : 3535, loss1 : 3.194769, loss2 : 1.898975
train_step : 3536, loss1 : 2.882288, loss2 : 4.805148
train_step : 3537, loss1 : 6.125769, loss2 : 4.013434
train_step : 3538, loss1 : 6.224478, loss2 : 6.507656
train_step : 3539, loss1 : 9.336312, loss2 : 7.528461
train_step : 3540, loss1 : 1.140224, loss2 : 2.665048
train_step : 3541, loss1 : 1.210235, loss2 : 2.108920
train_step : 3542, loss1 : 1.293944, loss2 : 1.888035
train_step : 3543, loss1 : 3.878520, loss2 : 1.089284
train_step : 3544, loss1 : 1.379710, loss2 : 2.961926
train_step : 3545, loss1 : 1.893707, loss2 : 1.514408
train_step : 3546, loss1 : 1.357176, loss2 : 1.470457
train_step : 3547, loss1 : 0.957545, loss2 : 0.660373
train_step : 3548, loss1 : 1.941775, loss2 : 1.322934
train_step : 3549, loss1 : 2.541915, loss2 : 1.801725
train_step : 3550, loss1 : 1.165645, loss2 : 1.446914
train_step : 3551, loss1 : 2.311904, loss2 : 1.925699
train_step : 3552, loss1 : 1.479079, loss2 : 1.446455
train_step : 3553, loss1 : 1.266852, loss2 : 2.064964
train_step : 3554, loss1 : 1.180381, loss2 : 0.948473
train_step : 3555, loss1 : 5.116788, loss2 : 1.069430
train_step : 3556, loss1 : 1.505864, loss2 : 1.260156
train_step : 3557, loss1 : 1.519182, loss2 : 1.006834
train_step : 3558, loss1 : 0.937122, loss2 : 2.306440
train_step : 3559, loss1 : 1.831648, loss2 : 1.387550
train_step : 3560, loss1 : 1.206652, loss2 : 0.583245
train_step : 3561, loss1 : 1.612357, loss2 : 1.054502
train_step : 3562, loss1 : 1.899030, loss2 : 2.251354
train_step : 3563, loss1 : 1.228592, loss2 : 1.785062
train_step : 3564, loss1 : 1.652903, loss2 : 1.537956
train_step : 3565, loss1 : 2.444234, loss2 : 1.253166
train_step : 3566, loss1 : 0.968984, loss2 : 2.350631
train_step : 3567, loss1 : 1.174030, loss2 : 0.927118
train_step : 3568, loss1 : 0.900557, loss2 : 1.565071
train_step : 3569, loss1 : 1.676403, loss2 : 1.062383
train_step : 3570, loss1 : 0.750820, loss2 : 1.270048
train_step : 3571, loss1 : 0.385197, loss2 : 0.669555
train_step : 3572, loss1 : 0.963544, loss2 : 1.411014
train_step : 3573, loss1 : 1.333392, loss2 : 1.430741
train_step : 3574, loss1 : 1.314504, loss2 : 1.220533
train_step : 3575, loss1 : 3.112050, loss2 : 1.511035
train_step : 3576, loss1 : 1.114449, loss2 : 1.265232
train_step : 3577, loss1 : 1.983257, loss2 : 1.969905
train_step : 3578, loss1 : 2.979227, loss2 : 1.279407
train_step : 3579, loss1 : 0.897765, loss2 : 1.766327
train_step : 3580, loss1 : 2.058773, loss2 : 1.869363
train_step : 3581, loss1 : 1.058075, loss2 : 1.097139
train_step : 3582, loss1 : 0.682715, loss2 : 1.831902
train_step : 3583, loss1 : 0.979312, loss2 : 0.877138
train_step : 3584, loss1 : 1.468165, loss2 : 1.348579
train_step : 3585, loss1 : 1.323608, loss2 : 1.478672
train_step : 3586, loss1 : 0.771709, loss2 : 1.185189
train_step : 3587, loss1 : 0.943440, loss2 : 0.981633
train_step : 3588, loss1 : 1.650045, loss2 : 1.230244
train_step : 3589, loss1 : 0.894439, loss2 : 0.738257
train_step : 3590, loss1 : 1.637981, loss2 : 2.284259
train_step : 3591, loss1 : 1.657326, loss2 : 1.514134
train_step : 3592, loss1 : 1.572103, loss2 : 1.023032
train_step : 3593, loss1 : 1.697370, loss2 : 1.131980
train_step : 3594, loss1 : 1.592327, loss2 : 1.172143
train_step : 3595, loss1 : 0.932161, loss2 : 0.924016
train_step : 3596, loss1 : 0.812554, loss2 : 1.708831
train_step : 3597, loss1 : 1.261009, loss2 : 1.432558
train_step : 3598, loss1 : 0.731213, loss2 : 0.899783
train_step : 3599, loss1 : 1.168047, loss2 : 1.323529
train_step : 3600, loss1 : 1.465765, loss2 : 1.541569
train_step : 3601, loss1 : 1.410555, loss2 : 1.293862
train_step : 3602, loss1 : 1.253961, loss2 : 0.661561
train_step : 3603, loss1 : 1.273455, loss2 : 1.042617
train_step : 3604, loss1 : 2.457514, loss2 : 1.979870
train_step : 3605, loss1 : 1.762048, loss2 : 1.137483
train_step : 3606, loss1 : 1.764348, loss2 : 1.621174
train_step : 3607, loss1 : 2.196063, loss2 : 2.176529
train_step : 3608, loss1 : 1.645746, loss2 : 2.383546
train_step : 3609, loss1 : 1.827026, loss2 : 2.464258
train_step : 3610, loss1 : 1.795052, loss2 : 2.050928
train_step : 3611, loss1 : 3.074619, loss2 : 3.051269
train_step : 3612, loss1 : 3.636889, loss2 : 2.335114
train_step : 3613, loss1 : 2.774854, loss2 : 1.087570
train_step : 3614, loss1 : 1.528994, loss2 : 1.540684
train_step : 3615, loss1 : 1.575805, loss2 : 2.736558
train_step : 3616, loss1 : 3.237902, loss2 : 3.360996
train_step : 3617, loss1 : 0.722507, loss2 : 1.284267
train_step : 3618, loss1 : 0.709103, loss2 : 1.323519
train_step : 3619, loss1 : 0.522456, loss2 : 0.928288
train_step : 3620, loss1 : 0.792919, loss2 : 1.100081
train_step : 3621, loss1 : 1.800687, loss2 : 1.339329
train_step : 3622, loss1 : 1.445959, loss2 : 1.080621
train_step : 3623, loss1 : 1.275740, loss2 : 5.194411
train_step : 3624, loss1 : 1.155109, loss2 : 0.647198
train_step : 3625, loss1 : 1.488427, loss2 : 0.683098
train_step : 3626, loss1 : 2.085359, loss2 : 1.538982
train_step : 3627, loss1 : 3.707944, loss2 : 2.258898
train_step : 3628, loss1 : 3.369642, loss2 : 5.307747
train_step : 3629, loss1 : 2.103755, loss2 : 3.821726
train_step : 3630, loss1 : 2.564989, loss2 : 2.525209
train_step : 3631, loss1 : 2.660223, loss2 : 1.913641
train_step : 3632, loss1 : 2.597003, loss2 : 2.632969
train_step : 3633, loss1 : 2.686858, loss2 : 3.339981
train_step : 3634, loss1 : 4.687544, loss2 : 2.488245
train_step : 3635, loss1 : 3.102928, loss2 : 3.726662
train_step : 3636, loss1 : 4.267867, loss2 : 4.491428
train_step : 3637, loss1 : 5.213887, loss2 : 4.618227
train_step : 3638, loss1 : 6.995638, loss2 : 7.339936
train_step : 3639, loss1 : 6.716107, loss2 : 4.378231
train_step : 3640, loss1 : 6.243391, loss2 : 7.581620
train_step : 3641, loss1 : 4.470495, loss2 : 3.142537
train_step : 3642, loss1 : 3.248444, loss2 : 3.625302
train_step : 3643, loss1 : 3.528089, loss2 : 4.701775
train_step : 3644, loss1 : 3.623431, loss2 : 4.445174
train_step : 3645, loss1 : 1.963585, loss2 : 2.471535
train_step : 3646, loss1 : 3.157026, loss2 : 1.120901
train_step : 3647, loss1 : 1.608654, loss2 : 1.324565
train_step : 3648, loss1 : 1.778050, loss2 : 1.077428
train_step : 3649, loss1 : 2.155199, loss2 : 3.427040
train_step : 3650, loss1 : 1.771214, loss2 : 1.761993
train_step : 3651, loss1 : 1.192367, loss2 : 2.999805
train_step : 3652, loss1 : 1.334102, loss2 : 2.560701
train_step : 3653, loss1 : 1.681823, loss2 : 2.819337
train_step : 3654, loss1 : 1.215097, loss2 : 1.696470
train_step : 3655, loss1 : 2.128850, loss2 : 1.641596
train_step : 3656, loss1 : 2.059194, loss2 : 1.333637
train_step : 3657, loss1 : 2.768776, loss2 : 2.140832
train_step : 3658, loss1 : 1.239604, loss2 : 2.102633
train_step : 3659, loss1 : 2.253008, loss2 : 1.693728
train_step : 3660, loss1 : 1.521010, loss2 : 2.197748
train_step : 3661, loss1 : 2.187376, loss2 : 2.157297
train_step : 3662, loss1 : 1.527656, loss2 : 2.894152
train_step : 3663, loss1 : 2.678145, loss2 : 2.504179
train_step : 3664, loss1 : 1.719184, loss2 : 2.348908
train_step : 3665, loss1 : 2.051202, loss2 : 1.398122
train_step : 3666, loss1 : 0.686428, loss2 : 1.959277
train_step : 3667, loss1 : 1.831690, loss2 : 1.573625
train_step : 3668, loss1 : 1.145716, loss2 : 1.248953
train_step : 3669, loss1 : 0.990985, loss2 : 1.160187
train_step : 3670, loss1 : 0.647745, loss2 : 1.345901
train_step : 3671, loss1 : 1.719440, loss2 : 0.688176
train_step : 3672, loss1 : 1.132684, loss2 : 1.954461
train_step : 3673, loss1 : 1.944041, loss2 : 0.960806
train_step : 3674, loss1 : 2.570663, loss2 : 1.618768
train_step : 3675, loss1 : 2.848125, loss2 : 3.586889
train_step : 3676, loss1 : 3.377406, loss2 : 3.358160
train_step : 3677, loss1 : 2.892961, loss2 : 2.496303
train_step : 3678, loss1 : 2.968373, loss2 : 2.159807
train_step : 3679, loss1 : 1.720167, loss2 : 1.996664
train_step : 3680, loss1 : 1.096910, loss2 : 1.996117
train_step : 3681, loss1 : 1.320935, loss2 : 2.836805
train_step : 3682, loss1 : 1.704675, loss2 : 2.173881
train_step : 3683, loss1 : 2.260409, loss2 : 1.788499
train_step : 3684, loss1 : 5.373377, loss2 : 1.781718
train_step : 3685, loss1 : 2.796356, loss2 : 1.870175
train_step : 3686, loss1 : 3.343252, loss2 : 2.849575
train_step : 3687, loss1 : 2.893760, loss2 : 4.291502
train_step : 3688, loss1 : 4.575674, loss2 : 4.544986
train_step : 3689, loss1 : 4.714855, loss2 : 3.927100
train_step : 3690, loss1 : 3.573720, loss2 : 5.122281
train_step : 3691, loss1 : 1.861435, loss2 : 3.979928
train_step : 3692, loss1 : 3.297068, loss2 : 1.929859
train_step : 3693, loss1 : 2.546252, loss2 : 1.280205
train_step : 3694, loss1 : 1.497071, loss2 : 2.582978
train_step : 3695, loss1 : 1.453445, loss2 : 1.756070
train_step : 3696, loss1 : 1.412263, loss2 : 1.104133
train_step : 3697, loss1 : 0.629176, loss2 : 1.372345
train_step : 3698, loss1 : 1.112742, loss2 : 1.404604
train_step : 3699, loss1 : 1.775806, loss2 : 1.015622
train_step : 3700, loss1 : 1.141222, loss2 : 0.975364
train_step : 3701, loss1 : 2.118830, loss2 : 1.760483
train_step : 3702, loss1 : 1.448562, loss2 : 0.491271
train_step : 3703, loss1 : 0.637624, loss2 : 1.360103
train_step : 3704, loss1 : 1.492068, loss2 : 1.436811
train_step : 3705, loss1 : 2.248148, loss2 : 1.044410
train_step : 3706, loss1 : 0.983015, loss2 : 0.967576
train_step : 3707, loss1 : 1.627973, loss2 : 1.865543
train_step : 3708, loss1 : 1.316726, loss2 : 1.129337
train_step : 3709, loss1 : 2.057836, loss2 : 2.166859
train_step : 3710, loss1 : 4.799151, loss2 : 2.683138
train_step : 3711, loss1 : 3.779877, loss2 : 3.809999
train_step : 3712, loss1 : 2.937212, loss2 : 2.562790
train_step : 3713, loss1 : 1.724977, loss2 : 2.395068
train_step : 3714, loss1 : 1.084787, loss2 : 2.054651
train_step : 3715, loss1 : 3.935514, loss2 : 1.973870
train_step : 3716, loss1 : 1.941585, loss2 : 3.294535
train_step : 3717, loss1 : 1.019081, loss2 : 3.246208
train_step : 3718, loss1 : 0.912843, loss2 : 1.249574
train_step : 3719, loss1 : 0.864729, loss2 : 1.438401
train_step : 3720, loss1 : 1.348325, loss2 : 0.774941
train_step : 3721, loss1 : 1.905670, loss2 : 0.912539
train_step : 3722, loss1 : 0.552035, loss2 : 1.065326
train_step : 3723, loss1 : 0.764988, loss2 : 1.231690
train_step : 3724, loss1 : 0.960942, loss2 : 1.004627
train_step : 3725, loss1 : 1.270970, loss2 : 2.680665
train_step : 3726, loss1 : 0.468470, loss2 : 2.728305
train_step : 3727, loss1 : 1.490817, loss2 : 1.049950
train_step : 3728, loss1 : 2.804521, loss2 : 1.720358
train_step : 3729, loss1 : 1.292759, loss2 : 0.998570
train_step : 3730, loss1 : 0.886429, loss2 : 1.105410
train_step : 3731, loss1 : 1.190679, loss2 : 1.584391
train_step : 3732, loss1 : 1.289914, loss2 : 1.519551
train_step : 3733, loss1 : 1.671249, loss2 : 1.080891
train_step : 3734, loss1 : 1.341977, loss2 : 1.097086
train_step : 3735, loss1 : 1.754902, loss2 : 1.230156
train_step : 3736, loss1 : 1.214513, loss2 : 1.474818
train_step : 3737, loss1 : 1.261367, loss2 : 1.106013
train_step : 3738, loss1 : 1.752388, loss2 : 1.380427
train_step : 3739, loss1 : 0.651143, loss2 : 0.890181
train_step : 3740, loss1 : 0.966468, loss2 : 1.752730
train_step : 3741, loss1 : 0.821934, loss2 : 1.525305
train_step : 3742, loss1 : 1.153193, loss2 : 1.536465
train_step : 3743, loss1 : 1.086170, loss2 : 1.504111
train_step : 3744, loss1 : 1.663064, loss2 : 0.969525
train_step : 3745, loss1 : 2.054956, loss2 : 1.379060
train_step : 3746, loss1 : 3.077534, loss2 : 1.241651
train_step : 3747, loss1 : 4.206529, loss2 : 3.468388
train_step : 3748, loss1 : 3.971905, loss2 : 4.189442
train_step : 3749, loss1 : 1.369329, loss2 : 1.904641
train_step : 3750, loss1 : 1.491539, loss2 : 1.610249
train_step : 3751, loss1 : 1.785865, loss2 : 1.342816
train_step : 3752, loss1 : 2.566825, loss2 : 3.186633
train_step : 3753, loss1 : 2.381684, loss2 : 3.375591
train_step : 3754, loss1 : 3.016675, loss2 : 4.543371
train_step : 3755, loss1 : 2.343491, loss2 : 3.084654
train_step : 3756, loss1 : 3.038242, loss2 : 3.096263
train_step : 3757, loss1 : 2.049721, loss2 : 3.107632
train_step : 3758, loss1 : 5.472626, loss2 : 4.326531
train_step : 3759, loss1 : 2.154166, loss2 : 1.206062
train_step : 3760, loss1 : 2.517731, loss2 : 1.658862
train_step : 3761, loss1 : 1.351106, loss2 : 1.121369
train_step : 3762, loss1 : 1.358201, loss2 : 1.153522
train_step : 3763, loss1 : 1.404707, loss2 : 1.506510
train_step : 3764, loss1 : 2.185730, loss2 : 1.427132
train_step : 3765, loss1 : 1.719013, loss2 : 1.220060
train_step : 3766, loss1 : 0.893450, loss2 : 0.815350
train_step : 3767, loss1 : 1.114310, loss2 : 1.406323
train_step : 3768, loss1 : 0.864248, loss2 : 1.560628
train_step : 3769, loss1 : 1.070493, loss2 : 1.246521
train_step : 3770, loss1 : 1.475308, loss2 : 1.316662
train_step : 3771, loss1 : 1.281216, loss2 : 1.533567
train_step : 3772, loss1 : 0.562647, loss2 : 2.129520
train_step : 3773, loss1 : 0.737517, loss2 : 1.371219
train_step : 3774, loss1 : 0.939043, loss2 : 0.661013
train_step : 3775, loss1 : 1.388829, loss2 : 1.084070
train_step : 3776, loss1 : 1.620404, loss2 : 0.835064
train_step : 3777, loss1 : 1.411720, loss2 : 1.118972
train_step : 3778, loss1 : 0.862855, loss2 : 0.920822
train_step : 3779, loss1 : 1.167661, loss2 : 0.986928
train_step : 3780, loss1 : 1.470538, loss2 : 1.444642
train_step : 3781, loss1 : 1.381166, loss2 : 2.022315
train_step : 3782, loss1 : 1.920876, loss2 : 1.540113
train_step : 3783, loss1 : 2.106672, loss2 : 1.109178
train_step : 3784, loss1 : 0.783643, loss2 : 1.408276
train_step : 3785, loss1 : 0.935919, loss2 : 2.350097
train_step : 3786, loss1 : 2.650126, loss2 : 0.983304
train_step : 3787, loss1 : 2.149798, loss2 : 1.428733
train_step : 3788, loss1 : 2.085070, loss2 : 1.606849
train_step : 3789, loss1 : 1.430026, loss2 : 1.506047
train_step : 3790, loss1 : 1.238748, loss2 : 0.815779
train_step : 3791, loss1 : 0.991318, loss2 : 1.204796
train_step : 3792, loss1 : 1.116658, loss2 : 2.053165
train_step : 3793, loss1 : 1.177799, loss2 : 1.100983
train_step : 3794, loss1 : 1.320587, loss2 : 0.958596
train_step : 3795, loss1 : 1.007253, loss2 : 1.363500
train_step : 3796, loss1 : 2.029538, loss2 : 2.821163
train_step : 3797, loss1 : 2.354251, loss2 : 2.801655
train_step : 3798, loss1 : 7.512398, loss2 : 1.919406
train_step : 3799, loss1 : 3.144656, loss2 : 4.896627
train_step : 3800, loss1 : 3.865269, loss2 : 3.766968
train_step : 3801, loss1 : 2.372919, loss2 : 4.176050
train_step : 3802, loss1 : 2.634753, loss2 : 2.748405
train_step : 3803, loss1 : 3.059563, loss2 : 2.178904
train_step : 3804, loss1 : 2.595807, loss2 : 2.968606
train_step : 3805, loss1 : 2.956184, loss2 : 3.542430
train_step : 3806, loss1 : 2.766195, loss2 : 5.099934
train_step : 3807, loss1 : 6.594656, loss2 : 5.467932
train_step : 3808, loss1 : 6.206551, loss2 : 5.997787
train_step : 3809, loss1 : 7.031733, loss2 : 5.168080
train_step : 3810, loss1 : 3.039929, loss2 : 3.192172
train_step : 3811, loss1 : 3.240934, loss2 : 3.118498
train_step : 3812, loss1 : 2.469431, loss2 : 1.807115
train_step : 3813, loss1 : 2.257778, loss2 : 1.253799
train_step : 3814, loss1 : 1.143299, loss2 : 1.499731
train_step : 3815, loss1 : 1.117788, loss2 : 0.845392
train_step : 3816, loss1 : 1.298429, loss2 : 1.450706
train_step : 3817, loss1 : 3.183020, loss2 : 1.680788
train_step : 3818, loss1 : 1.981685, loss2 : 1.306969
train_step : 3819, loss1 : 1.398369, loss2 : 1.550306
train_step : 3820, loss1 : 1.635282, loss2 : 1.473584
train_step : 3821, loss1 : 4.919454, loss2 : 1.609587
train_step : 3822, loss1 : 3.742572, loss2 : 3.225133
train_step : 3823, loss1 : 2.851619, loss2 : 3.559491
train_step : 3824, loss1 : 3.749978, loss2 : 3.105110
train_step : 3825, loss1 : 3.279027, loss2 : 4.627183
train_step : 3826, loss1 : 3.672996, loss2 : 2.898048
train_step : 3827, loss1 : 3.845610, loss2 : 2.901572
train_step : 3828, loss1 : 2.137355, loss2 : 2.613423
train_step : 3829, loss1 : 2.253925, loss2 : 3.289851
train_step : 3830, loss1 : 1.450432, loss2 : 2.791297
train_step : 3831, loss1 : 3.223938, loss2 : 2.528639
train_step : 3832, loss1 : 1.474702, loss2 : 1.435597
train_step : 3833, loss1 : 1.401628, loss2 : 0.927083
train_step : 3834, loss1 : 0.879605, loss2 : 1.950539
train_step : 3835, loss1 : 1.373325, loss2 : 1.061450
train_step : 3836, loss1 : 1.351190, loss2 : 0.848618
train_step : 3837, loss1 : 1.110944, loss2 : 0.987789
train_step : 3838, loss1 : 0.929738, loss2 : 1.769900
train_step : 3839, loss1 : 3.347683, loss2 : 1.046125
train_step : 3840, loss1 : 1.265290, loss2 : 0.826180
train_step : 3841, loss1 : 0.716666, loss2 : 1.998061
train_step : 3842, loss1 : 1.222204, loss2 : 1.544032
train_step : 3843, loss1 : 2.163272, loss2 : 1.247142
train_step : 3844, loss1 : 1.501687, loss2 : 2.616320
train_step : 3845, loss1 : 1.373628, loss2 : 2.280379
train_step : 3846, loss1 : 1.664535, loss2 : 2.370069
train_step : 3847, loss1 : 1.316426, loss2 : 1.527326
train_step : 3848, loss1 : 0.919076, loss2 : 1.796105
train_step : 3849, loss1 : 2.156592, loss2 : 1.284110
train_step : 3850, loss1 : 1.578284, loss2 : 1.163901
train_step : 3851, loss1 : 0.976587, loss2 : 1.248815
train_step : 3852, loss1 : 1.102419, loss2 : 0.587414
train_step : 3853, loss1 : 1.885972, loss2 : 1.765704
train_step : 3854, loss1 : 1.861621, loss2 : 1.752494
train_step : 3855, loss1 : 1.522524, loss2 : 1.964391
train_step : 3856, loss1 : 2.178727, loss2 : 2.699228
train_step : 3857, loss1 : 2.460367, loss2 : 1.077987
train_step : 3858, loss1 : 2.431275, loss2 : 2.202840
train_step : 3859, loss1 : 0.849219, loss2 : 0.933082
train_step : 3860, loss1 : 0.895557, loss2 : 0.974891
train_step : 3861, loss1 : 2.077395, loss2 : 1.186734
train_step : 3862, loss1 : 2.036634, loss2 : 0.785460
train_step : 3863, loss1 : 1.540867, loss2 : 1.753315
train_step : 3864, loss1 : 3.313751, loss2 : 1.035125
train_step : 3865, loss1 : 1.266416, loss2 : 2.759477
train_step : 3866, loss1 : 1.637977, loss2 : 1.306136
train_step : 3867, loss1 : 1.547198, loss2 : 1.509648
train_step : 3868, loss1 : 1.545453, loss2 : 1.674093
train_step : 3869, loss1 : 1.623651, loss2 : 1.483346
train_step : 3870, loss1 : 2.252821, loss2 : 2.429941
train_step : 3871, loss1 : 1.923843, loss2 : 2.504304
train_step : 3872, loss1 : 2.070099, loss2 : 1.623225
train_step : 3873, loss1 : 0.859620, loss2 : 2.124189
train_step : 3874, loss1 : 1.357161, loss2 : 1.718331
train_step : 3875, loss1 : 2.814412, loss2 : 2.381644
train_step : 3876, loss1 : 4.213547, loss2 : 2.494229
train_step : 3877, loss1 : 3.716642, loss2 : 4.336273
train_step : 3878, loss1 : 2.060351, loss2 : 3.940670
train_step : 3879, loss1 : 2.441118, loss2 : 2.226641
train_step : 3880, loss1 : 1.949690, loss2 : 1.455894
train_step : 3881, loss1 : 1.262042, loss2 : 1.487371
train_step : 3882, loss1 : 2.085145, loss2 : 1.268841
train_step : 3883, loss1 : 2.414443, loss2 : 2.145239
train_step : 3884, loss1 : 1.901309, loss2 : 1.525292
train_step : 3885, loss1 : 1.440758, loss2 : 1.244827
train_step : 3886, loss1 : 1.246482, loss2 : 0.904502
train_step : 3887, loss1 : 1.182989, loss2 : 0.919247
train_step : 3888, loss1 : 0.956861, loss2 : 0.947311
train_step : 3889, loss1 : 0.800983, loss2 : 1.911754
train_step : 3890, loss1 : 5.876968, loss2 : 1.659567
train_step : 3891, loss1 : 1.117948, loss2 : 1.131579
train_step : 3892, loss1 : 1.094377, loss2 : 0.982805
train_step : 3893, loss1 : 2.820455, loss2 : 0.888344
train_step : 3894, loss1 : 0.807490, loss2 : 1.713764
train_step : 3895, loss1 : 1.487246, loss2 : 2.029220
train_step : 3896, loss1 : 1.816607, loss2 : 1.791266
train_step : 3897, loss1 : 1.133131, loss2 : 1.588912
train_step : 3898, loss1 : 0.971735, loss2 : 0.984503
train_step : 3899, loss1 : 1.811203, loss2 : 2.569204
train_step : 3900, loss1 : 0.768251, loss2 : 1.629052
train_step : 3901, loss1 : 0.854262, loss2 : 1.187172
train_step : 3902, loss1 : 2.809918, loss2 : 1.617996
train_step : 3903, loss1 : 1.599044, loss2 : 1.803031
train_step : 3904, loss1 : 1.563917, loss2 : 2.794400
train_step : 3905, loss1 : 0.896901, loss2 : 0.889938
train_step : 3906, loss1 : 1.191612, loss2 : 1.645865
train_step : 3907, loss1 : 1.655416, loss2 : 0.912350
train_step : 3908, loss1 : 0.991157, loss2 : 1.376419
train_step : 3909, loss1 : 1.399593, loss2 : 0.671915
train_step : 3910, loss1 : 1.482227, loss2 : 0.665515
train_step : 3911, loss1 : 1.368004, loss2 : 1.723050
train_step : 3912, loss1 : 1.264887, loss2 : 1.621229
train_step : 3913, loss1 : 1.249792, loss2 : 1.115759
train_step : 3914, loss1 : 1.503002, loss2 : 0.660413
train_step : 3915, loss1 : 1.541403, loss2 : 1.714921
train_step : 3916, loss1 : 0.538491, loss2 : 1.443866
train_step : 3917, loss1 : 1.648612, loss2 : 1.418742
train_step : 3918, loss1 : 1.054418, loss2 : 0.812456
train_step : 3919, loss1 : 2.260973, loss2 : 1.285288
train_step : 3920, loss1 : 3.036232, loss2 : 2.475585
train_step : 3921, loss1 : 2.577767, loss2 : 3.079133
train_step : 3922, loss1 : 1.489456, loss2 : 1.852392
train_step : 3923, loss1 : 0.876426, loss2 : 2.318696
train_step : 3924, loss1 : 1.336961, loss2 : 2.544768
train_step : 3925, loss1 : 1.256491, loss2 : 2.288783
train_step : 3926, loss1 : 2.165802, loss2 : 2.009528
train_step : 3927, loss1 : 1.987121, loss2 : 3.533845
train_step : 3928, loss1 : 1.680494, loss2 : 1.489375
train_step : 3929, loss1 : 1.414639, loss2 : 2.862342
train_step : 3930, loss1 : 1.890047, loss2 : 2.107863
train_step : 3931, loss1 : 2.433843, loss2 : 2.127092
train_step : 3932, loss1 : 2.718840, loss2 : 1.666125
train_step : 3933, loss1 : 2.130879, loss2 : 3.975635
train_step : 3934, loss1 : 2.668543, loss2 : 1.379798
train_step : 3935, loss1 : 2.269967, loss2 : 1.684455
train_step : 3936, loss1 : 0.807223, loss2 : 0.511309
train_step : 3937, loss1 : 1.811817, loss2 : 1.262174
train_step : 3938, loss1 : 1.551625, loss2 : 1.498164
train_step : 3939, loss1 : 0.926704, loss2 : 0.886979
train_step : 3940, loss1 : 1.875813, loss2 : 0.607827
train_step : 3941, loss1 : 0.987798, loss2 : 0.900530
train_step : 3942, loss1 : 2.404402, loss2 : 1.800353
train_step : 3943, loss1 : 1.290552, loss2 : 1.308476
train_step : 3944, loss1 : 1.174365, loss2 : 1.257140
train_step : 3945, loss1 : 2.136733, loss2 : 1.069136
train_step : 3946, loss1 : 1.053446, loss2 : 1.079027
train_step : 3947, loss1 : 1.131269, loss2 : 1.841351
train_step : 3948, loss1 : 3.258690, loss2 : 1.068131
train_step : 3949, loss1 : 2.577113, loss2 : 2.474180
train_step : 3950, loss1 : 4.057069, loss2 : 3.368437
train_step : 3951, loss1 : 3.954728, loss2 : 3.842815
train_step : 3952, loss1 : 2.386217, loss2 : 3.569647
train_step : 3953, loss1 : 4.952878, loss2 : 3.845183
train_step : 3954, loss1 : 2.575749, loss2 : 7.073169
train_step : 3955, loss1 : 6.569621, loss2 : 6.761744
train_step : 3956, loss1 : 4.924728, loss2 : 10.606483
train_step : 3957, loss1 : 12.420841, loss2 : 13.489964
train_step : 3958, loss1 : 12.204525, loss2 : 10.779415
train_step : 3959, loss1 : 14.125791, loss2 : 13.672750
train_step : 3960, loss1 : 8.466512, loss2 : 5.778951
train_step : 3961, loss1 : 8.098053, loss2 : 6.613139
train_step : 3962, loss1 : 4.183917, loss2 : 4.437643
train_step : 3963, loss1 : 3.932272, loss2 : 5.265917
train_step : 3964, loss1 : 1.831168, loss2 : 3.373056
train_step : 3965, loss1 : 1.525803, loss2 : 2.950391
train_step : 3966, loss1 : 2.089739, loss2 : 2.297734
train_step : 3967, loss1 : 1.886273, loss2 : 2.684978
train_step : 3968, loss1 : 1.222258, loss2 : 1.097241
train_step : 3969, loss1 : 1.170049, loss2 : 1.365862
train_step : 3970, loss1 : 2.473882, loss2 : 2.656933
train_step : 3971, loss1 : 1.259773, loss2 : 1.957459
train_step : 3972, loss1 : 0.804253, loss2 : 3.331819
train_step : 3973, loss1 : 2.104049, loss2 : 1.121271
train_step : 3974, loss1 : 1.268120, loss2 : 0.863958
train_step : 3975, loss1 : 1.335719, loss2 : 1.270927
train_step : 3976, loss1 : 1.340748, loss2 : 1.746535
train_step : 3977, loss1 : 2.325124, loss2 : 1.400634
train_step : 3978, loss1 : 1.338481, loss2 : 1.065285
train_step : 3979, loss1 : 1.335566, loss2 : 0.824649
train_step : 3980, loss1 : 0.835831, loss2 : 1.161401
train_step : 3981, loss1 : 0.977658, loss2 : 1.742561
train_step : 3982, loss1 : 1.640990, loss2 : 0.898527
train_step : 3983, loss1 : 1.391595, loss2 : 0.866205
train_step : 3984, loss1 : 1.289274, loss2 : 0.674948
train_step : 3985, loss1 : 1.115288, loss2 : 1.368863
train_step : 3986, loss1 : 1.332561, loss2 : 1.316589
train_step : 3987, loss1 : 1.154949, loss2 : 0.793817
train_step : 3988, loss1 : 1.062599, loss2 : 0.729563
train_step : 3989, loss1 : 0.961078, loss2 : 1.525021
train_step : 3990, loss1 : 1.053656, loss2 : 1.397222
train_step : 3991, loss1 : 2.059566, loss2 : 0.469150
train_step : 3992, loss1 : 1.321134, loss2 : 0.964370
train_step : 3993, loss1 : 1.738171, loss2 : 1.860865
train_step : 3994, loss1 : 1.722280, loss2 : 1.472817
train_step : 3995, loss1 : 1.825156, loss2 : 1.959020
train_step : 3996, loss1 : 1.360456, loss2 : 1.603039
train_step : 3997, loss1 : 2.859671, loss2 : 1.848254
train_step : 3998, loss1 : 2.376729, loss2 : 2.087955
train_step : 3999, loss1 : 3.258033, loss2 : 2.917763
train_step : 4000, loss1 : 4.008804, loss2 : 3.525070
train_step : 4001, loss1 : 1.333294, loss2 : 2.634139
train_step : 4002, loss1 : 1.752329, loss2 : 1.546506
train_step : 4003, loss1 : 1.810686, loss2 : 2.511121
train_step : 4004, loss1 : 1.455962, loss2 : 1.156166
train_step : 4005, loss1 : 0.515971, loss2 : 1.972506
train_step : 4006, loss1 : 2.023865, loss2 : 1.713400
train_step : 4007, loss1 : 2.747564, loss2 : 1.242517
train_step : 4008, loss1 : 2.011028, loss2 : 1.462285
train_step : 4009, loss1 : 2.626608, loss2 : 2.735545
train_step : 4010, loss1 : 2.168696, loss2 : 2.848959
train_step : 4011, loss1 : 1.256943, loss2 : 1.142800
train_step : 4012, loss1 : 0.591409, loss2 : 0.681892
train_step : 4013, loss1 : 1.633659, loss2 : 1.701053
train_step : 4014, loss1 : 1.747964, loss2 : 2.085173
train_step : 4015, loss1 : 4.095255, loss2 : 3.430818
train_step : 4016, loss1 : 1.405394, loss2 : 1.971146
train_step : 4017, loss1 : 1.733213, loss2 : 1.912266
train_step : 4018, loss1 : 1.908381, loss2 : 3.610792
train_step : 4019, loss1 : 6.072227, loss2 : 2.343407
train_step : 4020, loss1 : 4.952853, loss2 : 4.010455
train_step : 4021, loss1 : 2.738062, loss2 : 3.743881
train_step : 4022, loss1 : 2.060004, loss2 : 3.471089
train_step : 4023, loss1 : 1.782832, loss2 : 1.464378
train_step : 4024, loss1 : 1.087472, loss2 : 1.336287
train_step : 4025, loss1 : 1.025396, loss2 : 1.695836
train_step : 4026, loss1 : 1.190444, loss2 : 1.362560
train_step : 4027, loss1 : 1.462264, loss2 : 1.394871
train_step : 4028, loss1 : 1.118333, loss2 : 1.820826
train_step : 4029, loss1 : 0.585238, loss2 : 0.957831
train_step : 4030, loss1 : 0.970476, loss2 : 1.258308
train_step : 4031, loss1 : 1.845374, loss2 : 1.264912
train_step : 4032, loss1 : 1.337737, loss2 : 1.440585
train_step : 4033, loss1 : 1.538106, loss2 : 0.778688
train_step : 4034, loss1 : 1.404761, loss2 : 1.019707
train_step : 4035, loss1 : 0.733186, loss2 : 0.800009
train_step : 4036, loss1 : 0.780963, loss2 : 1.576786
train_step : 4037, loss1 : 2.431426, loss2 : 1.254157
train_step : 4038, loss1 : 0.875847, loss2 : 0.870441
train_step : 4039, loss1 : 1.152966, loss2 : 1.204382
train_step : 4040, loss1 : 1.415074, loss2 : 1.586389
train_step : 4041, loss1 : 1.618239, loss2 : 1.640657
train_step : 4042, loss1 : 1.858596, loss2 : 1.513601
train_step : 4043, loss1 : 1.755610, loss2 : 0.979617
train_step : 4044, loss1 : 1.990055, loss2 : 1.186247
train_step : 4045, loss1 : 1.311955, loss2 : 2.445816
train_step : 4046, loss1 : 2.067197, loss2 : 2.545913
train_step : 4047, loss1 : 2.243184, loss2 : 1.851149
train_step : 4048, loss1 : 2.555429, loss2 : 1.902773
train_step : 4049, loss1 : 1.932314, loss2 : 2.805142
train_step : 4050, loss1 : 2.389607, loss2 : 2.273312
train_step : 4051, loss1 : 1.347502, loss2 : 1.477843
train_step : 4052, loss1 : 2.365198, loss2 : 1.209476
train_step : 4053, loss1 : 3.148024, loss2 : 2.142793
train_step : 4054, loss1 : 1.383023, loss2 : 2.532538
train_step : 4055, loss1 : 1.339533, loss2 : 2.420124
train_step : 4056, loss1 : 2.138923, loss2 : 1.136575
train_step : 4057, loss1 : 2.130093, loss2 : 0.570759
train_step : 4058, loss1 : 1.026971, loss2 : 0.670325
train_step : 4059, loss1 : 2.113048, loss2 : 1.922415
train_step : 4060, loss1 : 1.864468, loss2 : 1.362902
train_step : 4061, loss1 : 1.021096, loss2 : 1.248277
train_step : 4062, loss1 : 1.299894, loss2 : 0.856788
train_step : 4063, loss1 : 0.656796, loss2 : 1.237190
train_step : 4064, loss1 : 1.523001, loss2 : 1.144638
train_step : 4065, loss1 : 1.140290, loss2 : 1.102898
train_step : 4066, loss1 : 0.564042, loss2 : 1.554555
train_step : 4067, loss1 : 1.426861, loss2 : 1.317675
train_step : 4068, loss1 : 0.825056, loss2 : 0.870417
train_step : 4069, loss1 : 0.809265, loss2 : 1.095767
train_step : 4070, loss1 : 1.193359, loss2 : 1.003845
train_step : 4071, loss1 : 0.672329, loss2 : 1.150480
train_step : 4072, loss1 : 0.965063, loss2 : 0.590404
train_step : 4073, loss1 : 1.574180, loss2 : 0.818525
train_step : 4074, loss1 : 2.007756, loss2 : 1.508250
train_step : 4075, loss1 : 1.258900, loss2 : 0.962418
train_step : 4076, loss1 : 1.478073, loss2 : 0.820940
train_step : 4077, loss1 : 2.069647, loss2 : 1.327450
train_step : 4078, loss1 : 1.589364, loss2 : 1.386661
train_step : 4079, loss1 : 3.139860, loss2 : 1.077747
train_step : 4080, loss1 : 2.019231, loss2 : 1.392878
train_step : 4081, loss1 : 0.765147, loss2 : 1.177055
train_step : 4082, loss1 : 1.444609, loss2 : 1.320726
train_step : 4083, loss1 : 1.462624, loss2 : 1.083346
train_step : 4084, loss1 : 1.326697, loss2 : 1.170652
train_step : 4085, loss1 : 1.324234, loss2 : 1.124377
train_step : 4086, loss1 : 1.032471, loss2 : 0.975492
train_step : 4087, loss1 : 0.632237, loss2 : 0.938991
train_step : 4088, loss1 : 2.486655, loss2 : 1.423596
train_step : 4089, loss1 : 1.501286, loss2 : 1.868408
train_step : 4090, loss1 : 1.792690, loss2 : 1.240968
train_step : 4091, loss1 : 1.487337, loss2 : 0.773005
train_step : 4092, loss1 : 1.544192, loss2 : 1.287866
train_step : 4093, loss1 : 1.239975, loss2 : 1.228316
train_step : 4094, loss1 : 1.707827, loss2 : 2.313635
train_step : 4095, loss1 : 1.578418, loss2 : 2.017369
train_step : 4096, loss1 : 0.528265, loss2 : 0.598892
train_step : 4097, loss1 : 1.428178, loss2 : 0.938426
train_step : 4098, loss1 : 1.041946, loss2 : 1.318491
train_step : 4099, loss1 : 1.488721, loss2 : 0.996161
train_step : 4100, loss1 : 1.080273, loss2 : 1.232684
train_step : 4101, loss1 : 1.437292, loss2 : 1.143295
train_step : 4102, loss1 : 1.052243, loss2 : 1.207556
train_step : 4103, loss1 : 0.736045, loss2 : 1.950866
train_step : 4104, loss1 : 1.618845, loss2 : 1.335148
train_step : 4105, loss1 : 1.727457, loss2 : 2.448138
train_step : 4106, loss1 : 1.409780, loss2 : 2.524266
train_step : 4107, loss1 : 2.422476, loss2 : 2.416288
train_step : 4108, loss1 : 4.864734, loss2 : 2.215104
train_step : 4109, loss1 : 1.178244, loss2 : 2.078145
train_step : 4110, loss1 : 1.897122, loss2 : 1.952081
train_step : 4111, loss1 : 2.422718, loss2 : 2.503648
train_step : 4112, loss1 : 2.104935, loss2 : 2.710300
train_step : 4113, loss1 : 3.115592, loss2 : 3.252513
train_step : 4114, loss1 : 1.725319, loss2 : 2.837332
train_step : 4115, loss1 : 2.240797, loss2 : 1.953716
train_step : 4116, loss1 : 1.993712, loss2 : 2.211145
train_step : 4117, loss1 : 2.325564, loss2 : 2.446044
train_step : 4118, loss1 : 3.406551, loss2 : 3.386495
train_step : 4119, loss1 : 2.734868, loss2 : 2.760371
train_step : 4120, loss1 : 2.125600, loss2 : 2.155569
train_step : 4121, loss1 : 1.778992, loss2 : 1.359779
train_step : 4122, loss1 : 1.383557, loss2 : 0.884404
train_step : 4123, loss1 : 1.613792, loss2 : 1.222024
train_step : 4124, loss1 : 1.106807, loss2 : 1.470564
train_step : 4125, loss1 : 1.957056, loss2 : 1.537148
train_step : 4126, loss1 : 1.051408, loss2 : 1.233385
train_step : 4127, loss1 : 1.763008, loss2 : 0.932179
train_step : 4128, loss1 : 0.971913, loss2 : 2.566613
train_step : 4129, loss1 : 1.582323, loss2 : 3.072580
train_step : 4130, loss1 : 1.937137, loss2 : 2.453265
train_step : 4131, loss1 : 2.286454, loss2 : 2.522388
train_step : 4132, loss1 : 1.643907, loss2 : 1.453159
train_step : 4133, loss1 : 1.136693, loss2 : 1.494699
train_step : 4134, loss1 : 2.195624, loss2 : 1.473667
train_step : 4135, loss1 : 0.819124, loss2 : 1.139545
train_step : 4136, loss1 : 0.433044, loss2 : 1.665185
train_step : 4137, loss1 : 1.442853, loss2 : 1.081401
train_step : 4138, loss1 : 1.517942, loss2 : 0.758347
train_step : 4139, loss1 : 1.194350, loss2 : 1.647755
train_step : 4140, loss1 : 0.719212, loss2 : 1.078707
train_step : 4141, loss1 : 0.932480, loss2 : 1.027717
train_step : 4142, loss1 : 1.098549, loss2 : 2.194233
train_step : 4143, loss1 : 2.646024, loss2 : 1.791901
train_step : 4144, loss1 : 1.565953, loss2 : 1.429470
train_step : 4145, loss1 : 1.878809, loss2 : 2.055168
train_step : 4146, loss1 : 2.545788, loss2 : 3.518744
train_step : 4147, loss1 : 3.438305, loss2 : 3.807575
train_step : 4148, loss1 : 4.332130, loss2 : 3.506437
train_step : 4149, loss1 : 4.224124, loss2 : 4.418406
train_step : 4150, loss1 : 2.233083, loss2 : 3.586711
train_step : 4151, loss1 : 3.329457, loss2 : 4.019324
train_step : 4152, loss1 : 3.804091, loss2 : 3.315472
train_step : 4153, loss1 : 2.784035, loss2 : 1.952389
train_step : 4154, loss1 : 1.878209, loss2 : 1.273741
train_step : 4155, loss1 : 1.195779, loss2 : 2.009660
train_step : 4156, loss1 : 1.411840, loss2 : 1.279005
train_step : 4157, loss1 : 1.176161, loss2 : 1.279009
train_step : 4158, loss1 : 1.190715, loss2 : 1.240463
train_step : 4159, loss1 : 0.952311, loss2 : 1.271080
train_step : 4160, loss1 : 1.905147, loss2 : 2.133802
train_step : 4161, loss1 : 3.377513, loss2 : 2.756064
train_step : 4162, loss1 : 2.965610, loss2 : 2.972667
train_step : 4163, loss1 : 3.307624, loss2 : 2.611952
train_step : 4164, loss1 : 1.553672, loss2 : 1.473785
train_step : 4165, loss1 : 1.477315, loss2 : 1.475094
train_step : 4166, loss1 : 2.130874, loss2 : 1.028198
train_step : 4167, loss1 : 1.551199, loss2 : 1.484139
train_step : 4168, loss1 : 2.276484, loss2 : 2.068767
train_step : 4169, loss1 : 1.692088, loss2 : 1.797083
train_step : 4170, loss1 : 1.566399, loss2 : 2.091859
train_step : 4171, loss1 : 1.809250, loss2 : 1.733326
train_step : 4172, loss1 : 0.737189, loss2 : 1.868958
train_step : 4173, loss1 : 2.448289, loss2 : 1.278803
train_step : 4174, loss1 : 2.786433, loss2 : 1.888390
train_step : 4175, loss1 : 1.888832, loss2 : 1.168396
train_step : 4176, loss1 : 2.283443, loss2 : 1.311432
train_step : 4177, loss1 : 1.464076, loss2 : 1.289225
train_step : 4178, loss1 : 1.959431, loss2 : 1.757048
train_step : 4179, loss1 : 2.531579, loss2 : 2.176610
train_step : 4180, loss1 : 3.913242, loss2 : 2.361001
train_step : 4181, loss1 : 4.613291, loss2 : 3.582176
train_step : 4182, loss1 : 3.215343, loss2 : 4.053330
train_step : 4183, loss1 : 2.001403, loss2 : 3.133580
train_step : 4184, loss1 : 1.187482, loss2 : 1.594953
train_step : 4185, loss1 : 1.420981, loss2 : 2.034204
train_step : 4186, loss1 : 1.441518, loss2 : 2.287759
train_step : 4187, loss1 : 2.019368, loss2 : 3.191333
train_step : 4188, loss1 : 1.873595, loss2 : 0.926823
train_step : 4189, loss1 : 1.032434, loss2 : 1.295547
train_step : 4190, loss1 : 1.475691, loss2 : 1.946357
train_step : 4191, loss1 : 2.425420, loss2 : 1.807999
train_step : 4192, loss1 : 1.672945, loss2 : 3.177784
train_step : 4193, loss1 : 3.339129, loss2 : 2.151932
train_step : 4194, loss1 : 2.225516, loss2 : 0.588430
train_step : 4195, loss1 : 1.451686, loss2 : 1.475548
train_step : 4196, loss1 : 0.472354, loss2 : 0.964152
train_step : 4197, loss1 : 1.189586, loss2 : 1.097649
train_step : 4198, loss1 : 0.961288, loss2 : 1.226974
train_step : 4199, loss1 : 0.646817, loss2 : 0.741748
train_step : 4200, loss1 : 0.854528, loss2 : 0.717415
train_step : 4201, loss1 : 0.886499, loss2 : 1.838175
train_step : 4202, loss1 : 3.109799, loss2 : 1.946455
train_step : 4203, loss1 : 1.314440, loss2 : 2.736392
train_step : 4204, loss1 : 1.100251, loss2 : 1.843536
train_step : 4205, loss1 : 1.040417, loss2 : 0.980997
train_step : 4206, loss1 : 1.392473, loss2 : 1.725780
train_step : 4207, loss1 : 2.027262, loss2 : 1.170379
train_step : 4208, loss1 : 0.851218, loss2 : 0.675075
train_step : 4209, loss1 : 1.133259, loss2 : 1.470184
train_step : 4210, loss1 : 1.025543, loss2 : 1.525728
train_step : 4211, loss1 : 1.047324, loss2 : 1.038345
train_step : 4212, loss1 : 1.601646, loss2 : 2.169199
train_step : 4213, loss1 : 0.917156, loss2 : 2.436138
train_step : 4214, loss1 : 1.210870, loss2 : 2.153011
train_step : 4215, loss1 : 2.654169, loss2 : 1.424980
train_step : 4216, loss1 : 1.668805, loss2 : 1.992564
train_step : 4217, loss1 : 1.631681, loss2 : 0.713470
train_step : 4218, loss1 : 1.719101, loss2 : 1.854197
train_step : 4219, loss1 : 1.585975, loss2 : 1.455723
train_step : 4220, loss1 : 0.966918, loss2 : 1.221785
train_step : 4221, loss1 : 1.432419, loss2 : 1.773212
train_step : 4222, loss1 : 1.916622, loss2 : 1.329561
train_step : 4223, loss1 : 1.981434, loss2 : 1.185147
train_step : 4224, loss1 : 0.916765, loss2 : 0.702493
train_step : 4225, loss1 : 1.435423, loss2 : 1.756742
train_step : 4226, loss1 : 1.350505, loss2 : 0.771457
train_step : 4227, loss1 : 2.552377, loss2 : 2.067701
train_step : 4228, loss1 : 3.198894, loss2 : 1.372124
train_step : 4229, loss1 : 1.371778, loss2 : 1.608995
train_step : 4230, loss1 : 1.690000, loss2 : 1.140933
train_step : 4231, loss1 : 1.667064, loss2 : 3.386627
train_step : 4232, loss1 : 0.938975, loss2 : 1.291106
train_step : 4233, loss1 : 1.363752, loss2 : 1.225933
train_step : 4234, loss1 : 1.139849, loss2 : 1.319256
train_step : 4235, loss1 : 1.068482, loss2 : 2.251467
train_step : 4236, loss1 : 2.891064, loss2 : 1.727736
train_step : 4237, loss1 : 1.697261, loss2 : 2.492908
train_step : 4238, loss1 : 2.433386, loss2 : 2.574376
train_step : 4239, loss1 : 3.589361, loss2 : 2.222819
train_step : 4240, loss1 : 4.751983, loss2 : 4.889433
train_step : 4241, loss1 : 4.481123, loss2 : 2.621269
train_step : 4242, loss1 : 3.277046, loss2 : 3.539805
train_step : 4243, loss1 : 1.604609, loss2 : 1.769864
train_step : 4244, loss1 : 1.552990, loss2 : 2.260886
train_step : 4245, loss1 : 1.861783, loss2 : 1.795268
train_step : 4246, loss1 : 1.959520, loss2 : 1.362992
train_step : 4247, loss1 : 1.403700, loss2 : 1.378376
train_step : 4248, loss1 : 1.558575, loss2 : 1.615433
train_step : 4249, loss1 : 1.287760, loss2 : 1.129949
train_step : 4250, loss1 : 0.986510, loss2 : 1.070487
train_step : 4251, loss1 : 1.233922, loss2 : 1.429388
train_step : 4252, loss1 : 1.406599, loss2 : 1.647881
train_step : 4253, loss1 : 2.568496, loss2 : 2.479611
train_step : 4254, loss1 : 3.065458, loss2 : 2.710589
train_step : 4255, loss1 : 2.841587, loss2 : 3.122194
train_step : 4256, loss1 : 3.008331, loss2 : 3.981848
train_step : 4257, loss1 : 1.368823, loss2 : 2.079991
train_step : 4258, loss1 : 1.792494, loss2 : 1.147123
train_step : 4259, loss1 : 1.799073, loss2 : 1.413829
train_step : 4260, loss1 : 0.846176, loss2 : 2.786157
train_step : 4261, loss1 : 1.487266, loss2 : 1.013185
train_step : 4262, loss1 : 0.962049, loss2 : 0.827776
train_step : 4263, loss1 : 1.310941, loss2 : 0.852336
train_step : 4264, loss1 : 1.577206, loss2 : 1.003667
train_step : 4265, loss1 : 2.661880, loss2 : 0.753588
train_step : 4266, loss1 : 1.374941, loss2 : 1.368092
train_step : 4267, loss1 : 1.091556, loss2 : 2.412957
train_step : 4268, loss1 : 1.505220, loss2 : 1.844220
train_step : 4269, loss1 : 0.848523, loss2 : 1.123145
train_step : 4270, loss1 : 1.684077, loss2 : 1.316605
train_step : 4271, loss1 : 1.196188, loss2 : 2.009028
train_step : 4272, loss1 : 0.926722, loss2 : 1.034733
train_step : 4273, loss1 : 1.293424, loss2 : 1.544258
train_step : 4274, loss1 : 1.346785, loss2 : 0.806760
train_step : 4275, loss1 : 0.614880, loss2 : 0.936803
train_step : 4276, loss1 : 1.286617, loss2 : 1.264287
train_step : 4277, loss1 : 1.712083, loss2 : 1.023967
train_step : 4278, loss1 : 2.236849, loss2 : 1.601965
train_step : 4279, loss1 : 1.370836, loss2 : 5.138468
train_step : 4280, loss1 : 3.385585, loss2 : 3.048062
train_step : 4281, loss1 : 3.264873, loss2 : 3.170096
train_step : 4282, loss1 : 3.002354, loss2 : 3.409979
train_step : 4283, loss1 : 3.685452, loss2 : 1.229205
train_step : 4284, loss1 : 1.606967, loss2 : 3.299819
train_step : 4285, loss1 : 2.505034, loss2 : 3.313196
train_step : 4286, loss1 : 3.364836, loss2 : 3.066646
train_step : 4287, loss1 : 3.062753, loss2 : 3.205307
train_step : 4288, loss1 : 2.729588, loss2 : 3.396156
train_step : 4289, loss1 : 3.784803, loss2 : 2.422136
train_step : 4290, loss1 : 2.935692, loss2 : 4.150594
train_step : 4291, loss1 : 3.064123, loss2 : 2.289817
train_step : 4292, loss1 : 2.406549, loss2 : 2.242956
train_step : 4293, loss1 : 2.935923, loss2 : 1.517852
train_step : 4294, loss1 : 0.929597, loss2 : 1.130539
train_step : 4295, loss1 : 1.132935, loss2 : 1.139475
train_step : 4296, loss1 : 1.934222, loss2 : 1.042589
train_step : 4297, loss1 : 1.018149, loss2 : 0.741945
train_step : 4298, loss1 : 0.717507, loss2 : 0.702903
train_step : 4299, loss1 : 0.830355, loss2 : 1.387099
train_step : 4300, loss1 : 1.149418, loss2 : 1.070421
train_step : 4301, loss1 : 0.840945, loss2 : 1.013050
train_step : 4302, loss1 : 3.196897, loss2 : 0.946945
train_step : 4303, loss1 : 1.553115, loss2 : 1.715790
train_step : 4304, loss1 : 0.949149, loss2 : 0.776981
train_step : 4305, loss1 : 1.235151, loss2 : 1.629220
train_step : 4306, loss1 : 1.551678, loss2 : 1.436667
train_step : 4307, loss1 : 2.228179, loss2 : 1.456222
train_step : 4308, loss1 : 1.585839, loss2 : 1.896967
train_step : 4309, loss1 : 1.384205, loss2 : 2.319213
train_step : 4310, loss1 : 1.393382, loss2 : 1.390044
train_step : 4311, loss1 : 1.151376, loss2 : 1.177294
train_step : 4312, loss1 : 0.745424, loss2 : 1.276122
train_step : 4313, loss1 : 1.811241, loss2 : 1.914421
train_step : 4314, loss1 : 1.867422, loss2 : 1.550085
train_step : 4315, loss1 : 2.887121, loss2 : 0.969110
train_step : 4316, loss1 : 2.354056, loss2 : 2.617128
train_step : 4317, loss1 : 1.736229, loss2 : 1.733475
train_step : 4318, loss1 : 1.304550, loss2 : 1.683537
train_step : 4319, loss1 : 0.526018, loss2 : 1.360993
train_step : 4320, loss1 : 1.043094, loss2 : 0.936488
train_step : 4321, loss1 : 1.196032, loss2 : 0.974777
train_step : 4322, loss1 : 2.253954, loss2 : 1.109523
train_step : 4323, loss1 : 1.726375, loss2 : 2.475788
train_step : 4324, loss1 : 1.936085, loss2 : 3.635563
train_step : 4325, loss1 : 3.878814, loss2 : 4.840681
train_step : 4326, loss1 : 6.055828, loss2 : 6.482710
train_step : 4327, loss1 : 7.566017, loss2 : 8.570746
train_step : 4328, loss1 : 6.665764, loss2 : 6.424314
train_step : 4329, loss1 : 10.383686, loss2 : 8.187639
train_step : 4330, loss1 : 3.946709, loss2 : 4.718257
train_step : 4331, loss1 : 5.236579, loss2 : 4.277032
train_step : 4332, loss1 : 2.826968, loss2 : 2.157159
train_step : 4333, loss1 : 2.153660, loss2 : 3.177275
train_step : 4334, loss1 : 1.500081, loss2 : 2.946395
train_step : 4335, loss1 : 1.233997, loss2 : 2.857198
train_step : 4336, loss1 : 1.237729, loss2 : 1.859545
train_step : 4337, loss1 : 2.563004, loss2 : 1.836811
train_step : 4338, loss1 : 2.758411, loss2 : 2.636401
train_step : 4339, loss1 : 1.526704, loss2 : 2.434864
train_step : 4340, loss1 : 1.618930, loss2 : 1.079718
train_step : 4341, loss1 : 1.418934, loss2 : 0.890513
train_step : 4342, loss1 : 1.233296, loss2 : 1.524812
train_step : 4343, loss1 : 2.849566, loss2 : 1.026763
train_step : 4344, loss1 : 1.362964, loss2 : 2.916867
train_step : 4345, loss1 : 2.229970, loss2 : 1.398803
train_step : 4346, loss1 : 3.258824, loss2 : 1.792280
train_step : 4347, loss1 : 1.934331, loss2 : 2.365422
train_step : 4348, loss1 : 0.586433, loss2 : 0.886732
train_step : 4349, loss1 : 0.976830, loss2 : 1.163268
train_step : 4350, loss1 : 2.405062, loss2 : 1.644117
train_step : 4351, loss1 : 1.446741, loss2 : 1.754098
train_step : 4352, loss1 : 1.398556, loss2 : 1.081067
train_step : 4353, loss1 : 1.122408, loss2 : 1.246699
train_step : 4354, loss1 : 1.457226, loss2 : 1.595350
train_step : 4355, loss1 : 0.887713, loss2 : 0.709458
train_step : 4356, loss1 : 0.727496, loss2 : 1.365468
train_step : 4357, loss1 : 1.598323, loss2 : 0.450324
train_step : 4358, loss1 : 1.025908, loss2 : 1.376753
train_step : 4359, loss1 : 1.776543, loss2 : 0.970713
train_step : 4360, loss1 : 0.995102, loss2 : 1.886155
train_step : 4361, loss1 : 1.803158, loss2 : 2.134048
train_step : 4362, loss1 : 1.382830, loss2 : 0.797332
train_step : 4363, loss1 : 1.196031, loss2 : 0.717553
train_step : 4364, loss1 : 0.692885, loss2 : 1.246286
train_step : 4365, loss1 : 1.586908, loss2 : 1.098381
train_step : 4366, loss1 : 1.243304, loss2 : 1.252651
train_step : 4367, loss1 : 2.065743, loss2 : 1.500515
train_step : 4368, loss1 : 1.387624, loss2 : 0.813573
train_step : 4369, loss1 : 1.391355, loss2 : 1.357883
train_step : 4370, loss1 : 1.750978, loss2 : 0.756694
train_step : 4371, loss1 : 1.364517, loss2 : 1.477837
train_step : 4372, loss1 : 1.328481, loss2 : 1.043020
train_step : 4373, loss1 : 0.771397, loss2 : 1.164649
train_step : 4374, loss1 : 1.473255, loss2 : 1.133738
train_step : 4375, loss1 : 1.666305, loss2 : 1.400192
train_step : 4376, loss1 : 0.926014, loss2 : 1.476764
train_step : 4377, loss1 : 1.305718, loss2 : 1.473995
train_step : 4378, loss1 : 1.139426, loss2 : 1.893964
train_step : 4379, loss1 : 1.146480, loss2 : 1.247376
train_step : 4380, loss1 : 1.307904, loss2 : 0.815231
train_step : 4381, loss1 : 0.694930, loss2 : 1.254342
train_step : 4382, loss1 : 0.561678, loss2 : 1.026252
train_step : 4383, loss1 : 1.369151, loss2 : 1.238631
train_step : 4384, loss1 : 1.102252, loss2 : 0.776615
train_step : 4385, loss1 : 1.026489, loss2 : 1.030383
train_step : 4386, loss1 : 1.090486, loss2 : 1.012052
train_step : 4387, loss1 : 1.184481, loss2 : 1.061218
train_step : 4388, loss1 : 1.004148, loss2 : 0.822417
train_step : 4389, loss1 : 1.546939, loss2 : 1.291439
train_step : 4390, loss1 : 1.857878, loss2 : 0.878000
train_step : 4391, loss1 : 1.048557, loss2 : 1.068954
train_step : 4392, loss1 : 0.469199, loss2 : 1.192626
train_step : 4393, loss1 : 0.881739, loss2 : 1.670315
train_step : 4394, loss1 : 1.393896, loss2 : 1.232973
train_step : 4395, loss1 : 1.169054, loss2 : 0.522223
train_step : 4396, loss1 : 0.912057, loss2 : 1.569192
train_step : 4397, loss1 : 1.404475, loss2 : 0.715194
train_step : 4398, loss1 : 2.270319, loss2 : 1.736524
train_step : 4399, loss1 : 1.920233, loss2 : 1.540981
train_step : 4400, loss1 : 2.108432, loss2 : 1.355649
train_step : 4401, loss1 : 1.747172, loss2 : 1.537611
train_step : 4402, loss1 : 0.928526, loss2 : 1.327394
train_step : 4403, loss1 : 1.154214, loss2 : 0.699498
train_step : 4404, loss1 : 3.463461, loss2 : 1.635117
train_step : 4405, loss1 : 1.008942, loss2 : 1.347394
train_step : 4406, loss1 : 1.054100, loss2 : 1.077080
train_step : 4407, loss1 : 1.043727, loss2 : 1.663826
train_step : 4408, loss1 : 1.380959, loss2 : 0.856587
train_step : 4409, loss1 : 1.388387, loss2 : 1.452725
train_step : 4410, loss1 : 1.143857, loss2 : 1.580515
train_step : 4411, loss1 : 1.527788, loss2 : 1.251117
train_step : 4412, loss1 : 1.113387, loss2 : 1.421766
train_step : 4413, loss1 : 1.631213, loss2 : 2.115081
train_step : 4414, loss1 : 1.635894, loss2 : 2.243537
train_step : 4415, loss1 : 2.702394, loss2 : 2.120620
train_step : 4416, loss1 : 1.643694, loss2 : 1.881032
train_step : 4417, loss1 : 2.236892, loss2 : 1.717635
train_step : 4418, loss1 : 0.999129, loss2 : 1.018574
train_step : 4419, loss1 : 0.850742, loss2 : 1.377473
train_step : 4420, loss1 : 2.285593, loss2 : 0.696380
train_step : 4421, loss1 : 2.828851, loss2 : 1.393250
train_step : 4422, loss1 : 2.235692, loss2 : 2.219102
train_step : 4423, loss1 : 1.226289, loss2 : 1.622213
train_step : 4424, loss1 : 1.688646, loss2 : 1.618190
train_step : 4425, loss1 : 1.314158, loss2 : 1.236998
train_step : 4426, loss1 : 0.713030, loss2 : 0.917567
train_step : 4427, loss1 : 0.849046, loss2 : 1.021677
train_step : 4428, loss1 : 1.592338, loss2 : 0.740429
train_step : 4429, loss1 : 1.818760, loss2 : 2.151988
train_step : 4430, loss1 : 1.505784, loss2 : 0.768701
train_step : 4431, loss1 : 0.823678, loss2 : 1.151753
train_step : 4432, loss1 : 0.902173, loss2 : 1.377902
train_step : 4433, loss1 : 0.898172, loss2 : 1.196158
train_step : 4434, loss1 : 1.986170, loss2 : 1.781635
train_step : 4435, loss1 : 1.751492, loss2 : 0.715592
train_step : 4436, loss1 : 1.205356, loss2 : 0.973589
train_step : 4437, loss1 : 1.574485, loss2 : 0.857252
train_step : 4438, loss1 : 0.687024, loss2 : 1.431894
train_step : 4439, loss1 : 1.792403, loss2 : 1.191885
train_step : 4440, loss1 : 1.203184, loss2 : 1.141475
train_step : 4441, loss1 : 1.502398, loss2 : 1.922077
train_step : 4442, loss1 : 1.310501, loss2 : 1.404531
train_step : 4443, loss1 : 0.846129, loss2 : 1.211106
train_step : 4444, loss1 : 1.841497, loss2 : 1.034238
train_step : 4445, loss1 : 2.075763, loss2 : 1.576356
train_step : 4446, loss1 : 1.752528, loss2 : 2.215590
train_step : 4447, loss1 : 1.139008, loss2 : 1.554874
train_step : 4448, loss1 : 1.672717, loss2 : 1.303009
train_step : 4449, loss1 : 0.969191, loss2 : 1.784427
train_step : 4450, loss1 : 1.236944, loss2 : 1.563126
train_step : 4451, loss1 : 1.829601, loss2 : 2.850498
train_step : 4452, loss1 : 1.675507, loss2 : 2.395000
train_step : 4453, loss1 : 0.976766, loss2 : 0.880077
train_step : 4454, loss1 : 1.146654, loss2 : 1.701803
train_step : 4455, loss1 : 1.535893, loss2 : 0.793469
train_step : 4456, loss1 : 1.029531, loss2 : 0.723967
train_step : 4457, loss1 : 0.891167, loss2 : 1.184509
train_step : 4458, loss1 : 0.603790, loss2 : 0.552259
train_step : 4459, loss1 : 1.169631, loss2 : 1.125034
train_step : 4460, loss1 : 2.110361, loss2 : 1.477041
train_step : 4461, loss1 : 1.384352, loss2 : 1.075619
train_step : 4462, loss1 : 1.804119, loss2 : 1.696466
train_step : 4463, loss1 : 1.156449, loss2 : 0.916251
train_step : 4464, loss1 : 1.356329, loss2 : 1.823189
train_step : 4465, loss1 : 1.980320, loss2 : 0.739077
train_step : 4466, loss1 : 1.225460, loss2 : 1.458358
train_step : 4467, loss1 : 0.577557, loss2 : 1.833585
train_step : 4468, loss1 : 1.240949, loss2 : 1.336486
train_step : 4469, loss1 : 2.176156, loss2 : 1.453216
train_step : 4470, loss1 : 3.865642, loss2 : 3.257186
train_step : 4471, loss1 : 1.779082, loss2 : 2.870872
train_step : 4472, loss1 : 2.127880, loss2 : 2.719796
train_step : 4473, loss1 : 3.088779, loss2 : 3.088123
train_step : 4474, loss1 : 2.741254, loss2 : 3.413476
train_step : 4475, loss1 : 1.047457, loss2 : 1.416400
train_step : 4476, loss1 : 2.112708, loss2 : 1.863610
train_step : 4477, loss1 : 1.744635, loss2 : 1.384963
train_step : 4478, loss1 : 3.261425, loss2 : 0.789440
train_step : 4479, loss1 : 1.915005, loss2 : 1.056412
train_step : 4480, loss1 : 1.574992, loss2 : 1.344037
train_step : 4481, loss1 : 2.145855, loss2 : 0.536683
train_step : 4482, loss1 : 1.092659, loss2 : 1.056521
train_step : 4483, loss1 : 1.625918, loss2 : 0.844848
train_step : 4484, loss1 : 2.745241, loss2 : 1.245917
train_step : 4485, loss1 : 2.630085, loss2 : 2.507269
train_step : 4486, loss1 : 2.447793, loss2 : 2.649947
train_step : 4487, loss1 : 2.677276, loss2 : 2.745552
train_step : 4488, loss1 : 2.337029, loss2 : 2.308009
train_step : 4489, loss1 : 1.265887, loss2 : 1.714685
train_step : 4490, loss1 : 2.142332, loss2 : 0.994701
train_step : 4491, loss1 : 0.782953, loss2 : 0.725261
train_step : 4492, loss1 : 0.971805, loss2 : 1.467747
train_step : 4493, loss1 : 1.505500, loss2 : 1.084174
train_step : 4494, loss1 : 1.501776, loss2 : 0.893039
train_step : 4495, loss1 : 1.261648, loss2 : 0.555100
train_step : 4496, loss1 : 1.534530, loss2 : 1.007985
train_step : 4497, loss1 : 1.198558, loss2 : 1.118110
train_step : 4498, loss1 : 1.173125, loss2 : 0.868900
train_step : 4499, loss1 : 0.544706, loss2 : 1.480604
train_step : 4500, loss1 : 1.092287, loss2 : 0.965668
train_step : 4501, loss1 : 1.015110, loss2 : 1.905671
train_step : 4502, loss1 : 1.036017, loss2 : 1.226588
train_step : 4503, loss1 : 0.909676, loss2 : 1.124213
train_step : 4504, loss1 : 1.329116, loss2 : 0.974002
train_step : 4505, loss1 : 1.030930, loss2 : 0.539897
train_step : 4506, loss1 : 1.746958, loss2 : 1.450749
train_step : 4507, loss1 : 1.546108, loss2 : 1.365937
train_step : 4508, loss1 : 1.702129, loss2 : 1.271059
train_step : 4509, loss1 : 1.800206, loss2 : 1.586239
train_step : 4510, loss1 : 2.225507, loss2 : 1.268236
train_step : 4511, loss1 : 3.432756, loss2 : 1.172739
train_step : 4512, loss1 : 2.221525, loss2 : 1.243406
train_step : 4513, loss1 : 2.445200, loss2 : 2.135007
train_step : 4514, loss1 : 1.585709, loss2 : 3.805338
train_step : 4515, loss1 : 4.005313, loss2 : 2.253981
train_step : 4516, loss1 : 1.766316, loss2 : 3.064042
train_step : 4517, loss1 : 2.527436, loss2 : 2.908940
train_step : 4518, loss1 : 1.030222, loss2 : 2.204196
train_step : 4519, loss1 : 2.039629, loss2 : 1.167597
train_step : 4520, loss1 : 1.315433, loss2 : 1.246208
train_step : 4521, loss1 : 1.227268, loss2 : 1.717068
train_step : 4522, loss1 : 0.754803, loss2 : 2.118713
train_step : 4523, loss1 : 1.629525, loss2 : 1.994882
train_step : 4524, loss1 : 2.013016, loss2 : 0.741480
train_step : 4525, loss1 : 1.348302, loss2 : 1.298273
train_step : 4526, loss1 : 2.007987, loss2 : 1.773373
train_step : 4527, loss1 : 1.557736, loss2 : 2.068430
train_step : 4528, loss1 : 1.125055, loss2 : 1.926163
train_step : 4529, loss1 : 1.165331, loss2 : 2.815016
train_step : 4530, loss1 : 0.881165, loss2 : 0.809338
train_step : 4531, loss1 : 2.421841, loss2 : 1.677307
train_step : 4532, loss1 : 0.911482, loss2 : 0.962338
train_step : 4533, loss1 : 0.998834, loss2 : 4.620919
train_step : 4534, loss1 : 0.792978, loss2 : 1.717788
train_step : 4535, loss1 : 1.250943, loss2 : 0.852622
train_step : 4536, loss1 : 0.967030, loss2 : 1.189642
train_step : 4537, loss1 : 1.298692, loss2 : 2.166386
train_step : 4538, loss1 : 0.800811, loss2 : 0.766369
train_step : 4539, loss1 : 0.777762, loss2 : 0.989103
train_step : 4540, loss1 : 0.972051, loss2 : 0.831880
train_step : 4541, loss1 : 1.474604, loss2 : 1.284468
train_step : 4542, loss1 : 1.235456, loss2 : 2.279186
train_step : 4543, loss1 : 1.572422, loss2 : 1.744888
train_step : 4544, loss1 : 1.981785, loss2 : 2.003691
train_step : 4545, loss1 : 1.897454, loss2 : 2.612092
train_step : 4546, loss1 : 2.164191, loss2 : 2.545268
train_step : 4547, loss1 : 2.025967, loss2 : 2.185503
train_step : 4548, loss1 : 2.999797, loss2 : 3.024410
train_step : 4549, loss1 : 2.963357, loss2 : 2.611753
train_step : 4550, loss1 : 1.899619, loss2 : 4.196290
train_step : 4551, loss1 : 1.583859, loss2 : 2.956393
train_step : 4552, loss1 : 2.421863, loss2 : 3.002229
train_step : 4553, loss1 : 2.693525, loss2 : 4.760632
train_step : 4554, loss1 : 6.402080, loss2 : 4.478063
train_step : 4555, loss1 : 5.379575, loss2 : 2.453025
train_step : 4556, loss1 : 5.088906, loss2 : 3.292198
train_step : 4557, loss1 : 3.135830, loss2 : 2.161034
train_step : 4558, loss1 : 3.244871, loss2 : 4.840805
train_step : 4559, loss1 : 2.821046, loss2 : 5.620590
train_step : 4560, loss1 : 2.784224, loss2 : 3.595900
train_step : 4561, loss1 : 2.284588, loss2 : 3.399853
train_step : 4562, loss1 : 2.835411, loss2 : 2.287257
train_step : 4563, loss1 : 1.111799, loss2 : 1.855892
train_step : 4564, loss1 : 1.597002, loss2 : 0.994476
train_step : 4565, loss1 : 1.737319, loss2 : 1.250727
train_step : 4566, loss1 : 2.321566, loss2 : 1.041215
train_step : 4567, loss1 : 1.134664, loss2 : 1.850798
train_step : 4568, loss1 : 1.377209, loss2 : 1.437799
train_step : 4569, loss1 : 1.751402, loss2 : 0.799533
train_step : 4570, loss1 : 0.930498, loss2 : 1.132151
train_step : 4571, loss1 : 1.294505, loss2 : 0.719337
train_step : 4572, loss1 : 1.062946, loss2 : 0.923288
train_step : 4573, loss1 : 1.165819, loss2 : 1.295572
train_step : 4574, loss1 : 1.946189, loss2 : 1.595614
train_step : 4575, loss1 : 2.806655, loss2 : 3.623245
train_step : 4576, loss1 : 3.475114, loss2 : 3.586224
train_step : 4577, loss1 : 2.625479, loss2 : 3.744719
train_step : 4578, loss1 : 3.008865, loss2 : 2.122509
train_step : 4579, loss1 : 1.958411, loss2 : 1.189910
train_step : 4580, loss1 : 1.565797, loss2 : 1.070220
train_step : 4581, loss1 : 1.348560, loss2 : 0.530559
train_step : 4582, loss1 : 0.811822, loss2 : 1.275821
train_step : 4583, loss1 : 1.112154, loss2 : 0.795691
train_step : 4584, loss1 : 0.990830, loss2 : 1.157194
train_step : 4585, loss1 : 1.332346, loss2 : 0.573220
train_step : 4586, loss1 : 0.826808, loss2 : 1.635335
train_step : 4587, loss1 : 1.958426, loss2 : 1.059825
train_step : 4588, loss1 : 1.685292, loss2 : 2.410725
train_step : 4589, loss1 : 1.295571, loss2 : 1.121927
train_step : 4590, loss1 : 1.346516, loss2 : 1.128923
train_step : 4591, loss1 : 0.921860, loss2 : 0.956227
train_step : 4592, loss1 : 1.667360, loss2 : 0.711028
train_step : 4593, loss1 : 1.091973, loss2 : 1.239006
train_step : 4594, loss1 : 1.467944, loss2 : 1.171751
train_step : 4595, loss1 : 2.005467, loss2 : 0.928062
train_step : 4596, loss1 : 1.306280, loss2 : 1.916040
train_step : 4597, loss1 : 1.783966, loss2 : 1.256528
train_step : 4598, loss1 : 1.873284, loss2 : 2.839104
train_step : 4599, loss1 : 1.125057, loss2 : 3.881689
train_step : 4600, loss1 : 1.192753, loss2 : 1.829461
train_step : 4601, loss1 : 2.386525, loss2 : 2.670992
train_step : 4602, loss1 : 2.166716, loss2 : 4.593051
train_step : 4603, loss1 : 3.251655, loss2 : 3.301963
train_step : 4604, loss1 : 1.931239, loss2 : 3.838310
train_step : 4605, loss1 : 1.889890, loss2 : 0.841154
train_step : 4606, loss1 : 2.031451, loss2 : 1.855581
train_step : 4607, loss1 : 0.995120, loss2 : 1.427685
train_step : 4608, loss1 : 2.190563, loss2 : 1.009657
train_step : 4609, loss1 : 1.559388, loss2 : 1.317268
train_step : 4610, loss1 : 1.451201, loss2 : 0.890004
train_step : 4611, loss1 : 1.368839, loss2 : 1.128384
train_step : 4612, loss1 : 2.346241, loss2 : 1.136971
train_step : 4613, loss1 : 1.594244, loss2 : 2.897940
train_step : 4614, loss1 : 1.546496, loss2 : 2.285614
train_step : 4615, loss1 : 2.521058, loss2 : 1.346831
train_step : 4616, loss1 : 1.544839, loss2 : 1.857932
train_step : 4617, loss1 : 1.761155, loss2 : 1.752322
train_step : 4618, loss1 : 1.377791, loss2 : 0.905759
train_step : 4619, loss1 : 0.715545, loss2 : 1.571473
train_step : 4620, loss1 : 1.257676, loss2 : 1.448822
train_step : 4621, loss1 : 1.275083, loss2 : 1.258287
train_step : 4622, loss1 : 1.789889, loss2 : 1.384960
train_step : 4623, loss1 : 1.958998, loss2 : 2.122426
train_step : 4624, loss1 : 1.293659, loss2 : 1.953874
train_step : 4625, loss1 : 1.464723, loss2 : 1.908295
train_step : 4626, loss1 : 1.827568, loss2 : 2.735872
train_step : 4627, loss1 : 2.331258, loss2 : 2.153741
train_step : 4628, loss1 : 2.070063, loss2 : 1.382492
train_step : 4629, loss1 : 1.250689, loss2 : 1.499504
train_step : 4630, loss1 : 1.665257, loss2 : 0.672663
train_step : 4631, loss1 : 1.416024, loss2 : 2.373336
train_step : 4632, loss1 : 0.928563, loss2 : 1.262282
train_step : 4633, loss1 : 0.958188, loss2 : 1.663046
train_step : 4634, loss1 : 1.226371, loss2 : 1.257323
train_step : 4635, loss1 : 1.407264, loss2 : 1.245032
train_step : 4636, loss1 : 1.673249, loss2 : 0.556598
train_step : 4637, loss1 : 1.729925, loss2 : 1.573367
train_step : 4638, loss1 : 0.503723, loss2 : 0.814910
train_step : 4639, loss1 : 0.892175, loss2 : 0.918499
train_step : 4640, loss1 : 0.980834, loss2 : 2.544207
train_step : 4641, loss1 : 1.706983, loss2 : 1.396889
train_step : 4642, loss1 : 1.329829, loss2 : 0.803026
train_step : 4643, loss1 : 1.426646, loss2 : 1.018986
train_step : 4644, loss1 : 1.062797, loss2 : 2.006931
train_step : 4645, loss1 : 1.309103, loss2 : 1.292474
train_step : 4646, loss1 : 1.546195, loss2 : 1.472443
train_step : 4647, loss1 : 1.702388, loss2 : 1.946435
train_step : 4648, loss1 : 2.707867, loss2 : 1.949611
train_step : 4649, loss1 : 2.273447, loss2 : 2.563016
train_step : 4650, loss1 : 1.896888, loss2 : 1.923862
train_step : 4651, loss1 : 1.572620, loss2 : 1.921493
train_step : 4652, loss1 : 0.991814, loss2 : 1.932433
train_step : 4653, loss1 : 1.104013, loss2 : 2.604940
train_step : 4654, loss1 : 1.232335, loss2 : 1.177770
train_step : 4655, loss1 : 1.288993, loss2 : 0.861506
train_step : 4656, loss1 : 1.239206, loss2 : 0.911771
train_step : 4657, loss1 : 1.475118, loss2 : 1.748278
train_step : 4658, loss1 : 1.548958, loss2 : 0.692940
train_step : 4659, loss1 : 1.345407, loss2 : 1.932665
train_step : 4660, loss1 : 0.997430, loss2 : 1.676783
train_step : 4661, loss1 : 1.978675, loss2 : 1.639056
train_step : 4662, loss1 : 1.320925, loss2 : 1.708526
train_step : 4663, loss1 : 1.228352, loss2 : 1.846436
train_step : 4664, loss1 : 1.389453, loss2 : 0.911883
train_step : 4665, loss1 : 1.573125, loss2 : 0.955408
train_step : 4666, loss1 : 1.375454, loss2 : 1.254001
train_step : 4667, loss1 : 0.910539, loss2 : 1.337224
train_step : 4668, loss1 : 0.979479, loss2 : 1.038897
train_step : 4669, loss1 : 0.668837, loss2 : 1.373262
train_step : 4670, loss1 : 0.543490, loss2 : 0.928790
train_step : 4671, loss1 : 1.048133, loss2 : 1.344901
train_step : 4672, loss1 : 1.635671, loss2 : 1.102549
train_step : 4673, loss1 : 0.759812, loss2 : 0.804259
train_step : 4674, loss1 : 0.909507, loss2 : 2.827882
train_step : 4675, loss1 : 1.025212, loss2 : 3.716780
train_step : 4676, loss1 : 1.336597, loss2 : 0.871830
train_step : 4677, loss1 : 1.011923, loss2 : 0.961544
train_step : 4678, loss1 : 1.051421, loss2 : 1.107695
train_step : 4679, loss1 : 1.088046, loss2 : 1.206584
train_step : 4680, loss1 : 1.963808, loss2 : 0.769546
train_step : 4681, loss1 : 0.692408, loss2 : 0.917771
train_step : 4682, loss1 : 0.614864, loss2 : 0.908415
train_step : 4683, loss1 : 1.498102, loss2 : 0.928081
train_step : 4684, loss1 : 0.804300, loss2 : 1.072899
train_step : 4685, loss1 : 1.536390, loss2 : 0.872485
train_step : 4686, loss1 : 1.907825, loss2 : 1.162508
train_step : 4687, loss1 : 1.046011, loss2 : 0.880384
train_step : 4688, loss1 : 0.926502, loss2 : 1.362610
train_step : 4689, loss1 : 2.033216, loss2 : 1.005900
train_step : 4690, loss1 : 1.695239, loss2 : 2.678277
train_step : 4691, loss1 : 1.114244, loss2 : 0.987496
train_step : 4692, loss1 : 1.193888, loss2 : 1.007327
train_step : 4693, loss1 : 1.166278, loss2 : 1.243244
train_step : 4694, loss1 : 1.695853, loss2 : 2.056068
train_step : 4695, loss1 : 1.253630, loss2 : 1.689145
train_step : 4696, loss1 : 2.202716, loss2 : 1.500683
train_step : 4697, loss1 : 0.639279, loss2 : 1.186334
train_step : 4698, loss1 : 1.207557, loss2 : 1.493291
train_step : 4699, loss1 : 1.672454, loss2 : 2.340750
train_step : 4700, loss1 : 1.403871, loss2 : 2.095725
train_step : 4701, loss1 : 1.574791, loss2 : 1.831843
train_step : 4702, loss1 : 1.936896, loss2 : 1.228016
train_step : 4703, loss1 : 1.072109, loss2 : 1.300633
train_step : 4704, loss1 : 1.245580, loss2 : 0.628490
train_step : 4705, loss1 : 1.145374, loss2 : 1.493781
train_step : 4706, loss1 : 1.522571, loss2 : 1.078370
train_step : 4707, loss1 : 1.886926, loss2 : 1.764536
train_step : 4708, loss1 : 1.723985, loss2 : 2.324591
train_step : 4709, loss1 : 3.634415, loss2 : 4.348196
train_step : 4710, loss1 : 4.430182, loss2 : 5.619495
train_step : 4711, loss1 : 6.897046, loss2 : 5.915004
train_step : 4712, loss1 : 4.743639, loss2 : 4.980696
train_step : 4713, loss1 : 4.339577, loss2 : 3.823296
train_step : 4714, loss1 : 2.632685, loss2 : 1.752690
train_step : 4715, loss1 : 2.027714, loss2 : 2.255867
train_step : 4716, loss1 : 1.409607, loss2 : 1.159352
train_step : 4717, loss1 : 1.468157, loss2 : 1.073594
train_step : 4718, loss1 : 0.894344, loss2 : 0.986864
train_step : 4719, loss1 : 1.884032, loss2 : 0.897362
train_step : 4720, loss1 : 1.013943, loss2 : 0.827457
train_step : 4721, loss1 : 0.954396, loss2 : 1.049098
train_step : 4722, loss1 : 2.002343, loss2 : 1.086692
train_step : 4723, loss1 : 1.118906, loss2 : 1.266517
train_step : 4724, loss1 : 1.597736, loss2 : 1.307119
train_step : 4725, loss1 : 2.415716, loss2 : 1.608845
train_step : 4726, loss1 : 1.918313, loss2 : 1.749756
train_step : 4727, loss1 : 1.122642, loss2 : 3.769608
train_step : 4728, loss1 : 2.881006, loss2 : 3.234921
train_step : 4729, loss1 : 4.132572, loss2 : 2.061574
train_step : 4730, loss1 : 2.786507, loss2 : 3.554458
train_step : 4731, loss1 : 2.096395, loss2 : 4.686547
train_step : 4732, loss1 : 3.527708, loss2 : 3.150844
train_step : 4733, loss1 : 1.730420, loss2 : 1.974989
train_step : 4734, loss1 : 1.898427, loss2 : 1.525380
train_step : 4735, loss1 : 1.505959, loss2 : 0.702633
train_step : 4736, loss1 : 1.073784, loss2 : 1.987084
train_step : 4737, loss1 : 1.194483, loss2 : 0.825267
train_step : 4738, loss1 : 0.913262, loss2 : 1.028203
train_step : 4739, loss1 : 0.935032, loss2 : 0.863723
train_step : 4740, loss1 : 0.963819, loss2 : 1.251580
train_step : 4741, loss1 : 1.169261, loss2 : 1.169793
train_step : 4742, loss1 : 1.138787, loss2 : 0.852481
train_step : 4743, loss1 : 1.305710, loss2 : 1.291703
train_step : 4744, loss1 : 1.763264, loss2 : 0.988544
train_step : 4745, loss1 : 2.462508, loss2 : 0.609207
train_step : 4746, loss1 : 1.377165, loss2 : 1.928748
train_step : 4747, loss1 : 2.661550, loss2 : 2.563562
train_step : 4748, loss1 : 2.899794, loss2 : 2.140951
train_step : 4749, loss1 : 4.014760, loss2 : 1.934896
train_step : 4750, loss1 : 3.113332, loss2 : 2.285605
train_step : 4751, loss1 : 1.684630, loss2 : 1.659362
train_step : 4752, loss1 : 1.500574, loss2 : 1.395887
train_step : 4753, loss1 : 1.226930, loss2 : 2.679588
train_step : 4754, loss1 : 2.128777, loss2 : 3.333647
train_step : 4755, loss1 : 1.608972, loss2 : 3.472118
train_step : 4756, loss1 : 1.487057, loss2 : 2.185296
train_step : 4757, loss1 : 1.760319, loss2 : 1.595057
train_step : 4758, loss1 : 1.423867, loss2 : 1.245349
train_step : 4759, loss1 : 1.058655, loss2 : 1.079763
train_step : 4760, loss1 : 1.037261, loss2 : 1.957212
train_step : 4761, loss1 : 2.412668, loss2 : 1.182759
train_step : 4762, loss1 : 1.613651, loss2 : 1.995025
train_step : 4763, loss1 : 1.124572, loss2 : 1.002098
train_step : 4764, loss1 : 1.807442, loss2 : 0.766435
train_step : 4765, loss1 : 0.908909, loss2 : 0.785985
train_step : 4766, loss1 : 0.831017, loss2 : 0.969329
train_step : 4767, loss1 : 0.860304, loss2 : 1.593867
train_step : 4768, loss1 : 0.963892, loss2 : 1.095142
train_step : 4769, loss1 : 0.908318, loss2 : 0.626590
train_step : 4770, loss1 : 0.894465, loss2 : 1.647997
train_step : 4771, loss1 : 1.258015, loss2 : 2.059514
train_step : 4772, loss1 : 1.443089, loss2 : 1.791795
train_step : 4773, loss1 : 1.249746, loss2 : 1.279818
train_step : 4774, loss1 : 1.143585, loss2 : 1.582198
train_step : 4775, loss1 : 1.438766, loss2 : 1.210785
train_step : 4776, loss1 : 0.827455, loss2 : 1.221275
train_step : 4777, loss1 : 1.197143, loss2 : 1.149455
train_step : 4778, loss1 : 1.616401, loss2 : 2.261966
train_step : 4779, loss1 : 1.448571, loss2 : 2.017125
train_step : 4780, loss1 : 1.043798, loss2 : 1.843930
train_step : 4781, loss1 : 1.235470, loss2 : 0.966679
train_step : 4782, loss1 : 1.087358, loss2 : 1.329236
train_step : 4783, loss1 : 0.636364, loss2 : 1.252135
train_step : 4784, loss1 : 0.578066, loss2 : 1.539593
train_step : 4785, loss1 : 0.870113, loss2 : 1.181340
train_step : 4786, loss1 : 0.606579, loss2 : 0.471816
train_step : 4787, loss1 : 1.310798, loss2 : 1.381500
train_step : 4788, loss1 : 2.430867, loss2 : 1.912651
train_step : 4789, loss1 : 1.120614, loss2 : 2.862576
train_step : 4790, loss1 : 1.835925, loss2 : 1.571528
train_step : 4791, loss1 : 0.879816, loss2 : 2.290688
train_step : 4792, loss1 : 0.830871, loss2 : 1.456464
train_step : 4793, loss1 : 2.278310, loss2 : 1.434754
train_step : 4794, loss1 : 1.866725, loss2 : 1.235132
train_step : 4795, loss1 : 0.915400, loss2 : 1.573653
train_step : 4796, loss1 : 1.283488, loss2 : 0.750912
train_step : 4797, loss1 : 2.255756, loss2 : 0.841375
train_step : 4798, loss1 : 1.837237, loss2 : 1.364760
train_step : 4799, loss1 : 1.480051, loss2 : 1.369567
train_step : 4800, loss1 : 1.135187, loss2 : 1.634457
train_step : 4801, loss1 : 0.937811, loss2 : 1.841518
train_step : 4802, loss1 : 3.371346, loss2 : 1.179321
train_step : 4803, loss1 : 1.838090, loss2 : 0.937120
train_step : 4804, loss1 : 1.666435, loss2 : 1.048789
train_step : 4805, loss1 : 1.321712, loss2 : 1.798265
train_step : 4806, loss1 : 1.156274, loss2 : 1.157838
train_step : 4807, loss1 : 1.571888, loss2 : 1.437500
train_step : 4808, loss1 : 1.548946, loss2 : 1.010544
train_step : 4809, loss1 : 1.047618, loss2 : 1.173312
train_step : 4810, loss1 : 0.790778, loss2 : 1.730257
train_step : 4811, loss1 : 1.558796, loss2 : 1.745721
train_step : 4812, loss1 : 1.877493, loss2 : 1.211379
train_step : 4813, loss1 : 1.709803, loss2 : 1.775679
train_step : 4814, loss1 : 1.750294, loss2 : 1.051399
train_step : 4815, loss1 : 1.861290, loss2 : 2.876870
train_step : 4816, loss1 : 3.395884, loss2 : 2.419469
train_step : 4817, loss1 : 1.811799, loss2 : 2.223041
train_step : 4818, loss1 : 1.206409, loss2 : 3.088196
train_step : 4819, loss1 : 0.970710, loss2 : 1.904835
train_step : 4820, loss1 : 1.430104, loss2 : 1.351334
train_step : 4821, loss1 : 1.927917, loss2 : 1.788743
train_step : 4822, loss1 : 1.863519, loss2 : 1.387160
train_step : 4823, loss1 : 3.829552, loss2 : 2.179429
train_step : 4824, loss1 : 0.782170, loss2 : 0.991694
train_step : 4825, loss1 : 0.915803, loss2 : 1.129894
train_step : 4826, loss1 : 1.007625, loss2 : 1.194515
train_step : 4827, loss1 : 1.273987, loss2 : 0.913677
train_step : 4828, loss1 : 1.195397, loss2 : 2.077970
train_step : 4829, loss1 : 2.281482, loss2 : 1.918951
train_step : 4830, loss1 : 2.350091, loss2 : 1.978696
train_step : 4831, loss1 : 1.953609, loss2 : 3.269682
train_step : 4832, loss1 : 3.507893, loss2 : 3.102478
train_step : 4833, loss1 : 1.879301, loss2 : 2.300669
train_step : 4834, loss1 : 1.692570, loss2 : 1.872733
train_step : 4835, loss1 : 2.303346, loss2 : 1.185153
train_step : 4836, loss1 : 2.735404, loss2 : 1.311211
train_step : 4837, loss1 : 2.480749, loss2 : 2.268800
train_step : 4838, loss1 : 2.894280, loss2 : 2.046542
train_step : 4839, loss1 : 1.151144, loss2 : 1.703612
train_step : 4840, loss1 : 2.134770, loss2 : 2.390310
train_step : 4841, loss1 : 2.985128, loss2 : 2.496455
train_step : 4842, loss1 : 3.480145, loss2 : 3.036466
train_step : 4843, loss1 : 1.869512, loss2 : 1.784473
train_step : 4844, loss1 : 2.425058, loss2 : 1.140682
train_step : 4845, loss1 : 1.440660, loss2 : 1.885563
train_step : 4846, loss1 : 3.970764, loss2 : 1.883666
train_step : 4847, loss1 : 1.014583, loss2 : 1.043817
train_step : 4848, loss1 : 1.381124, loss2 : 1.347478
train_step : 4849, loss1 : 0.473979, loss2 : 0.708294
train_step : 4850, loss1 : 1.144882, loss2 : 1.469313
train_step : 4851, loss1 : 0.918793, loss2 : 1.226534
train_step : 4852, loss1 : 1.127418, loss2 : 0.732627
train_step : 4853, loss1 : 0.944139, loss2 : 2.166107
train_step : 4854, loss1 : 1.697022, loss2 : 1.773676
train_step : 4855, loss1 : 2.752892, loss2 : 2.950083
train_step : 4856, loss1 : 3.250489, loss2 : 1.765961
train_step : 4857, loss1 : 1.141846, loss2 : 1.135457
train_step : 4858, loss1 : 0.694175, loss2 : 1.548300
train_step : 4859, loss1 : 1.038155, loss2 : 0.998643
train_step : 4860, loss1 : 1.884642, loss2 : 0.939019
train_step : 4861, loss1 : 1.234637, loss2 : 0.864797
train_step : 4862, loss1 : 0.500704, loss2 : 1.028233
train_step : 4863, loss1 : 1.069909, loss2 : 1.130585
train_step : 4864, loss1 : 1.175477, loss2 : 1.670591
train_step : 4865, loss1 : 0.860660, loss2 : 1.588494
train_step : 4866, loss1 : 1.107977, loss2 : 1.793956
train_step : 4867, loss1 : 1.011472, loss2 : 0.987509
train_step : 4868, loss1 : 0.721782, loss2 : 1.762902
train_step : 4869, loss1 : 1.035397, loss2 : 1.668688
train_step : 4870, loss1 : 2.131162, loss2 : 1.280081
train_step : 4871, loss1 : 2.246334, loss2 : 4.051820
train_step : 4872, loss1 : 2.339607, loss2 : 2.188051
train_step : 4873, loss1 : 2.384918, loss2 : 2.130198
train_step : 4874, loss1 : 1.994016, loss2 : 2.188876
train_step : 4875, loss1 : 2.352455, loss2 : 2.471692
train_step : 4876, loss1 : 3.083558, loss2 : 3.074341
train_step : 4877, loss1 : 3.714638, loss2 : 3.895869
train_step : 4878, loss1 : 4.279979, loss2 : 1.559366
train_step : 4879, loss1 : 4.533650, loss2 : 3.543105
train_step : 4880, loss1 : 4.543148, loss2 : 3.558756
train_step : 4881, loss1 : 3.189436, loss2 : 3.327071
train_step : 4882, loss1 : 1.781529, loss2 : 1.928166
train_step : 4883, loss1 : 1.541741, loss2 : 2.433259
train_step : 4884, loss1 : 0.858410, loss2 : 1.559460
train_step : 4885, loss1 : 1.083072, loss2 : 1.101611
train_step : 4886, loss1 : 2.112233, loss2 : 1.469472
train_step : 4887, loss1 : 1.800362, loss2 : 2.235825
train_step : 4888, loss1 : 1.261460, loss2 : 1.528813
train_step : 4889, loss1 : 2.394157, loss2 : 0.824770
train_step : 4890, loss1 : 2.469748, loss2 : 0.638000
train_step : 4891, loss1 : 1.465804, loss2 : 1.150801
train_step : 4892, loss1 : 0.640571, loss2 : 0.828221
train_step : 4893, loss1 : 2.583068, loss2 : 0.603092
train_step : 4894, loss1 : 3.704173, loss2 : 1.024866
train_step : 4895, loss1 : 2.445712, loss2 : 1.308015
train_step : 4896, loss1 : 1.693164, loss2 : 0.951847
train_step : 4897, loss1 : 1.525857, loss2 : 1.373698
train_step : 4898, loss1 : 1.121498, loss2 : 4.910141
train_step : 4899, loss1 : 1.352902, loss2 : 1.069464
train_step : 4900, loss1 : 0.854416, loss2 : 1.318986
train_step : 4901, loss1 : 1.568410, loss2 : 1.219007
train_step : 4902, loss1 : 1.263537, loss2 : 1.738874
train_step : 4903, loss1 : 1.912901, loss2 : 2.006391
train_step : 4904, loss1 : 1.635673, loss2 : 2.391487
train_step : 4905, loss1 : 1.945985, loss2 : 2.128413
train_step : 4906, loss1 : 2.048673, loss2 : 1.201549
train_step : 4907, loss1 : 2.046769, loss2 : 2.280861
train_step : 4908, loss1 : 2.221180, loss2 : 2.767008
train_step : 4909, loss1 : 1.182733, loss2 : 1.942772
train_step : 4910, loss1 : 1.907201, loss2 : 1.538573
train_step : 4911, loss1 : 1.126184, loss2 : 1.885039
train_step : 4912, loss1 : 1.376046, loss2 : 1.962811
train_step : 4913, loss1 : 2.607160, loss2 : 1.285777
train_step : 4914, loss1 : 2.009011, loss2 : 1.030249
train_step : 4915, loss1 : 3.067453, loss2 : 2.170736
train_step : 4916, loss1 : 2.723577, loss2 : 3.630195
train_step : 4917, loss1 : 1.532420, loss2 : 1.370897
train_step : 4918, loss1 : 2.242544, loss2 : 1.644119
train_step : 4919, loss1 : 1.281289, loss2 : 2.374633
train_step : 4920, loss1 : 2.902033, loss2 : 1.471461
train_step : 4921, loss1 : 2.719476, loss2 : 2.095813
train_step : 4922, loss1 : 2.266683, loss2 : 2.942710
train_step : 4923, loss1 : 2.748956, loss2 : 1.678596
train_step : 4924, loss1 : 2.595804, loss2 : 4.189491
train_step : 4925, loss1 : 1.466378, loss2 : 1.819496
train_step : 4926, loss1 : 1.274117, loss2 : 1.313254
train_step : 4927, loss1 : 1.219556, loss2 : 1.273105
train_step : 4928, loss1 : 1.867361, loss2 : 1.620887
train_step : 4929, loss1 : 0.819752, loss2 : 1.666431
train_step : 4930, loss1 : 1.396136, loss2 : 2.265884
train_step : 4931, loss1 : 1.384320, loss2 : 1.214698
train_step : 4932, loss1 : 0.561441, loss2 : 1.045384
train_step : 4933, loss1 : 1.611080, loss2 : 0.799983
train_step : 4934, loss1 : 0.521326, loss2 : 0.816107
train_step : 4935, loss1 : 2.644782, loss2 : 1.723979
train_step : 4936, loss1 : 1.801127, loss2 : 1.244929
train_step : 4937, loss1 : 1.062652, loss2 : 0.891381
train_step : 4938, loss1 : 1.126770, loss2 : 1.012264
train_step : 4939, loss1 : 0.790540, loss2 : 0.738121
train_step : 4940, loss1 : 1.164547, loss2 : 0.839936
train_step : 4941, loss1 : 2.107379, loss2 : 1.308439
train_step : 4942, loss1 : 1.267792, loss2 : 1.885487
train_step : 4943, loss1 : 1.720455, loss2 : 1.941205
train_step : 4944, loss1 : 1.455209, loss2 : 0.809123
train_step : 4945, loss1 : 1.159573, loss2 : 0.969702
train_step : 4946, loss1 : 1.408437, loss2 : 1.136663
train_step : 4947, loss1 : 1.589105, loss2 : 1.759237
train_step : 4948, loss1 : 1.263127, loss2 : 1.490798
train_step : 4949, loss1 : 1.550293, loss2 : 1.109611
train_step : 4950, loss1 : 1.957806, loss2 : 0.994173
train_step : 4951, loss1 : 0.808732, loss2 : 1.713558
train_step : 4952, loss1 : 1.797589, loss2 : 1.798432
train_step : 4953, loss1 : 1.296476, loss2 : 2.862001
train_step : 4954, loss1 : 1.329121, loss2 : 1.394747
train_step : 4955, loss1 : 1.384286, loss2 : 2.725347
train_step : 4956, loss1 : 3.100905, loss2 : 1.092378
train_step : 4957, loss1 : 2.407210, loss2 : 1.521044
train_step : 4958, loss1 : 1.260805, loss2 : 2.482301
train_step : 4959, loss1 : 0.948088, loss2 : 0.979808
train_step : 4960, loss1 : 0.821268, loss2 : 1.597138
train_step : 4961, loss1 : 1.314112, loss2 : 1.125828
train_step : 4962, loss1 : 1.649430, loss2 : 1.345420
train_step : 4963, loss1 : 2.346595, loss2 : 1.110611
train_step : 4964, loss1 : 1.520991, loss2 : 1.475474
train_step : 4965, loss1 : 0.981199, loss2 : 3.249923
train_step : 4966, loss1 : 1.520576, loss2 : 2.596628
train_step : 4967, loss1 : 2.237115, loss2 : 2.865151
train_step : 4968, loss1 : 1.886507, loss2 : 2.572249
train_step : 4969, loss1 : 1.311562, loss2 : 3.626269
train_step : 4970, loss1 : 1.589433, loss2 : 2.410755
train_step : 4971, loss1 : 3.156343, loss2 : 2.571776
train_step : 4972, loss1 : 3.770894, loss2 : 4.005372
train_step : 4973, loss1 : 3.587077, loss2 : 3.406852
train_step : 4974, loss1 : 4.752688, loss2 : 3.639726
train_step : 4975, loss1 : 2.931833, loss2 : 2.944208
train_step : 4976, loss1 : 2.624701, loss2 : 3.651280
train_step : 4977, loss1 : 1.594050, loss2 : 1.656827
train_step : 4978, loss1 : 1.043884, loss2 : 1.907233
train_step : 4979, loss1 : 1.328288, loss2 : 0.820782
train_step : 4980, loss1 : 0.899445, loss2 : 1.417063
train_step : 4981, loss1 : 0.804890, loss2 : 0.848291
train_step : 4982, loss1 : 0.740423, loss2 : 2.050658
train_step : 4983, loss1 : 0.665877, loss2 : 1.454081
train_step : 4984, loss1 : 1.229659, loss2 : 1.530866
train_step : 4985, loss1 : 1.229390, loss2 : 1.667880
train_step : 4986, loss1 : 1.099696, loss2 : 1.289393
train_step : 4987, loss1 : 1.164196, loss2 : 0.835740
train_step : 4988, loss1 : 0.767207, loss2 : 0.981630
train_step : 4989, loss1 : 1.401406, loss2 : 1.016521
train_step : 4990, loss1 : 1.957286, loss2 : 1.674865
train_step : 4991, loss1 : 1.796624, loss2 : 1.889207
train_step : 4992, loss1 : 1.073016, loss2 : 0.975718
train_step : 4993, loss1 : 1.160304, loss2 : 1.238611
train_step : 4994, loss1 : 1.785783, loss2 : 0.656638
train_step : 4995, loss1 : 1.407503, loss2 : 0.888969
train_step : 4996, loss1 : 1.253917, loss2 : 1.468465
train_step : 4997, loss1 : 0.758351, loss2 : 1.246840
train_step : 4998, loss1 : 1.190822, loss2 : 1.041888
train_step : 4999, loss1 : 1.048405, loss2 : 1.365365
train_step : 5000, loss1 : 0.839849, loss2 : 0.943496
train_step : 5001, loss1 : 1.628371, loss2 : 0.604373
train_step : 5002, loss1 : 1.391389, loss2 : 0.936443
train_step : 5003, loss1 : 0.835580, loss2 : 1.010587
train_step : 5004, loss1 : 1.506657, loss2 : 2.235454
train_step : 5005, loss1 : 1.192308, loss2 : 0.786152
train_step : 5006, loss1 : 0.906465, loss2 : 0.847317
train_step : 5007, loss1 : 1.840271, loss2 : 0.796849
train_step : 5008, loss1 : 0.440541, loss2 : 1.290063
train_step : 5009, loss1 : 0.980946, loss2 : 0.707967
train_step : 5010, loss1 : 1.664552, loss2 : 0.617301
train_step : 5011, loss1 : 1.677702, loss2 : 1.214747
train_step : 5012, loss1 : 1.229871, loss2 : 0.762132
train_step : 5013, loss1 : 0.729429, loss2 : 1.134182
train_step : 5014, loss1 : 1.670788, loss2 : 1.425772
train_step : 5015, loss1 : 1.966064, loss2 : 1.527029
train_step : 5016, loss1 : 0.936336, loss2 : 1.661102
train_step : 5017, loss1 : 1.030083, loss2 : 0.771556
train_step : 5018, loss1 : 1.247845, loss2 : 0.848710
train_step : 5019, loss1 : 1.135406, loss2 : 1.072355
train_step : 5020, loss1 : 1.221433, loss2 : 1.225124
train_step : 5021, loss1 : 1.846958, loss2 : 1.440170
train_step : 5022, loss1 : 1.857910, loss2 : 1.714003
train_step : 5023, loss1 : 1.117228, loss2 : 1.446288
train_step : 5024, loss1 : 0.918497, loss2 : 1.085935
train_step : 5025, loss1 : 1.324889, loss2 : 1.067948
train_step : 5026, loss1 : 0.666730, loss2 : 0.952897
train_step : 5027, loss1 : 0.600468, loss2 : 4.413201
train_step : 5028, loss1 : 0.669392, loss2 : 1.163323
train_step : 5029, loss1 : 1.621751, loss2 : 1.279238
train_step : 5030, loss1 : 1.138948, loss2 : 1.603809
train_step : 5031, loss1 : 1.219954, loss2 : 1.485327
train_step : 5032, loss1 : 1.527109, loss2 : 0.466494
train_step : 5033, loss1 : 0.568129, loss2 : 1.351269
train_step : 5034, loss1 : 0.905445, loss2 : 1.316238
train_step : 5035, loss1 : 1.044671, loss2 : 1.646836
train_step : 5036, loss1 : 0.910470, loss2 : 1.076588
train_step : 5037, loss1 : 1.217319, loss2 : 1.360516
train_step : 5038, loss1 : 1.150258, loss2 : 1.275404
train_step : 5039, loss1 : 2.041056, loss2 : 1.986873
train_step : 5040, loss1 : 0.798055, loss2 : 1.570282
train_step : 5041, loss1 : 1.341094, loss2 : 0.658116
train_step : 5042, loss1 : 1.349121, loss2 : 0.990700
train_step : 5043, loss1 : 0.996526, loss2 : 1.517256
train_step : 5044, loss1 : 2.283197, loss2 : 1.329705
train_step : 5045, loss1 : 2.794074, loss2 : 1.884798
train_step : 5046, loss1 : 2.029577, loss2 : 3.023996
train_step : 5047, loss1 : 2.839620, loss2 : 1.505548
train_step : 5048, loss1 : 1.889906, loss2 : 3.003378
train_step : 5049, loss1 : 2.174080, loss2 : 2.502337
train_step : 5050, loss1 : 1.052799, loss2 : 2.538142
train_step : 5051, loss1 : 1.693337, loss2 : 1.711964
train_step : 5052, loss1 : 2.127364, loss2 : 3.164246
train_step : 5053, loss1 : 2.467815, loss2 : 2.645827
train_step : 5054, loss1 : 2.828700, loss2 : 1.507668
train_step : 5055, loss1 : 3.096177, loss2 : 2.497868
train_step : 5056, loss1 : 2.541250, loss2 : 3.046468
train_step : 5057, loss1 : 3.310766, loss2 : 2.812180
train_step : 5058, loss1 : 3.968308, loss2 : 4.097274
train_step : 5059, loss1 : 4.517148, loss2 : 5.290511
train_step : 5060, loss1 : 5.540705, loss2 : 3.483933
train_step : 5061, loss1 : 4.250191, loss2 : 6.929480
train_step : 5062, loss1 : 3.273651, loss2 : 4.912894
train_step : 5063, loss1 : 3.950047, loss2 : 3.809534
train_step : 5064, loss1 : 1.504591, loss2 : 2.076806
train_step : 5065, loss1 : 1.638942, loss2 : 2.092366
train_step : 5066, loss1 : 1.127759, loss2 : 1.704836
train_step : 5067, loss1 : 1.052811, loss2 : 0.860151
train_step : 5068, loss1 : 0.690239, loss2 : 1.500389
train_step : 5069, loss1 : 2.023956, loss2 : 1.382613
train_step : 5070, loss1 : 1.985399, loss2 : 2.742204
train_step : 5071, loss1 : 1.405548, loss2 : 1.012713
train_step : 5072, loss1 : 1.079766, loss2 : 2.077673
train_step : 5073, loss1 : 1.617353, loss2 : 1.111991
train_step : 5074, loss1 : 0.598222, loss2 : 1.234380
train_step : 5075, loss1 : 0.904799, loss2 : 0.625740
train_step : 5076, loss1 : 0.850744, loss2 : 1.209684
train_step : 5077, loss1 : 1.417327, loss2 : 1.772158
train_step : 5078, loss1 : 0.882047, loss2 : 0.926814
train_step : 5079, loss1 : 1.607438, loss2 : 1.084186
train_step : 5080, loss1 : 1.711682, loss2 : 1.050940
train_step : 5081, loss1 : 0.850212, loss2 : 0.786466
train_step : 5082, loss1 : 1.191030, loss2 : 1.533689
train_step : 5083, loss1 : 1.361200, loss2 : 0.888757
train_step : 5084, loss1 : 0.795924, loss2 : 1.859458
train_step : 5085, loss1 : 1.297720, loss2 : 1.550067
train_step : 5086, loss1 : 1.210451, loss2 : 1.749987
train_step : 5087, loss1 : 0.310366, loss2 : 1.947593
train_step : 5088, loss1 : 1.166214, loss2 : 0.873402
train_step : 5089, loss1 : 1.368905, loss2 : 0.774271
train_step : 5090, loss1 : 1.274938, loss2 : 0.962937
train_step : 5091, loss1 : 1.954623, loss2 : 1.562620
train_step : 5092, loss1 : 1.406429, loss2 : 1.852604
train_step : 5093, loss1 : 1.621449, loss2 : 2.008941
train_step : 5094, loss1 : 1.606293, loss2 : 0.946293
train_step : 5095, loss1 : 0.830824, loss2 : 0.903230
train_step : 5096, loss1 : 1.271857, loss2 : 1.454595
train_step : 5097, loss1 : 1.369984, loss2 : 2.201999
train_step : 5098, loss1 : 0.820703, loss2 : 1.890117
train_step : 5099, loss1 : 1.605905, loss2 : 1.323613
train_step : 5100, loss1 : 1.730473, loss2 : 1.294353
train_step : 5101, loss1 : 1.391588, loss2 : 1.300812
train_step : 5102, loss1 : 1.666428, loss2 : 0.875735
train_step : 5103, loss1 : 0.749960, loss2 : 0.706121
train_step : 5104, loss1 : 0.908541, loss2 : 0.983785
train_step : 5105, loss1 : 0.853628, loss2 : 1.136453
train_step : 5106, loss1 : 1.456256, loss2 : 0.606305
train_step : 5107, loss1 : 1.682051, loss2 : 0.596661
train_step : 5108, loss1 : 0.801238, loss2 : 1.535797
train_step : 5109, loss1 : 1.873393, loss2 : 1.196143
train_step : 5110, loss1 : 0.696215, loss2 : 2.186115
train_step : 5111, loss1 : 1.621315, loss2 : 0.966205
train_step : 5112, loss1 : 1.625933, loss2 : 1.840417
train_step : 5113, loss1 : 2.658390, loss2 : 2.466517
train_step : 5114, loss1 : 1.828298, loss2 : 2.992689
train_step : 5115, loss1 : 1.522485, loss2 : 3.206665
train_step : 5116, loss1 : 2.811028, loss2 : 3.154515
train_step : 5117, loss1 : 2.908293, loss2 : 2.601560
train_step : 5118, loss1 : 5.405245, loss2 : 3.546048
train_step : 5119, loss1 : 2.394906, loss2 : 1.500035
train_step : 5120, loss1 : 1.857793, loss2 : 3.163433
train_step : 5121, loss1 : 2.918920, loss2 : 2.472676
train_step : 5122, loss1 : 2.149015, loss2 : 2.443324
train_step : 5123, loss1 : 1.943559, loss2 : 2.796904
train_step : 5124, loss1 : 0.512266, loss2 : 2.085812
train_step : 5125, loss1 : 1.328092, loss2 : 1.403485
train_step : 5126, loss1 : 1.250295, loss2 : 0.865285
train_step : 5127, loss1 : 0.954340, loss2 : 1.784956
train_step : 5128, loss1 : 1.359176, loss2 : 1.462091
train_step : 5129, loss1 : 1.539947, loss2 : 1.437176
train_step : 5130, loss1 : 1.907814, loss2 : 0.977915
train_step : 5131, loss1 : 1.767063, loss2 : 0.719239
train_step : 5132, loss1 : 1.259459, loss2 : 0.986952
train_step : 5133, loss1 : 0.582375, loss2 : 1.173274
train_step : 5134, loss1 : 0.939552, loss2 : 1.239759
train_step : 5135, loss1 : 1.013143, loss2 : 1.951904
train_step : 5136, loss1 : 1.134213, loss2 : 0.772571
train_step : 5137, loss1 : 1.098819, loss2 : 1.159369
train_step : 5138, loss1 : 1.248219, loss2 : 1.334433
train_step : 5139, loss1 : 2.025262, loss2 : 1.422794
train_step : 5140, loss1 : 3.253458, loss2 : 2.714216
train_step : 5141, loss1 : 4.708089, loss2 : 3.993314
train_step : 5142, loss1 : 5.083223, loss2 : 5.439966
train_step : 5143, loss1 : 3.141371, loss2 : 4.278306
train_step : 5144, loss1 : 4.856964, loss2 : 2.847276
train_step : 5145, loss1 : 1.154405, loss2 : 2.303442
train_step : 5146, loss1 : 3.015002, loss2 : 1.893625
train_step : 5147, loss1 : 2.321021, loss2 : 1.953591
train_step : 5148, loss1 : 2.448344, loss2 : 3.490006
train_step : 5149, loss1 : 4.033131, loss2 : 2.970147
train_step : 5150, loss1 : 3.041264, loss2 : 4.108483
train_step : 5151, loss1 : 3.171969, loss2 : 2.678784
train_step : 5152, loss1 : 3.204119, loss2 : 1.976930
train_step : 5153, loss1 : 2.557332, loss2 : 2.261019
train_step : 5154, loss1 : 3.815127, loss2 : 2.272269
train_step : 5155, loss1 : 2.078215, loss2 : 2.452012
train_step : 5156, loss1 : 3.438760, loss2 : 2.562875
train_step : 5157, loss1 : 2.333858, loss2 : 3.370974
train_step : 5158, loss1 : 2.031663, loss2 : 1.920983
train_step : 5159, loss1 : 1.631969, loss2 : 1.169044
train_step : 5160, loss1 : 1.538753, loss2 : 1.582718
train_step : 5161, loss1 : 0.655900, loss2 : 1.220657
train_step : 5162, loss1 : 1.154228, loss2 : 1.736989
train_step : 5163, loss1 : 0.922574, loss2 : 0.873350
train_step : 5164, loss1 : 2.275232, loss2 : 0.822947
train_step : 5165, loss1 : 0.947323, loss2 : 1.387770
train_step : 5166, loss1 : 1.417956, loss2 : 2.272216
train_step : 5167, loss1 : 1.903665, loss2 : 2.838641
train_step : 5168, loss1 : 1.799907, loss2 : 0.949303
train_step : 5169, loss1 : 1.561899, loss2 : 1.014923
train_step : 5170, loss1 : 0.755984, loss2 : 0.946575
train_step : 5171, loss1 : 0.794666, loss2 : 1.932715
train_step : 5172, loss1 : 1.164368, loss2 : 1.076283
train_step : 5173, loss1 : 0.521794, loss2 : 0.729685
train_step : 5174, loss1 : 1.537354, loss2 : 1.511631
train_step : 5175, loss1 : 2.307995, loss2 : 1.516503
train_step : 5176, loss1 : 1.296172, loss2 : 1.160321
train_step : 5177, loss1 : 1.129221, loss2 : 1.240435
train_step : 5178, loss1 : 1.840931, loss2 : 2.381416
train_step : 5179, loss1 : 1.181210, loss2 : 1.345654
train_step : 5180, loss1 : 1.429179, loss2 : 1.828703
train_step : 5181, loss1 : 2.445261, loss2 : 2.538706
train_step : 5182, loss1 : 2.874724, loss2 : 2.425207
train_step : 5183, loss1 : 1.640422, loss2 : 1.726468
train_step : 5184, loss1 : 1.760156, loss2 : 2.092608
train_step : 5185, loss1 : 0.970278, loss2 : 1.495760
train_step : 5186, loss1 : 1.668403, loss2 : 3.118118
train_step : 5187, loss1 : 1.741356, loss2 : 1.284163
train_step : 5188, loss1 : 0.984803, loss2 : 1.432930
train_step : 5189, loss1 : 1.942072, loss2 : 0.966978
train_step : 5190, loss1 : 1.679348, loss2 : 1.521779
train_step : 5191, loss1 : 1.832197, loss2 : 1.434229
train_step : 5192, loss1 : 1.789549, loss2 : 1.092689
train_step : 5193, loss1 : 1.281020, loss2 : 0.972158
train_step : 5194, loss1 : 1.034484, loss2 : 1.676677
train_step : 5195, loss1 : 1.172992, loss2 : 1.280168
train_step : 5196, loss1 : 1.203625, loss2 : 1.015573
train_step : 5197, loss1 : 1.359314, loss2 : 1.785723
train_step : 5198, loss1 : 1.303035, loss2 : 1.630655
train_step : 5199, loss1 : 0.874771, loss2 : 1.005643
train_step : 5200, loss1 : 1.641844, loss2 : 1.491756
train_step : 5201, loss1 : 1.803987, loss2 : 2.489734
train_step : 5202, loss1 : 2.847611, loss2 : 1.507297
train_step : 5203, loss1 : 3.200641, loss2 : 2.873231
train_step : 5204, loss1 : 1.820388, loss2 : 1.915036
train_step : 5205, loss1 : 2.542063, loss2 : 2.594378
train_step : 5206, loss1 : 2.148530, loss2 : 1.723851
train_step : 5207, loss1 : 1.264774, loss2 : 1.832609
train_step : 5208, loss1 : 0.965558, loss2 : 0.851701
train_step : 5209, loss1 : 1.365541, loss2 : 1.249779
train_step : 5210, loss1 : 1.112578, loss2 : 1.178112
train_step : 5211, loss1 : 0.717600, loss2 : 0.962255
train_step : 5212, loss1 : 0.945062, loss2 : 1.684999
train_step : 5213, loss1 : 1.655482, loss2 : 1.722061
train_step : 5214, loss1 : 0.686974, loss2 : 1.736672
train_step : 5215, loss1 : 1.534532, loss2 : 1.459908
train_step : 5216, loss1 : 0.713018, loss2 : 2.104817
train_step : 5217, loss1 : 1.865266, loss2 : 1.759452
train_step : 5218, loss1 : 1.346694, loss2 : 1.689209
train_step : 5219, loss1 : 2.067464, loss2 : 1.624612
train_step : 5220, loss1 : 0.954919, loss2 : 2.065004
train_step : 5221, loss1 : 0.944843, loss2 : 1.145166
train_step : 5222, loss1 : 0.493795, loss2 : 1.275540
train_step : 5223, loss1 : 1.211537, loss2 : 1.315004
train_step : 5224, loss1 : 1.385398, loss2 : 0.844933
train_step : 5225, loss1 : 1.354005, loss2 : 0.967128
train_step : 5226, loss1 : 1.235972, loss2 : 1.169875
train_step : 5227, loss1 : 0.618829, loss2 : 1.458694
train_step : 5228, loss1 : 1.225748, loss2 : 1.614034
train_step : 5229, loss1 : 1.214308, loss2 : 2.019884
train_step : 5230, loss1 : 1.857057, loss2 : 1.876191
train_step : 5231, loss1 : 2.033401, loss2 : 1.371788
train_step : 5232, loss1 : 1.249751, loss2 : 1.142890
train_step : 5233, loss1 : 1.321937, loss2 : 1.059960
train_step : 5234, loss1 : 1.099420, loss2 : 1.912703
train_step : 5235, loss1 : 1.115164, loss2 : 2.063047
train_step : 5236, loss1 : 1.407251, loss2 : 1.504364
train_step : 5237, loss1 : 1.497338, loss2 : 0.871798
train_step : 5238, loss1 : 1.498353, loss2 : 2.006753
train_step : 5239, loss1 : 2.016942, loss2 : 3.464476
train_step : 5240, loss1 : 1.243953, loss2 : 2.739765
train_step : 5241, loss1 : 1.955958, loss2 : 1.027594
train_step : 5242, loss1 : 1.575594, loss2 : 2.254057
train_step : 5243, loss1 : 2.987323, loss2 : 1.701394
train_step : 5244, loss1 : 2.085576, loss2 : 2.297667
train_step : 5245, loss1 : 1.437970, loss2 : 2.675717
train_step : 5246, loss1 : 1.606577, loss2 : 1.163675
train_step : 5247, loss1 : 0.755150, loss2 : 0.747215
train_step : 5248, loss1 : 1.906094, loss2 : 1.181489
train_step : 5249, loss1 : 1.321393, loss2 : 1.520221
train_step : 5250, loss1 : 0.664651, loss2 : 1.306117
train_step : 5251, loss1 : 0.949579, loss2 : 1.203984
train_step : 5252, loss1 : 0.799933, loss2 : 0.971708
train_step : 5253, loss1 : 1.664515, loss2 : 1.089736
train_step : 5254, loss1 : 1.491825, loss2 : 0.940695
train_step : 5255, loss1 : 1.409420, loss2 : 1.100092
train_step : 5256, loss1 : 1.288629, loss2 : 0.253913
train_step : 5257, loss1 : 0.978587, loss2 : 1.138906
train_step : 5258, loss1 : 1.372952, loss2 : 1.388505
train_step : 5259, loss1 : 1.055010, loss2 : 1.214718
train_step : 5260, loss1 : 1.134029, loss2 : 1.347981
train_step : 5261, loss1 : 1.289763, loss2 : 1.756763
train_step : 5262, loss1 : 0.859006, loss2 : 1.097041
train_step : 5263, loss1 : 1.744691, loss2 : 1.149643
train_step : 5264, loss1 : 0.789947, loss2 : 1.241127
train_step : 5265, loss1 : 0.937106, loss2 : 0.988361
train_step : 5266, loss1 : 0.672429, loss2 : 0.956044
train_step : 5267, loss1 : 0.892629, loss2 : 1.492909
train_step : 5268, loss1 : 1.225253, loss2 : 0.925073
train_step : 5269, loss1 : 1.681615, loss2 : 0.801824
train_step : 5270, loss1 : 1.253376, loss2 : 1.987493
train_step : 5271, loss1 : 1.968931, loss2 : 1.304490
train_step : 5272, loss1 : 2.278081, loss2 : 1.042413
train_step : 5273, loss1 : 1.732558, loss2 : 3.390614
train_step : 5274, loss1 : 2.446518, loss2 : 2.814279
train_step : 5275, loss1 : 2.549360, loss2 : 3.046267
train_step : 5276, loss1 : 1.887325, loss2 : 2.122782
train_step : 5277, loss1 : 1.311522, loss2 : 0.982701
train_step : 5278, loss1 : 1.093502, loss2 : 1.304784
train_step : 5279, loss1 : 3.395162, loss2 : 0.901933
train_step : 5280, loss1 : 1.220358, loss2 : 3.568207
train_step : 5281, loss1 : 1.346138, loss2 : 1.288990
train_step : 5282, loss1 : 1.040464, loss2 : 0.650869
train_step : 5283, loss1 : 1.122650, loss2 : 1.082407
train_step : 5284, loss1 : 0.906927, loss2 : 0.834655
train_step : 5285, loss1 : 1.281083, loss2 : 1.749071
train_step : 5286, loss1 : 1.678762, loss2 : 1.233452
train_step : 5287, loss1 : 1.652346, loss2 : 0.618184
train_step : 5288, loss1 : 1.410881, loss2 : 0.726836
train_step : 5289, loss1 : 1.769717, loss2 : 1.792341
train_step : 5290, loss1 : 3.005933, loss2 : 1.094623
train_step : 5291, loss1 : 1.114030, loss2 : 1.677500
train_step : 5292, loss1 : 1.122523, loss2 : 0.579221
train_step : 5293, loss1 : 1.752932, loss2 : 1.685463
train_step : 5294, loss1 : 1.502079, loss2 : 1.865905
train_step : 5295, loss1 : 1.408252, loss2 : 2.383922
train_step : 5296, loss1 : 1.682719, loss2 : 1.521059
train_step : 5297, loss1 : 2.719880, loss2 : 2.170966
train_step : 5298, loss1 : 2.375089, loss2 : 3.663126
train_step : 5299, loss1 : 3.779077, loss2 : 1.541695
train_step : 5300, loss1 : 2.399230, loss2 : 1.861431
train_step : 5301, loss1 : 0.500468, loss2 : 1.265332
train_step : 5302, loss1 : 2.116607, loss2 : 1.333864
train_step : 5303, loss1 : 1.070208, loss2 : 1.298798
train_step : 5304, loss1 : 1.556963, loss2 : 0.565643
train_step : 5305, loss1 : 0.908115, loss2 : 1.024137
train_step : 5306, loss1 : 1.297873, loss2 : 3.103280
train_step : 5307, loss1 : 0.465233, loss2 : 1.116253
train_step : 5308, loss1 : 0.989568, loss2 : 1.203190
train_step : 5309, loss1 : 1.145312, loss2 : 0.859547
train_step : 5310, loss1 : 1.172245, loss2 : 1.291915
train_step : 5311, loss1 : 3.096806, loss2 : 2.703435
train_step : 5312, loss1 : 3.093488, loss2 : 4.588147
train_step : 5313, loss1 : 2.443717, loss2 : 1.836296
train_step : 5314, loss1 : 1.801194, loss2 : 2.459888
train_step : 5315, loss1 : 2.065074, loss2 : 1.301154
train_step : 5316, loss1 : 3.224197, loss2 : 1.451289
train_step : 5317, loss1 : 2.467705, loss2 : 2.265498
train_step : 5318, loss1 : 1.820004, loss2 : 1.565620
train_step : 5319, loss1 : 2.456459, loss2 : 0.926941
train_step : 5320, loss1 : 0.932925, loss2 : 1.673331
train_step : 5321, loss1 : 1.539272, loss2 : 0.951765
train_step : 5322, loss1 : 1.261683, loss2 : 1.349015
train_step : 5323, loss1 : 1.150405, loss2 : 0.864742
train_step : 5324, loss1 : 1.814335, loss2 : 1.344209
train_step : 5325, loss1 : 1.490875, loss2 : 1.968763
train_step : 5326, loss1 : 1.994955, loss2 : 2.052940
train_step : 5327, loss1 : 3.566087, loss2 : 2.312972
train_step : 5328, loss1 : 4.374434, loss2 : 2.974634
train_step : 5329, loss1 : 3.840168, loss2 : 3.705847
train_step : 5330, loss1 : 1.333285, loss2 : 1.905642
train_step : 5331, loss1 : 1.251219, loss2 : 2.898866
train_step : 5332, loss1 : 1.804265, loss2 : 1.806507
train_step : 5333, loss1 : 1.933918, loss2 : 2.422439
train_step : 5334, loss1 : 3.482012, loss2 : 2.160085
train_step : 5335, loss1 : 2.689842, loss2 : 3.338386
train_step : 5336, loss1 : 1.140442, loss2 : 1.592877
train_step : 5337, loss1 : 1.570327, loss2 : 1.041643
train_step : 5338, loss1 : 0.821334, loss2 : 1.477487
train_step : 5339, loss1 : 2.357932, loss2 : 1.096173
train_step : 5340, loss1 : 0.707576, loss2 : 0.789307
train_step : 5341, loss1 : 1.216338, loss2 : 1.144284
train_step : 5342, loss1 : 1.116780, loss2 : 1.941586
train_step : 5343, loss1 : 1.060505, loss2 : 1.328889
train_step : 5344, loss1 : 0.788524, loss2 : 1.531219
train_step : 5345, loss1 : 0.647610, loss2 : 1.061538
train_step : 5346, loss1 : 1.236390, loss2 : 0.920826
train_step : 5347, loss1 : 0.779853, loss2 : 1.405704
train_step : 5348, loss1 : 0.859893, loss2 : 1.752797
train_step : 5349, loss1 : 1.179442, loss2 : 0.872144
train_step : 5350, loss1 : 0.636280, loss2 : 1.167826
train_step : 5351, loss1 : 1.334779, loss2 : 2.917085
train_step : 5352, loss1 : 2.501382, loss2 : 2.363814
train_step : 5353, loss1 : 1.301063, loss2 : 1.351049
train_step : 5354, loss1 : 1.226990, loss2 : 1.030813
train_step : 5355, loss1 : 1.509445, loss2 : 1.812303
train_step : 5356, loss1 : 1.094859, loss2 : 1.211090
train_step : 5357, loss1 : 1.423309, loss2 : 0.984206
train_step : 5358, loss1 : 1.046297, loss2 : 0.564759
train_step : 5359, loss1 : 2.497092, loss2 : 1.015117
train_step : 5360, loss1 : 0.774769, loss2 : 1.754533
train_step : 5361, loss1 : 1.178371, loss2 : 0.929021
train_step : 5362, loss1 : 1.110195, loss2 : 0.998858
train_step : 5363, loss1 : 0.978132, loss2 : 1.238607
train_step : 5364, loss1 : 0.662833, loss2 : 1.023579
train_step : 5365, loss1 : 2.061432, loss2 : 1.238050
train_step : 5366, loss1 : 2.546510, loss2 : 1.348882
train_step : 5367, loss1 : 1.921043, loss2 : 1.569962
train_step : 5368, loss1 : 0.845629, loss2 : 1.490281
train_step : 5369, loss1 : 0.878881, loss2 : 1.088972
train_step : 5370, loss1 : 1.101274, loss2 : 0.754082
train_step : 5371, loss1 : 0.746853, loss2 : 1.250117
train_step : 5372, loss1 : 1.356770, loss2 : 0.992325
train_step : 5373, loss1 : 1.091917, loss2 : 1.008347
train_step : 5374, loss1 : 1.276257, loss2 : 1.045577
train_step : 5375, loss1 : 1.301785, loss2 : 2.784001
train_step : 5376, loss1 : 1.112573, loss2 : 1.827582
train_step : 5377, loss1 : 0.790173, loss2 : 1.310936
train_step : 5378, loss1 : 1.594320, loss2 : 1.108464
train_step : 5379, loss1 : 0.906698, loss2 : 1.696630
train_step : 5380, loss1 : 1.107409, loss2 : 1.129083
train_step : 5381, loss1 : 1.314166, loss2 : 0.671247
train_step : 5382, loss1 : 0.946902, loss2 : 0.528736
train_step : 5383, loss1 : 0.728748, loss2 : 1.383611
train_step : 5384, loss1 : 0.976305, loss2 : 2.214415
train_step : 5385, loss1 : 1.133325, loss2 : 1.736899
train_step : 5386, loss1 : 0.513033, loss2 : 1.227113
train_step : 5387, loss1 : 0.393205, loss2 : 0.992167
train_step : 5388, loss1 : 1.461968, loss2 : 1.532661
train_step : 5389, loss1 : 1.219698, loss2 : 1.258318
train_step : 5390, loss1 : 1.970040, loss2 : 1.853874
train_step : 5391, loss1 : 2.840086, loss2 : 0.960750
train_step : 5392, loss1 : 1.810677, loss2 : 2.925103
train_step : 5393, loss1 : 2.984440, loss2 : 2.924457
train_step : 5394, loss1 : 3.098211, loss2 : 3.211462
train_step : 5395, loss1 : 2.537545, loss2 : 1.035387
train_step : 5396, loss1 : 1.982106, loss2 : 2.009508
train_step : 5397, loss1 : 2.113649, loss2 : 1.256747
train_step : 5398, loss1 : 1.227332, loss2 : 1.256870
train_step : 5399, loss1 : 0.751590, loss2 : 1.169635
train_step : 5400, loss1 : 0.903554, loss2 : 1.147094
train_step : 5401, loss1 : 0.790188, loss2 : 2.340972
train_step : 5402, loss1 : 1.785856, loss2 : 1.159627
train_step : 5403, loss1 : 0.723796, loss2 : 1.573356
train_step : 5404, loss1 : 1.336673, loss2 : 1.275354
train_step : 5405, loss1 : 1.236360, loss2 : 1.002213
train_step : 5406, loss1 : 1.255953, loss2 : 1.635678
train_step : 5407, loss1 : 1.011004, loss2 : 2.360318
train_step : 5408, loss1 : 1.262600, loss2 : 2.802569
train_step : 5409, loss1 : 2.156300, loss2 : 1.759122
train_step : 5410, loss1 : 1.347787, loss2 : 0.780362
train_step : 5411, loss1 : 1.100653, loss2 : 1.421682
train_step : 5412, loss1 : 1.259837, loss2 : 1.392031
train_step : 5413, loss1 : 1.720202, loss2 : 1.937554
train_step : 5414, loss1 : 0.749624, loss2 : 1.192322
train_step : 5415, loss1 : 1.164755, loss2 : 0.514797
train_step : 5416, loss1 : 1.063883, loss2 : 0.922188
train_step : 5417, loss1 : 1.142480, loss2 : 1.158653
train_step : 5418, loss1 : 1.520779, loss2 : 1.040779
train_step : 5419, loss1 : 0.735671, loss2 : 1.186698
train_step : 5420, loss1 : 0.989603, loss2 : 1.324370
train_step : 5421, loss1 : 0.534170, loss2 : 1.597812
train_step : 5422, loss1 : 1.068440, loss2 : 1.544981
train_step : 5423, loss1 : 0.902777, loss2 : 1.412877
train_step : 5424, loss1 : 1.235213, loss2 : 1.803005
train_step : 5425, loss1 : 0.699826, loss2 : 1.433631
train_step : 5426, loss1 : 1.357755, loss2 : 2.367655
train_step : 5427, loss1 : 0.930352, loss2 : 2.444649
train_step : 5428, loss1 : 1.531170, loss2 : 1.949806
train_step : 5429, loss1 : 0.660049, loss2 : 0.904626
train_step : 5430, loss1 : 1.030733, loss2 : 1.017519
train_step : 5431, loss1 : 1.136572, loss2 : 1.183769
train_step : 5432, loss1 : 1.418929, loss2 : 0.995802
train_step : 5433, loss1 : 1.035310, loss2 : 0.845359
train_step : 5434, loss1 : 1.060977, loss2 : 1.381437
train_step : 5435, loss1 : 1.333618, loss2 : 0.942482
train_step : 5436, loss1 : 0.690904, loss2 : 0.943078
train_step : 5437, loss1 : 0.954573, loss2 : 1.202479
train_step : 5438, loss1 : 1.409429, loss2 : 1.080334
train_step : 5439, loss1 : 0.678205, loss2 : 1.561468
train_step : 5440, loss1 : 1.061889, loss2 : 0.979500
train_step : 5441, loss1 : 1.541962, loss2 : 1.287532
train_step : 5442, loss1 : 2.280535, loss2 : 3.081770
train_step : 5443, loss1 : 3.131124, loss2 : 3.478782
train_step : 5444, loss1 : 3.067281, loss2 : 1.944840
train_step : 5445, loss1 : 2.197503, loss2 : 3.160657
train_step : 5446, loss1 : 2.824303, loss2 : 1.237704
train_step : 5447, loss1 : 1.969045, loss2 : 2.834617
train_step : 5448, loss1 : 2.501693, loss2 : 1.980324
train_step : 5449, loss1 : 1.536669, loss2 : 2.476397
train_step : 5450, loss1 : 1.740213, loss2 : 3.777295
train_step : 5451, loss1 : 1.905278, loss2 : 2.067595
train_step : 5452, loss1 : 2.036260, loss2 : 1.511022
train_step : 5453, loss1 : 2.208076, loss2 : 2.825958
train_step : 5454, loss1 : 2.742086, loss2 : 1.549344
train_step : 5455, loss1 : 3.386615, loss2 : 1.849574
train_step : 5456, loss1 : 2.760932, loss2 : 2.074304
train_step : 5457, loss1 : 3.624928, loss2 : 1.594879
train_step : 5458, loss1 : 2.310848, loss2 : 1.901602
train_step : 5459, loss1 : 1.204126, loss2 : 2.589367
train_step : 5460, loss1 : 1.650044, loss2 : 1.546267
train_step : 5461, loss1 : 1.191808, loss2 : 1.652186
train_step : 5462, loss1 : 1.577683, loss2 : 0.781529
train_step : 5463, loss1 : 1.852159, loss2 : 1.274492
train_step : 5464, loss1 : 1.091991, loss2 : 1.337779
train_step : 5465, loss1 : 0.934719, loss2 : 0.857620
train_step : 5466, loss1 : 0.622802, loss2 : 0.740017
train_step : 5467, loss1 : 0.767653, loss2 : 2.273592
train_step : 5468, loss1 : 1.647610, loss2 : 0.974627
train_step : 5469, loss1 : 1.234496, loss2 : 1.148927
train_step : 5470, loss1 : 0.998363, loss2 : 1.487378
train_step : 5471, loss1 : 1.139765, loss2 : 0.860153
train_step : 5472, loss1 : 2.084564, loss2 : 2.243014
train_step : 5473, loss1 : 2.300199, loss2 : 1.418795
train_step : 5474, loss1 : 0.990003, loss2 : 1.423067
train_step : 5475, loss1 : 1.999717, loss2 : 1.443126
train_step : 5476, loss1 : 1.729890, loss2 : 2.089045
train_step : 5477, loss1 : 1.636710, loss2 : 2.505601
train_step : 5478, loss1 : 1.632382, loss2 : 2.149389
train_step : 5479, loss1 : 3.060082, loss2 : 2.243034
train_step : 5480, loss1 : 2.993626, loss2 : 3.240049
train_step : 5481, loss1 : 1.603318, loss2 : 2.491468
train_step : 5482, loss1 : 1.487140, loss2 : 2.151876
train_step : 5483, loss1 : 1.312044, loss2 : 1.762010
train_step : 5484, loss1 : 1.830587, loss2 : 1.096199
train_step : 5485, loss1 : 1.708584, loss2 : 1.758106
train_step : 5486, loss1 : 2.373647, loss2 : 1.526925
train_step : 5487, loss1 : 1.757196, loss2 : 0.960471
train_step : 5488, loss1 : 1.722972, loss2 : 2.336983
train_step : 5489, loss1 : 1.839114, loss2 : 4.103414
train_step : 5490, loss1 : 3.834139, loss2 : 4.159192
train_step : 5491, loss1 : 2.839066, loss2 : 3.348279
train_step : 5492, loss1 : 3.241790, loss2 : 3.140667
train_step : 5493, loss1 : 2.405284, loss2 : 3.627025
train_step : 5494, loss1 : 4.091512, loss2 : 5.410365
train_step : 5495, loss1 : 2.828531, loss2 : 2.110785
train_step : 5496, loss1 : 1.125256, loss2 : 2.668981
train_step : 5497, loss1 : 1.993457, loss2 : 1.598680
train_step : 5498, loss1 : 1.651657, loss2 : 1.766815
train_step : 5499, loss1 : 1.869253, loss2 : 1.265319
train_step : 5500, loss1 : 1.044595, loss2 : 1.316985
train_step : 5501, loss1 : 3.406973, loss2 : 1.239128
train_step : 5502, loss1 : 0.804570, loss2 : 0.982760
train_step : 5503, loss1 : 0.562113, loss2 : 0.993753
train_step : 5504, loss1 : 1.612729, loss2 : 1.010372
train_step : 5505, loss1 : 0.887715, loss2 : 1.241025
train_step : 5506, loss1 : 1.939211, loss2 : 1.558631
train_step : 5507, loss1 : 1.687486, loss2 : 1.577572
train_step : 5508, loss1 : 1.289784, loss2 : 1.968528
train_step : 5509, loss1 : 1.492530, loss2 : 2.009372
train_step : 5510, loss1 : 2.461099, loss2 : 2.008498
train_step : 5511, loss1 : 2.561284, loss2 : 2.663675
train_step : 5512, loss1 : 2.854681, loss2 : 1.754427
train_step : 5513, loss1 : 3.006948, loss2 : 3.952629
train_step : 5514, loss1 : 4.188362, loss2 : 4.406084
train_step : 5515, loss1 : 5.162850, loss2 : 5.082576
train_step : 5516, loss1 : 2.577170, loss2 : 2.379428
train_step : 5517, loss1 : 2.989509, loss2 : 1.553386
train_step : 5518, loss1 : 2.201795, loss2 : 2.008163
train_step : 5519, loss1 : 2.607934, loss2 : 1.851197
train_step : 5520, loss1 : 2.882544, loss2 : 2.280805
train_step : 5521, loss1 : 3.763088, loss2 : 2.959126
train_step : 5522, loss1 : 4.414781, loss2 : 2.418795
train_step : 5523, loss1 : 4.699334, loss2 : 4.042248
train_step : 5524, loss1 : 4.597660, loss2 : 3.317534
train_step : 5525, loss1 : 2.645495, loss2 : 4.061333
train_step : 5526, loss1 : 2.429211, loss2 : 2.294852
train_step : 5527, loss1 : 1.015802, loss2 : 1.742349
train_step : 5528, loss1 : 2.396193, loss2 : 3.039950
train_step : 5529, loss1 : 3.076716, loss2 : 2.130638
train_step : 5530, loss1 : 3.245864, loss2 : 2.334774
train_step : 5531, loss1 : 3.457333, loss2 : 1.953824
train_step : 5532, loss1 : 3.156249, loss2 : 2.330860
train_step : 5533, loss1 : 2.438654, loss2 : 2.830613
train_step : 5534, loss1 : 1.639634, loss2 : 0.877649
train_step : 5535, loss1 : 0.683629, loss2 : 1.660602
train_step : 5536, loss1 : 1.499872, loss2 : 1.349519
train_step : 5537, loss1 : 0.830996, loss2 : 1.636390
train_step : 5538, loss1 : 1.029960, loss2 : 0.927562
train_step : 5539, loss1 : 1.817678, loss2 : 0.678874
train_step : 5540, loss1 : 0.913523, loss2 : 1.258396
train_step : 5541, loss1 : 1.660031, loss2 : 1.322572
train_step : 5542, loss1 : 1.256964, loss2 : 1.251465
train_step : 5543, loss1 : 1.076349, loss2 : 1.271361
train_step : 5544, loss1 : 2.402750, loss2 : 1.552372
train_step : 5545, loss1 : 0.972522, loss2 : 1.274087
train_step : 5546, loss1 : 1.056597, loss2 : 1.434452
train_step : 5547, loss1 : 1.302298, loss2 : 1.013484
train_step : 5548, loss1 : 0.633218, loss2 : 1.511276
train_step : 5549, loss1 : 1.446836, loss2 : 1.597166
train_step : 5550, loss1 : 0.870319, loss2 : 2.015296
train_step : 5551, loss1 : 1.080247, loss2 : 0.759676
train_step : 5552, loss1 : 0.911982, loss2 : 0.910763
train_step : 5553, loss1 : 1.013978, loss2 : 1.564386
train_step : 5554, loss1 : 1.281383, loss2 : 2.339511
train_step : 5555, loss1 : 1.945234, loss2 : 2.550696
train_step : 5556, loss1 : 1.199766, loss2 : 2.053465
train_step : 5557, loss1 : 1.444762, loss2 : 1.619961
train_step : 5558, loss1 : 1.281765, loss2 : 2.088525
train_step : 5559, loss1 : 1.964419, loss2 : 2.103097
train_step : 5560, loss1 : 1.380367, loss2 : 1.457169
train_step : 5561, loss1 : 2.113011, loss2 : 1.789020
train_step : 5562, loss1 : 1.768607, loss2 : 1.204851
train_step : 5563, loss1 : 1.918968, loss2 : 1.139776
train_step : 5564, loss1 : 2.099104, loss2 : 3.141251
train_step : 5565, loss1 : 2.760007, loss2 : 2.243176
train_step : 5566, loss1 : 1.887305, loss2 : 1.654422
train_step : 5567, loss1 : 1.191852, loss2 : 2.330038
train_step : 5568, loss1 : 1.596122, loss2 : 1.552987
train_step : 5569, loss1 : 1.131619, loss2 : 1.288758
train_step : 5570, loss1 : 1.765047, loss2 : 1.954779
train_step : 5571, loss1 : 1.362398, loss2 : 1.145256
train_step : 5572, loss1 : 2.242580, loss2 : 1.670525
train_step : 5573, loss1 : 1.057495, loss2 : 2.410051
train_step : 5574, loss1 : 1.713060, loss2 : 0.624322
train_step : 5575, loss1 : 0.849420, loss2 : 0.963927
train_step : 5576, loss1 : 0.430776, loss2 : 1.230603
train_step : 5577, loss1 : 1.415889, loss2 : 1.615557
train_step : 5578, loss1 : 0.994827, loss2 : 0.904486
train_step : 5579, loss1 : 1.207750, loss2 : 1.240027
train_step : 5580, loss1 : 1.488547, loss2 : 0.837308
train_step : 5581, loss1 : 1.239820, loss2 : 1.167942
train_step : 5582, loss1 : 1.190044, loss2 : 1.462204
train_step : 5583, loss1 : 1.452531, loss2 : 0.853553
train_step : 5584, loss1 : 1.532345, loss2 : 2.030858
train_step : 5585, loss1 : 0.927273, loss2 : 1.757120
train_step : 5586, loss1 : 0.769155, loss2 : 0.987002
train_step : 5587, loss1 : 1.015302, loss2 : 1.036689
train_step : 5588, loss1 : 0.592545, loss2 : 3.501843
train_step : 5589, loss1 : 1.571798, loss2 : 0.892692
train_step : 5590, loss1 : 1.336367, loss2 : 2.227224
train_step : 5591, loss1 : 1.459374, loss2 : 0.463171
train_step : 5592, loss1 : 1.076747, loss2 : 1.412398
train_step : 5593, loss1 : 1.225998, loss2 : 0.664882
train_step : 5594, loss1 : 0.596104, loss2 : 0.973776
train_step : 5595, loss1 : 0.721846, loss2 : 1.614192
train_step : 5596, loss1 : 0.894260, loss2 : 1.454999
train_step : 5597, loss1 : 1.274479, loss2 : 0.794648
train_step : 5598, loss1 : 1.310889, loss2 : 1.562081
train_step : 5599, loss1 : 1.441674, loss2 : 0.970961
train_step : 5600, loss1 : 1.857810, loss2 : 0.691781
train_step : 5601, loss1 : 0.984030, loss2 : 1.218851
train_step : 5602, loss1 : 1.457745, loss2 : 3.145566
train_step : 5603, loss1 : 3.363757, loss2 : 4.061375
train_step : 5604, loss1 : 4.289874, loss2 : 2.706741
train_step : 5605, loss1 : 3.339818, loss2 : 4.249747
train_step : 5606, loss1 : 2.083896, loss2 : 1.405073
train_step : 5607, loss1 : 1.489208, loss2 : 1.359269
train_step : 5608, loss1 : 0.852508, loss2 : 0.906035
train_step : 5609, loss1 : 1.155946, loss2 : 0.742280
train_step : 5610, loss1 : 0.758955, loss2 : 1.331156
train_step : 5611, loss1 : 1.578328, loss2 : 1.001812
train_step : 5612, loss1 : 1.850538, loss2 : 1.476611
train_step : 5613, loss1 : 2.838694, loss2 : 4.455560
train_step : 5614, loss1 : 2.518390, loss2 : 3.023668
train_step : 5615, loss1 : 1.835819, loss2 : 1.698287
train_step : 5616, loss1 : 1.723623, loss2 : 1.353276
train_step : 5617, loss1 : 1.349779, loss2 : 0.630955
train_step : 5618, loss1 : 1.267311, loss2 : 2.109117
train_step : 5619, loss1 : 1.219053, loss2 : 1.457564
train_step : 5620, loss1 : 1.086659, loss2 : 1.639703
train_step : 5621, loss1 : 1.156813, loss2 : 2.367709
train_step : 5622, loss1 : 1.889762, loss2 : 1.399683
train_step : 5623, loss1 : 2.444064, loss2 : 1.535844
train_step : 5624, loss1 : 1.224769, loss2 : 1.043008
train_step : 5625, loss1 : 1.154244, loss2 : 1.376909
train_step : 5626, loss1 : 1.322546, loss2 : 0.971875
train_step : 5627, loss1 : 1.312225, loss2 : 1.296351
train_step : 5628, loss1 : 1.466921, loss2 : 1.061956
train_step : 5629, loss1 : 1.609485, loss2 : 2.217823
train_step : 5630, loss1 : 2.151217, loss2 : 1.586097
train_step : 5631, loss1 : 1.403697, loss2 : 1.001518
train_step : 5632, loss1 : 1.022816, loss2 : 0.417280
train_step : 5633, loss1 : 1.712287, loss2 : 1.391411
train_step : 5634, loss1 : 1.207112, loss2 : 0.553092
train_step : 5635, loss1 : 0.880170, loss2 : 0.729187
train_step : 5636, loss1 : 0.797450, loss2 : 0.791740
train_step : 5637, loss1 : 2.048034, loss2 : 1.514749
train_step : 5638, loss1 : 1.568376, loss2 : 0.744950
train_step : 5639, loss1 : 1.144105, loss2 : 1.088311
train_step : 5640, loss1 : 1.220223, loss2 : 1.621525
train_step : 5641, loss1 : 1.218014, loss2 : 1.628925
train_step : 5642, loss1 : 1.076990, loss2 : 1.169116
train_step : 5643, loss1 : 1.068917, loss2 : 1.176773
train_step : 5644, loss1 : 1.003281, loss2 : 1.549514
train_step : 5645, loss1 : 1.617713, loss2 : 1.675740
train_step : 5646, loss1 : 0.938148, loss2 : 1.147158
train_step : 5647, loss1 : 2.012304, loss2 : 1.175096
train_step : 5648, loss1 : 0.839081, loss2 : 0.803346
train_step : 5649, loss1 : 1.253154, loss2 : 1.699940
train_step : 5650, loss1 : 0.887645, loss2 : 0.738118
train_step : 5651, loss1 : 1.315386, loss2 : 1.321648
train_step : 5652, loss1 : 1.447463, loss2 : 1.356312
train_step : 5653, loss1 : 0.789668, loss2 : 1.812212
train_step : 5654, loss1 : 0.965755, loss2 : 2.270276
train_step : 5655, loss1 : 1.388916, loss2 : 1.479187
train_step : 5656, loss1 : 1.827697, loss2 : 2.154833
train_step : 5657, loss1 : 2.468494, loss2 : 1.656363
train_step : 5658, loss1 : 1.648210, loss2 : 1.765538
train_step : 5659, loss1 : 0.893217, loss2 : 1.667045
train_step : 5660, loss1 : 0.546234, loss2 : 1.820041
train_step : 5661, loss1 : 0.875010, loss2 : 1.981563
train_step : 5662, loss1 : 0.762131, loss2 : 1.360022
train_step : 5663, loss1 : 0.792755, loss2 : 1.142383
train_step : 5664, loss1 : 0.960415, loss2 : 1.391342
train_step : 5665, loss1 : 1.293738, loss2 : 0.778382
train_step : 5666, loss1 : 1.024370, loss2 : 1.145695
train_step : 5667, loss1 : 1.180504, loss2 : 1.810872
train_step : 5668, loss1 : 1.093377, loss2 : 0.757291
train_step : 5669, loss1 : 0.492957, loss2 : 1.121447
train_step : 5670, loss1 : 0.786824, loss2 : 1.212641
train_step : 5671, loss1 : 1.660403, loss2 : 1.946023
train_step : 5672, loss1 : 2.370345, loss2 : 2.388300
train_step : 5673, loss1 : 0.951134, loss2 : 1.153911
train_step : 5674, loss1 : 0.927678, loss2 : 0.744996
train_step : 5675, loss1 : 1.528183, loss2 : 1.746348
train_step : 5676, loss1 : 1.080536, loss2 : 2.273125
train_step : 5677, loss1 : 1.745879, loss2 : 2.524992
train_step : 5678, loss1 : 3.253010, loss2 : 2.187871
train_step : 5679, loss1 : 1.545689, loss2 : 3.461462
train_step : 5680, loss1 : 3.078355, loss2 : 2.317557
train_step : 5681, loss1 : 2.712266, loss2 : 2.213943
train_step : 5682, loss1 : 0.906252, loss2 : 1.190814
train_step : 5683, loss1 : 1.714860, loss2 : 1.570346
train_step : 5684, loss1 : 1.068720, loss2 : 1.074923
train_step : 5685, loss1 : 0.857668, loss2 : 1.381055
train_step : 5686, loss1 : 2.278128, loss2 : 1.365451
train_step : 5687, loss1 : 1.878129, loss2 : 0.662109
train_step : 5688, loss1 : 1.270896, loss2 : 2.334165
train_step : 5689, loss1 : 1.818171, loss2 : 0.744006
train_step : 5690, loss1 : 1.464959, loss2 : 1.649728
train_step : 5691, loss1 : 1.783600, loss2 : 2.312552
train_step : 5692, loss1 : 3.954048, loss2 : 3.268713
train_step : 5693, loss1 : 3.784468, loss2 : 4.057623
train_step : 5694, loss1 : 3.768742, loss2 : 3.142867
train_step : 5695, loss1 : 5.277974, loss2 : 4.215555
train_step : 5696, loss1 : 4.236607, loss2 : 1.930897
train_step : 5697, loss1 : 3.435319, loss2 : 2.594779
train_step : 5698, loss1 : 2.681654, loss2 : 2.905404
train_step : 5699, loss1 : 2.990089, loss2 : 5.201914
train_step : 5700, loss1 : 1.784201, loss2 : 1.427313
train_step : 5701, loss1 : 1.990148, loss2 : 1.789971
train_step : 5702, loss1 : 1.097985, loss2 : 1.709004
train_step : 5703, loss1 : 1.496137, loss2 : 1.578054
train_step : 5704, loss1 : 1.311363, loss2 : 1.424852
train_step : 5705, loss1 : 1.302586, loss2 : 2.732745
train_step : 5706, loss1 : 1.467036, loss2 : 0.843901
train_step : 5707, loss1 : 1.915046, loss2 : 1.602952
train_step : 5708, loss1 : 1.319783, loss2 : 1.345229
train_step : 5709, loss1 : 0.583988, loss2 : 1.254994
train_step : 5710, loss1 : 0.802050, loss2 : 1.146510
train_step : 5711, loss1 : 1.022055, loss2 : 1.818307
train_step : 5712, loss1 : 0.894198, loss2 : 1.089266
train_step : 5713, loss1 : 2.584402, loss2 : 1.447583
train_step : 5714, loss1 : 2.405706, loss2 : 0.739025
train_step : 5715, loss1 : 1.261956, loss2 : 1.440072
train_step : 5716, loss1 : 1.467397, loss2 : 3.560512
train_step : 5717, loss1 : 2.681834, loss2 : 2.375524
train_step : 5718, loss1 : 1.277179, loss2 : 2.735040
train_step : 5719, loss1 : 1.990049, loss2 : 1.678955
train_step : 5720, loss1 : 1.789704, loss2 : 1.186481
train_step : 5721, loss1 : 1.543402, loss2 : 1.945619
train_step : 5722, loss1 : 1.078569, loss2 : 0.985955
train_step : 5723, loss1 : 1.696674, loss2 : 0.851355
train_step : 5724, loss1 : 1.523180, loss2 : 0.858785
train_step : 5725, loss1 : 1.292218, loss2 : 1.344352
train_step : 5726, loss1 : 1.292854, loss2 : 1.420136
train_step : 5727, loss1 : 0.703399, loss2 : 0.819199
train_step : 5728, loss1 : 0.821865, loss2 : 0.549453
train_step : 5729, loss1 : 1.558968, loss2 : 1.109685
train_step : 5730, loss1 : 1.388574, loss2 : 1.629394
train_step : 5731, loss1 : 1.133268, loss2 : 0.669463
train_step : 5732, loss1 : 1.664396, loss2 : 1.156880
train_step : 5733, loss1 : 1.080299, loss2 : 1.205691
train_step : 5734, loss1 : 1.074303, loss2 : 1.637540
train_step : 5735, loss1 : 0.769594, loss2 : 0.968735
train_step : 5736, loss1 : 1.164427, loss2 : 0.777648
train_step : 5737, loss1 : 1.051067, loss2 : 0.729874
train_step : 5738, loss1 : 2.092908, loss2 : 0.793491
train_step : 5739, loss1 : 0.837694, loss2 : 1.410598
train_step : 5740, loss1 : 1.697049, loss2 : 1.080033
train_step : 5741, loss1 : 3.699124, loss2 : 1.178500
train_step : 5742, loss1 : 1.636833, loss2 : 1.988743
train_step : 5743, loss1 : 1.463720, loss2 : 1.106845
train_step : 5744, loss1 : 0.979569, loss2 : 1.605005
train_step : 5745, loss1 : 1.362955, loss2 : 1.629157
train_step : 5746, loss1 : 0.668839, loss2 : 1.674515
train_step : 5747, loss1 : 1.070268, loss2 : 1.644672
train_step : 5748, loss1 : 1.856985, loss2 : 1.304199
train_step : 5749, loss1 : 1.099326, loss2 : 1.332612
train_step : 5750, loss1 : 1.371696, loss2 : 1.483526
train_step : 5751, loss1 : 0.991007, loss2 : 1.117227
train_step : 5752, loss1 : 0.776340, loss2 : 0.546242
train_step : 5753, loss1 : 1.070815, loss2 : 1.242511
train_step : 5754, loss1 : 1.239813, loss2 : 1.435766
train_step : 5755, loss1 : 1.422800, loss2 : 0.895892
train_step : 5756, loss1 : 1.473506, loss2 : 0.914336
train_step : 5757, loss1 : 1.338334, loss2 : 1.657082
train_step : 5758, loss1 : 1.412824, loss2 : 1.834311
train_step : 5759, loss1 : 1.826338, loss2 : 1.358336
train_step : 5760, loss1 : 1.839391, loss2 : 1.158132
train_step : 5761, loss1 : 1.280776, loss2 : 0.653361
train_step : 5762, loss1 : 0.824742, loss2 : 0.543313
train_step : 5763, loss1 : 1.309044, loss2 : 0.751214
train_step : 5764, loss1 : 1.504485, loss2 : 1.763915
train_step : 5765, loss1 : 1.823010, loss2 : 1.192325
train_step : 5766, loss1 : 1.446158, loss2 : 1.601325
train_step : 5767, loss1 : 0.809325, loss2 : 0.392769
train_step : 5768, loss1 : 0.872522, loss2 : 1.181182
train_step : 5769, loss1 : 1.797019, loss2 : 1.404506
train_step : 5770, loss1 : 1.608802, loss2 : 0.806144
train_step : 5771, loss1 : 1.523457, loss2 : 1.901602
train_step : 5772, loss1 : 1.772626, loss2 : 2.075707
train_step : 5773, loss1 : 1.402544, loss2 : 0.717751
train_step : 5774, loss1 : 1.853028, loss2 : 1.778113
train_step : 5775, loss1 : 1.707872, loss2 : 1.692091
train_step : 5776, loss1 : 1.453613, loss2 : 1.214207
train_step : 5777, loss1 : 1.459097, loss2 : 1.660795
train_step : 5778, loss1 : 2.105487, loss2 : 2.014735
train_step : 5779, loss1 : 1.939909, loss2 : 2.099588
train_step : 5780, loss1 : 2.029160, loss2 : 2.531056
train_step : 5781, loss1 : 1.516421, loss2 : 1.128312
train_step : 5782, loss1 : 1.153583, loss2 : 2.058897
train_step : 5783, loss1 : 1.675534, loss2 : 0.879950
train_step : 5784, loss1 : 1.150528, loss2 : 1.043628
train_step : 5785, loss1 : 0.792445, loss2 : 1.259417
train_step : 5786, loss1 : 1.299075, loss2 : 0.605447
train_step : 5787, loss1 : 1.980777, loss2 : 2.128810
train_step : 5788, loss1 : 0.879362, loss2 : 1.206748
train_step : 5789, loss1 : 1.111331, loss2 : 1.607674
train_step : 5790, loss1 : 0.978483, loss2 : 1.531194
train_step : 5791, loss1 : 1.252730, loss2 : 1.237597
train_step : 5792, loss1 : 1.697170, loss2 : 1.087151
train_step : 5793, loss1 : 1.451360, loss2 : 1.547775
train_step : 5794, loss1 : 1.293807, loss2 : 1.074633
train_step : 5795, loss1 : 1.831108, loss2 : 0.883922
train_step : 5796, loss1 : 0.983128, loss2 : 1.548597
train_step : 5797, loss1 : 1.547849, loss2 : 1.306351
train_step : 5798, loss1 : 0.928965, loss2 : 1.599587
train_step : 5799, loss1 : 1.984743, loss2 : 1.497843
train_step : 5800, loss1 : 1.183623, loss2 : 1.109425
train_step : 5801, loss1 : 1.416749, loss2 : 1.323137
train_step : 5802, loss1 : 0.786514, loss2 : 1.322328
train_step : 5803, loss1 : 1.614127, loss2 : 3.553201
train_step : 5804, loss1 : 1.143173, loss2 : 1.094047
train_step : 5805, loss1 : 1.017869, loss2 : 1.847222
train_step : 5806, loss1 : 0.690695, loss2 : 2.077887
train_step : 5807, loss1 : 1.374080, loss2 : 1.558421
train_step : 5808, loss1 : 1.630504, loss2 : 1.855231
train_step : 5809, loss1 : 0.892216, loss2 : 1.887010
train_step : 5810, loss1 : 0.535372, loss2 : 1.420515
train_step : 5811, loss1 : 0.477152, loss2 : 0.852162
train_step : 5812, loss1 : 0.786139, loss2 : 1.799434
train_step : 5813, loss1 : 2.298610, loss2 : 1.571635
train_step : 5814, loss1 : 1.891015, loss2 : 2.014670
train_step : 5815, loss1 : 1.666061, loss2 : 1.457312
train_step : 5816, loss1 : 2.526363, loss2 : 2.111959
train_step : 5817, loss1 : 3.257662, loss2 : 3.371992
train_step : 5818, loss1 : 3.623050, loss2 : 2.644128
train_step : 5819, loss1 : 4.241974, loss2 : 4.589544
train_step : 5820, loss1 : 3.973523, loss2 : 2.231456
train_step : 5821, loss1 : 2.259975, loss2 : 1.799486
train_step : 5822, loss1 : 1.989030, loss2 : 2.008703
train_step : 5823, loss1 : 2.092762, loss2 : 3.517359
train_step : 5824, loss1 : 3.240971, loss2 : 4.251023
train_step : 5825, loss1 : 5.363070, loss2 : 6.492435
train_step : 5826, loss1 : 3.204576, loss2 : 5.472035
train_step : 5827, loss1 : 5.713108, loss2 : 4.311689
train_step : 5828, loss1 : 2.606189, loss2 : 2.191000
train_step : 5829, loss1 : 1.912879, loss2 : 1.934153
train_step : 5830, loss1 : 3.337451, loss2 : 2.212364
train_step : 5831, loss1 : 1.529222, loss2 : 2.288949
train_step : 5832, loss1 : 0.980843, loss2 : 0.748110
train_step : 5833, loss1 : 1.308240, loss2 : 1.391039
train_step : 5834, loss1 : 1.525129, loss2 : 1.962799
train_step : 5835, loss1 : 1.164590, loss2 : 1.370425
train_step : 5836, loss1 : 1.789071, loss2 : 0.741634
train_step : 5837, loss1 : 1.249204, loss2 : 1.713118
train_step : 5838, loss1 : 1.374282, loss2 : 1.460453
train_step : 5839, loss1 : 1.432715, loss2 : 1.445876
train_step : 5840, loss1 : 1.419592, loss2 : 0.974513
train_step : 5841, loss1 : 2.308717, loss2 : 0.939424
train_step : 5842, loss1 : 1.532085, loss2 : 0.828045
train_step : 5843, loss1 : 1.073025, loss2 : 1.573353
train_step : 5844, loss1 : 1.221810, loss2 : 0.910253
train_step : 5845, loss1 : 0.819649, loss2 : 1.067617
train_step : 5846, loss1 : 1.482039, loss2 : 1.405628
train_step : 5847, loss1 : 1.394706, loss2 : 1.790498
train_step : 5848, loss1 : 0.873974, loss2 : 1.017754
train_step : 5849, loss1 : 1.958404, loss2 : 1.094940
train_step : 5850, loss1 : 1.008225, loss2 : 0.847690
train_step : 5851, loss1 : 1.211287, loss2 : 1.776201
train_step : 5852, loss1 : 1.113786, loss2 : 2.028988
train_step : 5853, loss1 : 1.798642, loss2 : 1.615908
train_step : 5854, loss1 : 2.499231, loss2 : 1.841760
train_step : 5855, loss1 : 2.169998, loss2 : 1.097642
train_step : 5856, loss1 : 1.184785, loss2 : 1.862630
train_step : 5857, loss1 : 1.777700, loss2 : 1.055955
train_step : 5858, loss1 : 1.447769, loss2 : 1.497490
train_step : 5859, loss1 : 1.723080, loss2 : 0.798709
train_step : 5860, loss1 : 1.333962, loss2 : 0.913038
train_step : 5861, loss1 : 0.837718, loss2 : 0.744855
train_step : 5862, loss1 : 1.097509, loss2 : 0.650322
train_step : 5863, loss1 : 1.348092, loss2 : 1.199094
train_step : 5864, loss1 : 0.994213, loss2 : 0.955620
train_step : 5865, loss1 : 1.019231, loss2 : 0.840472
train_step : 5866, loss1 : 1.593963, loss2 : 1.582777
train_step : 5867, loss1 : 1.322309, loss2 : 2.014810
train_step : 5868, loss1 : 1.715447, loss2 : 1.883848
train_step : 5869, loss1 : 0.810824, loss2 : 1.762576
train_step : 5870, loss1 : 1.311256, loss2 : 1.265510
train_step : 5871, loss1 : 1.159497, loss2 : 2.313174
train_step : 5872, loss1 : 1.869618, loss2 : 2.266892
train_step : 5873, loss1 : 2.963437, loss2 : 2.217539
train_step : 5874, loss1 : 3.027820, loss2 : 2.926949
train_step : 5875, loss1 : 1.751946, loss2 : 2.518501
train_step : 5876, loss1 : 1.806668, loss2 : 1.393126
train_step : 5877, loss1 : 1.067071, loss2 : 2.869499
train_step : 5878, loss1 : 2.210821, loss2 : 2.247596
train_step : 5879, loss1 : 1.778339, loss2 : 1.039263
train_step : 5880, loss1 : 2.225214, loss2 : 1.567564
train_step : 5881, loss1 : 1.653492, loss2 : 1.327991
train_step : 5882, loss1 : 1.494827, loss2 : 2.073201
train_step : 5883, loss1 : 2.056217, loss2 : 1.236423
train_step : 5884, loss1 : 2.518909, loss2 : 1.871263
train_step : 5885, loss1 : 2.335304, loss2 : 0.971165
train_step : 5886, loss1 : 1.036535, loss2 : 1.399211
train_step : 5887, loss1 : 1.665985, loss2 : 0.638218
train_step : 5888, loss1 : 1.527745, loss2 : 0.881058
train_step : 5889, loss1 : 1.868377, loss2 : 1.121420
train_step : 5890, loss1 : 0.438157, loss2 : 1.179030
train_step : 5891, loss1 : 0.969017, loss2 : 1.420569
train_step : 5892, loss1 : 1.731474, loss2 : 1.422358
train_step : 5893, loss1 : 2.317101, loss2 : 2.388983
train_step : 5894, loss1 : 1.476278, loss2 : 3.098615
train_step : 5895, loss1 : 1.512879, loss2 : 1.684927
train_step : 5896, loss1 : 1.735299, loss2 : 2.470496
train_step : 5897, loss1 : 1.995677, loss2 : 1.776380
train_step : 5898, loss1 : 2.140475, loss2 : 1.235384
train_step : 5899, loss1 : 1.067645, loss2 : 1.230093
train_step : 5900, loss1 : 1.430413, loss2 : 1.443993
train_step : 5901, loss1 : 1.734928, loss2 : 1.108178
train_step : 5902, loss1 : 1.070892, loss2 : 1.312777
train_step : 5903, loss1 : 0.617988, loss2 : 1.193762
train_step : 5904, loss1 : 1.032769, loss2 : 1.402576
train_step : 5905, loss1 : 1.380657, loss2 : 0.729915
train_step : 5906, loss1 : 1.447445, loss2 : 0.754906
train_step : 5907, loss1 : 1.232387, loss2 : 2.379981
train_step : 5908, loss1 : 1.476660, loss2 : 2.488060
train_step : 5909, loss1 : 3.173311, loss2 : 1.908626
train_step : 5910, loss1 : 2.671510, loss2 : 2.081919
train_step : 5911, loss1 : 2.500267, loss2 : 2.161819
train_step : 5912, loss1 : 1.502609, loss2 : 2.292850
train_step : 5913, loss1 : 2.403193, loss2 : 1.473521
train_step : 5914, loss1 : 0.922299, loss2 : 1.204484
train_step : 5915, loss1 : 1.101658, loss2 : 0.940092
train_step : 5916, loss1 : 1.941790, loss2 : 1.640767
train_step : 5917, loss1 : 1.211763, loss2 : 1.774366
train_step : 5918, loss1 : 1.672863, loss2 : 1.485017
train_step : 5919, loss1 : 1.230908, loss2 : 1.571136
train_step : 5920, loss1 : 1.234154, loss2 : 1.637292
train_step : 5921, loss1 : 1.827870, loss2 : 3.072468
train_step : 5922, loss1 : 2.053862, loss2 : 2.438340
train_step : 5923, loss1 : 2.042384, loss2 : 2.607773
train_step : 5924, loss1 : 1.468776, loss2 : 1.302439
train_step : 5925, loss1 : 0.893477, loss2 : 2.312911
train_step : 5926, loss1 : 2.124360, loss2 : 1.394068
train_step : 5927, loss1 : 1.355226, loss2 : 2.078383
train_step : 5928, loss1 : 3.000477, loss2 : 1.226435
train_step : 5929, loss1 : 2.305219, loss2 : 2.930200
train_step : 5930, loss1 : 3.162410, loss2 : 3.931033
train_step : 5931, loss1 : 2.024834, loss2 : 2.411103
train_step : 5932, loss1 : 2.425962, loss2 : 2.595122
train_step : 5933, loss1 : 2.941637, loss2 : 1.958181
train_step : 5934, loss1 : 2.167549, loss2 : 1.848738
train_step : 5935, loss1 : 2.416978, loss2 : 1.085894
train_step : 5936, loss1 : 2.295181, loss2 : 1.201198
train_step : 5937, loss1 : 0.929852, loss2 : 0.792658
train_step : 5938, loss1 : 0.695974, loss2 : 0.898810
train_step : 5939, loss1 : 1.599360, loss2 : 0.934451
train_step : 5940, loss1 : 0.747097, loss2 : 1.091457
train_step : 5941, loss1 : 0.814998, loss2 : 1.003725
train_step : 5942, loss1 : 1.239280, loss2 : 2.157949
train_step : 5943, loss1 : 1.391372, loss2 : 1.387421
train_step : 5944, loss1 : 1.715322, loss2 : 0.765142
train_step : 5945, loss1 : 1.271859, loss2 : 1.206085
train_step : 5946, loss1 : 1.386177, loss2 : 0.996574
train_step : 5947, loss1 : 1.298874, loss2 : 1.055406
train_step : 5948, loss1 : 1.327312, loss2 : 1.473073
train_step : 5949, loss1 : 1.408218, loss2 : 1.163330
train_step : 5950, loss1 : 0.537319, loss2 : 1.570865
train_step : 5951, loss1 : 1.622006, loss2 : 1.227226
train_step : 5952, loss1 : 2.014996, loss2 : 1.661800
train_step : 5953, loss1 : 2.241257, loss2 : 1.705087
train_step : 5954, loss1 : 0.713687, loss2 : 1.307855
train_step : 5955, loss1 : 0.915706, loss2 : 0.804770
train_step : 5956, loss1 : 0.790114, loss2 : 0.858730
train_step : 5957, loss1 : 1.397915, loss2 : 0.908469
train_step : 5958, loss1 : 2.281474, loss2 : 1.150758
train_step : 5959, loss1 : 1.363259, loss2 : 1.832448
train_step : 5960, loss1 : 1.490741, loss2 : 1.017621
train_step : 5961, loss1 : 0.706542, loss2 : 0.929051
train_step : 5962, loss1 : 1.097493, loss2 : 0.784189
train_step : 5963, loss1 : 1.916796, loss2 : 1.770063
train_step : 5964, loss1 : 1.866710, loss2 : 1.401878
train_step : 5965, loss1 : 1.984994, loss2 : 2.493833
train_step : 5966, loss1 : 0.979844, loss2 : 1.082328
train_step : 5967, loss1 : 0.701334, loss2 : 1.445880
train_step : 5968, loss1 : 1.947423, loss2 : 0.956756
train_step : 5969, loss1 : 1.016940, loss2 : 0.936476
train_step : 5970, loss1 : 0.885427, loss2 : 1.348474
train_step : 5971, loss1 : 0.933886, loss2 : 4.377316
train_step : 5972, loss1 : 1.555679, loss2 : 1.971663
train_step : 5973, loss1 : 1.244330, loss2 : 1.755555
train_step : 5974, loss1 : 2.659893, loss2 : 1.994956
train_step : 5975, loss1 : 1.341421, loss2 : 0.476280
train_step : 5976, loss1 : 0.999029, loss2 : 0.944344
train_step : 5977, loss1 : 0.893188, loss2 : 1.350637
train_step : 5978, loss1 : 1.528981, loss2 : 1.322510
train_step : 5979, loss1 : 0.965474, loss2 : 1.384822
train_step : 5980, loss1 : 1.024661, loss2 : 1.037929
train_step : 5981, loss1 : 0.901458, loss2 : 1.508902
train_step : 5982, loss1 : 1.175937, loss2 : 1.380191
train_step : 5983, loss1 : 1.698079, loss2 : 1.402340
train_step : 5984, loss1 : 1.631149, loss2 : 2.024236
train_step : 5985, loss1 : 1.510537, loss2 : 1.566156
train_step : 5986, loss1 : 1.099545, loss2 : 1.977248
train_step : 5987, loss1 : 1.421011, loss2 : 1.541336
train_step : 5988, loss1 : 1.339616, loss2 : 1.603000
train_step : 5989, loss1 : 1.701024, loss2 : 1.607161
train_step : 5990, loss1 : 0.872162, loss2 : 1.854729
train_step : 5991, loss1 : 1.682711, loss2 : 1.974377
train_step : 5992, loss1 : 1.756288, loss2 : 1.255549
train_step : 5993, loss1 : 1.261555, loss2 : 1.618607
train_step : 5994, loss1 : 1.535177, loss2 : 0.949111
train_step : 5995, loss1 : 1.915182, loss2 : 1.263759
train_step : 5996, loss1 : 0.718748, loss2 : 3.142000
train_step : 5997, loss1 : 1.263164, loss2 : 1.754844
train_step : 5998, loss1 : 1.336881, loss2 : 1.074153
train_step : 5999, loss1 : 1.189465, loss2 : 1.478913
train_step : 6000, loss1 : 0.726263, loss2 : 1.344090
train_step : 6001, loss1 : 1.566732, loss2 : 1.611365
train_step : 6002, loss1 : 0.599415, loss2 : 0.727917
train_step : 6003, loss1 : 1.322425, loss2 : 1.162312
train_step : 6004, loss1 : 1.171633, loss2 : 1.121184
train_step : 6005, loss1 : 0.650650, loss2 : 0.605305
train_step : 6006, loss1 : 1.968156, loss2 : 1.295751
train_step : 6007, loss1 : 0.959921, loss2 : 1.699889
train_step : 6008, loss1 : 2.081460, loss2 : 1.143145
train_step : 6009, loss1 : 1.862106, loss2 : 1.531547
train_step : 6010, loss1 : 0.693892, loss2 : 0.901204
train_step : 6011, loss1 : 1.104052, loss2 : 0.965798
train_step : 6012, loss1 : 1.033496, loss2 : 0.894146
train_step : 6013, loss1 : 0.818389, loss2 : 1.232998
train_step : 6014, loss1 : 1.031143, loss2 : 0.775375
train_step : 6015, loss1 : 1.102301, loss2 : 0.599766
train_step : 6016, loss1 : 0.795062, loss2 : 1.009644
train_step : 6017, loss1 : 1.015409, loss2 : 1.042846
train_step : 6018, loss1 : 1.127523, loss2 : 1.250217
train_step : 6019, loss1 : 1.082446, loss2 : 1.075709
train_step : 6020, loss1 : 0.891387, loss2 : 1.298735
train_step : 6021, loss1 : 1.120793, loss2 : 0.866864
train_step : 6022, loss1 : 1.086912, loss2 : 1.709866
train_step : 6023, loss1 : 0.931638, loss2 : 1.070246
train_step : 6024, loss1 : 1.630503, loss2 : 1.565968
train_step : 6025, loss1 : 1.368403, loss2 : 1.829627
train_step : 6026, loss1 : 1.798220, loss2 : 2.669879
train_step : 6027, loss1 : 1.838353, loss2 : 1.699448
train_step : 6028, loss1 : 1.939415, loss2 : 1.451921
train_step : 6029, loss1 : 2.565209, loss2 : 2.432796
train_step : 6030, loss1 : 3.696215, loss2 : 2.546587
train_step : 6031, loss1 : 1.965092, loss2 : 2.407660
train_step : 6032, loss1 : 1.424014, loss2 : 1.616052
train_step : 6033, loss1 : 1.171931, loss2 : 3.388967
train_step : 6034, loss1 : 1.977754, loss2 : 1.905977
train_step : 6035, loss1 : 1.126467, loss2 : 1.357740
train_step : 6036, loss1 : 2.923097, loss2 : 1.189081
train_step : 6037, loss1 : 1.188757, loss2 : 2.763171
train_step : 6038, loss1 : 2.222805, loss2 : 1.710279
train_step : 6039, loss1 : 1.423521, loss2 : 2.098571
train_step : 6040, loss1 : 0.730539, loss2 : 1.183245
train_step : 6041, loss1 : 0.686945, loss2 : 1.089704
train_step : 6042, loss1 : 1.198867, loss2 : 0.805817
train_step : 6043, loss1 : 1.383533, loss2 : 1.084928
train_step : 6044, loss1 : 1.400969, loss2 : 0.905273
train_step : 6045, loss1 : 2.006989, loss2 : 2.440802
train_step : 6046, loss1 : 2.640378, loss2 : 3.178612
train_step : 6047, loss1 : 3.222292, loss2 : 1.012161
train_step : 6048, loss1 : 1.738012, loss2 : 2.772732
train_step : 6049, loss1 : 3.566045, loss2 : 5.072579
train_step : 6050, loss1 : 6.304406, loss2 : 5.828304
train_step : 6051, loss1 : 4.108656, loss2 : 3.340189
train_step : 6052, loss1 : 4.209719, loss2 : 3.356252
train_step : 6053, loss1 : 2.274141, loss2 : 2.784214
train_step : 6054, loss1 : 3.417140, loss2 : 2.654856
train_step : 6055, loss1 : 1.265550, loss2 : 2.248880
train_step : 6056, loss1 : 0.539815, loss2 : 1.696241
train_step : 6057, loss1 : 1.465959, loss2 : 0.395743
train_step : 6058, loss1 : 1.112604, loss2 : 0.902686
train_step : 6059, loss1 : 2.227315, loss2 : 1.200642
train_step : 6060, loss1 : 0.793804, loss2 : 0.791289
train_step : 6061, loss1 : 0.884981, loss2 : 0.543316
train_step : 6062, loss1 : 1.594635, loss2 : 0.600838
train_step : 6063, loss1 : 1.070650, loss2 : 0.993667
train_step : 6064, loss1 : 1.687472, loss2 : 1.515225
train_step : 6065, loss1 : 1.106510, loss2 : 1.886392
train_step : 6066, loss1 : 1.748199, loss2 : 1.360955
train_step : 6067, loss1 : 2.090308, loss2 : 2.846275
train_step : 6068, loss1 : 2.904696, loss2 : 1.682830
train_step : 6069, loss1 : 1.546955, loss2 : 2.318302
train_step : 6070, loss1 : 1.768121, loss2 : 1.890568
train_step : 6071, loss1 : 1.883079, loss2 : 1.405525
train_step : 6072, loss1 : 1.555124, loss2 : 1.249891
train_step : 6073, loss1 : 1.536594, loss2 : 1.030506
train_step : 6074, loss1 : 1.663329, loss2 : 1.130013
train_step : 6075, loss1 : 0.854041, loss2 : 1.633008
train_step : 6076, loss1 : 0.850338, loss2 : 0.938751
train_step : 6077, loss1 : 1.766891, loss2 : 1.723215
train_step : 6078, loss1 : 0.907832, loss2 : 0.814491
train_step : 6079, loss1 : 1.211388, loss2 : 1.137163
train_step : 6080, loss1 : 1.000125, loss2 : 1.094209
train_step : 6081, loss1 : 1.673248, loss2 : 1.212660
train_step : 6082, loss1 : 1.959968, loss2 : 1.240062
train_step : 6083, loss1 : 1.592567, loss2 : 1.090491
train_step : 6084, loss1 : 1.414218, loss2 : 1.373679
train_step : 6085, loss1 : 0.687930, loss2 : 1.408540
train_step : 6086, loss1 : 1.259634, loss2 : 0.579358
train_step : 6087, loss1 : 1.092259, loss2 : 1.812643
train_step : 6088, loss1 : 1.044625, loss2 : 2.588804
train_step : 6089, loss1 : 1.780414, loss2 : 1.877826
train_step : 6090, loss1 : 1.179918, loss2 : 1.568633
train_step : 6091, loss1 : 0.542406, loss2 : 1.243760
train_step : 6092, loss1 : 0.951813, loss2 : 1.266248
train_step : 6093, loss1 : 0.858316, loss2 : 0.935690
train_step : 6094, loss1 : 0.957730, loss2 : 1.158640
train_step : 6095, loss1 : 2.017477, loss2 : 1.879895
train_step : 6096, loss1 : 0.680796, loss2 : 1.270165
train_step : 6097, loss1 : 1.226271, loss2 : 1.146715
train_step : 6098, loss1 : 0.946183, loss2 : 1.237629
train_step : 6099, loss1 : 0.571016, loss2 : 0.659330
train_step : 6100, loss1 : 1.526357, loss2 : 1.166006
train_step : 6101, loss1 : 0.903396, loss2 : 1.224640
train_step : 6102, loss1 : 0.907854, loss2 : 1.230521
train_step : 6103, loss1 : 1.127043, loss2 : 1.851959
train_step : 6104, loss1 : 1.797268, loss2 : 1.979954
train_step : 6105, loss1 : 1.985277, loss2 : 2.047729
train_step : 6106, loss1 : 1.797619, loss2 : 1.077191
train_step : 6107, loss1 : 1.647401, loss2 : 0.932813
train_step : 6108, loss1 : 2.126287, loss2 : 1.222489
train_step : 6109, loss1 : 2.078865, loss2 : 2.865438
train_step : 6110, loss1 : 1.829605, loss2 : 2.756876
train_step : 6111, loss1 : 2.452404, loss2 : 2.668365
train_step : 6112, loss1 : 2.892997, loss2 : 1.603217
train_step : 6113, loss1 : 2.986823, loss2 : 2.986894
train_step : 6114, loss1 : 4.028618, loss2 : 3.048533
train_step : 6115, loss1 : 3.775826, loss2 : 1.841869
train_step : 6116, loss1 : 2.606376, loss2 : 1.719970
train_step : 6117, loss1 : 3.857779, loss2 : 3.353297
train_step : 6118, loss1 : 2.850327, loss2 : 2.876815
train_step : 6119, loss1 : 2.381588, loss2 : 2.967344
train_step : 6120, loss1 : 1.704426, loss2 : 1.924851
train_step : 6121, loss1 : 2.008771, loss2 : 2.264133
train_step : 6122, loss1 : 1.864366, loss2 : 2.145363
train_step : 6123, loss1 : 1.842100, loss2 : 1.430480
train_step : 6124, loss1 : 1.349481, loss2 : 1.094349
train_step : 6125, loss1 : 0.833936, loss2 : 1.165914
train_step : 6126, loss1 : 1.027228, loss2 : 2.389085
train_step : 6127, loss1 : 1.147370, loss2 : 1.035234
train_step : 6128, loss1 : 1.596591, loss2 : 1.257780
train_step : 6129, loss1 : 1.635940, loss2 : 1.210990
train_step : 6130, loss1 : 1.837950, loss2 : 0.970732
train_step : 6131, loss1 : 1.269906, loss2 : 1.830460
train_step : 6132, loss1 : 1.451123, loss2 : 1.258377
train_step : 6133, loss1 : 1.875171, loss2 : 0.976742
train_step : 6134, loss1 : 1.402758, loss2 : 2.730956
train_step : 6135, loss1 : 1.151835, loss2 : 1.826715
train_step : 6136, loss1 : 1.204195, loss2 : 3.204906
train_step : 6137, loss1 : 0.919938, loss2 : 1.255660
train_step : 6138, loss1 : 1.057976, loss2 : 1.021291
train_step : 6139, loss1 : 1.653398, loss2 : 2.620101
train_step : 6140, loss1 : 0.741553, loss2 : 1.005429
train_step : 6141, loss1 : 0.874387, loss2 : 1.618619
train_step : 6142, loss1 : 1.329467, loss2 : 0.737822
train_step : 6143, loss1 : 0.782866, loss2 : 0.524599
train_step : 6144, loss1 : 1.628327, loss2 : 1.586769
train_step : 6145, loss1 : 2.373663, loss2 : 2.232841
train_step : 6146, loss1 : 1.502727, loss2 : 1.821806
train_step : 6147, loss1 : 1.452869, loss2 : 1.054188
train_step : 6148, loss1 : 0.905426, loss2 : 1.556554
train_step : 6149, loss1 : 1.226615, loss2 : 0.963180
train_step : 6150, loss1 : 1.144777, loss2 : 1.687364
train_step : 6151, loss1 : 2.550692, loss2 : 2.981353
train_step : 6152, loss1 : 1.451948, loss2 : 1.049224
train_step : 6153, loss1 : 1.616177, loss2 : 2.332657
train_step : 6154, loss1 : 1.149584, loss2 : 1.860530
train_step : 6155, loss1 : 1.237173, loss2 : 1.792759
train_step : 6156, loss1 : 1.685394, loss2 : 1.206469
train_step : 6157, loss1 : 0.730460, loss2 : 1.253017
train_step : 6158, loss1 : 0.453399, loss2 : 0.639964
train_step : 6159, loss1 : 1.541925, loss2 : 1.165480
train_step : 6160, loss1 : 1.012836, loss2 : 1.135899
train_step : 6161, loss1 : 1.477211, loss2 : 1.457732
train_step : 6162, loss1 : 0.922928, loss2 : 1.708812
train_step : 6163, loss1 : 2.486091, loss2 : 2.179321
train_step : 6164, loss1 : 2.536719, loss2 : 4.293999
train_step : 6165, loss1 : 2.903689, loss2 : 2.788251
train_step : 6166, loss1 : 1.506839, loss2 : 1.690042
train_step : 6167, loss1 : 1.562295, loss2 : 1.060998
train_step : 6168, loss1 : 0.615521, loss2 : 0.483737
train_step : 6169, loss1 : 1.304068, loss2 : 0.849858
train_step : 6170, loss1 : 0.992922, loss2 : 1.565561
train_step : 6171, loss1 : 1.001041, loss2 : 1.685760
train_step : 6172, loss1 : 1.083773, loss2 : 1.056058
train_step : 6173, loss1 : 1.368492, loss2 : 0.644396
train_step : 6174, loss1 : 1.445090, loss2 : 1.840196
train_step : 6175, loss1 : 1.723377, loss2 : 1.329544
train_step : 6176, loss1 : 1.929409, loss2 : 2.029457
train_step : 6177, loss1 : 3.752382, loss2 : 1.488544
train_step : 6178, loss1 : 2.078917, loss2 : 1.755884
train_step : 6179, loss1 : 1.504798, loss2 : 2.480691
train_step : 6180, loss1 : 2.436891, loss2 : 2.920716
train_step : 6181, loss1 : 3.046600, loss2 : 3.317544
train_step : 6182, loss1 : 1.785256, loss2 : 1.642126
train_step : 6183, loss1 : 1.751153, loss2 : 2.171642
train_step : 6184, loss1 : 3.549048, loss2 : 2.617165
train_step : 6185, loss1 : 4.491920, loss2 : 4.667957
train_step : 6186, loss1 : 3.193070, loss2 : 2.080066
train_step : 6187, loss1 : 2.103252, loss2 : 0.815336
train_step : 6188, loss1 : 1.717571, loss2 : 1.430001
train_step : 6189, loss1 : 1.452943, loss2 : 1.557606
train_step : 6190, loss1 : 1.097317, loss2 : 1.430736
train_step : 6191, loss1 : 1.823835, loss2 : 1.332344
train_step : 6192, loss1 : 1.930017, loss2 : 1.806548
train_step : 6193, loss1 : 1.037401, loss2 : 1.024100
train_step : 6194, loss1 : 0.902903, loss2 : 2.419339
train_step : 6195, loss1 : 1.783907, loss2 : 2.275556
train_step : 6196, loss1 : 1.609724, loss2 : 1.341861
train_step : 6197, loss1 : 1.644571, loss2 : 2.044117
train_step : 6198, loss1 : 2.785557, loss2 : 2.723522
train_step : 6199, loss1 : 3.182614, loss2 : 2.336589
train_step : 6200, loss1 : 1.920330, loss2 : 0.896944
train_step : 6201, loss1 : 0.945022, loss2 : 1.085612
train_step : 6202, loss1 : 1.089630, loss2 : 2.401263
train_step : 6203, loss1 : 1.635961, loss2 : 0.922688
train_step : 6204, loss1 : 1.737911, loss2 : 2.039602
train_step : 6205, loss1 : 0.923094, loss2 : 0.899044
train_step : 6206, loss1 : 0.776389, loss2 : 0.686625
train_step : 6207, loss1 : 1.185799, loss2 : 0.819886
train_step : 6208, loss1 : 1.136803, loss2 : 0.684623
train_step : 6209, loss1 : 1.299673, loss2 : 0.737707
train_step : 6210, loss1 : 1.664039, loss2 : 0.815339
train_step : 6211, loss1 : 0.772106, loss2 : 0.960623
train_step : 6212, loss1 : 1.733783, loss2 : 1.001549
train_step : 6213, loss1 : 1.042885, loss2 : 1.914473
train_step : 6214, loss1 : 0.642788, loss2 : 0.873589
train_step : 6215, loss1 : 0.783388, loss2 : 0.769948
train_step : 6216, loss1 : 1.708812, loss2 : 1.591832
train_step : 6217, loss1 : 1.191115, loss2 : 1.001496
train_step : 6218, loss1 : 0.943706, loss2 : 1.511793
train_step : 6219, loss1 : 1.670733, loss2 : 1.185665
train_step : 6220, loss1 : 0.751599, loss2 : 1.047375
train_step : 6221, loss1 : 0.892716, loss2 : 1.170981
train_step : 6222, loss1 : 0.791062, loss2 : 1.544741
train_step : 6223, loss1 : 1.167394, loss2 : 1.125663
train_step : 6224, loss1 : 1.256902, loss2 : 1.197547
train_step : 6225, loss1 : 0.928469, loss2 : 0.908855
train_step : 6226, loss1 : 1.258091, loss2 : 1.008355
train_step : 6227, loss1 : 0.464754, loss2 : 0.882069
train_step : 6228, loss1 : 1.506201, loss2 : 0.856263
train_step : 6229, loss1 : 0.584437, loss2 : 1.563753
train_step : 6230, loss1 : 1.386679, loss2 : 0.998126
train_step : 6231, loss1 : 0.705138, loss2 : 1.848623
train_step : 6232, loss1 : 0.922501, loss2 : 1.573241
train_step : 6233, loss1 : 3.841944, loss2 : 1.878814
train_step : 6234, loss1 : 1.562648, loss2 : 0.748933
train_step : 6235, loss1 : 1.063948, loss2 : 1.632670
train_step : 6236, loss1 : 1.248838, loss2 : 1.274313
train_step : 6237, loss1 : 1.184428, loss2 : 1.559677
train_step : 6238, loss1 : 0.902099, loss2 : 1.458972
train_step : 6239, loss1 : 1.914518, loss2 : 1.199407
train_step : 6240, loss1 : 1.209825, loss2 : 1.258299
train_step : 6241, loss1 : 1.160498, loss2 : 1.443051
train_step : 6242, loss1 : 1.456764, loss2 : 1.306918
train_step : 6243, loss1 : 1.547026, loss2 : 1.733615
train_step : 6244, loss1 : 1.167708, loss2 : 1.857888
train_step : 6245, loss1 : 1.508830, loss2 : 1.672026
train_step : 6246, loss1 : 1.726039, loss2 : 1.689319
train_step : 6247, loss1 : 1.288667, loss2 : 0.931011
train_step : 6248, loss1 : 1.535184, loss2 : 1.483279
train_step : 6249, loss1 : 1.197846, loss2 : 1.281692
train_step : 6250, loss1 : 1.600688, loss2 : 3.029244
train_step : 6251, loss1 : 1.833500, loss2 : 1.373234
train_step : 6252, loss1 : 0.966198, loss2 : 1.331100
train_step : 6253, loss1 : 0.984488, loss2 : 1.560022
train_step : 6254, loss1 : 1.830450, loss2 : 0.649684
train_step : 6255, loss1 : 2.350369, loss2 : 0.648868
train_step : 6256, loss1 : 1.748857, loss2 : 1.303775
train_step : 6257, loss1 : 2.247184, loss2 : 4.172156
train_step : 6258, loss1 : 2.450806, loss2 : 2.662367
train_step : 6259, loss1 : 2.357826, loss2 : 2.191034
train_step : 6260, loss1 : 1.645767, loss2 : 0.917422
train_step : 6261, loss1 : 1.198885, loss2 : 1.460408
train_step : 6262, loss1 : 0.491561, loss2 : 0.985664
train_step : 6263, loss1 : 0.976992, loss2 : 1.259882
train_step : 6264, loss1 : 1.401343, loss2 : 1.323614
train_step : 6265, loss1 : 0.980464, loss2 : 1.158840
train_step : 6266, loss1 : 2.310995, loss2 : 0.614255
train_step : 6267, loss1 : 1.797095, loss2 : 1.404422
train_step : 6268, loss1 : 1.225234, loss2 : 0.808159
train_step : 6269, loss1 : 1.043164, loss2 : 0.853058
train_step : 6270, loss1 : 0.932460, loss2 : 1.298849
train_step : 6271, loss1 : 1.257159, loss2 : 1.654963
train_step : 6272, loss1 : 1.974944, loss2 : 2.229183
train_step : 6273, loss1 : 1.517271, loss2 : 3.165606
train_step : 6274, loss1 : 1.847706, loss2 : 1.690534
train_step : 6275, loss1 : 5.212004, loss2 : 2.034249
train_step : 6276, loss1 : 2.025625, loss2 : 1.543540
train_step : 6277, loss1 : 2.411933, loss2 : 1.616503
train_step : 6278, loss1 : 1.528839, loss2 : 2.185681
train_step : 6279, loss1 : 1.666706, loss2 : 0.525009
train_step : 6280, loss1 : 0.960575, loss2 : 1.313887
train_step : 6281, loss1 : 1.435027, loss2 : 0.883533
train_step : 6282, loss1 : 0.832631, loss2 : 1.049785
train_step : 6283, loss1 : 1.013541, loss2 : 1.299207
train_step : 6284, loss1 : 1.491135, loss2 : 2.010779
train_step : 6285, loss1 : 0.722143, loss2 : 0.542401
train_step : 6286, loss1 : 1.198252, loss2 : 1.884347
train_step : 6287, loss1 : 1.427577, loss2 : 1.612561
train_step : 6288, loss1 : 2.502261, loss2 : 1.192802
train_step : 6289, loss1 : 2.224863, loss2 : 2.102918
train_step : 6290, loss1 : 2.284090, loss2 : 3.071835
train_step : 6291, loss1 : 2.222704, loss2 : 3.206347
train_step : 6292, loss1 : 1.466118, loss2 : 1.433447
train_step : 6293, loss1 : 0.685019, loss2 : 1.064113
train_step : 6294, loss1 : 1.083357, loss2 : 0.761662
train_step : 6295, loss1 : 0.715037, loss2 : 1.250134
train_step : 6296, loss1 : 0.832921, loss2 : 1.493821
train_step : 6297, loss1 : 0.756528, loss2 : 0.749355
train_step : 6298, loss1 : 1.693697, loss2 : 1.673253
train_step : 6299, loss1 : 1.504551, loss2 : 1.501353
train_step : 6300, loss1 : 1.421154, loss2 : 1.181111
train_step : 6301, loss1 : 0.927118, loss2 : 1.218677
train_step : 6302, loss1 : 1.063649, loss2 : 1.123193
train_step : 6303, loss1 : 1.549674, loss2 : 0.982007
train_step : 6304, loss1 : 0.988758, loss2 : 2.054166
train_step : 6305, loss1 : 1.487853, loss2 : 1.920716
train_step : 6306, loss1 : 1.882898, loss2 : 2.120324
train_step : 6307, loss1 : 1.876366, loss2 : 1.476052
train_step : 6308, loss1 : 1.222602, loss2 : 1.366116
train_step : 6309, loss1 : 2.356749, loss2 : 1.373001
train_step : 6310, loss1 : 1.924632, loss2 : 1.223297
train_step : 6311, loss1 : 1.643231, loss2 : 1.468448
train_step : 6312, loss1 : 0.859963, loss2 : 0.577062
train_step : 6313, loss1 : 0.831720, loss2 : 1.780211
train_step : 6314, loss1 : 1.229894, loss2 : 1.349760
train_step : 6315, loss1 : 1.250308, loss2 : 1.387070
train_step : 6316, loss1 : 0.960261, loss2 : 0.924309
train_step : 6317, loss1 : 1.559075, loss2 : 0.975456
train_step : 6318, loss1 : 1.935823, loss2 : 1.521703
train_step : 6319, loss1 : 2.105031, loss2 : 1.166142
train_step : 6320, loss1 : 0.817164, loss2 : 1.140493
train_step : 6321, loss1 : 1.357241, loss2 : 0.941901
train_step : 6322, loss1 : 1.001966, loss2 : 1.058249
train_step : 6323, loss1 : 1.338206, loss2 : 1.796243
train_step : 6324, loss1 : 1.189306, loss2 : 0.827678
train_step : 6325, loss1 : 1.372857, loss2 : 1.011349
train_step : 6326, loss1 : 1.012855, loss2 : 1.660321
train_step : 6327, loss1 : 0.830287, loss2 : 0.813320
train_step : 6328, loss1 : 1.144630, loss2 : 1.586844
train_step : 6329, loss1 : 1.644485, loss2 : 1.781861
train_step : 6330, loss1 : 0.991856, loss2 : 1.825027
train_step : 6331, loss1 : 0.863949, loss2 : 0.960615
train_step : 6332, loss1 : 0.756327, loss2 : 2.189789
train_step : 6333, loss1 : 1.474877, loss2 : 1.113386
train_step : 6334, loss1 : 1.388832, loss2 : 1.238969
train_step : 6335, loss1 : 2.076324, loss2 : 0.909832
train_step : 6336, loss1 : 1.397907, loss2 : 0.819281
train_step : 6337, loss1 : 1.155623, loss2 : 1.014058
train_step : 6338, loss1 : 1.366125, loss2 : 1.764093
train_step : 6339, loss1 : 1.402247, loss2 : 0.601959
train_step : 6340, loss1 : 1.472881, loss2 : 1.045772
train_step : 6341, loss1 : 1.056180, loss2 : 0.761899
train_step : 6342, loss1 : 0.769000, loss2 : 1.075521
train_step : 6343, loss1 : 1.902395, loss2 : 1.019425
train_step : 6344, loss1 : 2.188441, loss2 : 1.722106
train_step : 6345, loss1 : 1.934669, loss2 : 1.683007
train_step : 6346, loss1 : 1.312930, loss2 : 1.098225
train_step : 6347, loss1 : 1.691315, loss2 : 1.175711
train_step : 6348, loss1 : 1.921207, loss2 : 0.697099
train_step : 6349, loss1 : 1.736779, loss2 : 1.059016
train_step : 6350, loss1 : 1.718241, loss2 : 1.749728
train_step : 6351, loss1 : 1.971380, loss2 : 1.306462
train_step : 6352, loss1 : 1.843562, loss2 : 1.407034
train_step : 6353, loss1 : 1.262926, loss2 : 1.215397
train_step : 6354, loss1 : 2.442361, loss2 : 2.402775
train_step : 6355, loss1 : 5.298255, loss2 : 2.692137
train_step : 6356, loss1 : 1.807537, loss2 : 2.338437
train_step : 6357, loss1 : 2.921642, loss2 : 2.114163
train_step : 6358, loss1 : 3.855142, loss2 : 3.248675
train_step : 6359, loss1 : 2.152070, loss2 : 3.523586
train_step : 6360, loss1 : 1.920286, loss2 : 3.146700
train_step : 6361, loss1 : 1.705913, loss2 : 2.722891
train_step : 6362, loss1 : 2.730801, loss2 : 1.834909
train_step : 6363, loss1 : 1.893816, loss2 : 2.091768
train_step : 6364, loss1 : 1.970052, loss2 : 0.838382
train_step : 6365, loss1 : 1.685961, loss2 : 1.035447
train_step : 6366, loss1 : 0.699634, loss2 : 1.429033
train_step : 6367, loss1 : 0.974938, loss2 : 0.960148
train_step : 6368, loss1 : 0.702707, loss2 : 0.707345
train_step : 6369, loss1 : 1.868485, loss2 : 1.350781
train_step : 6370, loss1 : 3.370857, loss2 : 1.599324
train_step : 6371, loss1 : 3.327360, loss2 : 4.082332
train_step : 6372, loss1 : 3.480715, loss2 : 3.163499
train_step : 6373, loss1 : 4.024666, loss2 : 3.586828
train_step : 6374, loss1 : 2.389063, loss2 : 3.065440
train_step : 6375, loss1 : 2.934022, loss2 : 1.791685
train_step : 6376, loss1 : 1.917592, loss2 : 1.419718
train_step : 6377, loss1 : 1.992173, loss2 : 2.085519
train_step : 6378, loss1 : 1.653030, loss2 : 1.218517
train_step : 6379, loss1 : 2.131231, loss2 : 1.270507
train_step : 6380, loss1 : 0.790259, loss2 : 1.421089
train_step : 6381, loss1 : 1.599304, loss2 : 2.067788
train_step : 6382, loss1 : 2.251819, loss2 : 1.407788
train_step : 6383, loss1 : 0.971852, loss2 : 1.124272
train_step : 6384, loss1 : 0.842186, loss2 : 1.030350
train_step : 6385, loss1 : 1.443305, loss2 : 1.349996
train_step : 6386, loss1 : 1.347898, loss2 : 1.002621
train_step : 6387, loss1 : 1.267253, loss2 : 1.141930
train_step : 6388, loss1 : 1.184838, loss2 : 1.778010
train_step : 6389, loss1 : 0.991677, loss2 : 1.959360
train_step : 6390, loss1 : 0.721502, loss2 : 0.799289
train_step : 6391, loss1 : 0.921860, loss2 : 1.006060
train_step : 6392, loss1 : 1.860727, loss2 : 2.472134
train_step : 6393, loss1 : 1.317065, loss2 : 1.498099
train_step : 6394, loss1 : 2.157875, loss2 : 1.413697
train_step : 6395, loss1 : 1.431457, loss2 : 1.241064
train_step : 6396, loss1 : 0.672689, loss2 : 1.201142
train_step : 6397, loss1 : 2.084809, loss2 : 0.642840
train_step : 6398, loss1 : 0.970623, loss2 : 1.277341
train_step : 6399, loss1 : 1.599936, loss2 : 0.890706
train_step : 6400, loss1 : 1.364467, loss2 : 0.891848
train_step : 6401, loss1 : 0.993844, loss2 : 0.496447
train_step : 6402, loss1 : 1.081274, loss2 : 0.847537
train_step : 6403, loss1 : 1.495764, loss2 : 1.314877
train_step : 6404, loss1 : 1.781883, loss2 : 1.088246
train_step : 6405, loss1 : 0.647226, loss2 : 0.864804
train_step : 6406, loss1 : 1.254948, loss2 : 0.555881
train_step : 6407, loss1 : 1.574439, loss2 : 1.461872
train_step : 6408, loss1 : 2.213520, loss2 : 2.145781
train_step : 6409, loss1 : 3.048157, loss2 : 2.285372
train_step : 6410, loss1 : 4.412227, loss2 : 2.380064
train_step : 6411, loss1 : 4.573487, loss2 : 2.955895
train_step : 6412, loss1 : 3.840747, loss2 : 4.647862
train_step : 6413, loss1 : 3.919414, loss2 : 3.425058
train_step : 6414, loss1 : 4.077077, loss2 : 3.801136
train_step : 6415, loss1 : 2.886561, loss2 : 2.093636
train_step : 6416, loss1 : 2.342105, loss2 : 2.440120
train_step : 6417, loss1 : 0.661148, loss2 : 1.177593
train_step : 6418, loss1 : 1.265404, loss2 : 0.935330
train_step : 6419, loss1 : 0.699041, loss2 : 1.074298
train_step : 6420, loss1 : 1.242490, loss2 : 1.387481
train_step : 6421, loss1 : 1.628654, loss2 : 1.764434
train_step : 6422, loss1 : 2.527279, loss2 : 2.002081
train_step : 6423, loss1 : 1.923267, loss2 : 1.640837
train_step : 6424, loss1 : 1.301177, loss2 : 2.051150
train_step : 6425, loss1 : 2.094478, loss2 : 2.128139
train_step : 6426, loss1 : 0.915142, loss2 : 2.935601
train_step : 6427, loss1 : 1.913455, loss2 : 1.976021
train_step : 6428, loss1 : 1.734767, loss2 : 1.783801
train_step : 6429, loss1 : 1.704326, loss2 : 1.155675
train_step : 6430, loss1 : 1.356739, loss2 : 1.501227
train_step : 6431, loss1 : 0.771274, loss2 : 1.462233
train_step : 6432, loss1 : 1.548064, loss2 : 1.107561
train_step : 6433, loss1 : 1.674314, loss2 : 1.268201
train_step : 6434, loss1 : 0.826393, loss2 : 1.172004
train_step : 6435, loss1 : 1.120813, loss2 : 2.020924
train_step : 6436, loss1 : 1.458249, loss2 : 1.281595
train_step : 6437, loss1 : 1.594872, loss2 : 1.966712
train_step : 6438, loss1 : 2.613938, loss2 : 1.529924
train_step : 6439, loss1 : 2.797500, loss2 : 2.626232
train_step : 6440, loss1 : 2.393577, loss2 : 3.449165
train_step : 6441, loss1 : 1.371435, loss2 : 2.630550
train_step : 6442, loss1 : 1.557712, loss2 : 1.666988
train_step : 6443, loss1 : 1.166785, loss2 : 1.284962
train_step : 6444, loss1 : 1.782958, loss2 : 1.043985
train_step : 6445, loss1 : 0.984183, loss2 : 1.457658
train_step : 6446, loss1 : 1.121158, loss2 : 0.935452
train_step : 6447, loss1 : 1.502831, loss2 : 1.239969
train_step : 6448, loss1 : 1.894543, loss2 : 1.181075
train_step : 6449, loss1 : 0.713219, loss2 : 1.081852
train_step : 6450, loss1 : 1.040972, loss2 : 1.932117
train_step : 6451, loss1 : 2.661758, loss2 : 2.246144
train_step : 6452, loss1 : 2.003954, loss2 : 3.268436
train_step : 6453, loss1 : 1.460740, loss2 : 0.735897
train_step : 6454, loss1 : 0.894241, loss2 : 0.976624
train_step : 6455, loss1 : 1.712284, loss2 : 1.585211
train_step : 6456, loss1 : 1.190331, loss2 : 1.442684
train_step : 6457, loss1 : 1.092407, loss2 : 1.092569
train_step : 6458, loss1 : 1.063028, loss2 : 1.127358
train_step : 6459, loss1 : 1.400439, loss2 : 1.166106
train_step : 6460, loss1 : 1.387774, loss2 : 2.387381
train_step : 6461, loss1 : 1.824872, loss2 : 0.986953
train_step : 6462, loss1 : 1.739201, loss2 : 1.423233
train_step : 6463, loss1 : 1.643091, loss2 : 1.370384
train_step : 6464, loss1 : 1.360426, loss2 : 1.020872
train_step : 6465, loss1 : 1.791968, loss2 : 1.007511
train_step : 6466, loss1 : 1.411131, loss2 : 0.911648
train_step : 6467, loss1 : 0.982353, loss2 : 0.838095
train_step : 6468, loss1 : 1.543503, loss2 : 1.266509
train_step : 6469, loss1 : 0.914933, loss2 : 1.350203
train_step : 6470, loss1 : 0.754828, loss2 : 1.868108
train_step : 6471, loss1 : 2.179076, loss2 : 0.849725
train_step : 6472, loss1 : 1.753212, loss2 : 1.513297
train_step : 6473, loss1 : 1.609236, loss2 : 1.003441
train_step : 6474, loss1 : 0.951656, loss2 : 0.947089
train_step : 6475, loss1 : 1.067019, loss2 : 3.532089
train_step : 6476, loss1 : 1.649922, loss2 : 0.933602
train_step : 6477, loss1 : 1.159491, loss2 : 1.539041
train_step : 6478, loss1 : 1.238566, loss2 : 1.446713
train_step : 6479, loss1 : 0.944026, loss2 : 1.157754
train_step : 6480, loss1 : 1.128453, loss2 : 2.224098
train_step : 6481, loss1 : 1.456441, loss2 : 1.957333
train_step : 6482, loss1 : 1.444870, loss2 : 2.245470
train_step : 6483, loss1 : 0.542739, loss2 : 1.009054
train_step : 6484, loss1 : 1.176941, loss2 : 0.766387
train_step : 6485, loss1 : 0.913845, loss2 : 0.641951
train_step : 6486, loss1 : 1.092522, loss2 : 1.322308
train_step : 6487, loss1 : 0.901796, loss2 : 1.809580
train_step : 6488, loss1 : 1.067866, loss2 : 1.086925
train_step : 6489, loss1 : 1.497205, loss2 : 1.176289
train_step : 6490, loss1 : 1.766327, loss2 : 1.077247
train_step : 6491, loss1 : 0.856670, loss2 : 4.003500
train_step : 6492, loss1 : 0.701433, loss2 : 2.551813
train_step : 6493, loss1 : 1.940648, loss2 : 1.773262
train_step : 6494, loss1 : 2.216142, loss2 : 2.667108
train_step : 6495, loss1 : 3.807522, loss2 : 2.509025
train_step : 6496, loss1 : 3.167620, loss2 : 3.789272
train_step : 6497, loss1 : 2.179428, loss2 : 1.750470
train_step : 6498, loss1 : 1.952036, loss2 : 1.995859
train_step : 6499, loss1 : 1.263916, loss2 : 2.056333
train_step : 6500, loss1 : 1.713017, loss2 : 1.543260
train_step : 6501, loss1 : 1.521694, loss2 : 1.783755
train_step : 6502, loss1 : 1.495951, loss2 : 1.889337
train_step : 6503, loss1 : 1.751557, loss2 : 0.833429
train_step : 6504, loss1 : 0.825455, loss2 : 1.561183
train_step : 6505, loss1 : 1.002376, loss2 : 1.748157
train_step : 6506, loss1 : 1.056575, loss2 : 0.940719
train_step : 6507, loss1 : 0.886702, loss2 : 0.647655
train_step : 6508, loss1 : 1.036864, loss2 : 0.948068
train_step : 6509, loss1 : 1.058201, loss2 : 0.719775
train_step : 6510, loss1 : 1.058200, loss2 : 1.003813
train_step : 6511, loss1 : 0.739948, loss2 : 1.198268
train_step : 6512, loss1 : 1.064056, loss2 : 1.418036
train_step : 6513, loss1 : 1.082366, loss2 : 1.207846
train_step : 6514, loss1 : 0.749933, loss2 : 2.602690
train_step : 6515, loss1 : 0.910408, loss2 : 0.591420
train_step : 6516, loss1 : 1.478896, loss2 : 1.004854
train_step : 6517, loss1 : 0.987324, loss2 : 1.228836
train_step : 6518, loss1 : 1.477756, loss2 : 1.270926
train_step : 6519, loss1 : 1.165825, loss2 : 1.104667
train_step : 6520, loss1 : 1.504864, loss2 : 1.585260
train_step : 6521, loss1 : 0.587519, loss2 : 0.682034
train_step : 6522, loss1 : 0.889571, loss2 : 2.047958
train_step : 6523, loss1 : 1.797350, loss2 : 2.212455
train_step : 6524, loss1 : 1.806237, loss2 : 0.993638
train_step : 6525, loss1 : 2.739940, loss2 : 1.970115
train_step : 6526, loss1 : 2.957798, loss2 : 3.010067
train_step : 6527, loss1 : 2.542531, loss2 : 2.360168
train_step : 6528, loss1 : 1.488684, loss2 : 2.127175
train_step : 6529, loss1 : 3.017637, loss2 : 3.012806
train_step : 6530, loss1 : 2.954710, loss2 : 2.113634
train_step : 6531, loss1 : 0.973744, loss2 : 0.883686
train_step : 6532, loss1 : 1.096741, loss2 : 0.624034
train_step : 6533, loss1 : 1.271261, loss2 : 0.857346
train_step : 6534, loss1 : 1.391153, loss2 : 1.947074
train_step : 6535, loss1 : 1.314405, loss2 : 2.023148
train_step : 6536, loss1 : 1.317846, loss2 : 1.178614
train_step : 6537, loss1 : 1.233637, loss2 : 1.211010
train_step : 6538, loss1 : 1.462511, loss2 : 0.740685
train_step : 6539, loss1 : 1.783008, loss2 : 1.865159
train_step : 6540, loss1 : 1.936632, loss2 : 1.462584
train_step : 6541, loss1 : 1.562764, loss2 : 2.998292
train_step : 6542, loss1 : 2.114134, loss2 : 1.697834
train_step : 6543, loss1 : 1.652240, loss2 : 1.788411
train_step : 6544, loss1 : 2.566801, loss2 : 0.966955
train_step : 6545, loss1 : 1.587995, loss2 : 0.988229
train_step : 6546, loss1 : 2.189409, loss2 : 2.173532
train_step : 6547, loss1 : 2.091147, loss2 : 2.054426
train_step : 6548, loss1 : 0.931198, loss2 : 1.068932
train_step : 6549, loss1 : 1.302243, loss2 : 1.299813
train_step : 6550, loss1 : 1.627101, loss2 : 0.733353
train_step : 6551, loss1 : 1.843101, loss2 : 1.970891
train_step : 6552, loss1 : 2.175826, loss2 : 3.347918
train_step : 6553, loss1 : 3.090243, loss2 : 3.298934
train_step : 6554, loss1 : 2.655503, loss2 : 2.190659
train_step : 6555, loss1 : 2.490117, loss2 : 3.065855
train_step : 6556, loss1 : 1.372571, loss2 : 2.432963
train_step : 6557, loss1 : 1.258686, loss2 : 1.301454
train_step : 6558, loss1 : 1.219392, loss2 : 1.406921
train_step : 6559, loss1 : 1.491801, loss2 : 1.504669
train_step : 6560, loss1 : 1.390916, loss2 : 1.368461
train_step : 6561, loss1 : 1.771769, loss2 : 1.365090
train_step : 6562, loss1 : 1.790971, loss2 : 1.578868
train_step : 6563, loss1 : 1.597642, loss2 : 1.643033
train_step : 6564, loss1 : 2.059793, loss2 : 2.506587
train_step : 6565, loss1 : 1.575404, loss2 : 1.319014
train_step : 6566, loss1 : 1.106552, loss2 : 0.953951
train_step : 6567, loss1 : 2.256495, loss2 : 2.603166
train_step : 6568, loss1 : 3.157649, loss2 : 1.415444
train_step : 6569, loss1 : 2.537080, loss2 : 2.673042
train_step : 6570, loss1 : 2.549956, loss2 : 1.560839
train_step : 6571, loss1 : 2.076379, loss2 : 1.569054
train_step : 6572, loss1 : 1.469979, loss2 : 3.332914
train_step : 6573, loss1 : 1.716203, loss2 : 2.806743
train_step : 6574, loss1 : 2.392757, loss2 : 3.581748
train_step : 6575, loss1 : 1.969610, loss2 : 2.540404
train_step : 6576, loss1 : 3.247862, loss2 : 2.800694
train_step : 6577, loss1 : 2.111786, loss2 : 3.669070
train_step : 6578, loss1 : 1.881930, loss2 : 0.899998
train_step : 6579, loss1 : 1.521225, loss2 : 1.701293
train_step : 6580, loss1 : 1.662005, loss2 : 1.558030
train_step : 6581, loss1 : 2.075071, loss2 : 1.876608
train_step : 6582, loss1 : 1.427260, loss2 : 1.889810
train_step : 6583, loss1 : 1.366229, loss2 : 1.850939
train_step : 6584, loss1 : 2.003159, loss2 : 0.778609
train_step : 6585, loss1 : 1.450963, loss2 : 0.967632
train_step : 6586, loss1 : 1.453171, loss2 : 1.509063
train_step : 6587, loss1 : 1.528726, loss2 : 1.009685
train_step : 6588, loss1 : 1.523184, loss2 : 0.955959
train_step : 6589, loss1 : 1.083469, loss2 : 1.867804
train_step : 6590, loss1 : 0.560116, loss2 : 1.233538
train_step : 6591, loss1 : 0.741306, loss2 : 0.729444
train_step : 6592, loss1 : 1.003434, loss2 : 1.022679
train_step : 6593, loss1 : 0.588451, loss2 : 0.556305
train_step : 6594, loss1 : 0.935416, loss2 : 1.011420
train_step : 6595, loss1 : 1.048667, loss2 : 1.017059
train_step : 6596, loss1 : 0.874944, loss2 : 1.203859
train_step : 6597, loss1 : 1.221553, loss2 : 1.407121
train_step : 6598, loss1 : 1.373111, loss2 : 1.833135
train_step : 6599, loss1 : 1.190329, loss2 : 0.978625
train_step : 6600, loss1 : 1.501829, loss2 : 1.152892
train_step : 6601, loss1 : 2.110167, loss2 : 1.294974
train_step : 6602, loss1 : 1.457621, loss2 : 1.552209
train_step : 6603, loss1 : 0.608191, loss2 : 1.412171
train_step : 6604, loss1 : 1.985369, loss2 : 2.204137
train_step : 6605, loss1 : 1.359459, loss2 : 2.341090
train_step : 6606, loss1 : 1.515554, loss2 : 2.449013
train_step : 6607, loss1 : 0.509446, loss2 : 1.472828
train_step : 6608, loss1 : 1.418382, loss2 : 3.653416
train_step : 6609, loss1 : 1.493451, loss2 : 0.772356
train_step : 6610, loss1 : 0.755319, loss2 : 1.155569
train_step : 6611, loss1 : 0.689479, loss2 : 0.830488
train_step : 6612, loss1 : 2.125030, loss2 : 0.925854
train_step : 6613, loss1 : 1.541312, loss2 : 0.820981
train_step : 6614, loss1 : 1.978000, loss2 : 1.681532
train_step : 6615, loss1 : 2.113938, loss2 : 2.292154
train_step : 6616, loss1 : 1.220165, loss2 : 1.097044
train_step : 6617, loss1 : 1.752173, loss2 : 1.012400
train_step : 6618, loss1 : 2.023395, loss2 : 1.153223
train_step : 6619, loss1 : 1.440394, loss2 : 1.119697
train_step : 6620, loss1 : 0.912299, loss2 : 1.612743
train_step : 6621, loss1 : 1.833821, loss2 : 2.207596
train_step : 6622, loss1 : 1.918994, loss2 : 2.320690
train_step : 6623, loss1 : 2.590736, loss2 : 2.472578
train_step : 6624, loss1 : 0.749373, loss2 : 1.734545
train_step : 6625, loss1 : 1.161024, loss2 : 1.888795
train_step : 6626, loss1 : 1.677615, loss2 : 1.102581
train_step : 6627, loss1 : 1.858776, loss2 : 0.903109
train_step : 6628, loss1 : 1.192275, loss2 : 0.829409
train_step : 6629, loss1 : 1.130243, loss2 : 0.992702
train_step : 6630, loss1 : 1.213668, loss2 : 1.747329
train_step : 6631, loss1 : 0.979817, loss2 : 1.233628
train_step : 6632, loss1 : 0.790116, loss2 : 1.418648
train_step : 6633, loss1 : 0.987689, loss2 : 1.141445
train_step : 6634, loss1 : 1.638636, loss2 : 1.508248
train_step : 6635, loss1 : 1.332811, loss2 : 0.829858
train_step : 6636, loss1 : 0.859328, loss2 : 1.573623
train_step : 6637, loss1 : 1.235084, loss2 : 1.059136
train_step : 6638, loss1 : 0.964924, loss2 : 0.687069
train_step : 6639, loss1 : 0.752632, loss2 : 4.377423
train_step : 6640, loss1 : 1.157557, loss2 : 1.724278
train_step : 6641, loss1 : 1.327263, loss2 : 0.845891
train_step : 6642, loss1 : 1.360447, loss2 : 0.927372
train_step : 6643, loss1 : 1.080857, loss2 : 1.122777
train_step : 6644, loss1 : 0.705673, loss2 : 0.960342
train_step : 6645, loss1 : 1.136639, loss2 : 1.749786
train_step : 6646, loss1 : 0.805136, loss2 : 1.315975
train_step : 6647, loss1 : 1.236366, loss2 : 1.451314
train_step : 6648, loss1 : 0.757583, loss2 : 1.630805
train_step : 6649, loss1 : 1.357411, loss2 : 1.070173
train_step : 6650, loss1 : 1.327967, loss2 : 1.050128
train_step : 6651, loss1 : 1.155317, loss2 : 0.667248
train_step : 6652, loss1 : 0.599033, loss2 : 1.216142
train_step : 6653, loss1 : 1.715071, loss2 : 1.531565
train_step : 6654, loss1 : 1.122370, loss2 : 1.089230
train_step : 6655, loss1 : 1.026786, loss2 : 1.383695
train_step : 6656, loss1 : 0.523233, loss2 : 1.827032
train_step : 6657, loss1 : 1.872553, loss2 : 2.043416
train_step : 6658, loss1 : 2.020620, loss2 : 2.897462
train_step : 6659, loss1 : 2.513986, loss2 : 1.879842
train_step : 6660, loss1 : 1.960177, loss2 : 1.663593
train_step : 6661, loss1 : 1.567492, loss2 : 0.980988
train_step : 6662, loss1 : 1.339753, loss2 : 1.237938
train_step : 6663, loss1 : 1.246860, loss2 : 0.952216
train_step : 6664, loss1 : 0.822391, loss2 : 1.049349
train_step : 6665, loss1 : 1.438821, loss2 : 0.924366
train_step : 6666, loss1 : 1.201542, loss2 : 1.394259
train_step : 6667, loss1 : 1.232522, loss2 : 1.574426
train_step : 6668, loss1 : 1.213368, loss2 : 1.877960
train_step : 6669, loss1 : 1.806005, loss2 : 2.507459
train_step : 6670, loss1 : 2.549738, loss2 : 2.192653
train_step : 6671, loss1 : 1.337647, loss2 : 1.294089
train_step : 6672, loss1 : 2.619473, loss2 : 2.664660
train_step : 6673, loss1 : 2.506789, loss2 : 2.117660
train_step : 6674, loss1 : 2.131551, loss2 : 3.161425
train_step : 6675, loss1 : 2.808457, loss2 : 2.155021
train_step : 6676, loss1 : 3.329609, loss2 : 2.827724
train_step : 6677, loss1 : 2.113350, loss2 : 1.291337
train_step : 6678, loss1 : 1.162123, loss2 : 1.764677
train_step : 6679, loss1 : 1.576894, loss2 : 1.903828
train_step : 6680, loss1 : 2.906283, loss2 : 1.503968
train_step : 6681, loss1 : 1.728174, loss2 : 0.935531
train_step : 6682, loss1 : 2.033471, loss2 : 2.624516
train_step : 6683, loss1 : 1.617451, loss2 : 3.561033
train_step : 6684, loss1 : 3.610708, loss2 : 2.067003
train_step : 6685, loss1 : 2.588315, loss2 : 2.033981
train_step : 6686, loss1 : 2.319474, loss2 : 2.719644
train_step : 6687, loss1 : 1.702415, loss2 : 2.515523
train_step : 6688, loss1 : 3.983875, loss2 : 2.245978
train_step : 6689, loss1 : 1.879392, loss2 : 3.788761
train_step : 6690, loss1 : 1.685005, loss2 : 3.587517
train_step : 6691, loss1 : 4.296613, loss2 : 1.683975
train_step : 6692, loss1 : 4.765401, loss2 : 3.635642
train_step : 6693, loss1 : 2.274921, loss2 : 3.707366
train_step : 6694, loss1 : 1.996620, loss2 : 2.519342
train_step : 6695, loss1 : 1.164411, loss2 : 2.860743
train_step : 6696, loss1 : 1.776093, loss2 : 2.320465
train_step : 6697, loss1 : 1.773155, loss2 : 1.535472
train_step : 6698, loss1 : 1.539348, loss2 : 2.091484
train_step : 6699, loss1 : 1.287202, loss2 : 1.358304
train_step : 6700, loss1 : 1.460498, loss2 : 1.240093
train_step : 6701, loss1 : 1.021723, loss2 : 1.346185
train_step : 6702, loss1 : 1.044665, loss2 : 1.989014
train_step : 6703, loss1 : 2.101257, loss2 : 1.265434
train_step : 6704, loss1 : 1.227489, loss2 : 1.766622
train_step : 6705, loss1 : 0.706008, loss2 : 1.451388
train_step : 6706, loss1 : 1.296789, loss2 : 1.053427
train_step : 6707, loss1 : 0.754823, loss2 : 0.948641
train_step : 6708, loss1 : 1.860403, loss2 : 2.179317
train_step : 6709, loss1 : 1.025812, loss2 : 2.122269
train_step : 6710, loss1 : 1.093276, loss2 : 1.962097
train_step : 6711, loss1 : 1.413622, loss2 : 1.025819
train_step : 6712, loss1 : 0.716150, loss2 : 1.890811
train_step : 6713, loss1 : 1.224077, loss2 : 0.886891
train_step : 6714, loss1 : 1.111544, loss2 : 0.845574
train_step : 6715, loss1 : 2.462015, loss2 : 1.480190
train_step : 6716, loss1 : 1.345584, loss2 : 0.969619
train_step : 6717, loss1 : 1.260844, loss2 : 1.230362
train_step : 6718, loss1 : 2.108936, loss2 : 1.256101
train_step : 6719, loss1 : 2.009496, loss2 : 1.767354
train_step : 6720, loss1 : 1.686600, loss2 : 1.778726
train_step : 6721, loss1 : 1.921605, loss2 : 0.780044
train_step : 6722, loss1 : 1.025843, loss2 : 1.234426
train_step : 6723, loss1 : 0.743026, loss2 : 1.007797
train_step : 6724, loss1 : 1.356904, loss2 : 0.990682
train_step : 6725, loss1 : 0.999175, loss2 : 1.730734
train_step : 6726, loss1 : 1.197943, loss2 : 2.006366
train_step : 6727, loss1 : 2.193351, loss2 : 0.922926
train_step : 6728, loss1 : 1.106455, loss2 : 1.603866
train_step : 6729, loss1 : 1.166060, loss2 : 1.576477
train_step : 6730, loss1 : 1.091001, loss2 : 1.367115
train_step : 6731, loss1 : 1.415899, loss2 : 1.759813
train_step : 6732, loss1 : 1.477969, loss2 : 1.176483
train_step : 6733, loss1 : 1.292331, loss2 : 0.901030
train_step : 6734, loss1 : 1.082777, loss2 : 0.981596
train_step : 6735, loss1 : 1.501392, loss2 : 0.940104
train_step : 6736, loss1 : 1.740553, loss2 : 1.525572
train_step : 6737, loss1 : 1.240883, loss2 : 1.228634
train_step : 6738, loss1 : 1.694922, loss2 : 2.068703
train_step : 6739, loss1 : 0.416303, loss2 : 1.454768
train_step : 6740, loss1 : 1.834986, loss2 : 0.857129
train_step : 6741, loss1 : 1.632720, loss2 : 0.623406
train_step : 6742, loss1 : 1.523248, loss2 : 1.920108
train_step : 6743, loss1 : 0.942778, loss2 : 1.459715
train_step : 6744, loss1 : 1.714251, loss2 : 1.875061
train_step : 6745, loss1 : 1.477933, loss2 : 1.738376
train_step : 6746, loss1 : 1.656690, loss2 : 0.810444
train_step : 6747, loss1 : 1.218791, loss2 : 1.741575
train_step : 6748, loss1 : 0.560819, loss2 : 0.793306
train_step : 6749, loss1 : 1.170881, loss2 : 1.330961
train_step : 6750, loss1 : 0.626793, loss2 : 0.625957
train_step : 6751, loss1 : 0.680639, loss2 : 1.579520
train_step : 6752, loss1 : 0.575103, loss2 : 0.794368
train_step : 6753, loss1 : 1.255012, loss2 : 1.184926
train_step : 6754, loss1 : 1.555087, loss2 : 1.082862
train_step : 6755, loss1 : 0.748272, loss2 : 1.232786
train_step : 6756, loss1 : 1.955946, loss2 : 0.865232
train_step : 6757, loss1 : 0.893686, loss2 : 0.815597
train_step : 6758, loss1 : 1.892309, loss2 : 1.194422
train_step : 6759, loss1 : 1.615046, loss2 : 1.121073
train_step : 6760, loss1 : 2.097742, loss2 : 2.787986
train_step : 6761, loss1 : 2.025050, loss2 : 2.736790
train_step : 6762, loss1 : 1.756831, loss2 : 2.322716
train_step : 6763, loss1 : 3.201651, loss2 : 2.784926
train_step : 6764, loss1 : 2.507986, loss2 : 4.019233
train_step : 6765, loss1 : 1.115952, loss2 : 1.310985
train_step : 6766, loss1 : 1.546529, loss2 : 1.170612
train_step : 6767, loss1 : 2.593132, loss2 : 1.119642
train_step : 6768, loss1 : 2.327292, loss2 : 1.669914
train_step : 6769, loss1 : 2.087472, loss2 : 1.595659
train_step : 6770, loss1 : 1.950689, loss2 : 1.689007
train_step : 6771, loss1 : 1.324955, loss2 : 2.443789
train_step : 6772, loss1 : 1.205332, loss2 : 1.436621
train_step : 6773, loss1 : 1.047822, loss2 : 1.513573
train_step : 6774, loss1 : 1.404292, loss2 : 1.471691
train_step : 6775, loss1 : 0.951235, loss2 : 1.486676
train_step : 6776, loss1 : 0.832785, loss2 : 0.877453
train_step : 6777, loss1 : 1.139582, loss2 : 1.653212
train_step : 6778, loss1 : 0.567158, loss2 : 1.055318
train_step : 6779, loss1 : 1.197342, loss2 : 1.418839
train_step : 6780, loss1 : 1.516673, loss2 : 1.438902
train_step : 6781, loss1 : 1.525614, loss2 : 1.192017
train_step : 6782, loss1 : 1.139457, loss2 : 1.078508
train_step : 6783, loss1 : 2.182356, loss2 : 0.706359
train_step : 6784, loss1 : 1.670718, loss2 : 1.102445
train_step : 6785, loss1 : 1.389387, loss2 : 2.454017
train_step : 6786, loss1 : 3.288749, loss2 : 1.700441
train_step : 6787, loss1 : 1.997485, loss2 : 1.546126
train_step : 6788, loss1 : 1.870579, loss2 : 1.536404
train_step : 6789, loss1 : 1.858358, loss2 : 3.038621
train_step : 6790, loss1 : 3.207816, loss2 : 2.928512
train_step : 6791, loss1 : 6.495653, loss2 : 3.262995
train_step : 6792, loss1 : 3.303638, loss2 : 2.209738
train_step : 6793, loss1 : 2.857143, loss2 : 2.993959
train_step : 6794, loss1 : 1.970425, loss2 : 2.374103
train_step : 6795, loss1 : 1.700445, loss2 : 1.990826
train_step : 6796, loss1 : 2.511719, loss2 : 1.568459
train_step : 6797, loss1 : 2.205491, loss2 : 1.886217
train_step : 6798, loss1 : 0.890070, loss2 : 1.443366
train_step : 6799, loss1 : 1.364763, loss2 : 1.478616
train_step : 6800, loss1 : 1.218565, loss2 : 0.963630
train_step : 6801, loss1 : 1.183418, loss2 : 1.486663
train_step : 6802, loss1 : 1.186580, loss2 : 1.164763
train_step : 6803, loss1 : 0.749941, loss2 : 1.454299
train_step : 6804, loss1 : 0.825286, loss2 : 2.628239
train_step : 6805, loss1 : 1.386311, loss2 : 1.328974
train_step : 6806, loss1 : 1.373144, loss2 : 0.878086
train_step : 6807, loss1 : 1.473989, loss2 : 2.244242
train_step : 6808, loss1 : 2.064497, loss2 : 2.240826
train_step : 6809, loss1 : 1.755697, loss2 : 1.092862
train_step : 6810, loss1 : 1.523004, loss2 : 0.902391
train_step : 6811, loss1 : 1.166047, loss2 : 1.442021
train_step : 6812, loss1 : 1.663494, loss2 : 0.951169
train_step : 6813, loss1 : 1.269065, loss2 : 2.349311
train_step : 6814, loss1 : 1.399123, loss2 : 1.630965
train_step : 6815, loss1 : 0.569918, loss2 : 0.894978
train_step : 6816, loss1 : 1.302233, loss2 : 0.869217
train_step : 6817, loss1 : 1.514364, loss2 : 1.250351
train_step : 6818, loss1 : 1.090869, loss2 : 2.408371
train_step : 6819, loss1 : 1.057362, loss2 : 0.763566
train_step : 6820, loss1 : 1.539455, loss2 : 1.898191
train_step : 6821, loss1 : 1.547902, loss2 : 2.488879
train_step : 6822, loss1 : 2.087490, loss2 : 1.756501
train_step : 6823, loss1 : 1.433136, loss2 : 1.517073
train_step : 6824, loss1 : 1.470306, loss2 : 0.767299
train_step : 6825, loss1 : 1.345785, loss2 : 0.741752
train_step : 6826, loss1 : 1.098851, loss2 : 2.141563
train_step : 6827, loss1 : 1.041798, loss2 : 1.144034
train_step : 6828, loss1 : 0.954243, loss2 : 1.233475
train_step : 6829, loss1 : 1.321740, loss2 : 1.075652
train_step : 6830, loss1 : 0.890544, loss2 : 1.170866
train_step : 6831, loss1 : 0.758887, loss2 : 0.628412
train_step : 6832, loss1 : 1.621762, loss2 : 0.775376
train_step : 6833, loss1 : 1.375588, loss2 : 1.218198
train_step : 6834, loss1 : 1.550414, loss2 : 1.094406
train_step : 6835, loss1 : 1.253949, loss2 : 2.118134
train_step : 6836, loss1 : 2.114584, loss2 : 2.606640
train_step : 6837, loss1 : 1.331441, loss2 : 2.276747
train_step : 6838, loss1 : 1.692505, loss2 : 3.240337
train_step : 6839, loss1 : 1.091584, loss2 : 1.136666
train_step : 6840, loss1 : 1.282820, loss2 : 1.774045
train_step : 6841, loss1 : 1.789812, loss2 : 3.627725
train_step : 6842, loss1 : 2.089274, loss2 : 2.551227
train_step : 6843, loss1 : 1.938108, loss2 : 1.197290
train_step : 6844, loss1 : 1.779711, loss2 : 1.779033
train_step : 6845, loss1 : 2.964819, loss2 : 2.512283
train_step : 6846, loss1 : 3.791539, loss2 : 2.988471
train_step : 6847, loss1 : 2.245200, loss2 : 3.089720
train_step : 6848, loss1 : 2.068552, loss2 : 2.279247
train_step : 6849, loss1 : 1.448528, loss2 : 1.685642
train_step : 6850, loss1 : 1.297574, loss2 : 1.722134
train_step : 6851, loss1 : 2.500093, loss2 : 1.705838
train_step : 6852, loss1 : 2.282991, loss2 : 2.458723
train_step : 6853, loss1 : 1.320956, loss2 : 1.093502
train_step : 6854, loss1 : 1.913410, loss2 : 1.320854
train_step : 6855, loss1 : 1.743248, loss2 : 1.366308
train_step : 6856, loss1 : 1.561138, loss2 : 1.864900
train_step : 6857, loss1 : 1.860836, loss2 : 1.226291
train_step : 6858, loss1 : 1.376977, loss2 : 0.621528
train_step : 6859, loss1 : 1.419132, loss2 : 1.135849
train_step : 6860, loss1 : 1.066835, loss2 : 1.325356
train_step : 6861, loss1 : 1.337468, loss2 : 1.013379
train_step : 6862, loss1 : 0.700925, loss2 : 1.045512
train_step : 6863, loss1 : 1.679600, loss2 : 0.753459
train_step : 6864, loss1 : 0.759354, loss2 : 0.976380
train_step : 6865, loss1 : 1.838463, loss2 : 1.110999
train_step : 6866, loss1 : 0.981441, loss2 : 1.273418
train_step : 6867, loss1 : 0.670869, loss2 : 0.907584
train_step : 6868, loss1 : 1.793981, loss2 : 1.134056
train_step : 6869, loss1 : 1.235259, loss2 : 0.949597
train_step : 6870, loss1 : 1.242154, loss2 : 1.061891
train_step : 6871, loss1 : 2.139630, loss2 : 1.476050
train_step : 6872, loss1 : 2.793787, loss2 : 2.415148
train_step : 6873, loss1 : 1.055871, loss2 : 1.451007
train_step : 6874, loss1 : 1.379655, loss2 : 1.286017
train_step : 6875, loss1 : 1.043995, loss2 : 1.310965
train_step : 6876, loss1 : 1.633963, loss2 : 0.821292
train_step : 6877, loss1 : 1.017761, loss2 : 0.489053
train_step : 6878, loss1 : 1.029889, loss2 : 1.351257
train_step : 6879, loss1 : 0.782053, loss2 : 1.405274
train_step : 6880, loss1 : 1.105908, loss2 : 1.517658
train_step : 6881, loss1 : 1.738974, loss2 : 1.708037
train_step : 6882, loss1 : 2.534950, loss2 : 1.916086
train_step : 6883, loss1 : 2.343035, loss2 : 2.620021
train_step : 6884, loss1 : 3.834219, loss2 : 2.862574
train_step : 6885, loss1 : 3.278474, loss2 : 3.047914
train_step : 6886, loss1 : 3.656457, loss2 : 1.662994
train_step : 6887, loss1 : 2.689902, loss2 : 3.475029
train_step : 6888, loss1 : 2.107587, loss2 : 2.637244
train_step : 6889, loss1 : 1.926996, loss2 : 1.960364
train_step : 6890, loss1 : 2.019303, loss2 : 1.184802
train_step : 6891, loss1 : 0.998275, loss2 : 1.599693
train_step : 6892, loss1 : 0.881749, loss2 : 1.240160
train_step : 6893, loss1 : 2.081226, loss2 : 0.743002
train_step : 6894, loss1 : 1.414139, loss2 : 0.790716
train_step : 6895, loss1 : 1.486418, loss2 : 1.399258
train_step : 6896, loss1 : 1.166636, loss2 : 1.915290
train_step : 6897, loss1 : 0.954299, loss2 : 1.217394
train_step : 6898, loss1 : 1.333891, loss2 : 1.443051
train_step : 6899, loss1 : 0.863306, loss2 : 0.746021
train_step : 6900, loss1 : 0.742628, loss2 : 0.933226
train_step : 6901, loss1 : 0.810309, loss2 : 1.122130
train_step : 6902, loss1 : 1.826652, loss2 : 2.091661
train_step : 6903, loss1 : 0.562684, loss2 : 1.335891
train_step : 6904, loss1 : 1.170501, loss2 : 0.871267
train_step : 6905, loss1 : 1.145980, loss2 : 1.564459
train_step : 6906, loss1 : 1.929003, loss2 : 2.579638
train_step : 6907, loss1 : 2.964452, loss2 : 2.714820
train_step : 6908, loss1 : 2.249617, loss2 : 2.178488
train_step : 6909, loss1 : 1.548895, loss2 : 1.325983
train_step : 6910, loss1 : 1.317646, loss2 : 2.241718
train_step : 6911, loss1 : 2.138124, loss2 : 1.915934
train_step : 6912, loss1 : 3.840453, loss2 : 3.097651
train_step : 6913, loss1 : 3.138848, loss2 : 2.446497
train_step : 6914, loss1 : 2.201141, loss2 : 2.035336
train_step : 6915, loss1 : 1.232641, loss2 : 2.595419
train_step : 6916, loss1 : 0.942436, loss2 : 0.354099
train_step : 6917, loss1 : 0.746852, loss2 : 0.883657
train_step : 6918, loss1 : 1.040563, loss2 : 1.165859
train_step : 6919, loss1 : 0.982557, loss2 : 1.222052
train_step : 6920, loss1 : 1.334869, loss2 : 0.563728
train_step : 6921, loss1 : 1.137812, loss2 : 1.457763
train_step : 6922, loss1 : 1.604164, loss2 : 0.634436
train_step : 6923, loss1 : 1.176309, loss2 : 1.574918
train_step : 6924, loss1 : 1.448165, loss2 : 1.563331
train_step : 6925, loss1 : 0.874206, loss2 : 1.283612
train_step : 6926, loss1 : 1.083766, loss2 : 1.233904
train_step : 6927, loss1 : 1.125146, loss2 : 1.454038
train_step : 6928, loss1 : 1.061491, loss2 : 1.614648
train_step : 6929, loss1 : 0.745960, loss2 : 1.181496
train_step : 6930, loss1 : 1.062200, loss2 : 0.880681
train_step : 6931, loss1 : 0.842049, loss2 : 1.325048
train_step : 6932, loss1 : 0.898539, loss2 : 1.045500
train_step : 6933, loss1 : 1.462914, loss2 : 1.281993
train_step : 6934, loss1 : 1.789338, loss2 : 1.431451
train_step : 6935, loss1 : 1.467696, loss2 : 1.121217
train_step : 6936, loss1 : 1.234101, loss2 : 0.883329
train_step : 6937, loss1 : 1.182268, loss2 : 1.247676
train_step : 6938, loss1 : 0.707859, loss2 : 1.940878
train_step : 6939, loss1 : 1.311935, loss2 : 0.797697
train_step : 6940, loss1 : 1.158205, loss2 : 1.264375
train_step : 6941, loss1 : 0.709396, loss2 : 0.762368
train_step : 6942, loss1 : 1.110830, loss2 : 1.115988
train_step : 6943, loss1 : 1.594929, loss2 : 1.624253
train_step : 6944, loss1 : 1.165033, loss2 : 1.410395
train_step : 6945, loss1 : 1.062767, loss2 : 0.755242
train_step : 6946, loss1 : 0.713856, loss2 : 1.403247
train_step : 6947, loss1 : 1.080776, loss2 : 1.102664
train_step : 6948, loss1 : 2.316530, loss2 : 1.871650
train_step : 6949, loss1 : 2.572049, loss2 : 2.550255
train_step : 6950, loss1 : 2.224436, loss2 : 2.469074
train_step : 6951, loss1 : 2.159868, loss2 : 2.845034
train_step : 6952, loss1 : 3.090718, loss2 : 1.270978
train_step : 6953, loss1 : 2.292036, loss2 : 1.692183
train_step : 6954, loss1 : 2.448654, loss2 : 1.790694
train_step : 6955, loss1 : 2.488737, loss2 : 2.444428
train_step : 6956, loss1 : 1.205509, loss2 : 2.852449
train_step : 6957, loss1 : 1.674941, loss2 : 1.756422
train_step : 6958, loss1 : 1.329556, loss2 : 2.042001
train_step : 6959, loss1 : 0.903738, loss2 : 1.519168
train_step : 6960, loss1 : 2.625352, loss2 : 3.017710
train_step : 6961, loss1 : 2.554868, loss2 : 1.553063
train_step : 6962, loss1 : 3.462848, loss2 : 1.358144
train_step : 6963, loss1 : 1.129652, loss2 : 1.610084
train_step : 6964, loss1 : 2.113266, loss2 : 1.603749
train_step : 6965, loss1 : 3.011785, loss2 : 1.946929
train_step : 6966, loss1 : 3.073110, loss2 : 2.673393
train_step : 6967, loss1 : 2.991700, loss2 : 3.310161
train_step : 6968, loss1 : 3.518290, loss2 : 2.680164
train_step : 6969, loss1 : 2.186587, loss2 : 3.065246
train_step : 6970, loss1 : 1.958104, loss2 : 2.639575
train_step : 6971, loss1 : 2.614721, loss2 : 2.210762
train_step : 6972, loss1 : 1.676172, loss2 : 2.140446
train_step : 6973, loss1 : 2.557769, loss2 : 2.438892
train_step : 6974, loss1 : 1.938760, loss2 : 1.733573
train_step : 6975, loss1 : 2.679970, loss2 : 3.036713
train_step : 6976, loss1 : 3.936843, loss2 : 3.350606
train_step : 6977, loss1 : 1.785803, loss2 : 3.184569
train_step : 6978, loss1 : 1.252091, loss2 : 1.482846
train_step : 6979, loss1 : 1.776401, loss2 : 1.656979
train_step : 6980, loss1 : 1.084119, loss2 : 1.003810
train_step : 6981, loss1 : 2.390299, loss2 : 1.081251
train_step : 6982, loss1 : 0.384028, loss2 : 0.998145
train_step : 6983, loss1 : 1.068234, loss2 : 2.103474
train_step : 6984, loss1 : 1.476174, loss2 : 1.193028
train_step : 6985, loss1 : 1.242802, loss2 : 1.518386
train_step : 6986, loss1 : 0.832053, loss2 : 1.756554
train_step : 6987, loss1 : 0.712364, loss2 : 1.177498
train_step : 6988, loss1 : 0.807943, loss2 : 1.822454
train_step : 6989, loss1 : 0.555085, loss2 : 0.999256
train_step : 6990, loss1 : 1.145281, loss2 : 0.681761
train_step : 6991, loss1 : 1.031161, loss2 : 1.294669
train_step : 6992, loss1 : 1.137264, loss2 : 0.782811
train_step : 6993, loss1 : 1.397959, loss2 : 0.891718
train_step : 6994, loss1 : 1.319602, loss2 : 1.105625
train_step : 6995, loss1 : 1.018637, loss2 : 1.174820
train_step : 6996, loss1 : 0.898477, loss2 : 1.409326
train_step : 6997, loss1 : 1.310345, loss2 : 1.832330
train_step : 6998, loss1 : 1.166009, loss2 : 0.790115
train_step : 6999, loss1 : 1.082662, loss2 : 1.099665
train_step : 7000, loss1 : 0.995708, loss2 : 0.690851
train_step : 7001, loss1 : 1.122332, loss2 : 1.305511
train_step : 7002, loss1 : 2.281019, loss2 : 1.837012
train_step : 7003, loss1 : 1.189045, loss2 : 0.803148
train_step : 7004, loss1 : 0.790158, loss2 : 1.311035
train_step : 7005, loss1 : 0.707137, loss2 : 1.379336
train_step : 7006, loss1 : 1.445878, loss2 : 1.523941
train_step : 7007, loss1 : 1.498532, loss2 : 0.839978
train_step : 7008, loss1 : 0.870213, loss2 : 0.908485
train_step : 7009, loss1 : 1.420517, loss2 : 1.057366
train_step : 7010, loss1 : 1.298274, loss2 : 1.115488
train_step : 7011, loss1 : 1.122710, loss2 : 1.270969
train_step : 7012, loss1 : 1.275149, loss2 : 2.154529
train_step : 7013, loss1 : 1.425958, loss2 : 1.346429
train_step : 7014, loss1 : 2.070541, loss2 : 1.718880
train_step : 7015, loss1 : 1.923962, loss2 : 1.556576
train_step : 7016, loss1 : 1.197133, loss2 : 1.569802
train_step : 7017, loss1 : 1.915116, loss2 : 1.825660
train_step : 7018, loss1 : 1.981657, loss2 : 1.015306
train_step : 7019, loss1 : 1.189480, loss2 : 1.263847
train_step : 7020, loss1 : 1.098859, loss2 : 1.581556
train_step : 7021, loss1 : 1.141735, loss2 : 0.819132
train_step : 7022, loss1 : 1.243410, loss2 : 0.955081
train_step : 7023, loss1 : 1.595764, loss2 : 0.922153
train_step : 7024, loss1 : 3.152525, loss2 : 1.718850
train_step : 7025, loss1 : 2.448858, loss2 : 1.845106
train_step : 7026, loss1 : 1.407505, loss2 : 2.453889
train_step : 7027, loss1 : 1.242361, loss2 : 2.066500
train_step : 7028, loss1 : 1.477085, loss2 : 1.163930
train_step : 7029, loss1 : 1.792812, loss2 : 1.381289
train_step : 7030, loss1 : 1.953950, loss2 : 1.578760
train_step : 7031, loss1 : 1.891497, loss2 : 1.610560
train_step : 7032, loss1 : 0.957978, loss2 : 1.023383
train_step : 7033, loss1 : 2.022350, loss2 : 1.256507
train_step : 7034, loss1 : 1.564328, loss2 : 1.223122
train_step : 7035, loss1 : 1.040726, loss2 : 1.288928
train_step : 7036, loss1 : 0.441019, loss2 : 1.501909
train_step : 7037, loss1 : 0.773414, loss2 : 1.235051
train_step : 7038, loss1 : 1.373263, loss2 : 0.778207
train_step : 7039, loss1 : 1.073139, loss2 : 0.656488
train_step : 7040, loss1 : 0.783784, loss2 : 0.603808
train_step : 7041, loss1 : 0.960464, loss2 : 0.821938
train_step : 7042, loss1 : 0.965344, loss2 : 1.241467
train_step : 7043, loss1 : 1.027246, loss2 : 1.934994
train_step : 7044, loss1 : 1.277423, loss2 : 1.395652
train_step : 7045, loss1 : 1.277514, loss2 : 1.718129
train_step : 7046, loss1 : 1.634271, loss2 : 2.368462
train_step : 7047, loss1 : 1.636259, loss2 : 1.653395
train_step : 7048, loss1 : 1.250742, loss2 : 1.038220
train_step : 7049, loss1 : 1.194119, loss2 : 1.170387
train_step : 7050, loss1 : 1.267612, loss2 : 0.964183
train_step : 7051, loss1 : 1.182465, loss2 : 2.414718
train_step : 7052, loss1 : 1.069669, loss2 : 1.876609
train_step : 7053, loss1 : 2.394046, loss2 : 1.912269
train_step : 7054, loss1 : 2.534544, loss2 : 3.327914
train_step : 7055, loss1 : 1.555086, loss2 : 1.989123
train_step : 7056, loss1 : 1.449899, loss2 : 1.289387
train_step : 7057, loss1 : 1.880682, loss2 : 1.170164
train_step : 7058, loss1 : 1.873706, loss2 : 1.283630
train_step : 7059, loss1 : 0.792072, loss2 : 0.679987
train_step : 7060, loss1 : 0.823106, loss2 : 2.112760
train_step : 7061, loss1 : 1.336504, loss2 : 0.838118
train_step : 7062, loss1 : 0.988544, loss2 : 1.117126
train_step : 7063, loss1 : 1.035127, loss2 : 0.844489
train_step : 7064, loss1 : 0.667328, loss2 : 1.844762
train_step : 7065, loss1 : 0.953156, loss2 : 0.806024
train_step : 7066, loss1 : 0.844499, loss2 : 0.637245
train_step : 7067, loss1 : 0.987116, loss2 : 1.515363
train_step : 7068, loss1 : 0.875981, loss2 : 0.885574
train_step : 7069, loss1 : 0.983164, loss2 : 1.128813
train_step : 7070, loss1 : 1.834134, loss2 : 1.468406
train_step : 7071, loss1 : 0.963348, loss2 : 2.939153
train_step : 7072, loss1 : 1.508385, loss2 : 1.366181
train_step : 7073, loss1 : 1.572578, loss2 : 1.201736
train_step : 7074, loss1 : 0.968853, loss2 : 1.567255
train_step : 7075, loss1 : 1.993332, loss2 : 0.825249
train_step : 7076, loss1 : 1.695992, loss2 : 1.354599
train_step : 7077, loss1 : 1.322258, loss2 : 0.445154
train_step : 7078, loss1 : 1.314426, loss2 : 2.116775
train_step : 7079, loss1 : 2.059254, loss2 : 1.319657
train_step : 7080, loss1 : 2.081701, loss2 : 0.881079
train_step : 7081, loss1 : 0.859751, loss2 : 1.711012
train_step : 7082, loss1 : 1.313310, loss2 : 1.268592
train_step : 7083, loss1 : 1.104983, loss2 : 1.427194
train_step : 7084, loss1 : 1.217288, loss2 : 0.891968
train_step : 7085, loss1 : 1.687867, loss2 : 1.944036
train_step : 7086, loss1 : 1.191474, loss2 : 2.086787
train_step : 7087, loss1 : 1.020477, loss2 : 0.966106
train_step : 7088, loss1 : 0.872245, loss2 : 1.069292
train_step : 7089, loss1 : 0.990477, loss2 : 2.226477
train_step : 7090, loss1 : 0.887266, loss2 : 1.677818
train_step : 7091, loss1 : 0.547590, loss2 : 1.720208
train_step : 7092, loss1 : 2.016518, loss2 : 1.236480
train_step : 7093, loss1 : 1.467191, loss2 : 1.539260
train_step : 7094, loss1 : 1.721745, loss2 : 1.234542
train_step : 7095, loss1 : 1.407720, loss2 : 1.146154
train_step : 7096, loss1 : 1.905062, loss2 : 1.224342
train_step : 7097, loss1 : 0.911777, loss2 : 1.008165
train_step : 7098, loss1 : 1.357274, loss2 : 1.007328
train_step : 7099, loss1 : 1.040861, loss2 : 1.413027
train_step : 7100, loss1 : 1.425151, loss2 : 1.193181
train_step : 7101, loss1 : 1.080275, loss2 : 1.666240
train_step : 7102, loss1 : 1.058844, loss2 : 0.933685
train_step : 7103, loss1 : 1.387760, loss2 : 0.902335
train_step : 7104, loss1 : 1.533148, loss2 : 1.187999
train_step : 7105, loss1 : 1.022022, loss2 : 1.046621
train_step : 7106, loss1 : 0.908810, loss2 : 1.477958
train_step : 7107, loss1 : 1.068942, loss2 : 0.798330
train_step : 7108, loss1 : 0.816896, loss2 : 0.879585
train_step : 7109, loss1 : 1.253737, loss2 : 1.236071
train_step : 7110, loss1 : 1.642584, loss2 : 1.012141
train_step : 7111, loss1 : 1.051540, loss2 : 2.075145
train_step : 7112, loss1 : 0.932445, loss2 : 1.246596
train_step : 7113, loss1 : 0.712627, loss2 : 1.140759
train_step : 7114, loss1 : 0.944836, loss2 : 0.789287
train_step : 7115, loss1 : 0.863744, loss2 : 0.852429
train_step : 7116, loss1 : 0.774282, loss2 : 0.965405
train_step : 7117, loss1 : 0.543459, loss2 : 0.507223
train_step : 7118, loss1 : 0.491433, loss2 : 0.844042
train_step : 7119, loss1 : 1.143671, loss2 : 1.138812
train_step : 7120, loss1 : 1.066049, loss2 : 1.109320
train_step : 7121, loss1 : 0.550528, loss2 : 1.183816
train_step : 7122, loss1 : 2.743543, loss2 : 0.656856
train_step : 7123, loss1 : 1.393120, loss2 : 1.774592
train_step : 7124, loss1 : 1.605715, loss2 : 1.492831
train_step : 7125, loss1 : 0.712723, loss2 : 1.254416
train_step : 7126, loss1 : 0.929507, loss2 : 1.178219
train_step : 7127, loss1 : 1.015734, loss2 : 1.480024
train_step : 7128, loss1 : 2.102813, loss2 : 1.682334
train_step : 7129, loss1 : 1.329643, loss2 : 1.250896
train_step : 7130, loss1 : 1.503079, loss2 : 1.612206
train_step : 7131, loss1 : 0.767413, loss2 : 0.840321
train_step : 7132, loss1 : 1.652088, loss2 : 0.683360
train_step : 7133, loss1 : 1.388516, loss2 : 1.551134
train_step : 7134, loss1 : 0.765159, loss2 : 0.819886
train_step : 7135, loss1 : 1.418518, loss2 : 1.136906
train_step : 7136, loss1 : 1.246395, loss2 : 0.959327
train_step : 7137, loss1 : 0.778411, loss2 : 0.924662
train_step : 7138, loss1 : 1.357300, loss2 : 0.895490
train_step : 7139, loss1 : 1.147590, loss2 : 0.810188
train_step : 7140, loss1 : 1.667808, loss2 : 1.271865
train_step : 7141, loss1 : 1.170463, loss2 : 2.001336
train_step : 7142, loss1 : 0.978474, loss2 : 1.051813
train_step : 7143, loss1 : 1.565482, loss2 : 1.165273
train_step : 7144, loss1 : 1.532706, loss2 : 1.619732
train_step : 7145, loss1 : 1.056413, loss2 : 1.068437
train_step : 7146, loss1 : 1.560960, loss2 : 3.520372
train_step : 7147, loss1 : 2.393755, loss2 : 2.259897
train_step : 7148, loss1 : 2.283641, loss2 : 2.097978
train_step : 7149, loss1 : 2.525242, loss2 : 2.062585
train_step : 7150, loss1 : 1.836843, loss2 : 2.921831
train_step : 7151, loss1 : 2.094995, loss2 : 2.289606
train_step : 7152, loss1 : 3.798767, loss2 : 2.044167
train_step : 7153, loss1 : 4.001665, loss2 : 4.273154
train_step : 7154, loss1 : 1.750021, loss2 : 3.553102
train_step : 7155, loss1 : 1.647136, loss2 : 3.007420
train_step : 7156, loss1 : 1.432434, loss2 : 2.174222
train_step : 7157, loss1 : 1.424851, loss2 : 1.974404
train_step : 7158, loss1 : 1.048509, loss2 : 1.000717
train_step : 7159, loss1 : 1.180909, loss2 : 1.116790
train_step : 7160, loss1 : 1.206504, loss2 : 1.425098
train_step : 7161, loss1 : 1.128120, loss2 : 0.987990
train_step : 7162, loss1 : 2.029642, loss2 : 1.723012
train_step : 7163, loss1 : 0.996744, loss2 : 1.351753
train_step : 7164, loss1 : 1.061781, loss2 : 1.236130
train_step : 7165, loss1 : 1.240321, loss2 : 0.856271
train_step : 7166, loss1 : 1.319949, loss2 : 1.076968
train_step : 7167, loss1 : 1.411930, loss2 : 1.431217
train_step : 7168, loss1 : 1.067726, loss2 : 1.778711
train_step : 7169, loss1 : 1.058461, loss2 : 1.032923
train_step : 7170, loss1 : 1.401309, loss2 : 1.835402
train_step : 7171, loss1 : 1.839946, loss2 : 1.334685
train_step : 7172, loss1 : 1.225493, loss2 : 1.076321
train_step : 7173, loss1 : 1.488691, loss2 : 1.038577
train_step : 7174, loss1 : 0.561827, loss2 : 1.324250
train_step : 7175, loss1 : 1.319265, loss2 : 1.195241
train_step : 7176, loss1 : 1.422233, loss2 : 2.528047
train_step : 7177, loss1 : 1.499999, loss2 : 0.813265
train_step : 7178, loss1 : 0.769043, loss2 : 1.253406
train_step : 7179, loss1 : 1.895003, loss2 : 1.613135
train_step : 7180, loss1 : 1.091363, loss2 : 0.952866
train_step : 7181, loss1 : 0.963641, loss2 : 1.816503
train_step : 7182, loss1 : 2.822373, loss2 : 1.190089
train_step : 7183, loss1 : 1.054114, loss2 : 1.229828
train_step : 7184, loss1 : 1.438762, loss2 : 0.788651
train_step : 7185, loss1 : 1.179963, loss2 : 0.765971
train_step : 7186, loss1 : 0.888812, loss2 : 0.552086
train_step : 7187, loss1 : 0.945883, loss2 : 0.755055
train_step : 7188, loss1 : 0.975859, loss2 : 0.752295
train_step : 7189, loss1 : 0.820997, loss2 : 1.061532
train_step : 7190, loss1 : 1.871815, loss2 : 1.257645
train_step : 7191, loss1 : 1.580302, loss2 : 2.171361
train_step : 7192, loss1 : 0.903274, loss2 : 1.650777
train_step : 7193, loss1 : 2.312172, loss2 : 1.331613
train_step : 7194, loss1 : 2.148722, loss2 : 1.094471
train_step : 7195, loss1 : 0.926771, loss2 : 1.337505
train_step : 7196, loss1 : 0.807663, loss2 : 1.054021
train_step : 7197, loss1 : 0.982772, loss2 : 0.973588
train_step : 7198, loss1 : 2.243295, loss2 : 1.228665
train_step : 7199, loss1 : 1.143882, loss2 : 0.728427
train_step : 7200, loss1 : 1.373845, loss2 : 1.124190
train_step : 7201, loss1 : 1.150756, loss2 : 1.441787
train_step : 7202, loss1 : 1.464910, loss2 : 1.604498
train_step : 7203, loss1 : 1.164324, loss2 : 1.517430
train_step : 7204, loss1 : 2.162087, loss2 : 0.967925
train_step : 7205, loss1 : 1.122426, loss2 : 1.417168
train_step : 7206, loss1 : 1.038247, loss2 : 1.306942
train_step : 7207, loss1 : 0.689696, loss2 : 0.991874
train_step : 7208, loss1 : 1.078012, loss2 : 1.101603
train_step : 7209, loss1 : 1.423565, loss2 : 1.106355
train_step : 7210, loss1 : 1.244046, loss2 : 1.144380
train_step : 7211, loss1 : 0.811723, loss2 : 0.930398
train_step : 7212, loss1 : 1.173330, loss2 : 1.056378
train_step : 7213, loss1 : 1.006077, loss2 : 1.001734
train_step : 7214, loss1 : 1.009709, loss2 : 2.164169
train_step : 7215, loss1 : 1.481961, loss2 : 1.948816
train_step : 7216, loss1 : 1.179939, loss2 : 1.359955
train_step : 7217, loss1 : 1.357213, loss2 : 1.172122
train_step : 7218, loss1 : 0.890133, loss2 : 0.676234
train_step : 7219, loss1 : 1.214594, loss2 : 0.762701
train_step : 7220, loss1 : 1.064819, loss2 : 1.361594
train_step : 7221, loss1 : 1.373239, loss2 : 1.262150
train_step : 7222, loss1 : 6.110875, loss2 : 1.666262
train_step : 7223, loss1 : 2.156222, loss2 : 2.404126
train_step : 7224, loss1 : 1.058521, loss2 : 2.068831
train_step : 7225, loss1 : 2.529615, loss2 : 1.901995
train_step : 7226, loss1 : 3.900241, loss2 : 1.927694
train_step : 7227, loss1 : 2.881687, loss2 : 1.949099
train_step : 7228, loss1 : 1.883761, loss2 : 1.993834
train_step : 7229, loss1 : 1.771889, loss2 : 2.360683
train_step : 7230, loss1 : 0.671149, loss2 : 1.221960
train_step : 7231, loss1 : 0.872572, loss2 : 0.942305
train_step : 7232, loss1 : 0.926723, loss2 : 1.615534
train_step : 7233, loss1 : 1.823942, loss2 : 0.937024
train_step : 7234, loss1 : 1.069506, loss2 : 2.059257
train_step : 7235, loss1 : 1.366442, loss2 : 1.248193
train_step : 7236, loss1 : 0.729233, loss2 : 0.777879
train_step : 7237, loss1 : 1.276520, loss2 : 1.512674
train_step : 7238, loss1 : 0.950951, loss2 : 1.572475
train_step : 7239, loss1 : 1.115016, loss2 : 0.946503
train_step : 7240, loss1 : 0.794876, loss2 : 1.255544
train_step : 7241, loss1 : 1.141616, loss2 : 1.005113
train_step : 7242, loss1 : 1.260486, loss2 : 1.046470
train_step : 7243, loss1 : 1.980190, loss2 : 2.124654
train_step : 7244, loss1 : 1.495368, loss2 : 1.668229
train_step : 7245, loss1 : 2.150431, loss2 : 1.354359
train_step : 7246, loss1 : 2.281872, loss2 : 1.336157
train_step : 7247, loss1 : 1.906253, loss2 : 1.814288
train_step : 7248, loss1 : 1.872509, loss2 : 1.248180
train_step : 7249, loss1 : 0.941523, loss2 : 0.753451
train_step : 7250, loss1 : 1.110595, loss2 : 0.808815
train_step : 7251, loss1 : 1.056360, loss2 : 1.514376
train_step : 7252, loss1 : 0.799467, loss2 : 1.211888
train_step : 7253, loss1 : 0.666162, loss2 : 1.356240
train_step : 7254, loss1 : 0.525890, loss2 : 1.051556
train_step : 7255, loss1 : 1.029163, loss2 : 1.558756
train_step : 7256, loss1 : 1.256573, loss2 : 1.614754
train_step : 7257, loss1 : 1.057223, loss2 : 1.317650
train_step : 7258, loss1 : 2.376722, loss2 : 0.795481
train_step : 7259, loss1 : 1.107557, loss2 : 0.927518
train_step : 7260, loss1 : 1.133408, loss2 : 0.586460
train_step : 7261, loss1 : 1.358389, loss2 : 0.830431
train_step : 7262, loss1 : 1.389494, loss2 : 1.185286
train_step : 7263, loss1 : 0.876440, loss2 : 0.982690
train_step : 7264, loss1 : 1.304284, loss2 : 1.323780
train_step : 7265, loss1 : 1.299827, loss2 : 1.130126
train_step : 7266, loss1 : 1.263936, loss2 : 1.222721
train_step : 7267, loss1 : 1.242983, loss2 : 0.820564
train_step : 7268, loss1 : 0.919431, loss2 : 1.608456
train_step : 7269, loss1 : 1.074571, loss2 : 0.960160
train_step : 7270, loss1 : 0.857069, loss2 : 1.779934
train_step : 7271, loss1 : 1.696741, loss2 : 1.234640
train_step : 7272, loss1 : 1.233399, loss2 : 1.415240
train_step : 7273, loss1 : 1.061459, loss2 : 1.767081
train_step : 7274, loss1 : 1.721871, loss2 : 1.336684
train_step : 7275, loss1 : 1.837603, loss2 : 1.638229
train_step : 7276, loss1 : 1.758558, loss2 : 1.326069
train_step : 7277, loss1 : 3.000100, loss2 : 2.268179
train_step : 7278, loss1 : 3.209844, loss2 : 2.068932
train_step : 7279, loss1 : 3.593340, loss2 : 2.183659
train_step : 7280, loss1 : 3.002785, loss2 : 2.269470
train_step : 7281, loss1 : 2.696685, loss2 : 4.159518
train_step : 7282, loss1 : 2.706204, loss2 : 2.223134
train_step : 7283, loss1 : 2.652921, loss2 : 1.336398
train_step : 7284, loss1 : 0.977618, loss2 : 1.783664
train_step : 7285, loss1 : 1.493290, loss2 : 1.730563
train_step : 7286, loss1 : 1.155753, loss2 : 0.739490
train_step : 7287, loss1 : 1.574281, loss2 : 1.011940
train_step : 7288, loss1 : 0.785952, loss2 : 0.867350
train_step : 7289, loss1 : 1.499962, loss2 : 1.370221
train_step : 7290, loss1 : 1.319265, loss2 : 0.888366
train_step : 7291, loss1 : 1.588661, loss2 : 1.459705
train_step : 7292, loss1 : 1.828015, loss2 : 1.431925
train_step : 7293, loss1 : 1.695349, loss2 : 1.151121
train_step : 7294, loss1 : 1.039568, loss2 : 1.588261
train_step : 7295, loss1 : 1.402546, loss2 : 2.251269
train_step : 7296, loss1 : 1.497684, loss2 : 1.089815
train_step : 7297, loss1 : 1.835004, loss2 : 1.665276
train_step : 7298, loss1 : 1.615772, loss2 : 1.551861
train_step : 7299, loss1 : 1.589061, loss2 : 1.489677
train_step : 7300, loss1 : 1.503048, loss2 : 0.989465
train_step : 7301, loss1 : 1.038536, loss2 : 0.774614
train_step : 7302, loss1 : 0.855718, loss2 : 1.510992
train_step : 7303, loss1 : 1.243672, loss2 : 0.780331
train_step : 7304, loss1 : 0.899362, loss2 : 1.281523
train_step : 7305, loss1 : 0.857837, loss2 : 1.623325
train_step : 7306, loss1 : 1.833092, loss2 : 1.339848
train_step : 7307, loss1 : 1.606682, loss2 : 1.639912
train_step : 7308, loss1 : 0.658739, loss2 : 1.055701
train_step : 7309, loss1 : 1.151467, loss2 : 0.679838
train_step : 7310, loss1 : 1.195014, loss2 : 1.165786
train_step : 7311, loss1 : 0.811144, loss2 : 1.234112
train_step : 7312, loss1 : 1.609432, loss2 : 1.432244
train_step : 7313, loss1 : 2.111546, loss2 : 2.503259
train_step : 7314, loss1 : 1.717055, loss2 : 2.274628
train_step : 7315, loss1 : 3.213318, loss2 : 2.565695
train_step : 7316, loss1 : 2.099259, loss2 : 2.923172
train_step : 7317, loss1 : 2.601325, loss2 : 2.287821
train_step : 7318, loss1 : 2.153130, loss2 : 2.099425
train_step : 7319, loss1 : 2.331488, loss2 : 1.737256
train_step : 7320, loss1 : 1.006494, loss2 : 1.044188
train_step : 7321, loss1 : 0.993234, loss2 : 1.190690
train_step : 7322, loss1 : 1.476223, loss2 : 0.938276
train_step : 7323, loss1 : 0.735050, loss2 : 1.320094
train_step : 7324, loss1 : 0.869441, loss2 : 1.200735
train_step : 7325, loss1 : 0.982076, loss2 : 1.071874
train_step : 7326, loss1 : 1.020160, loss2 : 0.972394
train_step : 7327, loss1 : 1.885560, loss2 : 0.949591
train_step : 7328, loss1 : 1.416424, loss2 : 1.027662
train_step : 7329, loss1 : 0.953928, loss2 : 1.136650
train_step : 7330, loss1 : 1.986500, loss2 : 0.928632
train_step : 7331, loss1 : 1.431012, loss2 : 1.009709
train_step : 7332, loss1 : 0.767012, loss2 : 1.480756
train_step : 7333, loss1 : 1.217081, loss2 : 1.096532
train_step : 7334, loss1 : 1.322494, loss2 : 1.699111
train_step : 7335, loss1 : 1.660376, loss2 : 0.924581
train_step : 7336, loss1 : 1.571383, loss2 : 0.956657
train_step : 7337, loss1 : 0.917007, loss2 : 1.438903
train_step : 7338, loss1 : 1.215571, loss2 : 1.402452
train_step : 7339, loss1 : 1.841629, loss2 : 2.047384
train_step : 7340, loss1 : 0.848070, loss2 : 2.502624
train_step : 7341, loss1 : 1.063847, loss2 : 1.987842
train_step : 7342, loss1 : 0.640169, loss2 : 1.245515
train_step : 7343, loss1 : 1.015947, loss2 : 1.204435
train_step : 7344, loss1 : 2.054086, loss2 : 1.624161
train_step : 7345, loss1 : 2.433140, loss2 : 1.151796
train_step : 7346, loss1 : 0.783839, loss2 : 0.822696
train_step : 7347, loss1 : 0.787123, loss2 : 1.214975
train_step : 7348, loss1 : 0.668136, loss2 : 1.612926
train_step : 7349, loss1 : 0.781483, loss2 : 1.431919
train_step : 7350, loss1 : 1.507991, loss2 : 1.894285
train_step : 7351, loss1 : 1.200544, loss2 : 1.041033
train_step : 7352, loss1 : 1.313209, loss2 : 1.725245
train_step : 7353, loss1 : 1.511966, loss2 : 1.493391
train_step : 7354, loss1 : 1.118693, loss2 : 1.185724
train_step : 7355, loss1 : 1.406927, loss2 : 2.973594
train_step : 7356, loss1 : 2.727882, loss2 : 2.906138
train_step : 7357, loss1 : 2.720416, loss2 : 1.588065
train_step : 7358, loss1 : 0.919885, loss2 : 2.141154
train_step : 7359, loss1 : 1.507869, loss2 : 1.603628
train_step : 7360, loss1 : 1.529060, loss2 : 1.327343
train_step : 7361, loss1 : 0.655669, loss2 : 1.235711
train_step : 7362, loss1 : 1.730940, loss2 : 0.752110
train_step : 7363, loss1 : 1.585035, loss2 : 0.625726
train_step : 7364, loss1 : 1.329793, loss2 : 1.504560
train_step : 7365, loss1 : 1.896182, loss2 : 2.125823
train_step : 7366, loss1 : 2.004674, loss2 : 1.588336
train_step : 7367, loss1 : 2.986006, loss2 : 2.033248
train_step : 7368, loss1 : 3.646887, loss2 : 1.869433
train_step : 7369, loss1 : 1.884836, loss2 : 2.489138
train_step : 7370, loss1 : 1.386830, loss2 : 1.629787
train_step : 7371, loss1 : 2.538404, loss2 : 1.935192
train_step : 7372, loss1 : 1.456417, loss2 : 2.485943
train_step : 7373, loss1 : 2.096029, loss2 : 1.892032
train_step : 7374, loss1 : 1.869079, loss2 : 1.999385
train_step : 7375, loss1 : 3.612535, loss2 : 2.327618
train_step : 7376, loss1 : 2.328786, loss2 : 3.006710
train_step : 7377, loss1 : 3.521972, loss2 : 2.916007
train_step : 7378, loss1 : 3.851146, loss2 : 2.519064
train_step : 7379, loss1 : 2.991897, loss2 : 3.525207
train_step : 7380, loss1 : 2.523672, loss2 : 3.031558
train_step : 7381, loss1 : 2.841437, loss2 : 1.840085
train_step : 7382, loss1 : 2.057148, loss2 : 1.180653
train_step : 7383, loss1 : 2.338176, loss2 : 2.644968
train_step : 7384, loss1 : 2.037783, loss2 : 2.000574
train_step : 7385, loss1 : 1.873624, loss2 : 3.925430
train_step : 7386, loss1 : 3.262208, loss2 : 2.614268
train_step : 7387, loss1 : 3.848682, loss2 : 2.704918
train_step : 7388, loss1 : 1.305217, loss2 : 2.089038
train_step : 7389, loss1 : 2.741516, loss2 : 3.069451
train_step : 7390, loss1 : 2.478167, loss2 : 2.802656
train_step : 7391, loss1 : 2.214601, loss2 : 2.484105
train_step : 7392, loss1 : 2.664139, loss2 : 2.197912
train_step : 7393, loss1 : 0.981142, loss2 : 3.207213
train_step : 7394, loss1 : 1.525103, loss2 : 2.756236
train_step : 7395, loss1 : 2.201499, loss2 : 4.185267
train_step : 7396, loss1 : 2.257182, loss2 : 1.642625
train_step : 7397, loss1 : 2.798794, loss2 : 1.137032
train_step : 7398, loss1 : 3.167176, loss2 : 2.585783
train_step : 7399, loss1 : 2.885046, loss2 : 1.830993
train_step : 7400, loss1 : 2.434559, loss2 : 2.214022
train_step : 7401, loss1 : 2.793113, loss2 : 2.931080
train_step : 7402, loss1 : 2.369452, loss2 : 2.650529
train_step : 7403, loss1 : 1.624536, loss2 : 1.752847
train_step : 7404, loss1 : 1.200348, loss2 : 1.733040
train_step : 7405, loss1 : 0.917819, loss2 : 0.973256
train_step : 7406, loss1 : 1.323739, loss2 : 0.687496
train_step : 7407, loss1 : 1.590441, loss2 : 1.599440
train_step : 7408, loss1 : 2.888852, loss2 : 1.316594
train_step : 7409, loss1 : 0.762076, loss2 : 1.003240
train_step : 7410, loss1 : 1.816357, loss2 : 1.971572
train_step : 7411, loss1 : 2.272125, loss2 : 2.194396
train_step : 7412, loss1 : 2.249155, loss2 : 2.771176
train_step : 7413, loss1 : 1.215632, loss2 : 1.998602
train_step : 7414, loss1 : 1.326163, loss2 : 1.719300
train_step : 7415, loss1 : 1.247214, loss2 : 1.077166
train_step : 7416, loss1 : 0.615888, loss2 : 1.166238
train_step : 7417, loss1 : 0.954213, loss2 : 1.390276
train_step : 7418, loss1 : 1.170932, loss2 : 0.955074
train_step : 7419, loss1 : 0.988601, loss2 : 1.025548
train_step : 7420, loss1 : 1.377862, loss2 : 1.152755
train_step : 7421, loss1 : 0.678343, loss2 : 1.472154
train_step : 7422, loss1 : 1.441181, loss2 : 1.856483
train_step : 7423, loss1 : 1.360833, loss2 : 1.837381
train_step : 7424, loss1 : 1.829698, loss2 : 1.663947
train_step : 7425, loss1 : 1.358298, loss2 : 1.827760
train_step : 7426, loss1 : 1.127385, loss2 : 1.427667
train_step : 7427, loss1 : 1.584851, loss2 : 1.268884
train_step : 7428, loss1 : 1.667103, loss2 : 1.546156
train_step : 7429, loss1 : 1.438398, loss2 : 1.856635
train_step : 7430, loss1 : 1.106530, loss2 : 0.967368
train_step : 7431, loss1 : 1.022821, loss2 : 1.606165
train_step : 7432, loss1 : 1.268189, loss2 : 1.809807
train_step : 7433, loss1 : 3.194741, loss2 : 0.798059
train_step : 7434, loss1 : 1.950314, loss2 : 2.127422
train_step : 7435, loss1 : 1.119130, loss2 : 2.067731
train_step : 7436, loss1 : 1.336851, loss2 : 1.245847
train_step : 7437, loss1 : 0.540775, loss2 : 0.825378
train_step : 7438, loss1 : 0.502719, loss2 : 0.944804
train_step : 7439, loss1 : 1.401916, loss2 : 1.145302
train_step : 7440, loss1 : 1.647980, loss2 : 1.465974
train_step : 7441, loss1 : 1.443156, loss2 : 0.641397
train_step : 7442, loss1 : 1.474340, loss2 : 1.393391
train_step : 7443, loss1 : 1.652285, loss2 : 1.618648
train_step : 7444, loss1 : 1.975609, loss2 : 1.770792
train_step : 7445, loss1 : 1.213380, loss2 : 1.641963
train_step : 7446, loss1 : 1.018760, loss2 : 1.232653
train_step : 7447, loss1 : 1.743851, loss2 : 1.007604
train_step : 7448, loss1 : 0.984497, loss2 : 0.797262
train_step : 7449, loss1 : 1.147496, loss2 : 0.955656
train_step : 7450, loss1 : 1.293191, loss2 : 1.331307
train_step : 7451, loss1 : 1.594223, loss2 : 1.720207
train_step : 7452, loss1 : 2.370888, loss2 : 1.414112
train_step : 7453, loss1 : 1.577392, loss2 : 2.065091
train_step : 7454, loss1 : 1.982658, loss2 : 1.111138
train_step : 7455, loss1 : 1.163923, loss2 : 1.388704
train_step : 7456, loss1 : 1.169848, loss2 : 1.780438
train_step : 7457, loss1 : 1.311321, loss2 : 1.350694
train_step : 7458, loss1 : 1.738915, loss2 : 1.900509
train_step : 7459, loss1 : 1.397114, loss2 : 1.474930
train_step : 7460, loss1 : 1.250220, loss2 : 0.760574
train_step : 7461, loss1 : 2.187570, loss2 : 1.041277
train_step : 7462, loss1 : 1.329471, loss2 : 1.293893
train_step : 7463, loss1 : 1.451328, loss2 : 0.963585
train_step : 7464, loss1 : 1.946664, loss2 : 1.099488
train_step : 7465, loss1 : 1.269204, loss2 : 1.317673
train_step : 7466, loss1 : 1.125414, loss2 : 1.146606
train_step : 7467, loss1 : 0.835324, loss2 : 1.575101
train_step : 7468, loss1 : 1.328610, loss2 : 2.118781
train_step : 7469, loss1 : 1.929354, loss2 : 1.266353
train_step : 7470, loss1 : 0.910430, loss2 : 1.637757
train_step : 7471, loss1 : 0.913483, loss2 : 0.404342
train_step : 7472, loss1 : 0.577451, loss2 : 0.959832
train_step : 7473, loss1 : 1.259836, loss2 : 1.641329
train_step : 7474, loss1 : 1.082877, loss2 : 0.826380
train_step : 7475, loss1 : 1.494544, loss2 : 1.302187
train_step : 7476, loss1 : 1.022412, loss2 : 1.391881
train_step : 7477, loss1 : 2.982479, loss2 : 2.286182
train_step : 7478, loss1 : 2.302682, loss2 : 2.901998
train_step : 7479, loss1 : 2.396864, loss2 : 2.569718
train_step : 7480, loss1 : 2.182927, loss2 : 2.118418
train_step : 7481, loss1 : 3.386678, loss2 : 1.400275
train_step : 7482, loss1 : 3.212071, loss2 : 2.863403
train_step : 7483, loss1 : 1.932194, loss2 : 2.167391
train_step : 7484, loss1 : 2.516810, loss2 : 2.903665
train_step : 7485, loss1 : 1.272548, loss2 : 2.696488
train_step : 7486, loss1 : 2.808651, loss2 : 1.635720
train_step : 7487, loss1 : 3.159352, loss2 : 2.200847
train_step : 7488, loss1 : 2.259616, loss2 : 3.391352
train_step : 7489, loss1 : 2.738737, loss2 : 1.191477
train_step : 7490, loss1 : 2.222021, loss2 : 1.416868
train_step : 7491, loss1 : 1.881377, loss2 : 3.774225
train_step : 7492, loss1 : 1.706906, loss2 : 3.155238
train_step : 7493, loss1 : 3.350842, loss2 : 1.621946
train_step : 7494, loss1 : 1.122223, loss2 : 2.668324
train_step : 7495, loss1 : 1.598114, loss2 : 1.732995
train_step : 7496, loss1 : 1.646249, loss2 : 1.228814
train_step : 7497, loss1 : 2.573778, loss2 : 1.231224
train_step : 7498, loss1 : 1.748234, loss2 : 1.519941
train_step : 7499, loss1 : 1.524241, loss2 : 2.095287
train_step : 7500, loss1 : 1.809197, loss2 : 2.314987
train_step : 7501, loss1 : 2.162072, loss2 : 1.608022
train_step : 7502, loss1 : 2.202752, loss2 : 1.517865
train_step : 7503, loss1 : 2.290579, loss2 : 2.163981
train_step : 7504, loss1 : 2.300814, loss2 : 0.889439
train_step : 7505, loss1 : 1.373907, loss2 : 0.788064
train_step : 7506, loss1 : 2.057445, loss2 : 1.219613
train_step : 7507, loss1 : 1.024071, loss2 : 1.622470
train_step : 7508, loss1 : 1.141292, loss2 : 0.908269
train_step : 7509, loss1 : 1.488662, loss2 : 1.725837
train_step : 7510, loss1 : 1.991593, loss2 : 1.374278
train_step : 7511, loss1 : 1.711684, loss2 : 2.213606
train_step : 7512, loss1 : 0.927624, loss2 : 0.715624
train_step : 7513, loss1 : 0.903891, loss2 : 0.718477
train_step : 7514, loss1 : 0.816561, loss2 : 1.934604
train_step : 7515, loss1 : 1.575861, loss2 : 0.977108
train_step : 7516, loss1 : 1.606302, loss2 : 0.675291
train_step : 7517, loss1 : 1.530505, loss2 : 1.390705
train_step : 7518, loss1 : 1.491219, loss2 : 1.225508
train_step : 7519, loss1 : 2.271140, loss2 : 1.858847
train_step : 7520, loss1 : 1.375716, loss2 : 1.708408
train_step : 7521, loss1 : 2.441602, loss2 : 2.049939
train_step : 7522, loss1 : 2.010527, loss2 : 2.898883
train_step : 7523, loss1 : 3.248441, loss2 : 2.639739
train_step : 7524, loss1 : 1.893965, loss2 : 1.517058
train_step : 7525, loss1 : 2.571509, loss2 : 1.264786
train_step : 7526, loss1 : 1.238122, loss2 : 1.295802
train_step : 7527, loss1 : 1.574275, loss2 : 0.643845
train_step : 7528, loss1 : 1.333092, loss2 : 0.993133
train_step : 7529, loss1 : 1.933658, loss2 : 1.347278
train_step : 7530, loss1 : 1.206202, loss2 : 1.703722
train_step : 7531, loss1 : 2.139539, loss2 : 1.446497
train_step : 7532, loss1 : 0.959747, loss2 : 1.127780
train_step : 7533, loss1 : 0.758210, loss2 : 0.737874
train_step : 7534, loss1 : 1.521313, loss2 : 1.308575
train_step : 7535, loss1 : 1.556493, loss2 : 3.505296
train_step : 7536, loss1 : 1.527101, loss2 : 3.174947
train_step : 7537, loss1 : 1.123048, loss2 : 2.631706
train_step : 7538, loss1 : 1.214838, loss2 : 1.837072
train_step : 7539, loss1 : 1.312041, loss2 : 2.474893
train_step : 7540, loss1 : 1.481709, loss2 : 1.805706
train_step : 7541, loss1 : 0.558033, loss2 : 1.013161
train_step : 7542, loss1 : 1.498532, loss2 : 0.648859
train_step : 7543, loss1 : 0.928532, loss2 : 1.136585
train_step : 7544, loss1 : 1.088785, loss2 : 1.146447
train_step : 7545, loss1 : 0.850337, loss2 : 1.093144
train_step : 7546, loss1 : 0.767166, loss2 : 1.164118
train_step : 7547, loss1 : 0.906900, loss2 : 1.817106
train_step : 7548, loss1 : 1.336703, loss2 : 0.723085
train_step : 7549, loss1 : 1.491044, loss2 : 1.043962
train_step : 7550, loss1 : 1.807205, loss2 : 0.724898
train_step : 7551, loss1 : 2.580679, loss2 : 0.806949
train_step : 7552, loss1 : 1.352448, loss2 : 1.470519
train_step : 7553, loss1 : 0.968428, loss2 : 1.471483
train_step : 7554, loss1 : 1.095976, loss2 : 1.063994
train_step : 7555, loss1 : 1.493036, loss2 : 0.742727
train_step : 7556, loss1 : 1.183848, loss2 : 1.544748
train_step : 7557, loss1 : 1.313204, loss2 : 0.764727
train_step : 7558, loss1 : 1.103327, loss2 : 1.602397
train_step : 7559, loss1 : 1.310227, loss2 : 0.907735
train_step : 7560, loss1 : 1.329282, loss2 : 1.385366
train_step : 7561, loss1 : 1.401103, loss2 : 1.626875
train_step : 7562, loss1 : 1.116117, loss2 : 1.243849
train_step : 7563, loss1 : 1.403292, loss2 : 1.593864
train_step : 7564, loss1 : 1.301829, loss2 : 1.976121
train_step : 7565, loss1 : 2.679522, loss2 : 1.391173
train_step : 7566, loss1 : 2.015024, loss2 : 2.911280
train_step : 7567, loss1 : 2.016833, loss2 : 4.084730
train_step : 7568, loss1 : 2.883751, loss2 : 3.130235
train_step : 7569, loss1 : 2.932436, loss2 : 3.703168
train_step : 7570, loss1 : 2.992038, loss2 : 2.094564
train_step : 7571, loss1 : 2.369284, loss2 : 4.103961
train_step : 7572, loss1 : 1.811928, loss2 : 1.584298
train_step : 7573, loss1 : 1.773353, loss2 : 1.171972
train_step : 7574, loss1 : 1.703886, loss2 : 1.769050
train_step : 7575, loss1 : 1.461034, loss2 : 2.093020
train_step : 7576, loss1 : 1.775670, loss2 : 1.463527
train_step : 7577, loss1 : 2.718843, loss2 : 1.818310
train_step : 7578, loss1 : 1.681977, loss2 : 2.115819
train_step : 7579, loss1 : 2.131701, loss2 : 1.757148
train_step : 7580, loss1 : 1.352012, loss2 : 2.006389
train_step : 7581, loss1 : 1.046335, loss2 : 1.368366
train_step : 7582, loss1 : 1.231240, loss2 : 1.572764
train_step : 7583, loss1 : 2.287155, loss2 : 1.184486
train_step : 7584, loss1 : 1.638191, loss2 : 1.179175
train_step : 7585, loss1 : 1.686430, loss2 : 1.236142
train_step : 7586, loss1 : 0.875647, loss2 : 1.364415
train_step : 7587, loss1 : 1.347768, loss2 : 1.221584
train_step : 7588, loss1 : 1.142652, loss2 : 1.031723
train_step : 7589, loss1 : 1.437046, loss2 : 1.889505
train_step : 7590, loss1 : 1.388700, loss2 : 1.413122
train_step : 7591, loss1 : 1.366474, loss2 : 2.477464
train_step : 7592, loss1 : 1.052417, loss2 : 0.759697
train_step : 7593, loss1 : 1.472616, loss2 : 1.288239
train_step : 7594, loss1 : 1.815317, loss2 : 1.002203
train_step : 7595, loss1 : 1.478843, loss2 : 0.629787
train_step : 7596, loss1 : 0.822884, loss2 : 1.017443
train_step : 7597, loss1 : 1.019770, loss2 : 1.476502
train_step : 7598, loss1 : 0.700691, loss2 : 1.052120
train_step : 7599, loss1 : 0.854425, loss2 : 0.862535
train_step : 7600, loss1 : 1.670433, loss2 : 1.198251
train_step : 7601, loss1 : 1.993292, loss2 : 1.064167
train_step : 7602, loss1 : 2.363442, loss2 : 1.159997
train_step : 7603, loss1 : 1.496580, loss2 : 1.653772
train_step : 7604, loss1 : 1.200453, loss2 : 1.157506
train_step : 7605, loss1 : 1.016346, loss2 : 1.472234
train_step : 7606, loss1 : 1.226087, loss2 : 1.034410
train_step : 7607, loss1 : 0.819208, loss2 : 0.950637
train_step : 7608, loss1 : 1.517894, loss2 : 1.529415
train_step : 7609, loss1 : 0.923623, loss2 : 1.046722
train_step : 7610, loss1 : 1.560597, loss2 : 1.128071
train_step : 7611, loss1 : 1.249933, loss2 : 0.635725
train_step : 7612, loss1 : 1.151149, loss2 : 0.966368
train_step : 7613, loss1 : 1.309564, loss2 : 0.980590
train_step : 7614, loss1 : 0.891452, loss2 : 0.772647
train_step : 7615, loss1 : 1.709358, loss2 : 2.114346
train_step : 7616, loss1 : 1.871938, loss2 : 1.107875
train_step : 7617, loss1 : 1.639080, loss2 : 1.280612
train_step : 7618, loss1 : 1.629218, loss2 : 1.269355
train_step : 7619, loss1 : 1.695899, loss2 : 1.271049
train_step : 7620, loss1 : 1.359970, loss2 : 0.680511
train_step : 7621, loss1 : 0.739815, loss2 : 0.907291
train_step : 7622, loss1 : 1.144400, loss2 : 1.052375
train_step : 7623, loss1 : 1.293513, loss2 : 0.979084
train_step : 7624, loss1 : 1.361546, loss2 : 0.470969
train_step : 7625, loss1 : 1.444236, loss2 : 1.416087
train_step : 7626, loss1 : 1.082592, loss2 : 0.553206
train_step : 7627, loss1 : 0.836503, loss2 : 1.018063
train_step : 7628, loss1 : 1.161155, loss2 : 1.535585
train_step : 7629, loss1 : 2.582830, loss2 : 1.341342
train_step : 7630, loss1 : 1.710952, loss2 : 2.684855
train_step : 7631, loss1 : 0.825093, loss2 : 0.975456
train_step : 7632, loss1 : 1.485239, loss2 : 2.166701
train_step : 7633, loss1 : 1.310499, loss2 : 1.383220
train_step : 7634, loss1 : 1.409057, loss2 : 2.159305
train_step : 7635, loss1 : 1.808232, loss2 : 1.674278
train_step : 7636, loss1 : 1.057251, loss2 : 2.188927
train_step : 7637, loss1 : 2.909642, loss2 : 1.377789
train_step : 7638, loss1 : 1.110126, loss2 : 1.053674
train_step : 7639, loss1 : 1.064660, loss2 : 0.981869
train_step : 7640, loss1 : 0.976751, loss2 : 0.689538
train_step : 7641, loss1 : 1.662244, loss2 : 1.246773
train_step : 7642, loss1 : 0.763059, loss2 : 1.170582
train_step : 7643, loss1 : 1.687034, loss2 : 1.699095
train_step : 7644, loss1 : 0.965872, loss2 : 1.069969
train_step : 7645, loss1 : 1.007526, loss2 : 1.040445
train_step : 7646, loss1 : 1.516845, loss2 : 0.563339
train_step : 7647, loss1 : 1.254306, loss2 : 1.372381
train_step : 7648, loss1 : 0.595184, loss2 : 1.134780
train_step : 7649, loss1 : 0.985786, loss2 : 1.867300
train_step : 7650, loss1 : 1.185745, loss2 : 1.505127
train_step : 7651, loss1 : 2.171422, loss2 : 1.699090
train_step : 7652, loss1 : 2.408534, loss2 : 1.593461
train_step : 7653, loss1 : 1.936509, loss2 : 3.006256
train_step : 7654, loss1 : 1.774242, loss2 : 2.335621
train_step : 7655, loss1 : 1.845639, loss2 : 1.351839
train_step : 7656, loss1 : 0.903836, loss2 : 1.368577
train_step : 7657, loss1 : 0.704835, loss2 : 1.356525
train_step : 7658, loss1 : 1.003098, loss2 : 1.153706
train_step : 7659, loss1 : 1.685977, loss2 : 0.743870
train_step : 7660, loss1 : 0.596988, loss2 : 1.013313
train_step : 7661, loss1 : 3.140550, loss2 : 1.080529
train_step : 7662, loss1 : 0.993324, loss2 : 0.703359
train_step : 7663, loss1 : 0.844284, loss2 : 0.492451
train_step : 7664, loss1 : 0.782744, loss2 : 1.432727
train_step : 7665, loss1 : 1.177164, loss2 : 1.453270
train_step : 7666, loss1 : 1.271690, loss2 : 1.148908
train_step : 7667, loss1 : 1.302687, loss2 : 1.292170
train_step : 7668, loss1 : 2.507974, loss2 : 1.438759
train_step : 7669, loss1 : 1.904889, loss2 : 1.279188
train_step : 7670, loss1 : 2.102909, loss2 : 2.345894
train_step : 7671, loss1 : 2.083404, loss2 : 1.773492
train_step : 7672, loss1 : 2.101534, loss2 : 1.968665
train_step : 7673, loss1 : 1.484363, loss2 : 2.657475
train_step : 7674, loss1 : 3.441839, loss2 : 2.527551
train_step : 7675, loss1 : 1.701359, loss2 : 3.309401
train_step : 7676, loss1 : 1.740662, loss2 : 1.332740
train_step : 7677, loss1 : 1.723977, loss2 : 2.059257
train_step : 7678, loss1 : 1.795393, loss2 : 1.999594
train_step : 7679, loss1 : 3.282299, loss2 : 3.006935
train_step : 7680, loss1 : 3.711598, loss2 : 3.372188
train_step : 7681, loss1 : 6.336024, loss2 : 5.947131
train_step : 7682, loss1 : 6.150639, loss2 : 5.796626
train_step : 7683, loss1 : 6.894215, loss2 : 7.502466
train_step : 7684, loss1 : 3.384805, loss2 : 5.083765
train_step : 7685, loss1 : 3.941175, loss2 : 3.998089
train_step : 7686, loss1 : 1.804217, loss2 : 2.329181
train_step : 7687, loss1 : 0.956485, loss2 : 0.917015
train_step : 7688, loss1 : 1.880756, loss2 : 1.441528
train_step : 7689, loss1 : 1.264426, loss2 : 1.817058
train_step : 7690, loss1 : 1.650463, loss2 : 1.161981
train_step : 7691, loss1 : 2.062623, loss2 : 1.469582
train_step : 7692, loss1 : 0.926255, loss2 : 1.617056
train_step : 7693, loss1 : 1.594162, loss2 : 1.012996
train_step : 7694, loss1 : 0.830583, loss2 : 1.045189
train_step : 7695, loss1 : 1.971948, loss2 : 1.322345
train_step : 7696, loss1 : 1.039018, loss2 : 0.753062
train_step : 7697, loss1 : 1.492090, loss2 : 1.315104
train_step : 7698, loss1 : 1.402381, loss2 : 1.760887
train_step : 7699, loss1 : 0.848712, loss2 : 1.085387
train_step : 7700, loss1 : 0.742852, loss2 : 1.123749
train_step : 7701, loss1 : 1.121835, loss2 : 1.158891
train_step : 7702, loss1 : 1.868763, loss2 : 0.832719
train_step : 7703, loss1 : 0.665382, loss2 : 1.397486
train_step : 7704, loss1 : 1.677572, loss2 : 0.894027
train_step : 7705, loss1 : 0.818813, loss2 : 1.328290
train_step : 7706, loss1 : 1.247250, loss2 : 0.771431
train_step : 7707, loss1 : 1.330319, loss2 : 1.189182
train_step : 7708, loss1 : 0.888603, loss2 : 2.054406
train_step : 7709, loss1 : 1.176654, loss2 : 2.063590
train_step : 7710, loss1 : 1.438470, loss2 : 1.658714
train_step : 7711, loss1 : 1.323437, loss2 : 1.496845
train_step : 7712, loss1 : 1.477449, loss2 : 0.987063
train_step : 7713, loss1 : 1.901617, loss2 : 1.177562
train_step : 7714, loss1 : 1.385729, loss2 : 1.266334
train_step : 7715, loss1 : 1.619076, loss2 : 1.378824
train_step : 7716, loss1 : 1.604039, loss2 : 1.398003
train_step : 7717, loss1 : 1.122985, loss2 : 1.468935
train_step : 7718, loss1 : 1.383744, loss2 : 1.152411
train_step : 7719, loss1 : 1.299278, loss2 : 1.796154
train_step : 7720, loss1 : 1.904614, loss2 : 1.138782
train_step : 7721, loss1 : 0.749130, loss2 : 1.357478
train_step : 7722, loss1 : 1.001679, loss2 : 1.622461
train_step : 7723, loss1 : 0.912874, loss2 : 1.512578
train_step : 7724, loss1 : 1.113968, loss2 : 0.886984
train_step : 7725, loss1 : 1.122891, loss2 : 1.005837
train_step : 7726, loss1 : 1.419727, loss2 : 1.002198
train_step : 7727, loss1 : 2.175869, loss2 : 2.982863
train_step : 7728, loss1 : 3.392388, loss2 : 5.195109
train_step : 7729, loss1 : 1.932823, loss2 : 2.446072
train_step : 7730, loss1 : 2.228440, loss2 : 2.749064
train_step : 7731, loss1 : 1.801730, loss2 : 1.849797
train_step : 7732, loss1 : 1.448883, loss2 : 1.159127
train_step : 7733, loss1 : 0.689339, loss2 : 0.945852
train_step : 7734, loss1 : 1.003092, loss2 : 1.216635
train_step : 7735, loss1 : 1.331765, loss2 : 1.401955
train_step : 7736, loss1 : 1.128630, loss2 : 0.742658
train_step : 7737, loss1 : 1.288122, loss2 : 2.117480
train_step : 7738, loss1 : 1.884190, loss2 : 1.345775
train_step : 7739, loss1 : 1.402753, loss2 : 1.337076
train_step : 7740, loss1 : 1.483112, loss2 : 1.141061
train_step : 7741, loss1 : 1.013552, loss2 : 0.981004
train_step : 7742, loss1 : 0.938928, loss2 : 0.998226
train_step : 7743, loss1 : 1.126045, loss2 : 0.709364
train_step : 7744, loss1 : 0.653032, loss2 : 0.539278
train_step : 7745, loss1 : 0.679902, loss2 : 0.500486
train_step : 7746, loss1 : 1.686878, loss2 : 1.728069
train_step : 7747, loss1 : 1.414022, loss2 : 1.155995
train_step : 7748, loss1 : 0.947722, loss2 : 1.753429
train_step : 7749, loss1 : 1.158788, loss2 : 1.562243
train_step : 7750, loss1 : 1.359855, loss2 : 1.406339
train_step : 7751, loss1 : 1.048278, loss2 : 1.097495
train_step : 7752, loss1 : 0.827024, loss2 : 0.873318
train_step : 7753, loss1 : 1.271410, loss2 : 0.981938
train_step : 7754, loss1 : 1.410477, loss2 : 1.152306
train_step : 7755, loss1 : 0.577497, loss2 : 1.014349
train_step : 7756, loss1 : 0.882935, loss2 : 1.009459
train_step : 7757, loss1 : 1.553560, loss2 : 2.095114
train_step : 7758, loss1 : 1.705065, loss2 : 2.447837
train_step : 7759, loss1 : 0.952242, loss2 : 2.213814
train_step : 7760, loss1 : 1.135880, loss2 : 1.562233
train_step : 7761, loss1 : 0.684720, loss2 : 1.176195
train_step : 7762, loss1 : 1.023505, loss2 : 0.502182
train_step : 7763, loss1 : 0.911045, loss2 : 1.100727
train_step : 7764, loss1 : 0.887034, loss2 : 1.533746
train_step : 7765, loss1 : 1.789983, loss2 : 1.537805
train_step : 7766, loss1 : 1.866828, loss2 : 1.991288
train_step : 7767, loss1 : 1.288238, loss2 : 1.748485
train_step : 7768, loss1 : 1.526494, loss2 : 0.990949
train_step : 7769, loss1 : 1.095919, loss2 : 1.306780
train_step : 7770, loss1 : 1.530485, loss2 : 1.841110
train_step : 7771, loss1 : 1.391735, loss2 : 1.804431
train_step : 7772, loss1 : 0.751913, loss2 : 0.852051
train_step : 7773, loss1 : 1.076891, loss2 : 1.121642
train_step : 7774, loss1 : 1.543857, loss2 : 1.832345
train_step : 7775, loss1 : 0.855612, loss2 : 0.505117
train_step : 7776, loss1 : 1.910630, loss2 : 1.607847
train_step : 7777, loss1 : 1.001961, loss2 : 0.680089
train_step : 7778, loss1 : 1.101321, loss2 : 1.226412
train_step : 7779, loss1 : 1.411766, loss2 : 1.550392
train_step : 7780, loss1 : 1.523467, loss2 : 1.335292
train_step : 7781, loss1 : 1.097970, loss2 : 0.766259
train_step : 7782, loss1 : 1.391020, loss2 : 1.137451
train_step : 7783, loss1 : 0.673001, loss2 : 2.545431
train_step : 7784, loss1 : 1.918306, loss2 : 1.381576
train_step : 7785, loss1 : 0.731684, loss2 : 0.532150
train_step : 7786, loss1 : 0.661445, loss2 : 1.119551
train_step : 7787, loss1 : 1.462528, loss2 : 1.007843
train_step : 7788, loss1 : 0.987728, loss2 : 1.415379
train_step : 7789, loss1 : 0.826855, loss2 : 0.583513
train_step : 7790, loss1 : 0.894805, loss2 : 1.686604
train_step : 7791, loss1 : 1.639793, loss2 : 0.761724
train_step : 7792, loss1 : 0.611844, loss2 : 1.185131
train_step : 7793, loss1 : 0.831508, loss2 : 1.501103
train_step : 7794, loss1 : 0.634765, loss2 : 1.259430
train_step : 7795, loss1 : 1.156728, loss2 : 1.953998
train_step : 7796, loss1 : 1.703293, loss2 : 0.981891
train_step : 7797, loss1 : 1.228767, loss2 : 1.183089
train_step : 7798, loss1 : 1.036154, loss2 : 1.366387
train_step : 7799, loss1 : 1.281388, loss2 : 1.369149
train_step : 7800, loss1 : 0.812269, loss2 : 0.888776
train_step : 7801, loss1 : 1.135891, loss2 : 1.069852
train_step : 7802, loss1 : 1.366593, loss2 : 1.031560
train_step : 7803, loss1 : 1.324286, loss2 : 1.073843
train_step : 7804, loss1 : 0.961840, loss2 : 1.179008
train_step : 7805, loss1 : 0.501285, loss2 : 1.151920
train_step : 7806, loss1 : 0.797666, loss2 : 0.936808
train_step : 7807, loss1 : 1.886753, loss2 : 1.527957
train_step : 7808, loss1 : 0.468409, loss2 : 1.453704
train_step : 7809, loss1 : 1.731773, loss2 : 1.008611
train_step : 7810, loss1 : 1.264389, loss2 : 3.449043
train_step : 7811, loss1 : 1.182037, loss2 : 0.954207
train_step : 7812, loss1 : 0.536338, loss2 : 0.838638
train_step : 7813, loss1 : 1.271949, loss2 : 0.686465
train_step : 7814, loss1 : 1.009231, loss2 : 0.644879
train_step : 7815, loss1 : 0.584615, loss2 : 1.946112
train_step : 7816, loss1 : 0.713281, loss2 : 1.328854
train_step : 7817, loss1 : 0.918936, loss2 : 1.693440
train_step : 7818, loss1 : 1.090720, loss2 : 1.529202
train_step : 7819, loss1 : 0.724964, loss2 : 1.109484
train_step : 7820, loss1 : 2.164793, loss2 : 1.588871
train_step : 7821, loss1 : 1.356821, loss2 : 1.131784
train_step : 7822, loss1 : 1.150937, loss2 : 0.778405
train_step : 7823, loss1 : 2.237491, loss2 : 1.317710
train_step : 7824, loss1 : 1.460904, loss2 : 0.812656
train_step : 7825, loss1 : 1.880686, loss2 : 1.122151
train_step : 7826, loss1 : 1.987780, loss2 : 2.011971
train_step : 7827, loss1 : 2.013066, loss2 : 3.219307
train_step : 7828, loss1 : 2.863237, loss2 : 2.027631
train_step : 7829, loss1 : 2.041004, loss2 : 1.811900
train_step : 7830, loss1 : 1.938545, loss2 : 2.023935
train_step : 7831, loss1 : 0.802945, loss2 : 0.787952
train_step : 7832, loss1 : 0.856600, loss2 : 1.163104
train_step : 7833, loss1 : 2.165515, loss2 : 0.882825
train_step : 7834, loss1 : 0.466749, loss2 : 1.026286
train_step : 7835, loss1 : 2.168887, loss2 : 0.648131
train_step : 7836, loss1 : 1.694537, loss2 : 1.847484
train_step : 7837, loss1 : 1.675910, loss2 : 2.448829
train_step : 7838, loss1 : 0.976711, loss2 : 1.393917
train_step : 7839, loss1 : 0.849163, loss2 : 1.658237
train_step : 7840, loss1 : 0.764370, loss2 : 1.273314
train_step : 7841, loss1 : 2.456372, loss2 : 1.077274
train_step : 7842, loss1 : 0.862171, loss2 : 1.587174
train_step : 7843, loss1 : 0.967444, loss2 : 1.010424
train_step : 7844, loss1 : 1.401591, loss2 : 1.156486
train_step : 7845, loss1 : 0.929064, loss2 : 1.205163
train_step : 7846, loss1 : 1.228619, loss2 : 1.507215
train_step : 7847, loss1 : 1.883058, loss2 : 2.010399
train_step : 7848, loss1 : 1.902947, loss2 : 1.798883
train_step : 7849, loss1 : 1.772533, loss2 : 1.207857
train_step : 7850, loss1 : 1.451386, loss2 : 1.732170
train_step : 7851, loss1 : 1.703911, loss2 : 1.237858
train_step : 7852, loss1 : 0.727408, loss2 : 1.032495
train_step : 7853, loss1 : 0.753401, loss2 : 1.275713
train_step : 7854, loss1 : 1.247064, loss2 : 1.163340
train_step : 7855, loss1 : 1.095428, loss2 : 0.779147
train_step : 7856, loss1 : 1.333556, loss2 : 1.146361
train_step : 7857, loss1 : 0.954730, loss2 : 1.411894
train_step : 7858, loss1 : 1.810860, loss2 : 2.346543
train_step : 7859, loss1 : 0.968565, loss2 : 1.308275
train_step : 7860, loss1 : 0.802829, loss2 : 1.937849
train_step : 7861, loss1 : 1.639264, loss2 : 1.190162
train_step : 7862, loss1 : 0.995682, loss2 : 1.262305
train_step : 7863, loss1 : 1.408612, loss2 : 3.453071
train_step : 7864, loss1 : 1.984479, loss2 : 1.314519
train_step : 7865, loss1 : 3.029899, loss2 : 1.740323
train_step : 7866, loss1 : 1.553729, loss2 : 3.405805
train_step : 7867, loss1 : 3.029530, loss2 : 2.811689
train_step : 7868, loss1 : 2.964094, loss2 : 2.182995
train_step : 7869, loss1 : 2.346178, loss2 : 2.264533
train_step : 7870, loss1 : 1.025673, loss2 : 2.787626
train_step : 7871, loss1 : 1.065186, loss2 : 1.818826
train_step : 7872, loss1 : 2.048120, loss2 : 1.148606
train_step : 7873, loss1 : 1.430478, loss2 : 1.814745
train_step : 7874, loss1 : 1.496703, loss2 : 2.219506
train_step : 7875, loss1 : 1.702429, loss2 : 1.628882
train_step : 7876, loss1 : 1.353738, loss2 : 2.329062
train_step : 7877, loss1 : 2.568803, loss2 : 1.909111
train_step : 7878, loss1 : 0.825252, loss2 : 1.459726
train_step : 7879, loss1 : 1.336648, loss2 : 1.362197
train_step : 7880, loss1 : 1.876492, loss2 : 1.247946
train_step : 7881, loss1 : 0.872803, loss2 : 1.223360
train_step : 7882, loss1 : 0.821065, loss2 : 1.543845
train_step : 7883, loss1 : 0.837953, loss2 : 1.839497
train_step : 7884, loss1 : 0.913383, loss2 : 0.907928
train_step : 7885, loss1 : 1.068623, loss2 : 1.043532
train_step : 7886, loss1 : 1.547155, loss2 : 1.904557
train_step : 7887, loss1 : 0.919941, loss2 : 1.345911
train_step : 7888, loss1 : 0.962662, loss2 : 0.741187
train_step : 7889, loss1 : 1.238492, loss2 : 0.502167
train_step : 7890, loss1 : 1.070796, loss2 : 0.889708
train_step : 7891, loss1 : 1.561808, loss2 : 1.434890
train_step : 7892, loss1 : 2.078211, loss2 : 2.083719
train_step : 7893, loss1 : 1.648078, loss2 : 1.406389
train_step : 7894, loss1 : 0.758212, loss2 : 4.797925
train_step : 7895, loss1 : 1.607889, loss2 : 1.276419
train_step : 7896, loss1 : 2.086146, loss2 : 1.087257
train_step : 7897, loss1 : 0.929120, loss2 : 0.879495
train_step : 7898, loss1 : 1.457390, loss2 : 1.670479
train_step : 7899, loss1 : 2.333822, loss2 : 1.964467
train_step : 7900, loss1 : 2.316818, loss2 : 1.642692
train_step : 7901, loss1 : 2.554530, loss2 : 2.267525
train_step : 7902, loss1 : 3.350941, loss2 : 2.641637
train_step : 7903, loss1 : 3.046372, loss2 : 4.061567
train_step : 7904, loss1 : 3.343031, loss2 : 2.060090
train_step : 7905, loss1 : 2.493802, loss2 : 4.519283
train_step : 7906, loss1 : 5.810747, loss2 : 3.194444
train_step : 7907, loss1 : 2.066151, loss2 : 4.586947
train_step : 7908, loss1 : 1.145698, loss2 : 2.237821
train_step : 7909, loss1 : 1.198711, loss2 : 1.580573
train_step : 7910, loss1 : 1.335875, loss2 : 0.820650
train_step : 7911, loss1 : 1.027268, loss2 : 1.472647
train_step : 7912, loss1 : 1.910943, loss2 : 0.731919
train_step : 7913, loss1 : 1.084710, loss2 : 2.125757
train_step : 7914, loss1 : 0.844922, loss2 : 1.627808
train_step : 7915, loss1 : 1.280883, loss2 : 1.190899
train_step : 7916, loss1 : 1.281481, loss2 : 1.472684
train_step : 7917, loss1 : 1.638430, loss2 : 1.058813
train_step : 7918, loss1 : 0.904736, loss2 : 0.996160
train_step : 7919, loss1 : 0.998384, loss2 : 1.952313
train_step : 7920, loss1 : 1.200504, loss2 : 1.216045
train_step : 7921, loss1 : 1.682168, loss2 : 0.879359
train_step : 7922, loss1 : 0.979081, loss2 : 0.806160
train_step : 7923, loss1 : 0.730725, loss2 : 0.476458
train_step : 7924, loss1 : 1.979210, loss2 : 1.001440
train_step : 7925, loss1 : 1.246769, loss2 : 0.835399
train_step : 7926, loss1 : 2.829443, loss2 : 1.465275
train_step : 7927, loss1 : 1.903651, loss2 : 1.121887
train_step : 7928, loss1 : 1.890715, loss2 : 2.565978
train_step : 7929, loss1 : 2.471771, loss2 : 2.650692
train_step : 7930, loss1 : 3.946217, loss2 : 3.034634
train_step : 7931, loss1 : 2.424197, loss2 : 4.017818
train_step : 7932, loss1 : 3.981265, loss2 : 4.767147
train_step : 7933, loss1 : 2.358608, loss2 : 1.433836
train_step : 7934, loss1 : 1.358552, loss2 : 1.809917
train_step : 7935, loss1 : 0.730457, loss2 : 0.905651
train_step : 7936, loss1 : 1.424077, loss2 : 0.672202
train_step : 7937, loss1 : 0.989212, loss2 : 1.349413
train_step : 7938, loss1 : 0.962518, loss2 : 0.890776
train_step : 7939, loss1 : 0.772092, loss2 : 1.215779
train_step : 7940, loss1 : 1.256899, loss2 : 1.727004
train_step : 7941, loss1 : 0.636693, loss2 : 0.904525
train_step : 7942, loss1 : 1.120573, loss2 : 0.788708
train_step : 7943, loss1 : 0.558408, loss2 : 1.156100
train_step : 7944, loss1 : 0.998867, loss2 : 0.641981
train_step : 7945, loss1 : 1.364664, loss2 : 1.653755
train_step : 7946, loss1 : 1.344992, loss2 : 1.679465
train_step : 7947, loss1 : 1.724867, loss2 : 1.169413
train_step : 7948, loss1 : 1.550690, loss2 : 1.619206
train_step : 7949, loss1 : 1.467452, loss2 : 1.440295
train_step : 7950, loss1 : 0.817917, loss2 : 1.293811
train_step : 7951, loss1 : 0.764777, loss2 : 1.338393
train_step : 7952, loss1 : 1.580894, loss2 : 0.786181
train_step : 7953, loss1 : 1.369708, loss2 : 1.674383
train_step : 7954, loss1 : 1.043006, loss2 : 0.806558
train_step : 7955, loss1 : 1.193336, loss2 : 0.819854
train_step : 7956, loss1 : 1.682912, loss2 : 0.855547
train_step : 7957, loss1 : 1.144840, loss2 : 0.834938
train_step : 7958, loss1 : 1.728426, loss2 : 1.000208
train_step : 7959, loss1 : 1.438904, loss2 : 2.078629
train_step : 7960, loss1 : 2.157813, loss2 : 1.064725
train_step : 7961, loss1 : 1.960426, loss2 : 1.985546
train_step : 7962, loss1 : 1.957241, loss2 : 2.086746
train_step : 7963, loss1 : 2.174806, loss2 : 1.353129
train_step : 7964, loss1 : 1.308640, loss2 : 1.585462
train_step : 7965, loss1 : 1.123641, loss2 : 1.963612
train_step : 7966, loss1 : 1.720319, loss2 : 1.542723
train_step : 7967, loss1 : 1.125977, loss2 : 1.811779
train_step : 7968, loss1 : 2.994050, loss2 : 1.382997
train_step : 7969, loss1 : 1.108638, loss2 : 1.751423
train_step : 7970, loss1 : 1.204884, loss2 : 3.048012
train_step : 7971, loss1 : 1.435459, loss2 : 2.023176
train_step : 7972, loss1 : 1.070264, loss2 : 2.610547
train_step : 7973, loss1 : 1.180218, loss2 : 1.545253
train_step : 7974, loss1 : 0.935771, loss2 : 0.635459
train_step : 7975, loss1 : 1.187061, loss2 : 1.280600
train_step : 7976, loss1 : 1.081557, loss2 : 0.868645
train_step : 7977, loss1 : 0.980193, loss2 : 0.885981
train_step : 7978, loss1 : 1.739142, loss2 : 1.452197
train_step : 7979, loss1 : 0.892228, loss2 : 1.198488
train_step : 7980, loss1 : 1.332810, loss2 : 1.065422
train_step : 7981, loss1 : 0.770117, loss2 : 0.716055
train_step : 7982, loss1 : 1.779901, loss2 : 2.194046
train_step : 7983, loss1 : 1.206550, loss2 : 0.899714
train_step : 7984, loss1 : 0.865525, loss2 : 2.093432
train_step : 7985, loss1 : 1.146026, loss2 : 1.182013
train_step : 7986, loss1 : 1.024296, loss2 : 0.757850
train_step : 7987, loss1 : 1.270149, loss2 : 1.391550
train_step : 7988, loss1 : 0.561680, loss2 : 0.922683
train_step : 7989, loss1 : 2.428756, loss2 : 1.125497
train_step : 7990, loss1 : 0.691257, loss2 : 0.501441
train_step : 7991, loss1 : 1.216429, loss2 : 1.394707
train_step : 7992, loss1 : 0.985527, loss2 : 1.610277
train_step : 7993, loss1 : 0.886747, loss2 : 1.070238
train_step : 7994, loss1 : 1.368219, loss2 : 1.706203
train_step : 7995, loss1 : 1.171253, loss2 : 0.578703
train_step : 7996, loss1 : 1.344341, loss2 : 1.194980
train_step : 7997, loss1 : 1.474779, loss2 : 3.929670
train_step : 7998, loss1 : 1.888615, loss2 : 1.851719
train_step : 7999, loss1 : 1.798165, loss2 : 1.033949
train_step : 8000, loss1 : 1.413616, loss2 : 1.941650
train_step : 8001, loss1 : 1.184609, loss2 : 1.583136
train_step : 8002, loss1 : 0.726726, loss2 : 1.895056
train_step : 8003, loss1 : 1.756411, loss2 : 1.737986
train_step : 8004, loss1 : 1.047003, loss2 : 1.071778
train_step : 8005, loss1 : 0.863386, loss2 : 1.451614
train_step : 8006, loss1 : 0.976462, loss2 : 0.832388
train_step : 8007, loss1 : 1.068042, loss2 : 1.176497
train_step : 8008, loss1 : 0.634929, loss2 : 0.722687
train_step : 8009, loss1 : 0.930106, loss2 : 0.927877
train_step : 8010, loss1 : 1.515862, loss2 : 1.336653
train_step : 8011, loss1 : 0.843985, loss2 : 1.042650
train_step : 8012, loss1 : 1.597524, loss2 : 1.920356
train_step : 8013, loss1 : 3.519588, loss2 : 2.470105
train_step : 8014, loss1 : 3.479785, loss2 : 2.714223
train_step : 8015, loss1 : 1.381323, loss2 : 1.389168
train_step : 8016, loss1 : 0.691141, loss2 : 1.142322
train_step : 8017, loss1 : 2.351587, loss2 : 1.920709
train_step : 8018, loss1 : 1.373083, loss2 : 2.017118
train_step : 8019, loss1 : 2.514998, loss2 : 2.128650
train_step : 8020, loss1 : 2.472142, loss2 : 3.929411
train_step : 8021, loss1 : 1.790937, loss2 : 3.210601
train_step : 8022, loss1 : 1.913713, loss2 : 1.762850
train_step : 8023, loss1 : 1.604370, loss2 : 0.989723
train_step : 8024, loss1 : 1.538874, loss2 : 2.159105
train_step : 8025, loss1 : 1.518713, loss2 : 2.367930
train_step : 8026, loss1 : 1.672660, loss2 : 1.626268
train_step : 8027, loss1 : 1.451299, loss2 : 1.130254
train_step : 8028, loss1 : 1.111108, loss2 : 1.107355
train_step : 8029, loss1 : 1.426488, loss2 : 1.888862
train_step : 8030, loss1 : 1.603894, loss2 : 0.878721
train_step : 8031, loss1 : 1.879508, loss2 : 0.604535
train_step : 8032, loss1 : 1.332052, loss2 : 2.054433
train_step : 8033, loss1 : 1.864275, loss2 : 2.053296
train_step : 8034, loss1 : 2.628059, loss2 : 2.133556
train_step : 8035, loss1 : 3.679618, loss2 : 3.175046
train_step : 8036, loss1 : 4.592001, loss2 : 4.776033
train_step : 8037, loss1 : 2.940273, loss2 : 2.964258
train_step : 8038, loss1 : 2.640854, loss2 : 1.962505
train_step : 8039, loss1 : 1.179464, loss2 : 1.577604
train_step : 8040, loss1 : 0.983835, loss2 : 1.620390
train_step : 8041, loss1 : 1.080493, loss2 : 1.280934
train_step : 8042, loss1 : 1.525536, loss2 : 1.158713
train_step : 8043, loss1 : 1.088535, loss2 : 1.173097
train_step : 8044, loss1 : 0.933503, loss2 : 0.627018
train_step : 8045, loss1 : 1.881669, loss2 : 1.000664
train_step : 8046, loss1 : 0.497045, loss2 : 1.244669
train_step : 8047, loss1 : 1.388493, loss2 : 1.017158
train_step : 8048, loss1 : 0.953094, loss2 : 1.054399
train_step : 8049, loss1 : 1.717604, loss2 : 1.201306
train_step : 8050, loss1 : 1.315839, loss2 : 1.386519
train_step : 8051, loss1 : 2.286174, loss2 : 1.585189
train_step : 8052, loss1 : 3.205566, loss2 : 2.117787
train_step : 8053, loss1 : 1.831536, loss2 : 1.875287
train_step : 8054, loss1 : 1.530697, loss2 : 1.179862
train_step : 8055, loss1 : 2.116292, loss2 : 2.420742
train_step : 8056, loss1 : 2.980566, loss2 : 3.027020
train_step : 8057, loss1 : 1.204375, loss2 : 1.415038
train_step : 8058, loss1 : 1.225911, loss2 : 1.429896
train_step : 8059, loss1 : 1.388342, loss2 : 1.767675
train_step : 8060, loss1 : 1.171644, loss2 : 1.805443
train_step : 8061, loss1 : 1.342835, loss2 : 0.956139
train_step : 8062, loss1 : 1.212694, loss2 : 1.254530
train_step : 8063, loss1 : 0.904490, loss2 : 1.548955
train_step : 8064, loss1 : 0.809299, loss2 : 1.081336
train_step : 8065, loss1 : 1.350496, loss2 : 0.597869
train_step : 8066, loss1 : 0.985580, loss2 : 1.883740
train_step : 8067, loss1 : 1.089909, loss2 : 0.721915
train_step : 8068, loss1 : 1.042853, loss2 : 0.586661
train_step : 8069, loss1 : 1.011373, loss2 : 0.832084
train_step : 8070, loss1 : 1.108515, loss2 : 0.675231
train_step : 8071, loss1 : 1.506498, loss2 : 1.039904
train_step : 8072, loss1 : 2.075306, loss2 : 1.133751
train_step : 8073, loss1 : 0.562025, loss2 : 1.180673
train_step : 8074, loss1 : 1.791754, loss2 : 2.141291
train_step : 8075, loss1 : 1.815374, loss2 : 2.674174
train_step : 8076, loss1 : 1.694231, loss2 : 0.925978
train_step : 8077, loss1 : 1.630194, loss2 : 1.189111
train_step : 8078, loss1 : 1.670438, loss2 : 2.528463
train_step : 8079, loss1 : 1.671764, loss2 : 2.017962
train_step : 8080, loss1 : 2.511336, loss2 : 2.030525
train_step : 8081, loss1 : 1.579909, loss2 : 2.582376
train_step : 8082, loss1 : 1.309328, loss2 : 1.864782
train_step : 8083, loss1 : 1.114180, loss2 : 1.717347
train_step : 8084, loss1 : 0.759404, loss2 : 1.491031
train_step : 8085, loss1 : 0.804419, loss2 : 1.035316
train_step : 8086, loss1 : 1.111387, loss2 : 0.875656
train_step : 8087, loss1 : 0.951297, loss2 : 1.465716
train_step : 8088, loss1 : 0.759187, loss2 : 1.625681
train_step : 8089, loss1 : 1.713869, loss2 : 2.873856
train_step : 8090, loss1 : 0.685921, loss2 : 1.000996
train_step : 8091, loss1 : 3.366838, loss2 : 1.038762
train_step : 8092, loss1 : 1.952184, loss2 : 2.379760
train_step : 8093, loss1 : 2.750650, loss2 : 2.565129
train_step : 8094, loss1 : 2.695588, loss2 : 1.437012
train_step : 8095, loss1 : 1.328539, loss2 : 2.248590
train_step : 8096, loss1 : 1.441816, loss2 : 1.429930
train_step : 8097, loss1 : 0.973468, loss2 : 1.952671
train_step : 8098, loss1 : 1.111498, loss2 : 0.582873
train_step : 8099, loss1 : 0.935295, loss2 : 1.311282
train_step : 8100, loss1 : 1.726329, loss2 : 2.408545
train_step : 8101, loss1 : 1.203607, loss2 : 1.052281
train_step : 8102, loss1 : 1.016143, loss2 : 1.986681
train_step : 8103, loss1 : 1.760427, loss2 : 1.375536
train_step : 8104, loss1 : 0.743521, loss2 : 1.212031
train_step : 8105, loss1 : 0.846665, loss2 : 0.526782
train_step : 8106, loss1 : 1.677754, loss2 : 0.471624
train_step : 8107, loss1 : 1.274746, loss2 : 1.286848
train_step : 8108, loss1 : 1.734069, loss2 : 1.553178
train_step : 8109, loss1 : 0.906444, loss2 : 0.786768
train_step : 8110, loss1 : 1.426320, loss2 : 1.640469
train_step : 8111, loss1 : 0.898885, loss2 : 1.184594
train_step : 8112, loss1 : 1.135370, loss2 : 1.597073
train_step : 8113, loss1 : 1.016685, loss2 : 1.063876
train_step : 8114, loss1 : 1.419599, loss2 : 0.525335
train_step : 8115, loss1 : 1.341124, loss2 : 2.493565
train_step : 8116, loss1 : 2.549588, loss2 : 2.564369
train_step : 8117, loss1 : 4.060822, loss2 : 2.255025
train_step : 8118, loss1 : 4.201036, loss2 : 3.673903
train_step : 8119, loss1 : 4.107672, loss2 : 3.008208
train_step : 8120, loss1 : 5.306968, loss2 : 3.379715
train_step : 8121, loss1 : 4.449509, loss2 : 3.873470
train_step : 8122, loss1 : 4.077648, loss2 : 3.910507
train_step : 8123, loss1 : 4.346722, loss2 : 3.477109
train_step : 8124, loss1 : 3.361907, loss2 : 3.576793
train_step : 8125, loss1 : 3.048906, loss2 : 1.853649
train_step : 8126, loss1 : 3.024227, loss2 : 1.616914
train_step : 8127, loss1 : 1.257636, loss2 : 1.383375
train_step : 8128, loss1 : 0.777752, loss2 : 0.939358
train_step : 8129, loss1 : 1.578096, loss2 : 2.102445
train_step : 8130, loss1 : 2.556789, loss2 : 1.183847
train_step : 8131, loss1 : 0.999415, loss2 : 1.770610
train_step : 8132, loss1 : 1.286515, loss2 : 1.051250
train_step : 8133, loss1 : 0.857778, loss2 : 0.633796
train_step : 8134, loss1 : 2.097889, loss2 : 1.003851
train_step : 8135, loss1 : 1.085688, loss2 : 1.284181
train_step : 8136, loss1 : 1.266949, loss2 : 1.267339
train_step : 8137, loss1 : 0.972596, loss2 : 1.486606
train_step : 8138, loss1 : 1.279115, loss2 : 2.037890
train_step : 8139, loss1 : 2.077266, loss2 : 1.898892
train_step : 8140, loss1 : 1.942447, loss2 : 2.647688
train_step : 8141, loss1 : 1.068183, loss2 : 2.489938
train_step : 8142, loss1 : 0.826673, loss2 : 1.665233
train_step : 8143, loss1 : 1.400803, loss2 : 3.904423
train_step : 8144, loss1 : 2.155823, loss2 : 1.729572
train_step : 8145, loss1 : 0.908558, loss2 : 2.002035
train_step : 8146, loss1 : 0.494866, loss2 : 1.083348
train_step : 8147, loss1 : 0.923509, loss2 : 1.115794
train_step : 8148, loss1 : 2.264780, loss2 : 1.292235
train_step : 8149, loss1 : 1.022303, loss2 : 1.378356
train_step : 8150, loss1 : 1.268669, loss2 : 1.446203
train_step : 8151, loss1 : 2.496568, loss2 : 0.771900
train_step : 8152, loss1 : 1.464301, loss2 : 1.037450
train_step : 8153, loss1 : 1.221094, loss2 : 0.724036
train_step : 8154, loss1 : 1.961434, loss2 : 1.599976
train_step : 8155, loss1 : 1.450772, loss2 : 2.647019
train_step : 8156, loss1 : 1.124943, loss2 : 1.708481
train_step : 8157, loss1 : 2.281619, loss2 : 1.061993
train_step : 8158, loss1 : 0.754722, loss2 : 1.348769
train_step : 8159, loss1 : 0.767731, loss2 : 1.590321
train_step : 8160, loss1 : 1.287758, loss2 : 1.317903
train_step : 8161, loss1 : 1.379824, loss2 : 1.480177
train_step : 8162, loss1 : 2.010861, loss2 : 1.402807
train_step : 8163, loss1 : 1.099456, loss2 : 1.565495
train_step : 8164, loss1 : 0.793472, loss2 : 1.727829
train_step : 8165, loss1 : 0.615245, loss2 : 0.976839
train_step : 8166, loss1 : 1.136468, loss2 : 1.702161
train_step : 8167, loss1 : 1.019277, loss2 : 1.105652
train_step : 8168, loss1 : 0.694164, loss2 : 0.955128
train_step : 8169, loss1 : 0.437489, loss2 : 1.043798
train_step : 8170, loss1 : 1.199427, loss2 : 1.292334
train_step : 8171, loss1 : 5.481523, loss2 : 2.275576
train_step : 8172, loss1 : 2.658896, loss2 : 1.914226
train_step : 8173, loss1 : 2.007483, loss2 : 2.457244
train_step : 8174, loss1 : 2.188506, loss2 : 3.104681
train_step : 8175, loss1 : 2.468611, loss2 : 3.086083
train_step : 8176, loss1 : 1.720508, loss2 : 1.705022
train_step : 8177, loss1 : 1.586153, loss2 : 1.892275
train_step : 8178, loss1 : 0.948489, loss2 : 1.013974
train_step : 8179, loss1 : 0.923793, loss2 : 0.628866
train_step : 8180, loss1 : 0.967819, loss2 : 1.053450
train_step : 8181, loss1 : 1.121932, loss2 : 1.140121
train_step : 8182, loss1 : 1.286154, loss2 : 0.873957
train_step : 8183, loss1 : 1.404816, loss2 : 0.782436
train_step : 8184, loss1 : 1.502773, loss2 : 0.896654
train_step : 8185, loss1 : 1.125618, loss2 : 1.034976
train_step : 8186, loss1 : 1.912690, loss2 : 0.907156
train_step : 8187, loss1 : 1.508663, loss2 : 1.144409
train_step : 8188, loss1 : 1.617888, loss2 : 0.743554
train_step : 8189, loss1 : 0.946427, loss2 : 1.671586
train_step : 8190, loss1 : 0.822388, loss2 : 0.621626
train_step : 8191, loss1 : 0.966106, loss2 : 0.902163
train_step : 8192, loss1 : 1.394455, loss2 : 0.970399
train_step : 8193, loss1 : 1.236949, loss2 : 1.152768
train_step : 8194, loss1 : 1.108165, loss2 : 1.245391
train_step : 8195, loss1 : 1.313962, loss2 : 1.535578
train_step : 8196, loss1 : 0.863777, loss2 : 1.321069
train_step : 8197, loss1 : 1.497161, loss2 : 1.000031
train_step : 8198, loss1 : 1.059036, loss2 : 0.873306
train_step : 8199, loss1 : 0.838897, loss2 : 1.309653
train_step : 8200, loss1 : 1.996223, loss2 : 0.989780
train_step : 8201, loss1 : 1.520153, loss2 : 1.231485
train_step : 8202, loss1 : 1.331505, loss2 : 1.597391
train_step : 8203, loss1 : 1.848152, loss2 : 1.120719
train_step : 8204, loss1 : 0.819667, loss2 : 1.318103
train_step : 8205, loss1 : 1.281591, loss2 : 1.257559
train_step : 8206, loss1 : 1.276373, loss2 : 1.159273
train_step : 8207, loss1 : 1.632274, loss2 : 0.930713
train_step : 8208, loss1 : 0.756997, loss2 : 1.115672
train_step : 8209, loss1 : 0.884783, loss2 : 0.674801
train_step : 8210, loss1 : 1.398735, loss2 : 1.153147
train_step : 8211, loss1 : 0.739278, loss2 : 1.306362
train_step : 8212, loss1 : 1.458175, loss2 : 0.995551
train_step : 8213, loss1 : 0.593439, loss2 : 1.093210
train_step : 8214, loss1 : 1.577961, loss2 : 1.910840
train_step : 8215, loss1 : 2.613633, loss2 : 1.658512
train_step : 8216, loss1 : 1.052216, loss2 : 1.146733
train_step : 8217, loss1 : 1.222573, loss2 : 1.301942
train_step : 8218, loss1 : 0.759871, loss2 : 1.094153
train_step : 8219, loss1 : 1.615713, loss2 : 0.903015
train_step : 8220, loss1 : 1.442792, loss2 : 1.037367
train_step : 8221, loss1 : 1.789798, loss2 : 1.393776
train_step : 8222, loss1 : 2.307655, loss2 : 2.167760
train_step : 8223, loss1 : 1.656878, loss2 : 1.742870
train_step : 8224, loss1 : 0.846005, loss2 : 1.196164
train_step : 8225, loss1 : 1.605178, loss2 : 0.830462
train_step : 8226, loss1 : 1.075953, loss2 : 1.498442
train_step : 8227, loss1 : 1.494474, loss2 : 1.418294
train_step : 8228, loss1 : 1.901855, loss2 : 1.255565
train_step : 8229, loss1 : 1.448613, loss2 : 1.296385
train_step : 8230, loss1 : 2.001549, loss2 : 2.074423
train_step : 8231, loss1 : 0.926188, loss2 : 0.931844
train_step : 8232, loss1 : 0.951094, loss2 : 1.522390
train_step : 8233, loss1 : 0.660110, loss2 : 1.250602
train_step : 8234, loss1 : 1.232120, loss2 : 0.651551
train_step : 8235, loss1 : 2.288891, loss2 : 1.075027
train_step : 8236, loss1 : 1.302127, loss2 : 1.040263
train_step : 8237, loss1 : 1.653697, loss2 : 1.752432
train_step : 8238, loss1 : 2.116528, loss2 : 1.701462
train_step : 8239, loss1 : 1.216140, loss2 : 2.806463
train_step : 8240, loss1 : 2.012092, loss2 : 1.729965
train_step : 8241, loss1 : 3.161595, loss2 : 2.197887
train_step : 8242, loss1 : 2.055853, loss2 : 3.097749
train_step : 8243, loss1 : 1.456938, loss2 : 2.546312
train_step : 8244, loss1 : 1.700013, loss2 : 3.099383
train_step : 8245, loss1 : 3.797342, loss2 : 3.598910
train_step : 8246, loss1 : 5.916048, loss2 : 4.968194
train_step : 8247, loss1 : 4.857914, loss2 : 4.217993
train_step : 8248, loss1 : 5.010007, loss2 : 5.173540
train_step : 8249, loss1 : 3.198052, loss2 : 2.191246
train_step : 8250, loss1 : 1.108266, loss2 : 1.689548
train_step : 8251, loss1 : 0.992724, loss2 : 1.713042
train_step : 8252, loss1 : 0.809053, loss2 : 1.663321
train_step : 8253, loss1 : 3.937343, loss2 : 1.788363
train_step : 8254, loss1 : 2.394152, loss2 : 1.457660
train_step : 8255, loss1 : 1.915807, loss2 : 1.433389
train_step : 8256, loss1 : 1.433995, loss2 : 1.389557
train_step : 8257, loss1 : 1.406401, loss2 : 1.487684
train_step : 8258, loss1 : 1.169363, loss2 : 1.422689
train_step : 8259, loss1 : 0.566370, loss2 : 1.061404
train_step : 8260, loss1 : 1.440256, loss2 : 1.250771
train_step : 8261, loss1 : 0.567774, loss2 : 1.144326
train_step : 8262, loss1 : 0.925575, loss2 : 1.030839
train_step : 8263, loss1 : 0.861831, loss2 : 0.871417
train_step : 8264, loss1 : 1.732876, loss2 : 0.955217
train_step : 8265, loss1 : 1.592483, loss2 : 1.017375
train_step : 8266, loss1 : 0.947979, loss2 : 0.635035
train_step : 8267, loss1 : 1.590218, loss2 : 0.881412
train_step : 8268, loss1 : 0.484761, loss2 : 0.969540
train_step : 8269, loss1 : 1.008076, loss2 : 0.825425
train_step : 8270, loss1 : 1.584794, loss2 : 0.803525
train_step : 8271, loss1 : 1.385757, loss2 : 1.390034
train_step : 8272, loss1 : 2.224923, loss2 : 1.134464
train_step : 8273, loss1 : 1.707976, loss2 : 1.116473
train_step : 8274, loss1 : 2.167894, loss2 : 0.824191
train_step : 8275, loss1 : 1.427589, loss2 : 1.062684
train_step : 8276, loss1 : 0.901544, loss2 : 1.543040
train_step : 8277, loss1 : 1.707020, loss2 : 1.339038
train_step : 8278, loss1 : 1.913187, loss2 : 1.848861
train_step : 8279, loss1 : 2.026526, loss2 : 2.314711
train_step : 8280, loss1 : 1.581458, loss2 : 1.627134
train_step : 8281, loss1 : 1.162900, loss2 : 1.068758
train_step : 8282, loss1 : 1.254028, loss2 : 0.540043
train_step : 8283, loss1 : 1.576444, loss2 : 0.900294
train_step : 8284, loss1 : 0.630520, loss2 : 0.693021
train_step : 8285, loss1 : 1.164316, loss2 : 0.663445
train_step : 8286, loss1 : 1.245718, loss2 : 1.653759
train_step : 8287, loss1 : 1.229766, loss2 : 1.295769
train_step : 8288, loss1 : 1.337966, loss2 : 1.263373
train_step : 8289, loss1 : 0.970705, loss2 : 1.751216
train_step : 8290, loss1 : 1.186345, loss2 : 1.026151
train_step : 8291, loss1 : 1.474251, loss2 : 1.969728
train_step : 8292, loss1 : 1.428167, loss2 : 1.222258
train_step : 8293, loss1 : 1.496022, loss2 : 0.983356
train_step : 8294, loss1 : 1.560176, loss2 : 1.339148
train_step : 8295, loss1 : 0.984801, loss2 : 0.909216
train_step : 8296, loss1 : 0.959312, loss2 : 0.759136
train_step : 8297, loss1 : 0.873101, loss2 : 1.379598
train_step : 8298, loss1 : 1.146913, loss2 : 0.430350
train_step : 8299, loss1 : 1.297734, loss2 : 0.423236
train_step : 8300, loss1 : 0.733023, loss2 : 1.085932
train_step : 8301, loss1 : 1.753395, loss2 : 1.122742
train_step : 8302, loss1 : 1.094385, loss2 : 0.671238
train_step : 8303, loss1 : 1.814400, loss2 : 1.321964
train_step : 8304, loss1 : 0.961230, loss2 : 1.346647
train_step : 8305, loss1 : 0.692652, loss2 : 1.515229
train_step : 8306, loss1 : 0.932962, loss2 : 1.403852
train_step : 8307, loss1 : 1.155040, loss2 : 0.632525
train_step : 8308, loss1 : 0.809407, loss2 : 1.776407
train_step : 8309, loss1 : 0.940695, loss2 : 1.692632
train_step : 8310, loss1 : 1.026047, loss2 : 0.940463
train_step : 8311, loss1 : 1.514841, loss2 : 4.479934
train_step : 8312, loss1 : 0.991384, loss2 : 1.201089
train_step : 8313, loss1 : 2.191559, loss2 : 1.493341
train_step : 8314, loss1 : 1.603416, loss2 : 3.000525
train_step : 8315, loss1 : 1.259230, loss2 : 1.014367
train_step : 8316, loss1 : 1.307779, loss2 : 2.059249
train_step : 8317, loss1 : 1.430526, loss2 : 1.117840
train_step : 8318, loss1 : 1.517841, loss2 : 1.376135
train_step : 8319, loss1 : 1.580914, loss2 : 2.437997
train_step : 8320, loss1 : 1.811809, loss2 : 1.917102
train_step : 8321, loss1 : 1.240205, loss2 : 0.786920
train_step : 8322, loss1 : 1.277501, loss2 : 0.667469
train_step : 8323, loss1 : 1.516055, loss2 : 0.535311
train_step : 8324, loss1 : 1.380881, loss2 : 1.541846
train_step : 8325, loss1 : 1.187189, loss2 : 2.212543
train_step : 8326, loss1 : 1.736715, loss2 : 1.121588
train_step : 8327, loss1 : 1.899538, loss2 : 1.656811
train_step : 8328, loss1 : 2.201072, loss2 : 2.031549
train_step : 8329, loss1 : 1.447402, loss2 : 1.992351
train_step : 8330, loss1 : 2.156776, loss2 : 1.616991
train_step : 8331, loss1 : 1.679721, loss2 : 1.686191
train_step : 8332, loss1 : 0.972957, loss2 : 1.547806
train_step : 8333, loss1 : 1.671755, loss2 : 1.462692
train_step : 8334, loss1 : 1.763122, loss2 : 2.211099
train_step : 8335, loss1 : 2.853086, loss2 : 2.540732
train_step : 8336, loss1 : 1.985558, loss2 : 3.426479
train_step : 8337, loss1 : 2.183138, loss2 : 2.632356
train_step : 8338, loss1 : 2.143294, loss2 : 2.517892
train_step : 8339, loss1 : 1.042371, loss2 : 1.687989
train_step : 8340, loss1 : 1.686219, loss2 : 0.865134
train_step : 8341, loss1 : 1.232451, loss2 : 1.266593
train_step : 8342, loss1 : 1.318984, loss2 : 3.396364
train_step : 8343, loss1 : 1.289203, loss2 : 1.498493
train_step : 8344, loss1 : 1.305484, loss2 : 1.129051
train_step : 8345, loss1 : 1.318301, loss2 : 1.656822
train_step : 8346, loss1 : 0.836159, loss2 : 0.520116
train_step : 8347, loss1 : 0.979219, loss2 : 1.175186
train_step : 8348, loss1 : 0.712264, loss2 : 1.347889
train_step : 8349, loss1 : 1.426358, loss2 : 0.883188
train_step : 8350, loss1 : 1.219165, loss2 : 0.921956
train_step : 8351, loss1 : 1.379730, loss2 : 1.194551
train_step : 8352, loss1 : 0.765203, loss2 : 0.564994
train_step : 8353, loss1 : 1.163213, loss2 : 0.819469
train_step : 8354, loss1 : 1.700327, loss2 : 1.022392
train_step : 8355, loss1 : 1.908292, loss2 : 1.367318
train_step : 8356, loss1 : 0.981503, loss2 : 1.008147
train_step : 8357, loss1 : 1.379124, loss2 : 1.343066
train_step : 8358, loss1 : 1.213352, loss2 : 0.817368
train_step : 8359, loss1 : 0.776382, loss2 : 1.612864
train_step : 8360, loss1 : 1.058334, loss2 : 0.931798
train_step : 8361, loss1 : 0.770266, loss2 : 1.051979
train_step : 8362, loss1 : 0.784773, loss2 : 1.995235
train_step : 8363, loss1 : 1.399197, loss2 : 1.878679
train_step : 8364, loss1 : 1.784904, loss2 : 2.075189
train_step : 8365, loss1 : 1.440448, loss2 : 0.611332
train_step : 8366, loss1 : 1.016587, loss2 : 1.092856
train_step : 8367, loss1 : 3.950372, loss2 : 1.144918
train_step : 8368, loss1 : 1.764908, loss2 : 1.391973
train_step : 8369, loss1 : 1.097175, loss2 : 1.921054
train_step : 8370, loss1 : 1.772540, loss2 : 1.495086
train_step : 8371, loss1 : 1.151753, loss2 : 2.682940
train_step : 8372, loss1 : 2.384953, loss2 : 1.988444
train_step : 8373, loss1 : 3.725884, loss2 : 2.683497
train_step : 8374, loss1 : 3.030843, loss2 : 1.812393
train_step : 8375, loss1 : 2.345085, loss2 : 2.150419
train_step : 8376, loss1 : 2.907212, loss2 : 1.682479
train_step : 8377, loss1 : 2.210627, loss2 : 2.570048
train_step : 8378, loss1 : 2.447777, loss2 : 1.688296
train_step : 8379, loss1 : 2.657971, loss2 : 1.940366
train_step : 8380, loss1 : 2.529751, loss2 : 2.158168
train_step : 8381, loss1 : 1.957467, loss2 : 1.519761
train_step : 8382, loss1 : 1.431462, loss2 : 1.627655
train_step : 8383, loss1 : 2.555716, loss2 : 2.901078
train_step : 8384, loss1 : 1.403768, loss2 : 2.130788
train_step : 8385, loss1 : 2.095481, loss2 : 1.490916
train_step : 8386, loss1 : 1.642460, loss2 : 2.007846
train_step : 8387, loss1 : 2.762691, loss2 : 2.159719
train_step : 8388, loss1 : 1.418604, loss2 : 3.043697
train_step : 8389, loss1 : 2.131505, loss2 : 1.199561
train_step : 8390, loss1 : 0.875145, loss2 : 1.414234
train_step : 8391, loss1 : 1.493640, loss2 : 1.260088
train_step : 8392, loss1 : 2.640427, loss2 : 1.190518
train_step : 8393, loss1 : 1.738446, loss2 : 2.738876
train_step : 8394, loss1 : 4.053147, loss2 : 1.507979
train_step : 8395, loss1 : 1.851809, loss2 : 3.341859
train_step : 8396, loss1 : 0.714011, loss2 : 1.368344
train_step : 8397, loss1 : 1.169380, loss2 : 0.982363
train_step : 8398, loss1 : 2.147788, loss2 : 1.299979
train_step : 8399, loss1 : 2.189720, loss2 : 1.075300
train_step : 8400, loss1 : 1.127755, loss2 : 1.287773
train_step : 8401, loss1 : 1.111813, loss2 : 1.388078
train_step : 8402, loss1 : 0.875772, loss2 : 0.784668
train_step : 8403, loss1 : 0.784287, loss2 : 1.021946
train_step : 8404, loss1 : 1.034301, loss2 : 1.003538
train_step : 8405, loss1 : 1.281352, loss2 : 1.533280
train_step : 8406, loss1 : 1.746356, loss2 : 1.057716
train_step : 8407, loss1 : 1.744063, loss2 : 1.274035
train_step : 8408, loss1 : 1.171267, loss2 : 0.975511
train_step : 8409, loss1 : 0.681376, loss2 : 0.663488
train_step : 8410, loss1 : 0.786202, loss2 : 1.789243
train_step : 8411, loss1 : 1.960311, loss2 : 0.713555
train_step : 8412, loss1 : 0.511216, loss2 : 1.059859
train_step : 8413, loss1 : 0.780604, loss2 : 0.649084
train_step : 8414, loss1 : 1.402637, loss2 : 1.009569
train_step : 8415, loss1 : 0.822833, loss2 : 0.859615
train_step : 8416, loss1 : 1.155040, loss2 : 0.864128
train_step : 8417, loss1 : 0.388670, loss2 : 1.576161
train_step : 8418, loss1 : 1.253727, loss2 : 1.330986
train_step : 8419, loss1 : 1.512187, loss2 : 0.993374
train_step : 8420, loss1 : 1.308730, loss2 : 1.805200
train_step : 8421, loss1 : 0.600473, loss2 : 0.788062
train_step : 8422, loss1 : 0.936736, loss2 : 1.213344
train_step : 8423, loss1 : 2.088356, loss2 : 0.542063
train_step : 8424, loss1 : 1.073799, loss2 : 1.672789
train_step : 8425, loss1 : 1.404059, loss2 : 1.067227
train_step : 8426, loss1 : 1.126216, loss2 : 1.233897
train_step : 8427, loss1 : 1.943620, loss2 : 0.956288
train_step : 8428, loss1 : 1.139984, loss2 : 1.496190
train_step : 8429, loss1 : 1.081457, loss2 : 1.431066
train_step : 8430, loss1 : 2.613215, loss2 : 1.632982
train_step : 8431, loss1 : 2.536259, loss2 : 1.384351
train_step : 8432, loss1 : 1.814468, loss2 : 1.447131
train_step : 8433, loss1 : 2.245655, loss2 : 2.245293
train_step : 8434, loss1 : 3.765815, loss2 : 1.593162
train_step : 8435, loss1 : 2.533704, loss2 : 1.314402
train_step : 8436, loss1 : 2.525007, loss2 : 2.366609
train_step : 8437, loss1 : 1.533929, loss2 : 2.798804
train_step : 8438, loss1 : 2.045980, loss2 : 2.202832
train_step : 8439, loss1 : 2.032131, loss2 : 1.273432
train_step : 8440, loss1 : 1.721910, loss2 : 1.468500
train_step : 8441, loss1 : 0.831765, loss2 : 1.494320
train_step : 8442, loss1 : 1.390692, loss2 : 1.557220
train_step : 8443, loss1 : 1.466723, loss2 : 1.415450
train_step : 8444, loss1 : 1.801171, loss2 : 1.653713
train_step : 8445, loss1 : 0.993422, loss2 : 0.927564
train_step : 8446, loss1 : 1.386146, loss2 : 1.723381
train_step : 8447, loss1 : 1.090511, loss2 : 2.178657
train_step : 8448, loss1 : 0.989153, loss2 : 1.344103
train_step : 8449, loss1 : 1.694174, loss2 : 1.013191
train_step : 8450, loss1 : 1.295426, loss2 : 1.240286
train_step : 8451, loss1 : 1.078631, loss2 : 1.103736
train_step : 8452, loss1 : 1.013901, loss2 : 0.953105
train_step : 8453, loss1 : 2.914483, loss2 : 1.224191
train_step : 8454, loss1 : 1.179937, loss2 : 0.773634
train_step : 8455, loss1 : 1.086343, loss2 : 1.198808
train_step : 8456, loss1 : 1.321533, loss2 : 0.793380
train_step : 8457, loss1 : 2.628379, loss2 : 2.081722
train_step : 8458, loss1 : 2.759132, loss2 : 2.114599
train_step : 8459, loss1 : 3.461439, loss2 : 1.257713
train_step : 8460, loss1 : 2.001304, loss2 : 2.769071
train_step : 8461, loss1 : 2.272900, loss2 : 1.386045
train_step : 8462, loss1 : 1.616454, loss2 : 1.141402
train_step : 8463, loss1 : 1.359850, loss2 : 1.913989
train_step : 8464, loss1 : 1.117024, loss2 : 0.786647
train_step : 8465, loss1 : 1.766529, loss2 : 0.707379
train_step : 8466, loss1 : 1.188321, loss2 : 1.248768
train_step : 8467, loss1 : 1.835215, loss2 : 1.890191
train_step : 8468, loss1 : 1.682363, loss2 : 1.671347
train_step : 8469, loss1 : 1.131707, loss2 : 1.710298
train_step : 8470, loss1 : 1.427875, loss2 : 1.291056
train_step : 8471, loss1 : 1.769586, loss2 : 0.721599
train_step : 8472, loss1 : 2.409896, loss2 : 2.317341
train_step : 8473, loss1 : 1.431550, loss2 : 1.003711
train_step : 8474, loss1 : 1.022989, loss2 : 0.984883
train_step : 8475, loss1 : 1.212466, loss2 : 0.805745
train_step : 8476, loss1 : 0.717549, loss2 : 0.812853
train_step : 8477, loss1 : 1.122716, loss2 : 0.672759
train_step : 8478, loss1 : 1.145299, loss2 : 0.846377
train_step : 8479, loss1 : 0.732295, loss2 : 0.516814
train_step : 8480, loss1 : 1.147924, loss2 : 1.378109
train_step : 8481, loss1 : 0.714928, loss2 : 1.245118
train_step : 8482, loss1 : 1.422085, loss2 : 1.019755
train_step : 8483, loss1 : 0.833167, loss2 : 1.067508
train_step : 8484, loss1 : 1.608307, loss2 : 0.923700
train_step : 8485, loss1 : 1.925303, loss2 : 2.711284
train_step : 8486, loss1 : 2.304358, loss2 : 1.235209
train_step : 8487, loss1 : 1.321721, loss2 : 2.424849
train_step : 8488, loss1 : 1.036829, loss2 : 0.740328
train_step : 8489, loss1 : 1.878741, loss2 : 0.977941
train_step : 8490, loss1 : 0.561246, loss2 : 1.314438
train_step : 8491, loss1 : 1.655949, loss2 : 1.235009
train_step : 8492, loss1 : 1.922430, loss2 : 1.058382
train_step : 8493, loss1 : 1.216265, loss2 : 1.501292
train_step : 8494, loss1 : 0.947535, loss2 : 1.459162
train_step : 8495, loss1 : 0.850399, loss2 : 1.148163
train_step : 8496, loss1 : 1.329132, loss2 : 1.019046
train_step : 8497, loss1 : 1.160560, loss2 : 1.150639
train_step : 8498, loss1 : 1.151831, loss2 : 0.979304
train_step : 8499, loss1 : 1.634478, loss2 : 0.870135
train_step : 8500, loss1 : 1.126569, loss2 : 1.156044
train_step : 8501, loss1 : 1.154984, loss2 : 1.001920
train_step : 8502, loss1 : 1.502682, loss2 : 1.831807
train_step : 8503, loss1 : 2.590841, loss2 : 1.450577
train_step : 8504, loss1 : 2.009880, loss2 : 1.809824
train_step : 8505, loss1 : 1.817076, loss2 : 2.740650
train_step : 8506, loss1 : 0.897847, loss2 : 1.777593
train_step : 8507, loss1 : 1.485902, loss2 : 1.782468
train_step : 8508, loss1 : 1.605877, loss2 : 2.022282
train_step : 8509, loss1 : 1.026812, loss2 : 2.160129
train_step : 8510, loss1 : 1.453287, loss2 : 0.891803
train_step : 8511, loss1 : 0.634534, loss2 : 1.462399
train_step : 8512, loss1 : 1.642472, loss2 : 0.711190
train_step : 8513, loss1 : 0.927165, loss2 : 0.844672
train_step : 8514, loss1 : 1.834467, loss2 : 1.095145
train_step : 8515, loss1 : 1.861711, loss2 : 1.986970
train_step : 8516, loss1 : 2.309707, loss2 : 2.663899
train_step : 8517, loss1 : 3.028769, loss2 : 2.231781
train_step : 8518, loss1 : 2.002781, loss2 : 2.962599
train_step : 8519, loss1 : 0.937778, loss2 : 1.633256
train_step : 8520, loss1 : 1.176539, loss2 : 1.050520
train_step : 8521, loss1 : 1.060233, loss2 : 0.690782
train_step : 8522, loss1 : 0.834032, loss2 : 1.466230
train_step : 8523, loss1 : 1.252300, loss2 : 1.525822
train_step : 8524, loss1 : 2.841128, loss2 : 1.473504
train_step : 8525, loss1 : 1.712803, loss2 : 1.702801
train_step : 8526, loss1 : 1.499919, loss2 : 0.733356
train_step : 8527, loss1 : 1.305022, loss2 : 1.852227
train_step : 8528, loss1 : 2.471698, loss2 : 2.376873
train_step : 8529, loss1 : 2.465931, loss2 : 1.671584
train_step : 8530, loss1 : 1.858670, loss2 : 1.510869
train_step : 8531, loss1 : 1.026042, loss2 : 1.272492
train_step : 8532, loss1 : 0.902638, loss2 : 2.102470
train_step : 8533, loss1 : 1.343420, loss2 : 1.718411
train_step : 8534, loss1 : 2.281924, loss2 : 0.941460
train_step : 8535, loss1 : 1.586848, loss2 : 1.535518
train_step : 8536, loss1 : 1.245704, loss2 : 2.216163
train_step : 8537, loss1 : 0.613994, loss2 : 0.967626
train_step : 8538, loss1 : 1.209889, loss2 : 1.140891
train_step : 8539, loss1 : 0.977323, loss2 : 1.531345
train_step : 8540, loss1 : 1.272599, loss2 : 1.244662
train_step : 8541, loss1 : 0.901279, loss2 : 1.058598
train_step : 8542, loss1 : 1.782612, loss2 : 1.399709
train_step : 8543, loss1 : 2.725304, loss2 : 0.748870
train_step : 8544, loss1 : 0.894510, loss2 : 0.975968
train_step : 8545, loss1 : 0.775072, loss2 : 1.823795
train_step : 8546, loss1 : 0.913378, loss2 : 1.453731
train_step : 8547, loss1 : 0.756055, loss2 : 0.890301
train_step : 8548, loss1 : 0.584967, loss2 : 0.681412
train_step : 8549, loss1 : 1.063857, loss2 : 1.920695
train_step : 8550, loss1 : 0.960352, loss2 : 1.027795
train_step : 8551, loss1 : 1.065129, loss2 : 0.905862
train_step : 8552, loss1 : 1.298557, loss2 : 0.749372
train_step : 8553, loss1 : 0.804644, loss2 : 3.513175
train_step : 8554, loss1 : 0.858300, loss2 : 1.309908
train_step : 8555, loss1 : 1.037927, loss2 : 1.332590
train_step : 8556, loss1 : 0.992290, loss2 : 1.403316
train_step : 8557, loss1 : 1.307397, loss2 : 1.026429
train_step : 8558, loss1 : 2.055864, loss2 : 1.340659
train_step : 8559, loss1 : 2.003913, loss2 : 1.908918
train_step : 8560, loss1 : 0.963820, loss2 : 1.005619
train_step : 8561, loss1 : 1.006931, loss2 : 0.678098
train_step : 8562, loss1 : 1.314060, loss2 : 2.401295
train_step : 8563, loss1 : 2.372903, loss2 : 2.557483
train_step : 8564, loss1 : 2.593446, loss2 : 3.426856
train_step : 8565, loss1 : 3.691258, loss2 : 4.635216
train_step : 8566, loss1 : 4.592320, loss2 : 3.391155
train_step : 8567, loss1 : 5.865407, loss2 : 4.226182
train_step : 8568, loss1 : 3.497198, loss2 : 3.033812
train_step : 8569, loss1 : 2.784702, loss2 : 3.091738
train_step : 8570, loss1 : 1.508964, loss2 : 1.552618
train_step : 8571, loss1 : 0.613356, loss2 : 1.972638
train_step : 8572, loss1 : 1.010355, loss2 : 0.948102
train_step : 8573, loss1 : 1.637632, loss2 : 1.321488
train_step : 8574, loss1 : 1.966765, loss2 : 1.526833
train_step : 8575, loss1 : 2.128399, loss2 : 1.119498
train_step : 8576, loss1 : 0.820433, loss2 : 2.187263
train_step : 8577, loss1 : 1.896832, loss2 : 1.318691
train_step : 8578, loss1 : 1.334100, loss2 : 1.680992
train_step : 8579, loss1 : 1.668549, loss2 : 2.066355
train_step : 8580, loss1 : 0.900038, loss2 : 1.244744
train_step : 8581, loss1 : 1.625954, loss2 : 1.243465
train_step : 8582, loss1 : 1.265754, loss2 : 1.727098
train_step : 8583, loss1 : 1.178570, loss2 : 1.495878
train_step : 8584, loss1 : 1.094142, loss2 : 1.344358
train_step : 8585, loss1 : 1.497133, loss2 : 1.385469
train_step : 8586, loss1 : 1.321072, loss2 : 1.339770
train_step : 8587, loss1 : 2.515719, loss2 : 1.257770
train_step : 8588, loss1 : 0.624222, loss2 : 2.190538
train_step : 8589, loss1 : 1.165068, loss2 : 0.932718
train_step : 8590, loss1 : 1.361855, loss2 : 1.715076
train_step : 8591, loss1 : 1.109380, loss2 : 2.037442
train_step : 8592, loss1 : 1.262344, loss2 : 1.131717
train_step : 8593, loss1 : 1.924038, loss2 : 1.783381
train_step : 8594, loss1 : 1.326341, loss2 : 1.379726
train_step : 8595, loss1 : 1.062202, loss2 : 1.529355
train_step : 8596, loss1 : 1.222310, loss2 : 1.902951
train_step : 8597, loss1 : 0.729060, loss2 : 0.603091
train_step : 8598, loss1 : 0.917553, loss2 : 1.592601
train_step : 8599, loss1 : 0.923214, loss2 : 1.056569
train_step : 8600, loss1 : 0.672962, loss2 : 1.148940
train_step : 8601, loss1 : 1.101635, loss2 : 0.705977
train_step : 8602, loss1 : 0.891432, loss2 : 1.057577
train_step : 8603, loss1 : 0.536682, loss2 : 1.545470
train_step : 8604, loss1 : 0.842502, loss2 : 1.273094
train_step : 8605, loss1 : 1.034714, loss2 : 1.703930
train_step : 8606, loss1 : 0.862620, loss2 : 1.501890
train_step : 8607, loss1 : 0.655655, loss2 : 1.388203
train_step : 8608, loss1 : 2.648768, loss2 : 1.854945
train_step : 8609, loss1 : 1.238099, loss2 : 1.694947
train_step : 8610, loss1 : 1.657801, loss2 : 2.308513
train_step : 8611, loss1 : 2.619373, loss2 : 2.774144
train_step : 8612, loss1 : 2.920882, loss2 : 1.553639
train_step : 8613, loss1 : 1.216996, loss2 : 2.164340
train_step : 8614, loss1 : 0.945673, loss2 : 1.534444
train_step : 8615, loss1 : 1.668775, loss2 : 1.495697
train_step : 8616, loss1 : 2.153933, loss2 : 1.040443
train_step : 8617, loss1 : 2.021080, loss2 : 0.774854
train_step : 8618, loss1 : 3.640011, loss2 : 1.145306
train_step : 8619, loss1 : 0.818908, loss2 : 1.457825
train_step : 8620, loss1 : 1.414216, loss2 : 1.792651
train_step : 8621, loss1 : 1.620638, loss2 : 1.780458
train_step : 8622, loss1 : 2.123033, loss2 : 1.768962
train_step : 8623, loss1 : 1.241301, loss2 : 3.248028
train_step : 8624, loss1 : 3.186607, loss2 : 3.667864
train_step : 8625, loss1 : 2.749291, loss2 : 2.818139
train_step : 8626, loss1 : 4.110341, loss2 : 4.627939
train_step : 8627, loss1 : 3.576262, loss2 : 3.774621
train_step : 8628, loss1 : 3.892202, loss2 : 4.573576
train_step : 8629, loss1 : 2.343113, loss2 : 3.325413
train_step : 8630, loss1 : 1.038690, loss2 : 2.579762
train_step : 8631, loss1 : 1.915461, loss2 : 1.434060
train_step : 8632, loss1 : 2.155166, loss2 : 2.092967
train_step : 8633, loss1 : 2.882451, loss2 : 2.034235
train_step : 8634, loss1 : 2.814068, loss2 : 3.546507
train_step : 8635, loss1 : 2.373440, loss2 : 2.630928
train_step : 8636, loss1 : 2.750839, loss2 : 2.316308
train_step : 8637, loss1 : 1.976745, loss2 : 2.149981
train_step : 8638, loss1 : 2.138850, loss2 : 1.591229
train_step : 8639, loss1 : 1.268179, loss2 : 1.753000
train_step : 8640, loss1 : 1.848688, loss2 : 1.577825
train_step : 8641, loss1 : 0.849185, loss2 : 1.097240
train_step : 8642, loss1 : 1.386728, loss2 : 1.518839
train_step : 8643, loss1 : 1.198552, loss2 : 1.309213
train_step : 8644, loss1 : 1.459340, loss2 : 0.985594
train_step : 8645, loss1 : 1.714491, loss2 : 1.481542
train_step : 8646, loss1 : 0.697937, loss2 : 1.056929
train_step : 8647, loss1 : 1.838365, loss2 : 1.551329
train_step : 8648, loss1 : 0.921588, loss2 : 1.369198
train_step : 8649, loss1 : 1.757797, loss2 : 1.795127
train_step : 8650, loss1 : 1.004621, loss2 : 0.984721
train_step : 8651, loss1 : 1.642268, loss2 : 1.758440
train_step : 8652, loss1 : 1.476992, loss2 : 0.886513
train_step : 8653, loss1 : 0.813844, loss2 : 1.294276
train_step : 8654, loss1 : 1.615717, loss2 : 2.295422
train_step : 8655, loss1 : 0.877023, loss2 : 0.853190
train_step : 8656, loss1 : 1.327072, loss2 : 1.375893
train_step : 8657, loss1 : 2.190455, loss2 : 1.269591
train_step : 8658, loss1 : 0.907448, loss2 : 1.962713
train_step : 8659, loss1 : 1.534300, loss2 : 0.902808
train_step : 8660, loss1 : 1.885815, loss2 : 1.050376
train_step : 8661, loss1 : 2.241366, loss2 : 2.604185
train_step : 8662, loss1 : 3.672281, loss2 : 1.807041
train_step : 8663, loss1 : 3.426243, loss2 : 2.216641
train_step : 8664, loss1 : 1.219134, loss2 : 1.654699
train_step : 8665, loss1 : 0.952180, loss2 : 1.320425
train_step : 8666, loss1 : 1.325337, loss2 : 0.724847
train_step : 8667, loss1 : 1.363058, loss2 : 1.057559
train_step : 8668, loss1 : 0.935886, loss2 : 1.240430
train_step : 8669, loss1 : 1.381486, loss2 : 1.476221
train_step : 8670, loss1 : 2.149101, loss2 : 0.821131
train_step : 8671, loss1 : 1.359638, loss2 : 1.505785
train_step : 8672, loss1 : 2.182295, loss2 : 1.211899
train_step : 8673, loss1 : 1.627687, loss2 : 1.187835
train_step : 8674, loss1 : 0.809479, loss2 : 1.070204
train_step : 8675, loss1 : 1.503957, loss2 : 1.552220
train_step : 8676, loss1 : 1.760943, loss2 : 1.209643
train_step : 8677, loss1 : 1.282076, loss2 : 0.773673
train_step : 8678, loss1 : 1.113761, loss2 : 1.079007
train_step : 8679, loss1 : 1.333261, loss2 : 1.377753
train_step : 8680, loss1 : 1.052589, loss2 : 0.891418
train_step : 8681, loss1 : 1.322011, loss2 : 1.484864
train_step : 8682, loss1 : 1.719452, loss2 : 0.613498
train_step : 8683, loss1 : 1.121383, loss2 : 1.291456
train_step : 8684, loss1 : 1.085813, loss2 : 1.144458
train_step : 8685, loss1 : 1.099670, loss2 : 2.091436
train_step : 8686, loss1 : 1.654313, loss2 : 1.562116
train_step : 8687, loss1 : 1.094269, loss2 : 0.999935
train_step : 8688, loss1 : 1.006403, loss2 : 2.047696
train_step : 8689, loss1 : 1.239459, loss2 : 1.661122
train_step : 8690, loss1 : 0.771627, loss2 : 1.710872
train_step : 8691, loss1 : 1.347678, loss2 : 0.698175
train_step : 8692, loss1 : 2.996841, loss2 : 1.122324
train_step : 8693, loss1 : 1.466471, loss2 : 1.855316
train_step : 8694, loss1 : 1.585770, loss2 : 2.384740
train_step : 8695, loss1 : 1.170400, loss2 : 1.370898
train_step : 8696, loss1 : 2.006716, loss2 : 2.047253
train_step : 8697, loss1 : 1.171052, loss2 : 1.124739
train_step : 8698, loss1 : 1.111662, loss2 : 1.482071
train_step : 8699, loss1 : 0.764280, loss2 : 1.037952
train_step : 8700, loss1 : 1.960320, loss2 : 1.565259
train_step : 8701, loss1 : 1.952958, loss2 : 0.570134
train_step : 8702, loss1 : 1.108253, loss2 : 1.458042
train_step : 8703, loss1 : 1.140981, loss2 : 1.229877
train_step : 8704, loss1 : 1.061775, loss2 : 1.058908
train_step : 8705, loss1 : 1.713996, loss2 : 1.254364
train_step : 8706, loss1 : 1.909057, loss2 : 0.885329
train_step : 8707, loss1 : 1.305254, loss2 : 1.722504
train_step : 8708, loss1 : 1.744179, loss2 : 2.157917
train_step : 8709, loss1 : 1.361012, loss2 : 1.991643
train_step : 8710, loss1 : 1.940661, loss2 : 1.332037
train_step : 8711, loss1 : 1.746650, loss2 : 1.637729
train_step : 8712, loss1 : 2.298353, loss2 : 0.952390
train_step : 8713, loss1 : 0.736812, loss2 : 0.844059
train_step : 8714, loss1 : 1.231598, loss2 : 0.894195
train_step : 8715, loss1 : 1.343637, loss2 : 0.991906
train_step : 8716, loss1 : 1.239775, loss2 : 1.840772
train_step : 8717, loss1 : 1.292280, loss2 : 1.775976
train_step : 8718, loss1 : 1.278468, loss2 : 1.076507
train_step : 8719, loss1 : 1.605701, loss2 : 2.004048
train_step : 8720, loss1 : 1.125038, loss2 : 1.246828
train_step : 8721, loss1 : 1.252352, loss2 : 1.490209
train_step : 8722, loss1 : 1.148992, loss2 : 1.374482
train_step : 8723, loss1 : 2.280772, loss2 : 1.408390
train_step : 8724, loss1 : 1.729551, loss2 : 1.035102
train_step : 8725, loss1 : 1.180725, loss2 : 0.815266
train_step : 8726, loss1 : 1.408672, loss2 : 1.489345
train_step : 8727, loss1 : 1.163437, loss2 : 0.811270
train_step : 8728, loss1 : 1.419027, loss2 : 0.665815
train_step : 8729, loss1 : 0.558897, loss2 : 0.820964
train_step : 8730, loss1 : 1.192745, loss2 : 0.936901
train_step : 8731, loss1 : 1.087513, loss2 : 0.838674
train_step : 8732, loss1 : 2.118948, loss2 : 1.222023
train_step : 8733, loss1 : 0.887306, loss2 : 1.532242
train_step : 8734, loss1 : 1.117692, loss2 : 0.795376
train_step : 8735, loss1 : 1.064835, loss2 : 1.003897
train_step : 8736, loss1 : 1.192342, loss2 : 1.592663
train_step : 8737, loss1 : 1.275900, loss2 : 1.931623
train_step : 8738, loss1 : 1.011217, loss2 : 1.511000
train_step : 8739, loss1 : 1.213395, loss2 : 1.551519
train_step : 8740, loss1 : 1.251614, loss2 : 1.314697
train_step : 8741, loss1 : 0.622695, loss2 : 1.904488
train_step : 8742, loss1 : 1.671566, loss2 : 1.024570
train_step : 8743, loss1 : 1.101849, loss2 : 0.802388
train_step : 8744, loss1 : 0.886057, loss2 : 1.017079
train_step : 8745, loss1 : 1.808939, loss2 : 1.208709
train_step : 8746, loss1 : 1.553276, loss2 : 2.788917
train_step : 8747, loss1 : 0.983873, loss2 : 1.805986
train_step : 8748, loss1 : 0.582164, loss2 : 1.702619
train_step : 8749, loss1 : 1.239030, loss2 : 1.380007
train_step : 8750, loss1 : 0.586946, loss2 : 1.508678
train_step : 8751, loss1 : 1.229825, loss2 : 1.820249
train_step : 8752, loss1 : 0.641138, loss2 : 1.191538
train_step : 8753, loss1 : 1.158606, loss2 : 0.901602
train_step : 8754, loss1 : 1.154499, loss2 : 1.492966
train_step : 8755, loss1 : 0.659545, loss2 : 0.832423
train_step : 8756, loss1 : 1.366747, loss2 : 1.349492
train_step : 8757, loss1 : 1.952523, loss2 : 0.614241
train_step : 8758, loss1 : 1.036904, loss2 : 0.635984
train_step : 8759, loss1 : 0.801176, loss2 : 1.110631
train_step : 8760, loss1 : 1.175334, loss2 : 0.640610
train_step : 8761, loss1 : 1.661068, loss2 : 0.921731
train_step : 8762, loss1 : 1.424844, loss2 : 0.977075
train_step : 8763, loss1 : 1.262944, loss2 : 1.507554
train_step : 8764, loss1 : 1.078985, loss2 : 1.021823
train_step : 8765, loss1 : 1.103355, loss2 : 0.862300
train_step : 8766, loss1 : 0.812445, loss2 : 0.563750
train_step : 8767, loss1 : 1.342173, loss2 : 1.341317
train_step : 8768, loss1 : 2.449007, loss2 : 1.708656
train_step : 8769, loss1 : 0.928660, loss2 : 1.101575
train_step : 8770, loss1 : 1.067894, loss2 : 0.548814
train_step : 8771, loss1 : 0.747159, loss2 : 1.467852
train_step : 8772, loss1 : 1.112690, loss2 : 1.233944
train_step : 8773, loss1 : 1.045377, loss2 : 1.277490
train_step : 8774, loss1 : 1.293450, loss2 : 2.165432
train_step : 8775, loss1 : 1.312848, loss2 : 0.676702
train_step : 8776, loss1 : 0.923037, loss2 : 1.025440
train_step : 8777, loss1 : 0.530027, loss2 : 2.016347
train_step : 8778, loss1 : 1.563074, loss2 : 1.362188
train_step : 8779, loss1 : 1.415751, loss2 : 1.043405
train_step : 8780, loss1 : 0.805223, loss2 : 1.010820
train_step : 8781, loss1 : 1.109332, loss2 : 0.797520
train_step : 8782, loss1 : 1.435252, loss2 : 1.954427
train_step : 8783, loss1 : 0.947197, loss2 : 0.987001
train_step : 8784, loss1 : 0.478729, loss2 : 1.210156
train_step : 8785, loss1 : 0.432533, loss2 : 1.012712
train_step : 8786, loss1 : 1.111346, loss2 : 1.731915
train_step : 8787, loss1 : 1.614683, loss2 : 1.463840
train_step : 8788, loss1 : 1.441074, loss2 : 1.367135
train_step : 8789, loss1 : 1.459276, loss2 : 1.871300
train_step : 8790, loss1 : 0.808395, loss2 : 2.585618
train_step : 8791, loss1 : 1.214366, loss2 : 1.808250
train_step : 8792, loss1 : 0.981263, loss2 : 1.196959
train_step : 8793, loss1 : 0.906312, loss2 : 1.027403
train_step : 8794, loss1 : 1.981225, loss2 : 1.430634
train_step : 8795, loss1 : 1.735312, loss2 : 1.120312
train_step : 8796, loss1 : 1.978445, loss2 : 1.447410
train_step : 8797, loss1 : 0.781103, loss2 : 2.135275
train_step : 8798, loss1 : 1.818924, loss2 : 1.409254
train_step : 8799, loss1 : 1.215770, loss2 : 1.342129
train_step : 8800, loss1 : 1.422296, loss2 : 1.233139
train_step : 8801, loss1 : 1.446461, loss2 : 1.455851
train_step : 8802, loss1 : 1.071853, loss2 : 1.433291
train_step : 8803, loss1 : 1.164261, loss2 : 1.106907
train_step : 8804, loss1 : 1.010387, loss2 : 0.927346
train_step : 8805, loss1 : 1.304791, loss2 : 1.495174
train_step : 8806, loss1 : 1.024486, loss2 : 1.304298
train_step : 8807, loss1 : 1.424304, loss2 : 1.213120
train_step : 8808, loss1 : 2.147794, loss2 : 1.363979
train_step : 8809, loss1 : 1.304713, loss2 : 1.295438
train_step : 8810, loss1 : 1.596797, loss2 : 1.659949
train_step : 8811, loss1 : 1.599099, loss2 : 1.964962
train_step : 8812, loss1 : 1.854370, loss2 : 1.201141
train_step : 8813, loss1 : 1.200264, loss2 : 0.989843
train_step : 8814, loss1 : 0.745266, loss2 : 1.771572
train_step : 8815, loss1 : 0.669252, loss2 : 1.351311
train_step : 8816, loss1 : 0.881369, loss2 : 1.551364
train_step : 8817, loss1 : 0.905226, loss2 : 1.320538
train_step : 8818, loss1 : 1.346214, loss2 : 1.447460
train_step : 8819, loss1 : 0.625177, loss2 : 1.429461
train_step : 8820, loss1 : 1.662372, loss2 : 1.718190
train_step : 8821, loss1 : 1.669452, loss2 : 1.705248
train_step : 8822, loss1 : 2.474544, loss2 : 1.499747
train_step : 8823, loss1 : 2.520574, loss2 : 2.414669
train_step : 8824, loss1 : 4.019437, loss2 : 1.852419
train_step : 8825, loss1 : 2.185929, loss2 : 2.732743
train_step : 8826, loss1 : 2.202979, loss2 : 2.248227
train_step : 8827, loss1 : 2.035158, loss2 : 1.383381
train_step : 8828, loss1 : 0.522624, loss2 : 1.207523
train_step : 8829, loss1 : 1.056589, loss2 : 0.829208
train_step : 8830, loss1 : 1.363737, loss2 : 0.877014
train_step : 8831, loss1 : 1.741892, loss2 : 1.207327
train_step : 8832, loss1 : 1.482392, loss2 : 1.781972
train_step : 8833, loss1 : 0.926448, loss2 : 1.532998
train_step : 8834, loss1 : 1.323398, loss2 : 2.202556
train_step : 8835, loss1 : 0.791439, loss2 : 1.491324
train_step : 8836, loss1 : 1.106970, loss2 : 1.320433
train_step : 8837, loss1 : 1.335549, loss2 : 1.332488
train_step : 8838, loss1 : 0.878507, loss2 : 1.171339
train_step : 8839, loss1 : 1.870603, loss2 : 1.396095
train_step : 8840, loss1 : 2.359967, loss2 : 1.978816
train_step : 8841, loss1 : 2.558064, loss2 : 2.028120
train_step : 8842, loss1 : 2.061956, loss2 : 1.817962
train_step : 8843, loss1 : 1.164662, loss2 : 1.810248
train_step : 8844, loss1 : 2.458885, loss2 : 2.723245
train_step : 8845, loss1 : 3.311380, loss2 : 3.413296
train_step : 8846, loss1 : 3.724144, loss2 : 2.816934
train_step : 8847, loss1 : 1.727427, loss2 : 2.013607
train_step : 8848, loss1 : 1.542948, loss2 : 1.110117
train_step : 8849, loss1 : 1.687613, loss2 : 1.759045
train_step : 8850, loss1 : 2.459642, loss2 : 2.279397
train_step : 8851, loss1 : 2.281440, loss2 : 2.764318
train_step : 8852, loss1 : 1.114844, loss2 : 1.900239
train_step : 8853, loss1 : 0.614464, loss2 : 1.574384
train_step : 8854, loss1 : 1.167295, loss2 : 1.561676
train_step : 8855, loss1 : 1.257563, loss2 : 0.830531
train_step : 8856, loss1 : 1.181717, loss2 : 1.589956
train_step : 8857, loss1 : 1.455765, loss2 : 1.227648
train_step : 8858, loss1 : 1.577725, loss2 : 2.128782
train_step : 8859, loss1 : 3.299511, loss2 : 1.676033
train_step : 8860, loss1 : 3.327003, loss2 : 4.031675
train_step : 8861, loss1 : 2.005547, loss2 : 2.621751
train_step : 8862, loss1 : 2.572411, loss2 : 1.463314
train_step : 8863, loss1 : 3.141706, loss2 : 1.540248
train_step : 8864, loss1 : 3.127695, loss2 : 2.728184
train_step : 8865, loss1 : 2.816115, loss2 : 2.985690
train_step : 8866, loss1 : 2.352113, loss2 : 3.854907
train_step : 8867, loss1 : 1.021959, loss2 : 2.626847
train_step : 8868, loss1 : 0.849488, loss2 : 1.866582
train_step : 8869, loss1 : 1.374426, loss2 : 1.159163
train_step : 8870, loss1 : 1.597335, loss2 : 1.249017
train_step : 8871, loss1 : 1.166383, loss2 : 2.019470
train_step : 8872, loss1 : 0.845456, loss2 : 1.826247
train_step : 8873, loss1 : 0.477894, loss2 : 1.580907
train_step : 8874, loss1 : 0.930100, loss2 : 2.793394
train_step : 8875, loss1 : 0.919241, loss2 : 1.414600
train_step : 8876, loss1 : 0.603489, loss2 : 0.374834
train_step : 8877, loss1 : 1.684811, loss2 : 0.467785
train_step : 8878, loss1 : 0.882972, loss2 : 0.834256
train_step : 8879, loss1 : 1.269771, loss2 : 0.819461
train_step : 8880, loss1 : 0.963865, loss2 : 1.033973
train_step : 8881, loss1 : 0.633223, loss2 : 1.431548
train_step : 8882, loss1 : 1.228157, loss2 : 1.309850
train_step : 8883, loss1 : 0.825299, loss2 : 1.633896
train_step : 8884, loss1 : 0.978416, loss2 : 1.043652
train_step : 8885, loss1 : 0.853321, loss2 : 1.110530
train_step : 8886, loss1 : 1.040278, loss2 : 1.007821
train_step : 8887, loss1 : 0.797049, loss2 : 0.761858
train_step : 8888, loss1 : 1.159443, loss2 : 0.411213
train_step : 8889, loss1 : 2.035628, loss2 : 1.307935
train_step : 8890, loss1 : 1.041374, loss2 : 1.248750
train_step : 8891, loss1 : 1.177334, loss2 : 1.108273
train_step : 8892, loss1 : 1.486959, loss2 : 0.779455
train_step : 8893, loss1 : 1.636624, loss2 : 1.104180
train_step : 8894, loss1 : 1.017209, loss2 : 1.245163
train_step : 8895, loss1 : 0.871440, loss2 : 1.265452
train_step : 8896, loss1 : 1.155309, loss2 : 0.793800
train_step : 8897, loss1 : 1.431028, loss2 : 1.205060
train_step : 8898, loss1 : 1.627733, loss2 : 1.407150
train_step : 8899, loss1 : 2.158555, loss2 : 1.262898
train_step : 8900, loss1 : 1.890749, loss2 : 1.153020
train_step : 8901, loss1 : 1.241554, loss2 : 1.669443
train_step : 8902, loss1 : 1.087967, loss2 : 1.365383
train_step : 8903, loss1 : 1.591995, loss2 : 0.727447
train_step : 8904, loss1 : 1.374044, loss2 : 1.008099
train_step : 8905, loss1 : 2.162294, loss2 : 1.222938
train_step : 8906, loss1 : 1.564047, loss2 : 0.530500
train_step : 8907, loss1 : 1.249805, loss2 : 2.038008
train_step : 8908, loss1 : 1.942246, loss2 : 2.536051
train_step : 8909, loss1 : 2.169035, loss2 : 2.494130
train_step : 8910, loss1 : 3.514957, loss2 : 3.104212
train_step : 8911, loss1 : 3.133232, loss2 : 2.392394
train_step : 8912, loss1 : 2.328312, loss2 : 2.624307
train_step : 8913, loss1 : 1.932632, loss2 : 1.346753
train_step : 8914, loss1 : 2.447520, loss2 : 1.604654
train_step : 8915, loss1 : 1.290530, loss2 : 2.610750
train_step : 8916, loss1 : 1.506370, loss2 : 0.883756
train_step : 8917, loss1 : 1.221183, loss2 : 0.888346
train_step : 8918, loss1 : 0.604124, loss2 : 0.729831
train_step : 8919, loss1 : 1.564795, loss2 : 1.725956
train_step : 8920, loss1 : 1.444063, loss2 : 1.308677
train_step : 8921, loss1 : 1.118311, loss2 : 0.644260
train_step : 8922, loss1 : 1.091424, loss2 : 1.398991
train_step : 8923, loss1 : 1.147499, loss2 : 2.272488
train_step : 8924, loss1 : 1.444685, loss2 : 1.368376
train_step : 8925, loss1 : 1.161587, loss2 : 1.268070
train_step : 8926, loss1 : 1.135784, loss2 : 1.581888
train_step : 8927, loss1 : 1.192863, loss2 : 0.994854
train_step : 8928, loss1 : 1.155493, loss2 : 1.986349
train_step : 8929, loss1 : 1.529011, loss2 : 1.058702
train_step : 8930, loss1 : 1.154858, loss2 : 1.231977
train_step : 8931, loss1 : 0.982924, loss2 : 1.233618
train_step : 8932, loss1 : 1.170452, loss2 : 3.121910
train_step : 8933, loss1 : 2.141852, loss2 : 2.423506
train_step : 8934, loss1 : 2.093779, loss2 : 2.533887
train_step : 8935, loss1 : 3.060409, loss2 : 2.889163
train_step : 8936, loss1 : 2.142440, loss2 : 2.261948
train_step : 8937, loss1 : 1.237416, loss2 : 1.677126
train_step : 8938, loss1 : 1.362107, loss2 : 1.864958
train_step : 8939, loss1 : 0.815742, loss2 : 1.989705
train_step : 8940, loss1 : 2.015687, loss2 : 2.436147
train_step : 8941, loss1 : 3.384104, loss2 : 1.819762
train_step : 8942, loss1 : 3.060923, loss2 : 3.779580
train_step : 8943, loss1 : 3.094280, loss2 : 1.656943
train_step : 8944, loss1 : 1.423374, loss2 : 1.391807
train_step : 8945, loss1 : 1.432816, loss2 : 1.283468
train_step : 8946, loss1 : 0.979585, loss2 : 1.087640
train_step : 8947, loss1 : 1.120443, loss2 : 1.085898
train_step : 8948, loss1 : 0.966339, loss2 : 0.780585
train_step : 8949, loss1 : 0.972457, loss2 : 1.353406
train_step : 8950, loss1 : 1.936971, loss2 : 0.915421
train_step : 8951, loss1 : 1.835722, loss2 : 2.325923
train_step : 8952, loss1 : 1.553790, loss2 : 1.830053
train_step : 8953, loss1 : 1.795673, loss2 : 1.401881
train_step : 8954, loss1 : 1.635582, loss2 : 2.219802
train_step : 8955, loss1 : 2.151647, loss2 : 2.037897
train_step : 8956, loss1 : 2.033707, loss2 : 1.537952
train_step : 8957, loss1 : 1.294548, loss2 : 0.603918
train_step : 8958, loss1 : 0.801378, loss2 : 0.762098
train_step : 8959, loss1 : 1.187171, loss2 : 1.495654
train_step : 8960, loss1 : 1.052777, loss2 : 1.284224
train_step : 8961, loss1 : 1.210165, loss2 : 1.273579
train_step : 8962, loss1 : 1.153475, loss2 : 1.644511
train_step : 8963, loss1 : 2.079495, loss2 : 2.067406
train_step : 8964, loss1 : 2.800072, loss2 : 1.767181
train_step : 8965, loss1 : 2.624033, loss2 : 2.579735
train_step : 8966, loss1 : 2.535597, loss2 : 3.066987
train_step : 8967, loss1 : 1.238162, loss2 : 2.460580
train_step : 8968, loss1 : 2.138890, loss2 : 2.194760
train_step : 8969, loss1 : 1.909477, loss2 : 1.816426
train_step : 8970, loss1 : 0.893187, loss2 : 1.557446
train_step : 8971, loss1 : 1.401694, loss2 : 1.367354
train_step : 8972, loss1 : 1.003863, loss2 : 0.915596
train_step : 8973, loss1 : 0.687863, loss2 : 0.612657
train_step : 8974, loss1 : 1.269515, loss2 : 1.128322
train_step : 8975, loss1 : 1.140507, loss2 : 1.947527
train_step : 8976, loss1 : 1.188616, loss2 : 1.709165
train_step : 8977, loss1 : 1.202763, loss2 : 1.323531
train_step : 8978, loss1 : 0.874405, loss2 : 0.729271
train_step : 8979, loss1 : 0.635817, loss2 : 1.493429
train_step : 8980, loss1 : 0.865566, loss2 : 0.988304
train_step : 8981, loss1 : 1.466122, loss2 : 1.352008
train_step : 8982, loss1 : 0.819160, loss2 : 1.457321
train_step : 8983, loss1 : 0.935463, loss2 : 0.758444
train_step : 8984, loss1 : 1.373420, loss2 : 0.696488
train_step : 8985, loss1 : 0.637938, loss2 : 0.879044
train_step : 8986, loss1 : 0.494233, loss2 : 1.061810
train_step : 8987, loss1 : 1.669799, loss2 : 1.290743
train_step : 8988, loss1 : 1.834127, loss2 : 1.560679
train_step : 8989, loss1 : 1.848560, loss2 : 1.106166
train_step : 8990, loss1 : 1.483188, loss2 : 1.174107
train_step : 8991, loss1 : 0.921950, loss2 : 2.528211
train_step : 8992, loss1 : 1.805668, loss2 : 0.791726
train_step : 8993, loss1 : 1.033138, loss2 : 2.095052
train_step : 8994, loss1 : 1.240312, loss2 : 0.793585
train_step : 8995, loss1 : 1.528301, loss2 : 1.163911
train_step : 8996, loss1 : 2.851394, loss2 : 2.607467
train_step : 8997, loss1 : 2.062250, loss2 : 1.645500
train_step : 8998, loss1 : 0.879960, loss2 : 0.911341
train_step : 8999, loss1 : 1.106624, loss2 : 1.102713
train_step : 9000, loss1 : 1.465311, loss2 : 1.465544
train_step : 9001, loss1 : 0.993837, loss2 : 1.569756
train_step : 9002, loss1 : 1.599900, loss2 : 1.155609
train_step : 9003, loss1 : 1.166933, loss2 : 1.467966
train_step : 9004, loss1 : 1.337045, loss2 : 0.764698
train_step : 9005, loss1 : 1.823007, loss2 : 0.916469
train_step : 9006, loss1 : 1.119280, loss2 : 1.008847
train_step : 9007, loss1 : 1.032428, loss2 : 1.274904
train_step : 9008, loss1 : 1.905477, loss2 : 1.729352
train_step : 9009, loss1 : 1.561653, loss2 : 0.731620
train_step : 9010, loss1 : 1.316830, loss2 : 1.140053
train_step : 9011, loss1 : 1.968019, loss2 : 1.639427
train_step : 9012, loss1 : 1.292232, loss2 : 0.983729
train_step : 9013, loss1 : 1.127583, loss2 : 2.207804
train_step : 9014, loss1 : 0.779638, loss2 : 1.572034
train_step : 9015, loss1 : 1.301771, loss2 : 0.809354
train_step : 9016, loss1 : 2.369053, loss2 : 0.839944
train_step : 9017, loss1 : 2.225497, loss2 : 1.877669
train_step : 9018, loss1 : 1.395623, loss2 : 2.381680
train_step : 9019, loss1 : 1.516001, loss2 : 1.898613
train_step : 9020, loss1 : 1.348123, loss2 : 1.443442
train_step : 9021, loss1 : 1.219493, loss2 : 1.340211
train_step : 9022, loss1 : 2.189538, loss2 : 1.391643
train_step : 9023, loss1 : 0.915205, loss2 : 1.522994
train_step : 9024, loss1 : 1.236412, loss2 : 2.033994
train_step : 9025, loss1 : 0.954013, loss2 : 1.159335
train_step : 9026, loss1 : 0.756030, loss2 : 1.081855
train_step : 9027, loss1 : 1.439371, loss2 : 1.233412
train_step : 9028, loss1 : 1.111169, loss2 : 1.162636
train_step : 9029, loss1 : 2.421128, loss2 : 1.038720
train_step : 9030, loss1 : 1.615887, loss2 : 1.207498
train_step : 9031, loss1 : 1.836483, loss2 : 1.581831
train_step : 9032, loss1 : 0.700808, loss2 : 1.289185
train_step : 9033, loss1 : 1.088008, loss2 : 1.158123
train_step : 9034, loss1 : 1.703139, loss2 : 1.394041
train_step : 9035, loss1 : 1.658356, loss2 : 1.640207
train_step : 9036, loss1 : 1.703260, loss2 : 2.542390
train_step : 9037, loss1 : 2.246317, loss2 : 2.835538
train_step : 9038, loss1 : 2.170338, loss2 : 1.427925
train_step : 9039, loss1 : 1.709190, loss2 : 2.195415
train_step : 9040, loss1 : 2.032795, loss2 : 1.596936
train_step : 9041, loss1 : 1.750767, loss2 : 2.488370
train_step : 9042, loss1 : 1.327461, loss2 : 2.506906
train_step : 9043, loss1 : 1.651424, loss2 : 1.304619
train_step : 9044, loss1 : 2.059676, loss2 : 1.029046
train_step : 9045, loss1 : 1.443904, loss2 : 0.957964
train_step : 9046, loss1 : 1.146613, loss2 : 1.554695
train_step : 9047, loss1 : 1.374323, loss2 : 1.351021
train_step : 9048, loss1 : 0.749259, loss2 : 1.471270
train_step : 9049, loss1 : 1.053870, loss2 : 0.786898
train_step : 9050, loss1 : 1.639776, loss2 : 0.707557
train_step : 9051, loss1 : 0.869391, loss2 : 1.486044
train_step : 9052, loss1 : 2.243679, loss2 : 1.503267
train_step : 9053, loss1 : 2.463192, loss2 : 0.648138
train_step : 9054, loss1 : 0.782384, loss2 : 1.039041
train_step : 9055, loss1 : 0.907853, loss2 : 1.923940
train_step : 9056, loss1 : 0.637850, loss2 : 1.352640
train_step : 9057, loss1 : 1.813150, loss2 : 1.167634
train_step : 9058, loss1 : 1.301466, loss2 : 1.267659
train_step : 9059, loss1 : 1.427128, loss2 : 0.882018
train_step : 9060, loss1 : 1.351421, loss2 : 1.600033
train_step : 9061, loss1 : 0.665136, loss2 : 2.806017
train_step : 9062, loss1 : 1.867022, loss2 : 1.662289
train_step : 9063, loss1 : 1.508595, loss2 : 2.451926
train_step : 9064, loss1 : 2.678354, loss2 : 2.549521
train_step : 9065, loss1 : 2.096499, loss2 : 4.576017
train_step : 9066, loss1 : 2.460431, loss2 : 2.113990
train_step : 9067, loss1 : 2.006457, loss2 : 2.135047
train_step : 9068, loss1 : 2.369370, loss2 : 3.265092
train_step : 9069, loss1 : 2.993381, loss2 : 4.140403
train_step : 9070, loss1 : 3.981670, loss2 : 3.956685
train_step : 9071, loss1 : 3.625060, loss2 : 2.529739
train_step : 9072, loss1 : 3.459880, loss2 : 4.836258
train_step : 9073, loss1 : 3.042787, loss2 : 2.302447
train_step : 9074, loss1 : 3.459091, loss2 : 2.577276
train_step : 9075, loss1 : 3.029386, loss2 : 2.789154
train_step : 9076, loss1 : 4.552346, loss2 : 4.356465
train_step : 9077, loss1 : 3.385230, loss2 : 4.964541
train_step : 9078, loss1 : 4.044203, loss2 : 3.996133
train_step : 9079, loss1 : 2.943212, loss2 : 2.613679
train_step : 9080, loss1 : 2.710031, loss2 : 2.424953
train_step : 9081, loss1 : 3.366986, loss2 : 2.191667
train_step : 9082, loss1 : 2.864455, loss2 : 1.792466
train_step : 9083, loss1 : 1.513607, loss2 : 1.896947
train_step : 9084, loss1 : 1.180974, loss2 : 2.155521
train_step : 9085, loss1 : 1.107146, loss2 : 2.203874
train_step : 9086, loss1 : 2.111625, loss2 : 1.519024
train_step : 9087, loss1 : 1.168054, loss2 : 1.530082
train_step : 9088, loss1 : 1.261932, loss2 : 1.234422
train_step : 9089, loss1 : 1.238311, loss2 : 1.085319
train_step : 9090, loss1 : 1.481060, loss2 : 1.349973
train_step : 9091, loss1 : 0.669926, loss2 : 1.170642
train_step : 9092, loss1 : 1.207302, loss2 : 1.694966
train_step : 9093, loss1 : 2.187383, loss2 : 1.635402
train_step : 9094, loss1 : 1.990956, loss2 : 1.954334
train_step : 9095, loss1 : 2.427903, loss2 : 2.629486
train_step : 9096, loss1 : 4.978987, loss2 : 2.235013
train_step : 9097, loss1 : 4.455095, loss2 : 3.712281
train_step : 9098, loss1 : 6.049272, loss2 : 5.268891
train_step : 9099, loss1 : 2.529874, loss2 : 3.075643
train_step : 9100, loss1 : 2.838237, loss2 : 1.799750
train_step : 9101, loss1 : 1.957190, loss2 : 1.304631
train_step : 9102, loss1 : 1.972150, loss2 : 1.386947
train_step : 9103, loss1 : 2.017910, loss2 : 0.685361
train_step : 9104, loss1 : 0.687256, loss2 : 0.990403
train_step : 9105, loss1 : 0.809666, loss2 : 0.712657
train_step : 9106, loss1 : 1.163023, loss2 : 1.313725
train_step : 9107, loss1 : 1.355939, loss2 : 1.174283
train_step : 9108, loss1 : 1.083575, loss2 : 1.713497
train_step : 9109, loss1 : 1.862411, loss2 : 1.598163
train_step : 9110, loss1 : 1.748712, loss2 : 1.252768
train_step : 9111, loss1 : 1.304846, loss2 : 0.737092
train_step : 9112, loss1 : 1.029793, loss2 : 0.930560
train_step : 9113, loss1 : 1.328210, loss2 : 0.682178
train_step : 9114, loss1 : 2.123536, loss2 : 1.211105
train_step : 9115, loss1 : 1.776006, loss2 : 0.770429
train_step : 9116, loss1 : 0.757605, loss2 : 0.979129
train_step : 9117, loss1 : 1.389857, loss2 : 1.058627
train_step : 9118, loss1 : 1.230673, loss2 : 1.265900
train_step : 9119, loss1 : 1.190728, loss2 : 0.798444
train_step : 9120, loss1 : 0.926329, loss2 : 0.881917
train_step : 9121, loss1 : 0.979183, loss2 : 1.227251
train_step : 9122, loss1 : 1.043898, loss2 : 1.593720
train_step : 9123, loss1 : 1.054786, loss2 : 1.158228
train_step : 9124, loss1 : 1.476975, loss2 : 0.850003
train_step : 9125, loss1 : 1.344453, loss2 : 1.232882
train_step : 9126, loss1 : 0.850744, loss2 : 1.058762
train_step : 9127, loss1 : 1.100529, loss2 : 1.278994
train_step : 9128, loss1 : 0.892683, loss2 : 0.836849
train_step : 9129, loss1 : 1.328079, loss2 : 0.607685
train_step : 9130, loss1 : 0.476216, loss2 : 1.340560
train_step : 9131, loss1 : 1.158927, loss2 : 0.829586
train_step : 9132, loss1 : 1.171777, loss2 : 1.842274
train_step : 9133, loss1 : 1.140024, loss2 : 0.842338
train_step : 9134, loss1 : 1.371001, loss2 : 1.058669
train_step : 9135, loss1 : 0.873983, loss2 : 1.166293
train_step : 9136, loss1 : 0.912001, loss2 : 1.770197
train_step : 9137, loss1 : 1.390526, loss2 : 0.737801
train_step : 9138, loss1 : 1.121903, loss2 : 1.001789
train_step : 9139, loss1 : 1.533844, loss2 : 1.103458
train_step : 9140, loss1 : 1.403341, loss2 : 1.662318
train_step : 9141, loss1 : 2.520630, loss2 : 1.257776
train_step : 9142, loss1 : 1.897330, loss2 : 2.718542
train_step : 9143, loss1 : 1.513543, loss2 : 1.782198
train_step : 9144, loss1 : 1.985623, loss2 : 1.451087
train_step : 9145, loss1 : 1.488008, loss2 : 2.012271
train_step : 9146, loss1 : 1.404502, loss2 : 0.964173
train_step : 9147, loss1 : 0.624599, loss2 : 1.051686
train_step : 9148, loss1 : 1.142146, loss2 : 1.707174
train_step : 9149, loss1 : 1.076674, loss2 : 1.067567
train_step : 9150, loss1 : 1.755853, loss2 : 1.902156
train_step : 9151, loss1 : 1.048435, loss2 : 1.600263
train_step : 9152, loss1 : 0.726042, loss2 : 0.931343
train_step : 9153, loss1 : 1.055143, loss2 : 1.533499
train_step : 9154, loss1 : 1.392419, loss2 : 2.525405
train_step : 9155, loss1 : 1.513620, loss2 : 0.951428
train_step : 9156, loss1 : 2.866458, loss2 : 1.784557
train_step : 9157, loss1 : 0.902020, loss2 : 0.819176
train_step : 9158, loss1 : 1.414945, loss2 : 1.211828
train_step : 9159, loss1 : 0.762457, loss2 : 1.394920
train_step : 9160, loss1 : 1.521774, loss2 : 0.820640
train_step : 9161, loss1 : 0.918633, loss2 : 1.670637
train_step : 9162, loss1 : 1.847860, loss2 : 1.572784
train_step : 9163, loss1 : 1.574973, loss2 : 0.962722
train_step : 9164, loss1 : 1.759950, loss2 : 0.769425
train_step : 9165, loss1 : 1.536116, loss2 : 1.355848
train_step : 9166, loss1 : 1.486665, loss2 : 1.488084
train_step : 9167, loss1 : 0.993231, loss2 : 1.661672
train_step : 9168, loss1 : 1.481554, loss2 : 0.729345
train_step : 9169, loss1 : 0.636618, loss2 : 1.207436
train_step : 9170, loss1 : 1.025630, loss2 : 1.254107
train_step : 9171, loss1 : 0.929590, loss2 : 0.698100
train_step : 9172, loss1 : 1.416155, loss2 : 1.161066
train_step : 9173, loss1 : 1.354769, loss2 : 1.129747
train_step : 9174, loss1 : 1.534148, loss2 : 1.122057
train_step : 9175, loss1 : 1.608199, loss2 : 1.684813
train_step : 9176, loss1 : 1.199805, loss2 : 1.023892
train_step : 9177, loss1 : 1.047499, loss2 : 1.094026
train_step : 9178, loss1 : 0.943177, loss2 : 1.518874
train_step : 9179, loss1 : 1.669221, loss2 : 1.906244
train_step : 9180, loss1 : 1.698235, loss2 : 2.239989
train_step : 9181, loss1 : 2.943301, loss2 : 1.955022
train_step : 9182, loss1 : 2.030387, loss2 : 1.305043
train_step : 9183, loss1 : 1.722117, loss2 : 0.962208
train_step : 9184, loss1 : 0.678544, loss2 : 2.040880
train_step : 9185, loss1 : 0.917703, loss2 : 1.123190
train_step : 9186, loss1 : 1.593895, loss2 : 0.927461
train_step : 9187, loss1 : 0.728441, loss2 : 1.081990
train_step : 9188, loss1 : 0.931917, loss2 : 1.580903
train_step : 9189, loss1 : 1.809562, loss2 : 1.592283
train_step : 9190, loss1 : 0.982568, loss2 : 1.628841
train_step : 9191, loss1 : 1.629364, loss2 : 0.757208
train_step : 9192, loss1 : 1.353996, loss2 : 0.682043
train_step : 9193, loss1 : 1.179925, loss2 : 1.151163
train_step : 9194, loss1 : 1.243524, loss2 : 1.673328
train_step : 9195, loss1 : 2.283044, loss2 : 1.892641
train_step : 9196, loss1 : 1.512998, loss2 : 1.622410
train_step : 9197, loss1 : 1.192786, loss2 : 2.587137
train_step : 9198, loss1 : 2.323413, loss2 : 2.630324
train_step : 9199, loss1 : 1.812831, loss2 : 1.040631
train_step : 9200, loss1 : 1.087602, loss2 : 1.626942
train_step : 9201, loss1 : 1.445980, loss2 : 0.952078
train_step : 9202, loss1 : 1.543120, loss2 : 1.793501
train_step : 9203, loss1 : 1.579570, loss2 : 1.541551
train_step : 9204, loss1 : 1.350065, loss2 : 1.433296
train_step : 9205, loss1 : 1.221143, loss2 : 2.800436
train_step : 9206, loss1 : 1.274492, loss2 : 1.697948
train_step : 9207, loss1 : 1.233351, loss2 : 0.951031
train_step : 9208, loss1 : 0.912021, loss2 : 1.750470
train_step : 9209, loss1 : 0.945364, loss2 : 0.930340
train_step : 9210, loss1 : 0.947674, loss2 : 0.942440
train_step : 9211, loss1 : 1.707719, loss2 : 3.002870
train_step : 9212, loss1 : 1.939670, loss2 : 1.597453
train_step : 9213, loss1 : 1.459623, loss2 : 1.371786
train_step : 9214, loss1 : 0.958092, loss2 : 2.069875
train_step : 9215, loss1 : 1.748181, loss2 : 2.478492
train_step : 9216, loss1 : 2.690293, loss2 : 3.711087
train_step : 9217, loss1 : 3.806097, loss2 : 2.486370
train_step : 9218, loss1 : 2.568798, loss2 : 2.797441
train_step : 9219, loss1 : 1.606038, loss2 : 2.722750
train_step : 9220, loss1 : 2.589614, loss2 : 1.820188
train_step : 9221, loss1 : 1.472831, loss2 : 1.782681
train_step : 9222, loss1 : 2.109898, loss2 : 2.340973
train_step : 9223, loss1 : 1.905343, loss2 : 3.069251
train_step : 9224, loss1 : 3.569114, loss2 : 3.887938
train_step : 9225, loss1 : 3.967369, loss2 : 2.726372
train_step : 9226, loss1 : 3.508535, loss2 : 4.030101
train_step : 9227, loss1 : 3.837029, loss2 : 4.223446
train_step : 9228, loss1 : 3.933549, loss2 : 2.754228
train_step : 9229, loss1 : 0.934855, loss2 : 1.446145
train_step : 9230, loss1 : 1.797207, loss2 : 1.252756
train_step : 9231, loss1 : 0.764122, loss2 : 1.575232
train_step : 9232, loss1 : 1.002195, loss2 : 0.927281
train_step : 9233, loss1 : 0.667418, loss2 : 1.360988
train_step : 9234, loss1 : 1.865295, loss2 : 0.805737
train_step : 9235, loss1 : 1.046000, loss2 : 0.335984
train_step : 9236, loss1 : 2.011378, loss2 : 1.227289
train_step : 9237, loss1 : 0.516303, loss2 : 1.035821
train_step : 9238, loss1 : 1.032722, loss2 : 1.482541
train_step : 9239, loss1 : 0.305772, loss2 : 1.397262
train_step : 9240, loss1 : 0.696552, loss2 : 0.710521
train_step : 9241, loss1 : 1.416064, loss2 : 1.759287
train_step : 9242, loss1 : 1.124894, loss2 : 1.373251
train_step : 9243, loss1 : 0.907295, loss2 : 0.815412
train_step : 9244, loss1 : 2.020357, loss2 : 0.948579
train_step : 9245, loss1 : 1.005946, loss2 : 1.253280
train_step : 9246, loss1 : 1.800756, loss2 : 1.057636
train_step : 9247, loss1 : 1.063362, loss2 : 1.373863
train_step : 9248, loss1 : 0.511461, loss2 : 1.130223
train_step : 9249, loss1 : 1.438606, loss2 : 1.070419
train_step : 9250, loss1 : 1.333704, loss2 : 1.441167
train_step : 9251, loss1 : 1.233016, loss2 : 1.097725
train_step : 9252, loss1 : 1.631475, loss2 : 1.196351
train_step : 9253, loss1 : 1.022995, loss2 : 0.937590
train_step : 9254, loss1 : 0.815874, loss2 : 0.974990
train_step : 9255, loss1 : 1.436957, loss2 : 0.756050
train_step : 9256, loss1 : 1.311501, loss2 : 1.416180
train_step : 9257, loss1 : 2.034116, loss2 : 1.418495
train_step : 9258, loss1 : 2.594398, loss2 : 3.450342
train_step : 9259, loss1 : 3.403080, loss2 : 3.013416
train_step : 9260, loss1 : 2.090902, loss2 : 4.974075
train_step : 9261, loss1 : 3.528700, loss2 : 2.125218
train_step : 9262, loss1 : 2.647243, loss2 : 2.228997
train_step : 9263, loss1 : 1.756461, loss2 : 2.850106
train_step : 9264, loss1 : 4.010509, loss2 : 1.845148
train_step : 9265, loss1 : 2.832173, loss2 : 3.282441
train_step : 9266, loss1 : 3.911639, loss2 : 3.485915
train_step : 9267, loss1 : 1.954563, loss2 : 0.771262
train_step : 9268, loss1 : 0.658232, loss2 : 1.439058
train_step : 9269, loss1 : 1.286271, loss2 : 1.310649
train_step : 9270, loss1 : 0.591043, loss2 : 1.936892
train_step : 9271, loss1 : 0.482708, loss2 : 1.589614
train_step : 9272, loss1 : 1.324677, loss2 : 1.413801
train_step : 9273, loss1 : 0.516002, loss2 : 1.064009
train_step : 9274, loss1 : 1.377599, loss2 : 1.267957
train_step : 9275, loss1 : 1.478900, loss2 : 0.595041
train_step : 9276, loss1 : 1.035719, loss2 : 1.705302
train_step : 9277, loss1 : 4.611361, loss2 : 0.866102
train_step : 9278, loss1 : 1.477073, loss2 : 1.014109
train_step : 9279, loss1 : 0.917967, loss2 : 0.843191
train_step : 9280, loss1 : 1.182014, loss2 : 0.958716
train_step : 9281, loss1 : 1.001415, loss2 : 1.958398
train_step : 9282, loss1 : 1.016079, loss2 : 1.444490
train_step : 9283, loss1 : 0.931815, loss2 : 1.405527
train_step : 9284, loss1 : 1.428996, loss2 : 1.348774
train_step : 9285, loss1 : 0.816502, loss2 : 0.911113
train_step : 9286, loss1 : 0.997245, loss2 : 0.843366
train_step : 9287, loss1 : 1.020589, loss2 : 0.785412
train_step : 9288, loss1 : 0.912449, loss2 : 1.240190
train_step : 9289, loss1 : 1.879129, loss2 : 1.418915
train_step : 9290, loss1 : 0.992753, loss2 : 1.400325
train_step : 9291, loss1 : 1.053692, loss2 : 1.406903
train_step : 9292, loss1 : 1.137459, loss2 : 1.524283
train_step : 9293, loss1 : 1.075162, loss2 : 1.393271
train_step : 9294, loss1 : 1.712074, loss2 : 0.531593
train_step : 9295, loss1 : 1.113508, loss2 : 0.935257
train_step : 9296, loss1 : 0.757680, loss2 : 0.982196
train_step : 9297, loss1 : 0.816017, loss2 : 1.336111
train_step : 9298, loss1 : 1.056151, loss2 : 0.473047
train_step : 9299, loss1 : 1.042390, loss2 : 0.704792
train_step : 9300, loss1 : 1.016278, loss2 : 1.343672
train_step : 9301, loss1 : 0.951466, loss2 : 1.176120
train_step : 9302, loss1 : 0.786389, loss2 : 1.454084
train_step : 9303, loss1 : 0.645161, loss2 : 1.245996
train_step : 9304, loss1 : 1.026521, loss2 : 1.522719
train_step : 9305, loss1 : 0.661090, loss2 : 2.062309
train_step : 9306, loss1 : 0.878205, loss2 : 0.893727
train_step : 9307, loss1 : 1.876824, loss2 : 1.520504
train_step : 9308, loss1 : 1.260262, loss2 : 0.967046
train_step : 9309, loss1 : 1.098779, loss2 : 1.498012
train_step : 9310, loss1 : 1.648705, loss2 : 1.595210
train_step : 9311, loss1 : 1.577226, loss2 : 1.083443
train_step : 9312, loss1 : 1.770158, loss2 : 1.185779
train_step : 9313, loss1 : 0.925829, loss2 : 0.946258
train_step : 9314, loss1 : 1.661849, loss2 : 0.650211
train_step : 9315, loss1 : 1.010559, loss2 : 1.159985
train_step : 9316, loss1 : 0.812786, loss2 : 1.687146
train_step : 9317, loss1 : 1.078537, loss2 : 1.013363
train_step : 9318, loss1 : 1.354211, loss2 : 1.128432
train_step : 9319, loss1 : 1.474843, loss2 : 0.865431
train_step : 9320, loss1 : 1.688590, loss2 : 1.262433
train_step : 9321, loss1 : 1.593084, loss2 : 1.549003
train_step : 9322, loss1 : 2.068655, loss2 : 1.539994
train_step : 9323, loss1 : 0.797144, loss2 : 0.812373
train_step : 9324, loss1 : 2.092900, loss2 : 1.536773
train_step : 9325, loss1 : 1.188421, loss2 : 1.191171
train_step : 9326, loss1 : 0.997004, loss2 : 1.300079
train_step : 9327, loss1 : 1.111919, loss2 : 2.301974
train_step : 9328, loss1 : 1.520730, loss2 : 3.082516
train_step : 9329, loss1 : 1.849226, loss2 : 1.082990
train_step : 9330, loss1 : 1.343407, loss2 : 1.572679
train_step : 9331, loss1 : 1.147375, loss2 : 1.350937
train_step : 9332, loss1 : 0.772860, loss2 : 0.865241
train_step : 9333, loss1 : 1.505602, loss2 : 1.385696
train_step : 9334, loss1 : 1.182139, loss2 : 1.364723
train_step : 9335, loss1 : 1.154396, loss2 : 0.786718
train_step : 9336, loss1 : 1.385327, loss2 : 1.606923
train_step : 9337, loss1 : 2.168381, loss2 : 1.464832
train_step : 9338, loss1 : 1.434725, loss2 : 1.129385
train_step : 9339, loss1 : 0.669211, loss2 : 1.080301
train_step : 9340, loss1 : 0.793166, loss2 : 1.317545
train_step : 9341, loss1 : 2.281723, loss2 : 1.055947
train_step : 9342, loss1 : 2.168412, loss2 : 1.721727
train_step : 9343, loss1 : 1.380824, loss2 : 2.706425
train_step : 9344, loss1 : 0.721808, loss2 : 1.996012
train_step : 9345, loss1 : 1.133134, loss2 : 1.451180
train_step : 9346, loss1 : 0.796887, loss2 : 1.058627
train_step : 9347, loss1 : 1.363377, loss2 : 1.308137
train_step : 9348, loss1 : 1.240563, loss2 : 1.308379
train_step : 9349, loss1 : 1.089875, loss2 : 1.000410
train_step : 9350, loss1 : 1.576259, loss2 : 1.825296
train_step : 9351, loss1 : 1.261061, loss2 : 1.578597
train_step : 9352, loss1 : 1.208004, loss2 : 1.275914
train_step : 9353, loss1 : 1.084164, loss2 : 1.329237
train_step : 9354, loss1 : 0.923900, loss2 : 1.490782
train_step : 9355, loss1 : 0.990368, loss2 : 1.283246
train_step : 9356, loss1 : 0.455767, loss2 : 0.877722
train_step : 9357, loss1 : 0.968792, loss2 : 0.996275
train_step : 9358, loss1 : 0.708597, loss2 : 1.023072
train_step : 9359, loss1 : 0.881462, loss2 : 0.822291
train_step : 9360, loss1 : 0.783964, loss2 : 1.146013
train_step : 9361, loss1 : 1.556907, loss2 : 1.179443
train_step : 9362, loss1 : 0.859458, loss2 : 0.835983
train_step : 9363, loss1 : 1.266768, loss2 : 0.962552
train_step : 9364, loss1 : 0.918357, loss2 : 1.135267
train_step : 9365, loss1 : 1.572295, loss2 : 1.257138
train_step : 9366, loss1 : 1.539176, loss2 : 1.790337
train_step : 9367, loss1 : 1.528842, loss2 : 1.139279
train_step : 9368, loss1 : 1.003363, loss2 : 0.961680
train_step : 9369, loss1 : 1.000786, loss2 : 1.360795
train_step : 9370, loss1 : 1.263260, loss2 : 0.920089
train_step : 9371, loss1 : 1.340554, loss2 : 1.429370
train_step : 9372, loss1 : 1.091126, loss2 : 0.617853
train_step : 9373, loss1 : 1.858831, loss2 : 1.545605
train_step : 9374, loss1 : 1.207364, loss2 : 1.195621
train_step : 9375, loss1 : 0.891330, loss2 : 0.746959
train_step : 9376, loss1 : 0.724975, loss2 : 0.550594
train_step : 9377, loss1 : 0.881273, loss2 : 1.155385
train_step : 9378, loss1 : 1.208838, loss2 : 1.387599
train_step : 9379, loss1 : 2.553291, loss2 : 1.237951
train_step : 9380, loss1 : 2.782317, loss2 : 0.889342
train_step : 9381, loss1 : 1.371472, loss2 : 1.075825
train_step : 9382, loss1 : 1.138957, loss2 : 0.838989
train_step : 9383, loss1 : 0.712398, loss2 : 1.084549
train_step : 9384, loss1 : 1.084775, loss2 : 0.947748
train_step : 9385, loss1 : 0.906353, loss2 : 1.475512
train_step : 9386, loss1 : 0.961707, loss2 : 0.979467
train_step : 9387, loss1 : 2.014427, loss2 : 1.022713
train_step : 9388, loss1 : 0.420336, loss2 : 0.426467
train_step : 9389, loss1 : 2.617357, loss2 : 0.764310
train_step : 9390, loss1 : 1.489945, loss2 : 0.923595
train_step : 9391, loss1 : 1.050068, loss2 : 1.103407
train_step : 9392, loss1 : 1.069670, loss2 : 1.298143
train_step : 9393, loss1 : 1.195596, loss2 : 1.233339
train_step : 9394, loss1 : 1.577500, loss2 : 1.137043
train_step : 9395, loss1 : 1.877511, loss2 : 1.409485
train_step : 9396, loss1 : 0.994868, loss2 : 1.888306
train_step : 9397, loss1 : 1.376909, loss2 : 1.212264
train_step : 9398, loss1 : 1.729957, loss2 : 2.209693
train_step : 9399, loss1 : 1.286102, loss2 : 0.890936
train_step : 9400, loss1 : 2.571498, loss2 : 1.742243
train_step : 9401, loss1 : 1.344493, loss2 : 0.648468
train_step : 9402, loss1 : 0.764989, loss2 : 1.532136
train_step : 9403, loss1 : 1.099284, loss2 : 1.224836
train_step : 9404, loss1 : 1.097931, loss2 : 1.182621
train_step : 9405, loss1 : 0.835131, loss2 : 0.867941
train_step : 9406, loss1 : 1.440683, loss2 : 1.297373
train_step : 9407, loss1 : 0.906587, loss2 : 0.987115
train_step : 9408, loss1 : 1.391634, loss2 : 1.199461
train_step : 9409, loss1 : 0.962597, loss2 : 1.483295
train_step : 9410, loss1 : 1.403591, loss2 : 0.702199
train_step : 9411, loss1 : 1.975647, loss2 : 1.376132
train_step : 9412, loss1 : 1.509008, loss2 : 1.975964
train_step : 9413, loss1 : 2.265898, loss2 : 1.509071
train_step : 9414, loss1 : 1.976959, loss2 : 1.991503
train_step : 9415, loss1 : 3.589211, loss2 : 2.555412
train_step : 9416, loss1 : 3.036426, loss2 : 2.046108
train_step : 9417, loss1 : 1.391463, loss2 : 1.176506
train_step : 9418, loss1 : 1.539776, loss2 : 1.958907
train_step : 9419, loss1 : 2.192675, loss2 : 1.148188
train_step : 9420, loss1 : 1.345352, loss2 : 1.925934
train_step : 9421, loss1 : 1.335941, loss2 : 0.659104
train_step : 9422, loss1 : 1.145943, loss2 : 1.393311
train_step : 9423, loss1 : 0.893858, loss2 : 0.938997
train_step : 9424, loss1 : 0.862425, loss2 : 0.941551
train_step : 9425, loss1 : 0.969855, loss2 : 1.310409
train_step : 9426, loss1 : 0.918058, loss2 : 0.572669
train_step : 9427, loss1 : 0.611223, loss2 : 0.871899
train_step : 9428, loss1 : 1.355763, loss2 : 1.783392
train_step : 9429, loss1 : 1.498408, loss2 : 2.492682
train_step : 9430, loss1 : 2.435485, loss2 : 2.331333
train_step : 9431, loss1 : 0.976832, loss2 : 1.173420
train_step : 9432, loss1 : 1.730837, loss2 : 1.244294
train_step : 9433, loss1 : 1.115321, loss2 : 0.883420
train_step : 9434, loss1 : 0.621331, loss2 : 1.146858
train_step : 9435, loss1 : 0.924241, loss2 : 1.130916
train_step : 9436, loss1 : 1.963357, loss2 : 0.750433
train_step : 9437, loss1 : 1.121673, loss2 : 0.765351
train_step : 9438, loss1 : 0.660500, loss2 : 1.598421
train_step : 9439, loss1 : 1.261618, loss2 : 0.601145
train_step : 9440, loss1 : 1.360181, loss2 : 0.902070
train_step : 9441, loss1 : 1.344716, loss2 : 0.604035
train_step : 9442, loss1 : 1.515735, loss2 : 2.183081
train_step : 9443, loss1 : 1.281012, loss2 : 1.471820
train_step : 9444, loss1 : 0.845478, loss2 : 0.481568
train_step : 9445, loss1 : 1.697497, loss2 : 0.988240
train_step : 9446, loss1 : 1.613360, loss2 : 1.206216
train_step : 9447, loss1 : 0.532297, loss2 : 1.899899
train_step : 9448, loss1 : 0.692973, loss2 : 1.049600
train_step : 9449, loss1 : 1.241103, loss2 : 0.842411
train_step : 9450, loss1 : 1.069200, loss2 : 1.808964
train_step : 9451, loss1 : 0.748987, loss2 : 0.746847
train_step : 9452, loss1 : 0.858219, loss2 : 0.949669
train_step : 9453, loss1 : 0.873167, loss2 : 1.186152
train_step : 9454, loss1 : 1.658878, loss2 : 2.423729
train_step : 9455, loss1 : 1.419791, loss2 : 1.816038
train_step : 9456, loss1 : 0.651949, loss2 : 1.112467
train_step : 9457, loss1 : 1.511379, loss2 : 1.219294
train_step : 9458, loss1 : 1.632587, loss2 : 1.220479
train_step : 9459, loss1 : 1.502612, loss2 : 1.299736
train_step : 9460, loss1 : 1.621630, loss2 : 0.821441
train_step : 9461, loss1 : 1.092126, loss2 : 1.782294
train_step : 9462, loss1 : 2.234484, loss2 : 0.937399
train_step : 9463, loss1 : 0.514055, loss2 : 1.054055
train_step : 9464, loss1 : 1.100350, loss2 : 1.439955
train_step : 9465, loss1 : 1.382033, loss2 : 1.164649
train_step : 9466, loss1 : 1.958263, loss2 : 2.408452
train_step : 9467, loss1 : 4.293399, loss2 : 4.037634
train_step : 9468, loss1 : 3.981037, loss2 : 5.288241
train_step : 9469, loss1 : 5.757487, loss2 : 3.601401
train_step : 9470, loss1 : 2.893010, loss2 : 2.263899
train_step : 9471, loss1 : 2.673245, loss2 : 2.560984
train_step : 9472, loss1 : 2.450675, loss2 : 2.411535
train_step : 9473, loss1 : 2.235760, loss2 : 1.707269
train_step : 9474, loss1 : 1.985574, loss2 : 1.596963
train_step : 9475, loss1 : 1.221585, loss2 : 1.268192
train_step : 9476, loss1 : 1.478755, loss2 : 1.714908
train_step : 9477, loss1 : 2.487104, loss2 : 1.368898
train_step : 9478, loss1 : 1.061594, loss2 : 1.446350
train_step : 9479, loss1 : 1.369873, loss2 : 1.385875
train_step : 9480, loss1 : 1.444674, loss2 : 0.801379
train_step : 9481, loss1 : 1.304767, loss2 : 1.037450
train_step : 9482, loss1 : 1.306574, loss2 : 1.346482
train_step : 9483, loss1 : 0.794875, loss2 : 1.184613
train_step : 9484, loss1 : 0.770591, loss2 : 1.560474
train_step : 9485, loss1 : 1.224675, loss2 : 0.775558
train_step : 9486, loss1 : 1.508428, loss2 : 0.957823
train_step : 9487, loss1 : 1.339509, loss2 : 1.030596
train_step : 9488, loss1 : 0.677578, loss2 : 1.468412
train_step : 9489, loss1 : 1.729704, loss2 : 1.887888
train_step : 9490, loss1 : 1.119244, loss2 : 1.658931
train_step : 9491, loss1 : 1.187266, loss2 : 1.021347
train_step : 9492, loss1 : 0.972436, loss2 : 1.236920
train_step : 9493, loss1 : 1.120897, loss2 : 0.762412
train_step : 9494, loss1 : 1.403408, loss2 : 0.761714
train_step : 9495, loss1 : 1.815447, loss2 : 0.503639
train_step : 9496, loss1 : 0.938093, loss2 : 1.241319
train_step : 9497, loss1 : 0.711954, loss2 : 2.111066
train_step : 9498, loss1 : 0.824371, loss2 : 1.659767
train_step : 9499, loss1 : 0.933992, loss2 : 1.478420
train_step : 9500, loss1 : 0.518992, loss2 : 0.932760
train_step : 9501, loss1 : 1.637001, loss2 : 0.924065
train_step : 9502, loss1 : 1.010948, loss2 : 1.167404
train_step : 9503, loss1 : 1.475128, loss2 : 0.913556
train_step : 9504, loss1 : 1.607670, loss2 : 1.010786
train_step : 9505, loss1 : 1.060901, loss2 : 0.861505
train_step : 9506, loss1 : 1.226509, loss2 : 0.927353
train_step : 9507, loss1 : 1.159136, loss2 : 0.780860
train_step : 9508, loss1 : 0.852840, loss2 : 1.417698
train_step : 9509, loss1 : 0.864289, loss2 : 1.204908
train_step : 9510, loss1 : 0.620547, loss2 : 1.672744
train_step : 9511, loss1 : 0.842847, loss2 : 1.091056
train_step : 9512, loss1 : 0.909726, loss2 : 1.273670
train_step : 9513, loss1 : 1.180725, loss2 : 1.070997
train_step : 9514, loss1 : 0.799299, loss2 : 0.789512
train_step : 9515, loss1 : 1.323502, loss2 : 1.437495
train_step : 9516, loss1 : 1.235563, loss2 : 0.729149
train_step : 9517, loss1 : 0.824768, loss2 : 1.544887
train_step : 9518, loss1 : 1.098698, loss2 : 1.796061
train_step : 9519, loss1 : 1.468473, loss2 : 1.367162
train_step : 9520, loss1 : 1.513195, loss2 : 1.932574
train_step : 9521, loss1 : 0.962216, loss2 : 1.825074
train_step : 9522, loss1 : 1.255681, loss2 : 2.375184
train_step : 9523, loss1 : 0.787019, loss2 : 1.792307
train_step : 9524, loss1 : 1.329053, loss2 : 1.306109
train_step : 9525, loss1 : 1.499586, loss2 : 1.509569
train_step : 9526, loss1 : 0.715182, loss2 : 1.233263
train_step : 9527, loss1 : 1.474968, loss2 : 1.660628
train_step : 9528, loss1 : 0.779131, loss2 : 1.677807
train_step : 9529, loss1 : 0.763101, loss2 : 1.289691
train_step : 9530, loss1 : 1.694262, loss2 : 1.200066
train_step : 9531, loss1 : 1.054601, loss2 : 1.098852
train_step : 9532, loss1 : 1.586130, loss2 : 2.007172
train_step : 9533, loss1 : 0.915045, loss2 : 2.600470
train_step : 9534, loss1 : 2.147757, loss2 : 1.800186
train_step : 9535, loss1 : 3.136008, loss2 : 1.231888
train_step : 9536, loss1 : 2.009677, loss2 : 2.374481
train_step : 9537, loss1 : 1.304410, loss2 : 1.674977
train_step : 9538, loss1 : 1.806133, loss2 : 1.840448
train_step : 9539, loss1 : 2.300851, loss2 : 1.888772
train_step : 9540, loss1 : 1.446271, loss2 : 2.181248
train_step : 9541, loss1 : 1.394971, loss2 : 3.557782
train_step : 9542, loss1 : 2.006376, loss2 : 1.954007
train_step : 9543, loss1 : 1.767351, loss2 : 1.403502
train_step : 9544, loss1 : 2.059417, loss2 : 1.138338
train_step : 9545, loss1 : 1.636696, loss2 : 0.860955
train_step : 9546, loss1 : 0.904851, loss2 : 1.700049
train_step : 9547, loss1 : 1.212626, loss2 : 0.790221
train_step : 9548, loss1 : 0.966775, loss2 : 1.583093
train_step : 9549, loss1 : 1.620826, loss2 : 1.306454
train_step : 9550, loss1 : 1.073980, loss2 : 1.829427
train_step : 9551, loss1 : 1.276028, loss2 : 0.934109
train_step : 9552, loss1 : 1.045403, loss2 : 1.482978
train_step : 9553, loss1 : 1.467000, loss2 : 1.482930
train_step : 9554, loss1 : 0.785199, loss2 : 0.780348
train_step : 9555, loss1 : 0.780812, loss2 : 1.353909
train_step : 9556, loss1 : 1.148038, loss2 : 1.817000
train_step : 9557, loss1 : 0.758158, loss2 : 1.426147
train_step : 9558, loss1 : 0.906849, loss2 : 1.438924
train_step : 9559, loss1 : 1.759463, loss2 : 1.123828
train_step : 9560, loss1 : 1.859489, loss2 : 1.248561
train_step : 9561, loss1 : 1.775141, loss2 : 2.068520
train_step : 9562, loss1 : 1.671501, loss2 : 1.330438
train_step : 9563, loss1 : 1.453954, loss2 : 1.905989
train_step : 9564, loss1 : 1.339516, loss2 : 1.715174
train_step : 9565, loss1 : 1.705976, loss2 : 1.990641
train_step : 9566, loss1 : 3.599929, loss2 : 3.259433
train_step : 9567, loss1 : 1.815875, loss2 : 1.686906
train_step : 9568, loss1 : 1.568394, loss2 : 1.753359
train_step : 9569, loss1 : 1.559538, loss2 : 1.512949
train_step : 9570, loss1 : 1.384344, loss2 : 2.103226
train_step : 9571, loss1 : 0.868969, loss2 : 1.227137
train_step : 9572, loss1 : 1.245573, loss2 : 1.204657
train_step : 9573, loss1 : 1.140610, loss2 : 0.993705
train_step : 9574, loss1 : 1.856996, loss2 : 0.988343
train_step : 9575, loss1 : 0.716436, loss2 : 1.325368
train_step : 9576, loss1 : 1.817669, loss2 : 0.732938
train_step : 9577, loss1 : 1.164421, loss2 : 1.034192
train_step : 9578, loss1 : 0.442971, loss2 : 1.268856
train_step : 9579, loss1 : 1.242109, loss2 : 0.826207
train_step : 9580, loss1 : 1.694697, loss2 : 2.042717
train_step : 9581, loss1 : 1.150705, loss2 : 1.228802
train_step : 9582, loss1 : 1.606069, loss2 : 1.586826
train_step : 9583, loss1 : 1.672116, loss2 : 2.649051
train_step : 9584, loss1 : 1.810713, loss2 : 2.869309
train_step : 9585, loss1 : 1.786439, loss2 : 2.114623
train_step : 9586, loss1 : 0.958564, loss2 : 1.796597
train_step : 9587, loss1 : 2.090366, loss2 : 1.608023
train_step : 9588, loss1 : 2.634689, loss2 : 1.141486
train_step : 9589, loss1 : 2.931007, loss2 : 2.116333
train_step : 9590, loss1 : 1.991815, loss2 : 1.596404
train_step : 9591, loss1 : 1.838854, loss2 : 2.319774
train_step : 9592, loss1 : 1.902962, loss2 : 1.589166
train_step : 9593, loss1 : 0.997262, loss2 : 1.517966
train_step : 9594, loss1 : 0.753896, loss2 : 0.587888
train_step : 9595, loss1 : 1.508882, loss2 : 0.736902
train_step : 9596, loss1 : 1.232570, loss2 : 1.011518
train_step : 9597, loss1 : 1.284133, loss2 : 1.197812
train_step : 9598, loss1 : 0.674623, loss2 : 1.524427
train_step : 9599, loss1 : 1.202972, loss2 : 0.914022
train_step : 9600, loss1 : 2.032318, loss2 : 1.367334
train_step : 9601, loss1 : 1.084286, loss2 : 1.749887
train_step : 9602, loss1 : 1.516058, loss2 : 1.090948
train_step : 9603, loss1 : 0.750954, loss2 : 1.404009
train_step : 9604, loss1 : 0.882080, loss2 : 0.731570
train_step : 9605, loss1 : 1.072129, loss2 : 1.125737
train_step : 9606, loss1 : 1.674346, loss2 : 1.093694
train_step : 9607, loss1 : 0.958342, loss2 : 0.981563
train_step : 9608, loss1 : 0.999543, loss2 : 1.521710
train_step : 9609, loss1 : 0.661455, loss2 : 0.834256
train_step : 9610, loss1 : 0.978550, loss2 : 0.564679
train_step : 9611, loss1 : 1.510924, loss2 : 0.689705
train_step : 9612, loss1 : 0.876249, loss2 : 1.140824
train_step : 9613, loss1 : 1.048010, loss2 : 1.117176
train_step : 9614, loss1 : 1.197710, loss2 : 1.297630
train_step : 9615, loss1 : 1.198464, loss2 : 0.840071
train_step : 9616, loss1 : 1.130829, loss2 : 1.188808
train_step : 9617, loss1 : 2.283649, loss2 : 1.789904
train_step : 9618, loss1 : 3.727564, loss2 : 3.255759
train_step : 9619, loss1 : 2.518838, loss2 : 5.232188
train_step : 9620, loss1 : 2.783349, loss2 : 1.799726
train_step : 9621, loss1 : 2.635941, loss2 : 2.370204
train_step : 9622, loss1 : 1.796702, loss2 : 1.912998
train_step : 9623, loss1 : 1.397877, loss2 : 2.097212
train_step : 9624, loss1 : 1.034217, loss2 : 1.028857
train_step : 9625, loss1 : 0.687571, loss2 : 1.754378
train_step : 9626, loss1 : 1.097754, loss2 : 1.791157
train_step : 9627, loss1 : 1.037365, loss2 : 1.363902
train_step : 9628, loss1 : 1.904007, loss2 : 3.745815
train_step : 9629, loss1 : 1.157670, loss2 : 1.074749
train_step : 9630, loss1 : 0.899379, loss2 : 0.839921
train_step : 9631, loss1 : 0.847134, loss2 : 0.669376
train_step : 9632, loss1 : 1.006732, loss2 : 1.906761
train_step : 9633, loss1 : 2.789317, loss2 : 1.816103
train_step : 9634, loss1 : 1.090355, loss2 : 1.590840
train_step : 9635, loss1 : 2.481028, loss2 : 1.274079
train_step : 9636, loss1 : 2.068344, loss2 : 1.827314
train_step : 9637, loss1 : 1.981907, loss2 : 1.279198
train_step : 9638, loss1 : 1.685688, loss2 : 1.656779
train_step : 9639, loss1 : 1.616458, loss2 : 2.180990
train_step : 9640, loss1 : 0.965473, loss2 : 2.547838
train_step : 9641, loss1 : 1.599144, loss2 : 1.227598
train_step : 9642, loss1 : 0.821359, loss2 : 2.418481
train_step : 9643, loss1 : 0.921476, loss2 : 1.205002
train_step : 9644, loss1 : 1.357024, loss2 : 1.199372
train_step : 9645, loss1 : 1.881399, loss2 : 1.417317
train_step : 9646, loss1 : 1.391134, loss2 : 1.166346
train_step : 9647, loss1 : 1.159638, loss2 : 1.281164
train_step : 9648, loss1 : 1.998481, loss2 : 1.252224
train_step : 9649, loss1 : 1.667417, loss2 : 1.667687
train_step : 9650, loss1 : 2.720442, loss2 : 1.501105
train_step : 9651, loss1 : 2.892717, loss2 : 2.410229
train_step : 9652, loss1 : 3.524588, loss2 : 3.325789
train_step : 9653, loss1 : 3.505355, loss2 : 4.371334
train_step : 9654, loss1 : 2.650168, loss2 : 2.637138
train_step : 9655, loss1 : 2.247763, loss2 : 1.276994
train_step : 9656, loss1 : 0.829222, loss2 : 1.307763
train_step : 9657, loss1 : 3.019207, loss2 : 1.269663
train_step : 9658, loss1 : 1.615275, loss2 : 2.044582
train_step : 9659, loss1 : 1.745658, loss2 : 2.247832
train_step : 9660, loss1 : 2.819143, loss2 : 2.576890
train_step : 9661, loss1 : 2.565219, loss2 : 2.335058
train_step : 9662, loss1 : 2.136976, loss2 : 2.441341
train_step : 9663, loss1 : 1.842083, loss2 : 1.216834
train_step : 9664, loss1 : 1.030477, loss2 : 2.163343
train_step : 9665, loss1 : 1.460644, loss2 : 0.747175
train_step : 9666, loss1 : 0.984818, loss2 : 1.788365
train_step : 9667, loss1 : 1.305494, loss2 : 1.316373
train_step : 9668, loss1 : 1.726948, loss2 : 0.860913
train_step : 9669, loss1 : 1.683946, loss2 : 1.236362
train_step : 9670, loss1 : 0.787556, loss2 : 1.550538
train_step : 9671, loss1 : 1.540263, loss2 : 1.019395
train_step : 9672, loss1 : 1.235985, loss2 : 1.779334
train_step : 9673, loss1 : 0.911783, loss2 : 0.744194
train_step : 9674, loss1 : 0.836814, loss2 : 1.385510
train_step : 9675, loss1 : 1.260122, loss2 : 1.228701
train_step : 9676, loss1 : 0.864179, loss2 : 1.116226
train_step : 9677, loss1 : 1.104777, loss2 : 1.152080
train_step : 9678, loss1 : 1.360794, loss2 : 0.671044
train_step : 9679, loss1 : 0.754805, loss2 : 1.073277
train_step : 9680, loss1 : 1.085773, loss2 : 0.997538
train_step : 9681, loss1 : 1.550430, loss2 : 1.111589
train_step : 9682, loss1 : 1.470978, loss2 : 1.360666
train_step : 9683, loss1 : 1.344960, loss2 : 1.273928
train_step : 9684, loss1 : 0.905151, loss2 : 1.438645
train_step : 9685, loss1 : 1.232666, loss2 : 1.199502
train_step : 9686, loss1 : 0.807738, loss2 : 0.683922
train_step : 9687, loss1 : 0.710369, loss2 : 1.169876
train_step : 9688, loss1 : 1.014905, loss2 : 0.890842
train_step : 9689, loss1 : 0.802067, loss2 : 0.991367
train_step : 9690, loss1 : 1.767932, loss2 : 1.566590
train_step : 9691, loss1 : 0.886013, loss2 : 0.988159
train_step : 9692, loss1 : 1.018641, loss2 : 1.480900
train_step : 9693, loss1 : 1.660396, loss2 : 0.891784
train_step : 9694, loss1 : 0.879695, loss2 : 0.889620
train_step : 9695, loss1 : 0.878991, loss2 : 1.008537
train_step : 9696, loss1 : 0.694077, loss2 : 1.295100
train_step : 9697, loss1 : 0.909600, loss2 : 1.026193
train_step : 9698, loss1 : 0.892903, loss2 : 0.930017
train_step : 9699, loss1 : 1.036591, loss2 : 1.437964
train_step : 9700, loss1 : 1.701648, loss2 : 0.737071
train_step : 9701, loss1 : 2.593545, loss2 : 2.224815
train_step : 9702, loss1 : 2.577397, loss2 : 3.877205
train_step : 9703, loss1 : 4.075291, loss2 : 6.243425
train_step : 9704, loss1 : 6.465858, loss2 : 4.635429
train_step : 9705, loss1 : 5.978339, loss2 : 6.861219
train_step : 9706, loss1 : 4.633394, loss2 : 4.508665
train_step : 9707, loss1 : 6.471926, loss2 : 5.947864
train_step : 9708, loss1 : 3.016949, loss2 : 3.707104
train_step : 9709, loss1 : 3.123152, loss2 : 4.030687
train_step : 9710, loss1 : 3.141776, loss2 : 2.656210
train_step : 9711, loss1 : 2.530271, loss2 : 4.197388
train_step : 9712, loss1 : 4.415836, loss2 : 4.179090
train_step : 9713, loss1 : 5.412802, loss2 : 6.583072
train_step : 9714, loss1 : 3.357458, loss2 : 3.463630
train_step : 9715, loss1 : 2.996071, loss2 : 3.294603
train_step : 9716, loss1 : 4.145168, loss2 : 3.061698
train_step : 9717, loss1 : 3.812317, loss2 : 2.860817
train_step : 9718, loss1 : 2.686358, loss2 : 1.290433
train_step : 9719, loss1 : 1.040574, loss2 : 2.088378
train_step : 9720, loss1 : 0.988970, loss2 : 1.866052
train_step : 9721, loss1 : 1.665315, loss2 : 1.532649
train_step : 9722, loss1 : 1.176633, loss2 : 1.511718
train_step : 9723, loss1 : 1.262005, loss2 : 1.571174
train_step : 9724, loss1 : 1.412383, loss2 : 1.323296
train_step : 9725, loss1 : 1.345189, loss2 : 2.597060
train_step : 9726, loss1 : 1.709808, loss2 : 2.404642
train_step : 9727, loss1 : 1.070370, loss2 : 1.311722
train_step : 9728, loss1 : 1.452144, loss2 : 2.603812
train_step : 9729, loss1 : 1.407476, loss2 : 1.600036
train_step : 9730, loss1 : 1.458206, loss2 : 2.332478
train_step : 9731, loss1 : 0.625062, loss2 : 0.970191
train_step : 9732, loss1 : 1.031704, loss2 : 0.935283
train_step : 9733, loss1 : 1.654547, loss2 : 1.068503
train_step : 9734, loss1 : 1.396441, loss2 : 1.107115
train_step : 9735, loss1 : 1.052865, loss2 : 0.993972
train_step : 9736, loss1 : 0.682181, loss2 : 1.735123
train_step : 9737, loss1 : 1.786203, loss2 : 1.370031
train_step : 9738, loss1 : 1.314734, loss2 : 0.960134
train_step : 9739, loss1 : 1.101048, loss2 : 1.325931
train_step : 9740, loss1 : 0.971899, loss2 : 0.788624
train_step : 9741, loss1 : 1.101180, loss2 : 0.871578
train_step : 9742, loss1 : 1.493213, loss2 : 1.095421
train_step : 9743, loss1 : 1.219808, loss2 : 1.298048
train_step : 9744, loss1 : 2.369157, loss2 : 1.905278
train_step : 9745, loss1 : 0.909906, loss2 : 0.801621
train_step : 9746, loss1 : 0.806443, loss2 : 2.117758
train_step : 9747, loss1 : 1.388624, loss2 : 1.267948
train_step : 9748, loss1 : 0.692086, loss2 : 1.331974
train_step : 9749, loss1 : 1.269174, loss2 : 0.579880
train_step : 9750, loss1 : 1.207109, loss2 : 0.750926
train_step : 9751, loss1 : 1.421029, loss2 : 1.063431
train_step : 9752, loss1 : 1.733567, loss2 : 1.239567
train_step : 9753, loss1 : 1.441330, loss2 : 1.938053
train_step : 9754, loss1 : 1.619757, loss2 : 1.544223
train_step : 9755, loss1 : 1.346844, loss2 : 1.428342
train_step : 9756, loss1 : 0.804543, loss2 : 0.725501
train_step : 9757, loss1 : 1.414528, loss2 : 2.415009
train_step : 9758, loss1 : 1.363380, loss2 : 1.914852
train_step : 9759, loss1 : 1.773792, loss2 : 1.027439
train_step : 9760, loss1 : 1.838591, loss2 : 1.460539
train_step : 9761, loss1 : 3.300784, loss2 : 2.634430
train_step : 9762, loss1 : 3.837649, loss2 : 3.862503
train_step : 9763, loss1 : 4.572640, loss2 : 4.245256
train_step : 9764, loss1 : 2.646324, loss2 : 1.811680
train_step : 9765, loss1 : 3.250876, loss2 : 2.437322
train_step : 9766, loss1 : 2.729604, loss2 : 3.517189
train_step : 9767, loss1 : 2.840470, loss2 : 4.242181
train_step : 9768, loss1 : 1.947989, loss2 : 2.743963
train_step : 9769, loss1 : 2.876503, loss2 : 1.899630
train_step : 9770, loss1 : 2.350392, loss2 : 1.393299
train_step : 9771, loss1 : 1.560689, loss2 : 2.082740
train_step : 9772, loss1 : 1.120732, loss2 : 2.370112
train_step : 9773, loss1 : 2.111611, loss2 : 1.679784
train_step : 9774, loss1 : 0.998134, loss2 : 0.849839
train_step : 9775, loss1 : 0.805562, loss2 : 0.997158
train_step : 9776, loss1 : 1.624011, loss2 : 1.004867
train_step : 9777, loss1 : 0.919910, loss2 : 1.569783
train_step : 9778, loss1 : 0.906022, loss2 : 0.562594
train_step : 9779, loss1 : 2.383649, loss2 : 1.011225
train_step : 9780, loss1 : 1.429848, loss2 : 1.803943
train_step : 9781, loss1 : 1.277357, loss2 : 1.875431
train_step : 9782, loss1 : 0.767625, loss2 : 1.162208
train_step : 9783, loss1 : 1.339909, loss2 : 1.135328
train_step : 9784, loss1 : 1.035292, loss2 : 0.717270
train_step : 9785, loss1 : 0.954891, loss2 : 1.676887
train_step : 9786, loss1 : 1.698141, loss2 : 1.052745
train_step : 9787, loss1 : 1.910537, loss2 : 2.577141
train_step : 9788, loss1 : 3.060347, loss2 : 2.087914
train_step : 9789, loss1 : 1.439598, loss2 : 1.567723
train_step : 9790, loss1 : 1.327753, loss2 : 1.413584
train_step : 9791, loss1 : 1.261745, loss2 : 0.904037
train_step : 9792, loss1 : 1.267794, loss2 : 0.863544
train_step : 9793, loss1 : 1.565728, loss2 : 0.672718
train_step : 9794, loss1 : 1.453132, loss2 : 1.539673
train_step : 9795, loss1 : 1.234408, loss2 : 1.437949
train_step : 9796, loss1 : 1.501405, loss2 : 0.526655
train_step : 9797, loss1 : 1.069648, loss2 : 1.945869
train_step : 9798, loss1 : 0.754378, loss2 : 1.469320
train_step : 9799, loss1 : 1.004563, loss2 : 2.099837
train_step : 9800, loss1 : 0.627576, loss2 : 1.945620
train_step : 9801, loss1 : 1.814366, loss2 : 1.656682
train_step : 9802, loss1 : 1.143350, loss2 : 2.166845
train_step : 9803, loss1 : 2.149416, loss2 : 1.914013
train_step : 9804, loss1 : 1.621684, loss2 : 1.786778
train_step : 9805, loss1 : 1.556546, loss2 : 1.974927
train_step : 9806, loss1 : 1.407581, loss2 : 0.807492
train_step : 9807, loss1 : 0.797386, loss2 : 1.897206
train_step : 9808, loss1 : 1.284150, loss2 : 1.939122
train_step : 9809, loss1 : 0.636709, loss2 : 0.714692
train_step : 9810, loss1 : 1.244347, loss2 : 1.642798
train_step : 9811, loss1 : 1.736202, loss2 : 1.278840
train_step : 9812, loss1 : 1.898794, loss2 : 2.351882
train_step : 9813, loss1 : 1.147009, loss2 : 2.151617
train_step : 9814, loss1 : 1.073578, loss2 : 1.145654
train_step : 9815, loss1 : 0.979019, loss2 : 1.188354
train_step : 9816, loss1 : 1.092730, loss2 : 1.807701
train_step : 9817, loss1 : 1.752280, loss2 : 1.162658
train_step : 9818, loss1 : 1.591241, loss2 : 0.520679
train_step : 9819, loss1 : 1.654444, loss2 : 1.337575
train_step : 9820, loss1 : 1.484253, loss2 : 0.900935
train_step : 9821, loss1 : 1.278952, loss2 : 1.368112
train_step : 9822, loss1 : 1.049747, loss2 : 0.406164
train_step : 9823, loss1 : 1.726241, loss2 : 1.356591
train_step : 9824, loss1 : 1.319662, loss2 : 0.912778
train_step : 9825, loss1 : 1.114928, loss2 : 1.571446
train_step : 9826, loss1 : 1.564836, loss2 : 1.949568
train_step : 9827, loss1 : 2.138631, loss2 : 1.788754
train_step : 9828, loss1 : 4.121325, loss2 : 1.171082
train_step : 9829, loss1 : 1.472095, loss2 : 1.238895
train_step : 9830, loss1 : 1.655744, loss2 : 0.931994
train_step : 9831, loss1 : 1.450949, loss2 : 0.837090
train_step : 9832, loss1 : 0.939426, loss2 : 1.020637
train_step : 9833, loss1 : 1.120368, loss2 : 1.152682
train_step : 9834, loss1 : 1.293601, loss2 : 2.320480
train_step : 9835, loss1 : 1.123427, loss2 : 1.614055
train_step : 9836, loss1 : 1.271362, loss2 : 1.605176
train_step : 9837, loss1 : 1.176788, loss2 : 1.537778
train_step : 9838, loss1 : 2.449818, loss2 : 1.008707
train_step : 9839, loss1 : 0.689260, loss2 : 0.811254
train_step : 9840, loss1 : 0.953929, loss2 : 1.278041
train_step : 9841, loss1 : 0.993488, loss2 : 0.932903
train_step : 9842, loss1 : 1.568314, loss2 : 0.815685
train_step : 9843, loss1 : 1.514281, loss2 : 1.882041
train_step : 9844, loss1 : 2.248536, loss2 : 1.238228
train_step : 9845, loss1 : 2.521481, loss2 : 1.969848
train_step : 9846, loss1 : 3.078448, loss2 : 1.735380
train_step : 9847, loss1 : 2.335783, loss2 : 1.934421
train_step : 9848, loss1 : 1.539932, loss2 : 1.526257
train_step : 9849, loss1 : 1.897399, loss2 : 0.983897
train_step : 9850, loss1 : 0.895079, loss2 : 1.876561
train_step : 9851, loss1 : 0.872587, loss2 : 1.445624
train_step : 9852, loss1 : 0.936274, loss2 : 1.376634
train_step : 9853, loss1 : 0.933274, loss2 : 0.782372
train_step : 9854, loss1 : 1.374653, loss2 : 0.733670
train_step : 9855, loss1 : 1.104419, loss2 : 1.367112
train_step : 9856, loss1 : 1.173814, loss2 : 0.917933
train_step : 9857, loss1 : 1.263832, loss2 : 1.331966
train_step : 9858, loss1 : 1.434594, loss2 : 1.394922
train_step : 9859, loss1 : 1.679000, loss2 : 0.626414
train_step : 9860, loss1 : 0.904668, loss2 : 2.183239
train_step : 9861, loss1 : 0.972198, loss2 : 1.380252
train_step : 9862, loss1 : 1.294752, loss2 : 2.254652
train_step : 9863, loss1 : 0.825613, loss2 : 0.884473
train_step : 9864, loss1 : 1.451763, loss2 : 1.222473
train_step : 9865, loss1 : 1.530583, loss2 : 1.080724
train_step : 9866, loss1 : 2.146730, loss2 : 1.654181
train_step : 9867, loss1 : 1.026417, loss2 : 2.270143
train_step : 9868, loss1 : 0.799886, loss2 : 1.146845
train_step : 9869, loss1 : 0.907422, loss2 : 0.778597
train_step : 9870, loss1 : 0.591694, loss2 : 1.249961
train_step : 9871, loss1 : 0.998804, loss2 : 0.952201
train_step : 9872, loss1 : 0.934116, loss2 : 1.266563
train_step : 9873, loss1 : 1.359286, loss2 : 1.149709
train_step : 9874, loss1 : 1.009708, loss2 : 1.042180
train_step : 9875, loss1 : 1.127562, loss2 : 1.145876
train_step : 9876, loss1 : 1.067177, loss2 : 1.484676
train_step : 9877, loss1 : 1.291286, loss2 : 0.983030
train_step : 9878, loss1 : 0.741533, loss2 : 0.584418
train_step : 9879, loss1 : 1.113388, loss2 : 1.376944
train_step : 9880, loss1 : 1.540136, loss2 : 1.730869
train_step : 9881, loss1 : 1.342552, loss2 : 0.739714
train_step : 9882, loss1 : 1.337958, loss2 : 1.987460
train_step : 9883, loss1 : 2.733138, loss2 : 2.572118
train_step : 9884, loss1 : 1.485202, loss2 : 1.465203
train_step : 9885, loss1 : 1.062011, loss2 : 0.721952
train_step : 9886, loss1 : 1.113878, loss2 : 1.666222
train_step : 9887, loss1 : 2.277777, loss2 : 0.587341
train_step : 9888, loss1 : 1.142853, loss2 : 1.244837
train_step : 9889, loss1 : 0.636896, loss2 : 1.074839
train_step : 9890, loss1 : 1.188538, loss2 : 1.340726
train_step : 9891, loss1 : 1.186640, loss2 : 0.363171
train_step : 9892, loss1 : 1.236716, loss2 : 1.387027
train_step : 9893, loss1 : 1.480517, loss2 : 0.957037
train_step : 9894, loss1 : 1.314795, loss2 : 1.831398
train_step : 9895, loss1 : 1.279163, loss2 : 0.790881
train_step : 9896, loss1 : 0.649709, loss2 : 0.946026
train_step : 9897, loss1 : 1.327960, loss2 : 0.531163
train_step : 9898, loss1 : 1.118570, loss2 : 1.507581
train_step : 9899, loss1 : 0.998535, loss2 : 1.077886
train_step : 9900, loss1 : 1.148341, loss2 : 1.119302
train_step : 9901, loss1 : 0.634048, loss2 : 1.451996
train_step : 9902, loss1 : 0.743351, loss2 : 1.564441
train_step : 9903, loss1 : 1.134321, loss2 : 0.777607
train_step : 9904, loss1 : 1.455004, loss2 : 1.181251
train_step : 9905, loss1 : 1.714595, loss2 : 1.164874
train_step : 9906, loss1 : 1.102109, loss2 : 0.774044
train_step : 9907, loss1 : 1.882380, loss2 : 1.938430
train_step : 9908, loss1 : 1.136524, loss2 : 1.596305
train_step : 9909, loss1 : 1.300895, loss2 : 1.106670
train_step : 9910, loss1 : 0.636524, loss2 : 1.139505
train_step : 9911, loss1 : 0.951921, loss2 : 0.855298
train_step : 9912, loss1 : 1.038898, loss2 : 0.977868
train_step : 9913, loss1 : 1.391438, loss2 : 0.701723
train_step : 9914, loss1 : 0.737927, loss2 : 0.669319
train_step : 9915, loss1 : 0.952364, loss2 : 1.326609
train_step : 9916, loss1 : 1.678917, loss2 : 1.406929
train_step : 9917, loss1 : 1.112768, loss2 : 1.187029
train_step : 9918, loss1 : 1.624535, loss2 : 0.829818
train_step : 9919, loss1 : 0.791683, loss2 : 1.129262
train_step : 9920, loss1 : 1.335667, loss2 : 0.979588
train_step : 9921, loss1 : 0.765553, loss2 : 1.123641
train_step : 9922, loss1 : 1.199766, loss2 : 1.215675
train_step : 9923, loss1 : 1.871896, loss2 : 1.168092
train_step : 9924, loss1 : 1.436508, loss2 : 0.882098
train_step : 9925, loss1 : 1.114507, loss2 : 2.431026
train_step : 9926, loss1 : 1.021803, loss2 : 0.826205
train_step : 9927, loss1 : 1.124228, loss2 : 1.119347
train_step : 9928, loss1 : 1.160753, loss2 : 1.355379
train_step : 9929, loss1 : 2.327409, loss2 : 1.382031
train_step : 9930, loss1 : 3.030888, loss2 : 2.042494
train_step : 9931, loss1 : 2.657674, loss2 : 2.661152
train_step : 9932, loss1 : 3.825284, loss2 : 2.933879
train_step : 9933, loss1 : 1.006047, loss2 : 1.276180
train_step : 9934, loss1 : 0.775210, loss2 : 0.522983
train_step : 9935, loss1 : 0.959239, loss2 : 0.708764
train_step : 9936, loss1 : 0.699957, loss2 : 1.078911
train_step : 9937, loss1 : 2.847425, loss2 : 0.649982
train_step : 9938, loss1 : 1.212979, loss2 : 0.563317
train_step : 9939, loss1 : 1.012919, loss2 : 1.582320
train_step : 9940, loss1 : 1.205500, loss2 : 1.739890
train_step : 9941, loss1 : 0.880316, loss2 : 0.907559
train_step : 9942, loss1 : 1.583077, loss2 : 1.707308
train_step : 9943, loss1 : 1.086304, loss2 : 1.083446
train_step : 9944, loss1 : 0.595241, loss2 : 1.017849
train_step : 9945, loss1 : 3.018643, loss2 : 1.183200
train_step : 9946, loss1 : 0.903178, loss2 : 0.747196
train_step : 9947, loss1 : 1.165691, loss2 : 1.260818
train_step : 9948, loss1 : 0.617105, loss2 : 1.118135
train_step : 9949, loss1 : 1.172561, loss2 : 0.939224
train_step : 9950, loss1 : 1.139499, loss2 : 1.842575
train_step : 9951, loss1 : 1.184326, loss2 : 1.570230
train_step : 9952, loss1 : 3.703066, loss2 : 1.051461
train_step : 9953, loss1 : 2.169864, loss2 : 2.071669
train_step : 9954, loss1 : 1.768368, loss2 : 2.257787
train_step : 9955, loss1 : 2.587764, loss2 : 1.797231
train_step : 9956, loss1 : 3.045122, loss2 : 1.930628
train_step : 9957, loss1 : 0.911588, loss2 : 0.907299
train_step : 9958, loss1 : 0.985279, loss2 : 0.914764
train_step : 9959, loss1 : 0.894970, loss2 : 1.021278
train_step : 9960, loss1 : 1.295041, loss2 : 1.063572
train_step : 9961, loss1 : 0.506425, loss2 : 1.080202
train_step : 9962, loss1 : 1.158460, loss2 : 1.376978
train_step : 9963, loss1 : 1.526577, loss2 : 1.063675
train_step : 9964, loss1 : 0.446411, loss2 : 0.947680
train_step : 9965, loss1 : 0.659527, loss2 : 0.973494
train_step : 9966, loss1 : 1.247803, loss2 : 2.201071
train_step : 9967, loss1 : 1.621243, loss2 : 1.626860
train_step : 9968, loss1 : 1.999099, loss2 : 2.111006
train_step : 9969, loss1 : 1.456346, loss2 : 1.901728
train_step : 9970, loss1 : 2.883219, loss2 : 2.027874
train_step : 9971, loss1 : 2.602796, loss2 : 2.738073
train_step : 9972, loss1 : 2.009429, loss2 : 1.784575
train_step : 9973, loss1 : 4.212444, loss2 : 2.027660
train_step : 9974, loss1 : 1.574977, loss2 : 2.044485
train_step : 9975, loss1 : 3.689218, loss2 : 3.252541
train_step : 9976, loss1 : 3.693873, loss2 : 4.241099
train_step : 9977, loss1 : 4.096256, loss2 : 5.925048
train_step : 9978, loss1 : 3.869021, loss2 : 4.652713
train_step : 9979, loss1 : 3.813018, loss2 : 3.199586
train_step : 9980, loss1 : 2.233441, loss2 : 1.559792
train_step : 9981, loss1 : 1.765945, loss2 : 2.179859
train_step : 9982, loss1 : 1.095296, loss2 : 1.103651
train_step : 9983, loss1 : 1.039575, loss2 : 1.464053
train_step : 9984, loss1 : 1.241384, loss2 : 0.943382
train_step : 9985, loss1 : 1.044174, loss2 : 0.848253
train_step : 9986, loss1 : 1.761590, loss2 : 1.463579
train_step : 9987, loss1 : 1.689035, loss2 : 2.364738
train_step : 9988, loss1 : 1.270022, loss2 : 1.839641
train_step : 9989, loss1 : 3.172895, loss2 : 1.744698
train_step : 9990, loss1 : 1.399361, loss2 : 1.040219
train_step : 9991, loss1 : 1.101122, loss2 : 1.330036
train_step : 9992, loss1 : 1.690597, loss2 : 1.533147
train_step : 9993, loss1 : 1.893394, loss2 : 1.768849
train_step : 9994, loss1 : 0.683980, loss2 : 1.142710
train_step : 9995, loss1 : 0.712118, loss2 : 0.696769
train_step : 9996, loss1 : 1.789672, loss2 : 1.209199
train_step : 9997, loss1 : 0.993804, loss2 : 0.928894
train_step : 9998, loss1 : 0.755896, loss2 : 1.614353
train_step : 9999, loss1 : 1.029429, loss2 : 1.369255
train_step : 10000, loss1 : 0.820687, loss2 : 1.403604
train_step : 10001, loss1 : 1.599886, loss2 : 1.469678
train_step : 10002, loss1 : 0.992213, loss2 : 1.384101
train_step : 10003, loss1 : 0.708404, loss2 : 1.172362
train_step : 10004, loss1 : 0.982036, loss2 : 1.538185
train_step : 10005, loss1 : 1.483580, loss2 : 1.902307
train_step : 10006, loss1 : 1.800469, loss2 : 1.782971
train_step : 10007, loss1 : 1.991692, loss2 : 1.336313
train_step : 10008, loss1 : 2.090037, loss2 : 1.166713
train_step : 10009, loss1 : 1.082253, loss2 : 0.852658
train_step : 10010, loss1 : 1.060497, loss2 : 1.178269
train_step : 10011, loss1 : 1.767624, loss2 : 1.670016
train_step : 10012, loss1 : 1.929200, loss2 : 2.113275
train_step : 10013, loss1 : 2.166165, loss2 : 2.792976
train_step : 10014, loss1 : 2.501613, loss2 : 2.004735
train_step : 10015, loss1 : 2.222992, loss2 : 1.930417
train_step : 10016, loss1 : 2.075085, loss2 : 1.619350
train_step : 10017, loss1 : 1.601346, loss2 : 0.902375
train_step : 10018, loss1 : 1.893456, loss2 : 1.600585
train_step : 10019, loss1 : 1.192655, loss2 : 0.741817
train_step : 10020, loss1 : 0.847484, loss2 : 0.824645
train_step : 10021, loss1 : 1.776668, loss2 : 1.229375
train_step : 10022, loss1 : 4.282682, loss2 : 1.074314
train_step : 10023, loss1 : 1.994417, loss2 : 1.367311
train_step : 10024, loss1 : 1.275003, loss2 : 1.584314
train_step : 10025, loss1 : 2.523394, loss2 : 1.001636
train_step : 10026, loss1 : 1.437845, loss2 : 1.544252
train_step : 10027, loss1 : 0.797174, loss2 : 1.406731
train_step : 10028, loss1 : 1.465570, loss2 : 1.335266
train_step : 10029, loss1 : 1.292855, loss2 : 1.200184
train_step : 10030, loss1 : 0.908492, loss2 : 1.214602
train_step : 10031, loss1 : 0.959713, loss2 : 1.139259
train_step : 10032, loss1 : 1.245993, loss2 : 1.180537
train_step : 10033, loss1 : 0.912300, loss2 : 1.064868
train_step : 10034, loss1 : 1.426120, loss2 : 1.231462
train_step : 10035, loss1 : 1.363534, loss2 : 1.317666
train_step : 10036, loss1 : 1.236310, loss2 : 1.226412
train_step : 10037, loss1 : 1.513380, loss2 : 1.256258
train_step : 10038, loss1 : 0.824328, loss2 : 1.043496
train_step : 10039, loss1 : 1.459529, loss2 : 0.390729
train_step : 10040, loss1 : 0.976668, loss2 : 1.906689
train_step : 10041, loss1 : 0.940934, loss2 : 1.264581
train_step : 10042, loss1 : 0.903590, loss2 : 1.053998
train_step : 10043, loss1 : 0.909236, loss2 : 1.513484
train_step : 10044, loss1 : 2.073808, loss2 : 3.048626
train_step : 10045, loss1 : 1.576615, loss2 : 1.301699
train_step : 10046, loss1 : 1.851339, loss2 : 1.141334
train_step : 10047, loss1 : 0.936896, loss2 : 0.949005
train_step : 10048, loss1 : 0.797305, loss2 : 1.460745
train_step : 10049, loss1 : 2.465466, loss2 : 2.810956
train_step : 10050, loss1 : 1.930966, loss2 : 1.296367
train_step : 10051, loss1 : 1.998356, loss2 : 0.826696
train_step : 10052, loss1 : 2.394786, loss2 : 2.411096
train_step : 10053, loss1 : 1.341999, loss2 : 2.621052
train_step : 10054, loss1 : 0.819147, loss2 : 1.177135
train_step : 10055, loss1 : 1.263945, loss2 : 1.371789
train_step : 10056, loss1 : 1.881326, loss2 : 1.296779
train_step : 10057, loss1 : 2.430807, loss2 : 1.110837
train_step : 10058, loss1 : 0.441883, loss2 : 0.955025
train_step : 10059, loss1 : 0.875721, loss2 : 1.181029
train_step : 10060, loss1 : 1.711707, loss2 : 1.449297
train_step : 10061, loss1 : 0.619499, loss2 : 1.936424
train_step : 10062, loss1 : 1.658017, loss2 : 1.705290
train_step : 10063, loss1 : 1.466455, loss2 : 0.967576
train_step : 10064, loss1 : 1.219921, loss2 : 1.144520
train_step : 10065, loss1 : 1.297990, loss2 : 1.432645
train_step : 10066, loss1 : 1.115787, loss2 : 2.150979
train_step : 10067, loss1 : 1.829934, loss2 : 2.083792
train_step : 10068, loss1 : 2.490713, loss2 : 1.973943
train_step : 10069, loss1 : 2.020912, loss2 : 2.312553
train_step : 10070, loss1 : 3.119106, loss2 : 1.687393
train_step : 10071, loss1 : 1.831421, loss2 : 2.382948
train_step : 10072, loss1 : 1.094114, loss2 : 1.099591
train_step : 10073, loss1 : 0.621440, loss2 : 1.025967
train_step : 10074, loss1 : 1.173518, loss2 : 1.307821
train_step : 10075, loss1 : 1.220479, loss2 : 0.968584
train_step : 10076, loss1 : 1.428439, loss2 : 1.282559
train_step : 10077, loss1 : 2.535439, loss2 : 1.284951
train_step : 10078, loss1 : 1.136792, loss2 : 2.165714
train_step : 10079, loss1 : 1.554147, loss2 : 1.195924
train_step : 10080, loss1 : 1.603911, loss2 : 0.850102
train_step : 10081, loss1 : 1.401792, loss2 : 0.803848
train_step : 10082, loss1 : 0.888688, loss2 : 1.357148
train_step : 10083, loss1 : 1.444921, loss2 : 1.436237
train_step : 10084, loss1 : 1.054654, loss2 : 1.433135
train_step : 10085, loss1 : 1.106671, loss2 : 1.071004
train_step : 10086, loss1 : 0.986421, loss2 : 1.232120
train_step : 10087, loss1 : 1.276119, loss2 : 0.811175
train_step : 10088, loss1 : 1.920530, loss2 : 1.201788
train_step : 10089, loss1 : 2.141279, loss2 : 2.225823
train_step : 10090, loss1 : 1.400506, loss2 : 0.892579
train_step : 10091, loss1 : 1.297356, loss2 : 1.475062
train_step : 10092, loss1 : 1.174968, loss2 : 1.141738
train_step : 10093, loss1 : 1.156897, loss2 : 1.151405
train_step : 10094, loss1 : 1.987343, loss2 : 1.087116
train_step : 10095, loss1 : 2.414376, loss2 : 0.928713
train_step : 10096, loss1 : 1.307418, loss2 : 1.913287
train_step : 10097, loss1 : 0.883816, loss2 : 0.980145
train_step : 10098, loss1 : 0.501242, loss2 : 1.643800
train_step : 10099, loss1 : 0.974155, loss2 : 1.621534
train_step : 10100, loss1 : 2.661453, loss2 : 3.196766
train_step : 10101, loss1 : 2.921534, loss2 : 1.938834
train_step : 10102, loss1 : 1.178615, loss2 : 3.881235
train_step : 10103, loss1 : 3.736942, loss2 : 3.642346
train_step : 10104, loss1 : 3.875776, loss2 : 3.825677
train_step : 10105, loss1 : 5.311066, loss2 : 6.061774
train_step : 10106, loss1 : 5.175281, loss2 : 3.449851
train_step : 10107, loss1 : 6.121667, loss2 : 4.009658
train_step : 10108, loss1 : 2.360442, loss2 : 4.247125
train_step : 10109, loss1 : 3.015009, loss2 : 4.330923
train_step : 10110, loss1 : 1.816034, loss2 : 2.306772
train_step : 10111, loss1 : 1.833731, loss2 : 1.808572
train_step : 10112, loss1 : 2.086359, loss2 : 1.400797
train_step : 10113, loss1 : 0.713837, loss2 : 0.946910
train_step : 10114, loss1 : 0.884202, loss2 : 0.637969
train_step : 10115, loss1 : 1.091382, loss2 : 1.195198
train_step : 10116, loss1 : 1.585134, loss2 : 1.477558
train_step : 10117, loss1 : 1.352008, loss2 : 1.709723
train_step : 10118, loss1 : 2.403973, loss2 : 1.852469
train_step : 10119, loss1 : 1.351386, loss2 : 2.009910
train_step : 10120, loss1 : 1.832634, loss2 : 1.735741
train_step : 10121, loss1 : 1.780559, loss2 : 1.923550
train_step : 10122, loss1 : 1.820235, loss2 : 1.262331
train_step : 10123, loss1 : 2.118086, loss2 : 1.159517
train_step : 10124, loss1 : 1.316279, loss2 : 1.189307
train_step : 10125, loss1 : 1.273426, loss2 : 1.366950
train_step : 10126, loss1 : 1.104241, loss2 : 1.237181
train_step : 10127, loss1 : 1.886433, loss2 : 0.763405
train_step : 10128, loss1 : 1.063925, loss2 : 1.255120
train_step : 10129, loss1 : 1.371015, loss2 : 0.933229
train_step : 10130, loss1 : 1.091911, loss2 : 1.247089
train_step : 10131, loss1 : 3.623009, loss2 : 1.180977
train_step : 10132, loss1 : 1.475296, loss2 : 1.163613
train_step : 10133, loss1 : 1.220057, loss2 : 0.831571
train_step : 10134, loss1 : 1.037476, loss2 : 1.530989
train_step : 10135, loss1 : 1.312214, loss2 : 1.607584
train_step : 10136, loss1 : 0.938524, loss2 : 1.689878
train_step : 10137, loss1 : 1.625829, loss2 : 0.954329
train_step : 10138, loss1 : 1.269108, loss2 : 1.743452
train_step : 10139, loss1 : 2.076011, loss2 : 2.495539
train_step : 10140, loss1 : 1.862977, loss2 : 1.545595
train_step : 10141, loss1 : 0.762783, loss2 : 1.488825
train_step : 10142, loss1 : 1.652223, loss2 : 1.434024
train_step : 10143, loss1 : 0.986348, loss2 : 0.936905
train_step : 10144, loss1 : 1.121029, loss2 : 1.773156
train_step : 10145, loss1 : 1.019968, loss2 : 2.624115
train_step : 10146, loss1 : 2.682626, loss2 : 2.906015
train_step : 10147, loss1 : 1.142322, loss2 : 1.312673
train_step : 10148, loss1 : 1.541730, loss2 : 1.564032
train_step : 10149, loss1 : 1.674518, loss2 : 1.821979
train_step : 10150, loss1 : 1.452387, loss2 : 1.381599
train_step : 10151, loss1 : 1.938923, loss2 : 2.014220
train_step : 10152, loss1 : 1.544420, loss2 : 1.415814
train_step : 10153, loss1 : 2.478006, loss2 : 0.908904
train_step : 10154, loss1 : 2.713305, loss2 : 1.925728
train_step : 10155, loss1 : 1.930446, loss2 : 1.952876
train_step : 10156, loss1 : 1.835090, loss2 : 1.624761
train_step : 10157, loss1 : 1.947947, loss2 : 1.379836
train_step : 10158, loss1 : 1.390832, loss2 : 2.042023
train_step : 10159, loss1 : 1.244240, loss2 : 2.103042
train_step : 10160, loss1 : 0.966372, loss2 : 1.744637
train_step : 10161, loss1 : 1.373154, loss2 : 1.356257
train_step : 10162, loss1 : 0.801754, loss2 : 1.053270
train_step : 10163, loss1 : 0.842251, loss2 : 1.493621
train_step : 10164, loss1 : 0.904234, loss2 : 1.582594
train_step : 10165, loss1 : 1.466820, loss2 : 1.587242
train_step : 10166, loss1 : 0.680777, loss2 : 1.179478
train_step : 10167, loss1 : 1.245666, loss2 : 1.050682
train_step : 10168, loss1 : 1.403471, loss2 : 1.428969
train_step : 10169, loss1 : 0.933483, loss2 : 2.078380
train_step : 10170, loss1 : 1.200391, loss2 : 0.837206
train_step : 10171, loss1 : 1.424826, loss2 : 2.622830
train_step : 10172, loss1 : 1.936691, loss2 : 1.923517
train_step : 10173, loss1 : 1.571012, loss2 : 2.272154
train_step : 10174, loss1 : 1.732870, loss2 : 2.164007
train_step : 10175, loss1 : 1.229321, loss2 : 1.370617
train_step : 10176, loss1 : 1.825106, loss2 : 1.467158
train_step : 10177, loss1 : 1.565524, loss2 : 1.957825
train_step : 10178, loss1 : 2.931338, loss2 : 3.017752
train_step : 10179, loss1 : 2.619667, loss2 : 2.184806
train_step : 10180, loss1 : 2.843894, loss2 : 1.753026
train_step : 10181, loss1 : 0.752781, loss2 : 1.696220
train_step : 10182, loss1 : 1.828387, loss2 : 1.456621
train_step : 10183, loss1 : 1.194792, loss2 : 2.102326
train_step : 10184, loss1 : 2.704320, loss2 : 1.301102
train_step : 10185, loss1 : 2.549140, loss2 : 3.060118
train_step : 10186, loss1 : 3.788108, loss2 : 2.292309
train_step : 10187, loss1 : 2.484068, loss2 : 1.595921
train_step : 10188, loss1 : 2.871894, loss2 : 2.210995
train_step : 10189, loss1 : 3.581846, loss2 : 2.863055
train_step : 10190, loss1 : 3.602256, loss2 : 3.303775
train_step : 10191, loss1 : 2.545774, loss2 : 2.470935
train_step : 10192, loss1 : 2.811017, loss2 : 3.507017
train_step : 10193, loss1 : 1.963897, loss2 : 2.339296
train_step : 10194, loss1 : 1.947044, loss2 : 1.674193
train_step : 10195, loss1 : 0.955079, loss2 : 3.036435
train_step : 10196, loss1 : 2.288396, loss2 : 2.519488
train_step : 10197, loss1 : 1.760426, loss2 : 2.250904
train_step : 10198, loss1 : 1.567230, loss2 : 1.048513
train_step : 10199, loss1 : 1.380767, loss2 : 0.929293
train_step : 10200, loss1 : 1.401589, loss2 : 1.229911
train_step : 10201, loss1 : 0.598040, loss2 : 0.820281
train_step : 10202, loss1 : 1.427340, loss2 : 1.014600
train_step : 10203, loss1 : 0.954320, loss2 : 1.276921
train_step : 10204, loss1 : 1.325652, loss2 : 1.098439
train_step : 10205, loss1 : 1.147381, loss2 : 1.504796
train_step : 10206, loss1 : 1.113613, loss2 : 1.013244
train_step : 10207, loss1 : 1.765525, loss2 : 0.883392
train_step : 10208, loss1 : 0.859637, loss2 : 1.155738
train_step : 10209, loss1 : 1.088750, loss2 : 1.543530
train_step : 10210, loss1 : 0.707899, loss2 : 0.875997
train_step : 10211, loss1 : 1.102201, loss2 : 1.486735
train_step : 10212, loss1 : 0.922689, loss2 : 1.632067
train_step : 10213, loss1 : 1.217194, loss2 : 1.232682
train_step : 10214, loss1 : 1.448762, loss2 : 1.382045
train_step : 10215, loss1 : 1.542953, loss2 : 0.886654
train_step : 10216, loss1 : 1.047344, loss2 : 1.744579
train_step : 10217, loss1 : 1.854524, loss2 : 1.317050
train_step : 10218, loss1 : 2.400072, loss2 : 1.673319
train_step : 10219, loss1 : 1.518804, loss2 : 1.392008
train_step : 10220, loss1 : 1.090450, loss2 : 1.743678
train_step : 10221, loss1 : 0.920969, loss2 : 0.701290
train_step : 10222, loss1 : 1.209583, loss2 : 1.121872
train_step : 10223, loss1 : 0.628177, loss2 : 0.957254
train_step : 10224, loss1 : 0.700351, loss2 : 0.984656
train_step : 10225, loss1 : 1.761029, loss2 : 1.534090
train_step : 10226, loss1 : 1.455683, loss2 : 1.216269
train_step : 10227, loss1 : 1.354376, loss2 : 0.764419
train_step : 10228, loss1 : 1.689652, loss2 : 2.007771
train_step : 10229, loss1 : 1.656451, loss2 : 1.956945
train_step : 10230, loss1 : 2.174944, loss2 : 1.106479
train_step : 10231, loss1 : 1.452938, loss2 : 0.858363
train_step : 10232, loss1 : 0.866941, loss2 : 1.119741
train_step : 10233, loss1 : 1.015591, loss2 : 0.895722
train_step : 10234, loss1 : 1.268637, loss2 : 2.166917
train_step : 10235, loss1 : 1.106304, loss2 : 2.266739
train_step : 10236, loss1 : 1.295102, loss2 : 0.691232
train_step : 10237, loss1 : 1.108649, loss2 : 1.628035
train_step : 10238, loss1 : 1.023863, loss2 : 1.460482
train_step : 10239, loss1 : 2.086161, loss2 : 1.311441
train_step : 10240, loss1 : 1.650831, loss2 : 1.353059
train_step : 10241, loss1 : 1.162413, loss2 : 1.957078
train_step : 10242, loss1 : 1.121553, loss2 : 0.964101
train_step : 10243, loss1 : 1.453669, loss2 : 0.844103
train_step : 10244, loss1 : 0.899430, loss2 : 1.133779
train_step : 10245, loss1 : 1.472880, loss2 : 1.153619
train_step : 10246, loss1 : 1.382693, loss2 : 1.547611
train_step : 10247, loss1 : 1.438067, loss2 : 1.607641
train_step : 10248, loss1 : 1.518593, loss2 : 1.625482
train_step : 10249, loss1 : 1.543392, loss2 : 1.575332
train_step : 10250, loss1 : 2.089269, loss2 : 2.123962
train_step : 10251, loss1 : 2.068457, loss2 : 1.726884
train_step : 10252, loss1 : 2.502145, loss2 : 2.208191
train_step : 10253, loss1 : 1.816596, loss2 : 2.722248
train_step : 10254, loss1 : 1.248934, loss2 : 1.942877
train_step : 10255, loss1 : 1.191587, loss2 : 1.773643
train_step : 10256, loss1 : 1.525663, loss2 : 1.858402
train_step : 10257, loss1 : 2.527519, loss2 : 1.247206
train_step : 10258, loss1 : 0.815178, loss2 : 2.143228
train_step : 10259, loss1 : 2.585307, loss2 : 1.431895
train_step : 10260, loss1 : 2.540866, loss2 : 1.437215
train_step : 10261, loss1 : 1.900207, loss2 : 2.506521
train_step : 10262, loss1 : 1.400794, loss2 : 1.124081
train_step : 10263, loss1 : 1.528512, loss2 : 1.888893
train_step : 10264, loss1 : 0.753630, loss2 : 0.968240
train_step : 10265, loss1 : 2.093114, loss2 : 0.714599
train_step : 10266, loss1 : 1.954178, loss2 : 1.559377
train_step : 10267, loss1 : 0.762841, loss2 : 1.715396
train_step : 10268, loss1 : 1.113664, loss2 : 1.198628
train_step : 10269, loss1 : 2.529754, loss2 : 0.592716
train_step : 10270, loss1 : 1.000485, loss2 : 0.972039
train_step : 10271, loss1 : 0.908260, loss2 : 1.189613
train_step : 10272, loss1 : 0.700110, loss2 : 0.638590
train_step : 10273, loss1 : 1.043581, loss2 : 0.702142
train_step : 10274, loss1 : 0.490173, loss2 : 1.105699
train_step : 10275, loss1 : 1.071329, loss2 : 1.245286
train_step : 10276, loss1 : 1.254786, loss2 : 1.631714
train_step : 10277, loss1 : 1.897682, loss2 : 1.244247
train_step : 10278, loss1 : 1.223369, loss2 : 0.792917
train_step : 10279, loss1 : 1.116481, loss2 : 1.109620
train_step : 10280, loss1 : 0.828795, loss2 : 1.658674
train_step : 10281, loss1 : 1.054436, loss2 : 1.685969
train_step : 10282, loss1 : 1.599648, loss2 : 0.767206
train_step : 10283, loss1 : 1.329172, loss2 : 1.096875
train_step : 10284, loss1 : 1.444182, loss2 : 1.527617
train_step : 10285, loss1 : 2.333230, loss2 : 1.666349
train_step : 10286, loss1 : 1.950718, loss2 : 1.872789
train_step : 10287, loss1 : 1.636614, loss2 : 1.501690
train_step : 10288, loss1 : 1.703769, loss2 : 0.698225
train_step : 10289, loss1 : 1.856565, loss2 : 2.669672
train_step : 10290, loss1 : 1.010438, loss2 : 1.137835
train_step : 10291, loss1 : 0.960986, loss2 : 1.484423
train_step : 10292, loss1 : 0.945812, loss2 : 1.812550
train_step : 10293, loss1 : 1.451144, loss2 : 2.158200
train_step : 10294, loss1 : 1.177217, loss2 : 1.756524
train_step : 10295, loss1 : 1.425607, loss2 : 1.725397
train_step : 10296, loss1 : 1.215378, loss2 : 0.904121
train_step : 10297, loss1 : 1.752262, loss2 : 0.998714
train_step : 10298, loss1 : 1.218107, loss2 : 1.372087
train_step : 10299, loss1 : 1.372283, loss2 : 1.195419
train_step : 10300, loss1 : 0.632985, loss2 : 1.673270
train_step : 10301, loss1 : 1.000973, loss2 : 1.354324
train_step : 10302, loss1 : 0.910601, loss2 : 1.033649
train_step : 10303, loss1 : 1.531165, loss2 : 0.839936
train_step : 10304, loss1 : 0.787877, loss2 : 1.416354
train_step : 10305, loss1 : 1.088032, loss2 : 0.879867
train_step : 10306, loss1 : 1.360893, loss2 : 1.473981
train_step : 10307, loss1 : 1.284886, loss2 : 1.139180
train_step : 10308, loss1 : 1.565769, loss2 : 1.265477
train_step : 10309, loss1 : 1.202776, loss2 : 1.133627
train_step : 10310, loss1 : 1.064163, loss2 : 1.692388
train_step : 10311, loss1 : 2.282196, loss2 : 1.191018
train_step : 10312, loss1 : 1.329436, loss2 : 1.458617
train_step : 10313, loss1 : 0.646699, loss2 : 1.205961
train_step : 10314, loss1 : 2.123733, loss2 : 1.215102
train_step : 10315, loss1 : 1.675348, loss2 : 0.500052
train_step : 10316, loss1 : 1.720770, loss2 : 2.330804
train_step : 10317, loss1 : 1.731337, loss2 : 1.411255
train_step : 10318, loss1 : 1.188490, loss2 : 0.724703
train_step : 10319, loss1 : 0.766128, loss2 : 0.814938
train_step : 10320, loss1 : 1.001046, loss2 : 0.942262
train_step : 10321, loss1 : 1.662326, loss2 : 1.306911
train_step : 10322, loss1 : 1.390219, loss2 : 1.591455
train_step : 10323, loss1 : 1.126156, loss2 : 1.497012
train_step : 10324, loss1 : 1.016716, loss2 : 0.681950
train_step : 10325, loss1 : 1.744554, loss2 : 0.553325
train_step : 10326, loss1 : 1.630654, loss2 : 1.459971
train_step : 10327, loss1 : 1.228317, loss2 : 1.846823
train_step : 10328, loss1 : 1.682930, loss2 : 2.278095
train_step : 10329, loss1 : 3.272117, loss2 : 2.911217
train_step : 10330, loss1 : 2.825709, loss2 : 2.372448
train_step : 10331, loss1 : 2.360068, loss2 : 2.801114
train_step : 10332, loss1 : 2.579634, loss2 : 2.842442
train_step : 10333, loss1 : 2.515916, loss2 : 3.666087
train_step : 10334, loss1 : 1.845747, loss2 : 1.053518
train_step : 10335, loss1 : 1.199736, loss2 : 2.068994
train_step : 10336, loss1 : 1.069029, loss2 : 1.171556
train_step : 10337, loss1 : 1.738427, loss2 : 1.745783
train_step : 10338, loss1 : 0.834274, loss2 : 1.105544
train_step : 10339, loss1 : 0.645202, loss2 : 0.866139
train_step : 10340, loss1 : 0.713795, loss2 : 1.543512
train_step : 10341, loss1 : 0.593689, loss2 : 1.365750
train_step : 10342, loss1 : 0.755349, loss2 : 1.097337
train_step : 10343, loss1 : 1.252850, loss2 : 0.965989
train_step : 10344, loss1 : 1.035659, loss2 : 0.755331
train_step : 10345, loss1 : 2.589032, loss2 : 1.472376
train_step : 10346, loss1 : 1.364467, loss2 : 1.290093
train_step : 10347, loss1 : 0.997590, loss2 : 1.419174
train_step : 10348, loss1 : 1.501236, loss2 : 0.835986
train_step : 10349, loss1 : 1.266189, loss2 : 1.139500
train_step : 10350, loss1 : 1.947761, loss2 : 2.968087
train_step : 10351, loss1 : 1.521439, loss2 : 1.906299
train_step : 10352, loss1 : 1.246630, loss2 : 1.512029
train_step : 10353, loss1 : 1.582783, loss2 : 1.357867
train_step : 10354, loss1 : 1.750283, loss2 : 1.842252
train_step : 10355, loss1 : 0.563329, loss2 : 1.241583
train_step : 10356, loss1 : 1.034661, loss2 : 1.000980
train_step : 10357, loss1 : 1.428723, loss2 : 1.102753
train_step : 10358, loss1 : 1.232577, loss2 : 1.291487
train_step : 10359, loss1 : 1.022792, loss2 : 1.112990
train_step : 10360, loss1 : 1.081452, loss2 : 1.779203
train_step : 10361, loss1 : 0.844089, loss2 : 0.994430
train_step : 10362, loss1 : 1.080421, loss2 : 1.402846
train_step : 10363, loss1 : 0.719149, loss2 : 0.801856
train_step : 10364, loss1 : 1.155432, loss2 : 1.363655
train_step : 10365, loss1 : 1.675624, loss2 : 1.130468
train_step : 10366, loss1 : 1.171111, loss2 : 0.951760
train_step : 10367, loss1 : 0.752228, loss2 : 0.871869
train_step : 10368, loss1 : 1.150029, loss2 : 1.833026
train_step : 10369, loss1 : 1.229875, loss2 : 1.949862
train_step : 10370, loss1 : 1.084754, loss2 : 0.717974
train_step : 10371, loss1 : 1.311627, loss2 : 1.482121
train_step : 10372, loss1 : 1.205049, loss2 : 1.351275
train_step : 10373, loss1 : 1.546860, loss2 : 1.469682
train_step : 10374, loss1 : 1.075215, loss2 : 1.368399
train_step : 10375, loss1 : 1.209853, loss2 : 1.273050
train_step : 10376, loss1 : 1.156425, loss2 : 1.163498
train_step : 10377, loss1 : 1.251493, loss2 : 1.274369
train_step : 10378, loss1 : 2.584525, loss2 : 2.391565
train_step : 10379, loss1 : 1.189805, loss2 : 1.783386
train_step : 10380, loss1 : 0.806823, loss2 : 1.050145
train_step : 10381, loss1 : 1.017887, loss2 : 0.854116
train_step : 10382, loss1 : 1.541011, loss2 : 1.957838
train_step : 10383, loss1 : 2.302692, loss2 : 2.266081
train_step : 10384, loss1 : 2.300928, loss2 : 3.593999
train_step : 10385, loss1 : 2.887870, loss2 : 2.533151
train_step : 10386, loss1 : 2.601694, loss2 : 3.463173
train_step : 10387, loss1 : 3.146170, loss2 : 2.756618
train_step : 10388, loss1 : 1.493432, loss2 : 2.333858
train_step : 10389, loss1 : 1.296929, loss2 : 3.304557
train_step : 10390, loss1 : 2.050672, loss2 : 2.372905
train_step : 10391, loss1 : 1.913579, loss2 : 1.394788
train_step : 10392, loss1 : 1.911395, loss2 : 1.854944
train_step : 10393, loss1 : 1.255071, loss2 : 1.011006
train_step : 10394, loss1 : 0.962966, loss2 : 0.986722
train_step : 10395, loss1 : 0.934491, loss2 : 1.196036
train_step : 10396, loss1 : 1.048885, loss2 : 0.536384
train_step : 10397, loss1 : 2.032793, loss2 : 0.769988
train_step : 10398, loss1 : 2.852940, loss2 : 1.098886
train_step : 10399, loss1 : 1.043379, loss2 : 1.626605
train_step : 10400, loss1 : 1.460953, loss2 : 1.069018
train_step : 10401, loss1 : 1.676710, loss2 : 1.609355
train_step : 10402, loss1 : 1.989698, loss2 : 1.475622
train_step : 10403, loss1 : 2.190691, loss2 : 2.269986
train_step : 10404, loss1 : 1.728069, loss2 : 1.780370
train_step : 10405, loss1 : 1.256821, loss2 : 1.535290
train_step : 10406, loss1 : 1.275080, loss2 : 2.725264
train_step : 10407, loss1 : 1.394272, loss2 : 1.074565
train_step : 10408, loss1 : 1.279740, loss2 : 1.294803
train_step : 10409, loss1 : 1.040094, loss2 : 1.194012
train_step : 10410, loss1 : 1.846937, loss2 : 1.857216
train_step : 10411, loss1 : 2.032798, loss2 : 2.211392
train_step : 10412, loss1 : 2.838326, loss2 : 2.700670
train_step : 10413, loss1 : 2.592480, loss2 : 4.363145
train_step : 10414, loss1 : 2.430296, loss2 : 1.167130
train_step : 10415, loss1 : 1.789350, loss2 : 1.623598
train_step : 10416, loss1 : 1.160592, loss2 : 0.461727
train_step : 10417, loss1 : 1.076937, loss2 : 1.007881
train_step : 10418, loss1 : 1.515447, loss2 : 0.981787
train_step : 10419, loss1 : 1.659518, loss2 : 0.735312
train_step : 10420, loss1 : 1.666016, loss2 : 1.904578
train_step : 10421, loss1 : 1.616528, loss2 : 1.409117
train_step : 10422, loss1 : 0.754344, loss2 : 3.523200
train_step : 10423, loss1 : 1.623675, loss2 : 1.429073
train_step : 10424, loss1 : 2.457162, loss2 : 2.831749
train_step : 10425, loss1 : 2.974501, loss2 : 2.924745
train_step : 10426, loss1 : 2.453724, loss2 : 3.041782
train_step : 10427, loss1 : 2.203078, loss2 : 3.234686
train_step : 10428, loss1 : 1.214394, loss2 : 1.475816
train_step : 10429, loss1 : 1.538401, loss2 : 1.321872
train_step : 10430, loss1 : 1.108057, loss2 : 1.383275
train_step : 10431, loss1 : 1.534039, loss2 : 1.167222
train_step : 10432, loss1 : 1.103470, loss2 : 1.214592
train_step : 10433, loss1 : 1.708047, loss2 : 0.904269
train_step : 10434, loss1 : 1.339577, loss2 : 0.862315
train_step : 10435, loss1 : 0.724756, loss2 : 1.739209
train_step : 10436, loss1 : 0.691030, loss2 : 1.359926
train_step : 10437, loss1 : 0.987986, loss2 : 1.319182
train_step : 10438, loss1 : 2.075777, loss2 : 2.074971
train_step : 10439, loss1 : 1.123198, loss2 : 1.637060
train_step : 10440, loss1 : 1.340149, loss2 : 0.642440
train_step : 10441, loss1 : 1.326920, loss2 : 1.433963
train_step : 10442, loss1 : 1.368588, loss2 : 2.848893
train_step : 10443, loss1 : 2.466600, loss2 : 1.541951
train_step : 10444, loss1 : 1.711297, loss2 : 1.383495
train_step : 10445, loss1 : 1.767809, loss2 : 2.379609
train_step : 10446, loss1 : 0.489971, loss2 : 1.012144
train_step : 10447, loss1 : 2.040911, loss2 : 0.926967
train_step : 10448, loss1 : 0.789266, loss2 : 0.672494
train_step : 10449, loss1 : 1.010727, loss2 : 1.193262
train_step : 10450, loss1 : 1.170504, loss2 : 1.503330
train_step : 10451, loss1 : 0.897557, loss2 : 0.992558
train_step : 10452, loss1 : 1.293396, loss2 : 1.031036
train_step : 10453, loss1 : 1.678865, loss2 : 0.847682
train_step : 10454, loss1 : 1.443852, loss2 : 0.497608
train_step : 10455, loss1 : 1.463080, loss2 : 1.270556
train_step : 10456, loss1 : 1.273754, loss2 : 1.368657
train_step : 10457, loss1 : 1.915857, loss2 : 0.804124
train_step : 10458, loss1 : 1.393265, loss2 : 1.610116
train_step : 10459, loss1 : 4.572955, loss2 : 1.528616
train_step : 10460, loss1 : 1.407032, loss2 : 2.021661
train_step : 10461, loss1 : 2.402783, loss2 : 1.420115
train_step : 10462, loss1 : 2.008462, loss2 : 1.013966
train_step : 10463, loss1 : 2.220941, loss2 : 1.541765
train_step : 10464, loss1 : 1.968126, loss2 : 2.119497
train_step : 10465, loss1 : 1.343163, loss2 : 2.489718
train_step : 10466, loss1 : 1.372694, loss2 : 1.281222
train_step : 10467, loss1 : 0.772852, loss2 : 1.830206
train_step : 10468, loss1 : 1.114791, loss2 : 2.192138
train_step : 10469, loss1 : 1.111990, loss2 : 1.477978
train_step : 10470, loss1 : 0.958284, loss2 : 0.954176
train_step : 10471, loss1 : 1.629463, loss2 : 1.804554
train_step : 10472, loss1 : 0.869833, loss2 : 1.001371
train_step : 10473, loss1 : 1.038501, loss2 : 1.236619
train_step : 10474, loss1 : 0.895996, loss2 : 0.729701
train_step : 10475, loss1 : 1.141842, loss2 : 0.786033
train_step : 10476, loss1 : 1.091340, loss2 : 1.224272
train_step : 10477, loss1 : 1.217162, loss2 : 0.841270
train_step : 10478, loss1 : 1.346157, loss2 : 1.062399
train_step : 10479, loss1 : 0.871096, loss2 : 0.689225
train_step : 10480, loss1 : 0.832970, loss2 : 1.512246
train_step : 10481, loss1 : 1.957118, loss2 : 1.682089
train_step : 10482, loss1 : 1.563781, loss2 : 1.501850
train_step : 10483, loss1 : 1.648207, loss2 : 1.723527
train_step : 10484, loss1 : 1.534147, loss2 : 1.983157
train_step : 10485, loss1 : 2.054970, loss2 : 1.414052
train_step : 10486, loss1 : 2.442973, loss2 : 1.730142
train_step : 10487, loss1 : 2.482231, loss2 : 2.299919
train_step : 10488, loss1 : 2.312286, loss2 : 2.155319
train_step : 10489, loss1 : 1.363654, loss2 : 1.750449
train_step : 10490, loss1 : 0.928132, loss2 : 2.009759
train_step : 10491, loss1 : 1.737115, loss2 : 2.456385
train_step : 10492, loss1 : 1.761016, loss2 : 1.190355
train_step : 10493, loss1 : 1.362955, loss2 : 0.816519
train_step : 10494, loss1 : 0.937582, loss2 : 1.566437
train_step : 10495, loss1 : 1.320188, loss2 : 0.945352
train_step : 10496, loss1 : 0.579906, loss2 : 1.363882
train_step : 10497, loss1 : 0.717576, loss2 : 1.540030
train_step : 10498, loss1 : 1.727746, loss2 : 0.685809
train_step : 10499, loss1 : 0.864190, loss2 : 1.028650
train_step : 10500, loss1 : 1.435751, loss2 : 1.677641
train_step : 10501, loss1 : 1.399486, loss2 : 0.822928
train_step : 10502, loss1 : 1.224372, loss2 : 1.993166
train_step : 10503, loss1 : 1.329334, loss2 : 1.137661
train_step : 10504, loss1 : 1.370417, loss2 : 1.304777
train_step : 10505, loss1 : 1.149664, loss2 : 1.458668
train_step : 10506, loss1 : 1.293099, loss2 : 1.322982
train_step : 10507, loss1 : 2.739305, loss2 : 2.028476
train_step : 10508, loss1 : 0.419417, loss2 : 0.777993
train_step : 10509, loss1 : 2.129781, loss2 : 0.776238
train_step : 10510, loss1 : 1.790249, loss2 : 2.059555
train_step : 10511, loss1 : 0.990867, loss2 : 1.763106
train_step : 10512, loss1 : 1.376257, loss2 : 0.750752
train_step : 10513, loss1 : 1.922087, loss2 : 0.909075
train_step : 10514, loss1 : 1.309940, loss2 : 1.638014
train_step : 10515, loss1 : 1.353838, loss2 : 0.547020
train_step : 10516, loss1 : 1.023553, loss2 : 1.106517
train_step : 10517, loss1 : 1.915416, loss2 : 1.293626
train_step : 10518, loss1 : 1.370846, loss2 : 0.750573
train_step : 10519, loss1 : 0.971529, loss2 : 1.063929
train_step : 10520, loss1 : 1.031945, loss2 : 0.803472
train_step : 10521, loss1 : 1.176773, loss2 : 1.200993
train_step : 10522, loss1 : 0.951433, loss2 : 1.509886
train_step : 10523, loss1 : 1.045572, loss2 : 1.353730
train_step : 10524, loss1 : 0.979517, loss2 : 1.376523
train_step : 10525, loss1 : 1.264637, loss2 : 1.229506
train_step : 10526, loss1 : 0.982731, loss2 : 1.191966
train_step : 10527, loss1 : 1.274364, loss2 : 0.724519
train_step : 10528, loss1 : 1.658682, loss2 : 0.938159
train_step : 10529, loss1 : 1.836594, loss2 : 1.471687
train_step : 10530, loss1 : 1.542847, loss2 : 1.608357
train_step : 10531, loss1 : 1.939021, loss2 : 1.505377
train_step : 10532, loss1 : 0.799055, loss2 : 1.717649
train_step : 10533, loss1 : 1.675717, loss2 : 1.627194
train_step : 10534, loss1 : 0.984918, loss2 : 1.627073
train_step : 10535, loss1 : 1.204143, loss2 : 2.411740
train_step : 10536, loss1 : 1.078059, loss2 : 0.838188
train_step : 10537, loss1 : 1.987549, loss2 : 1.282635
train_step : 10538, loss1 : 2.092423, loss2 : 1.870293
train_step : 10539, loss1 : 1.029298, loss2 : 1.454492
train_step : 10540, loss1 : 0.792928, loss2 : 0.948339
train_step : 10541, loss1 : 0.980892, loss2 : 0.916886
train_step : 10542, loss1 : 1.260321, loss2 : 1.500631
train_step : 10543, loss1 : 1.162664, loss2 : 1.501172
train_step : 10544, loss1 : 1.451199, loss2 : 1.868150
train_step : 10545, loss1 : 2.048141, loss2 : 2.421624
train_step : 10546, loss1 : 2.035485, loss2 : 2.030571
train_step : 10547, loss1 : 1.796152, loss2 : 1.553278
train_step : 10548, loss1 : 1.845717, loss2 : 1.929232
train_step : 10549, loss1 : 2.302691, loss2 : 3.083189
train_step : 10550, loss1 : 2.406363, loss2 : 1.407255
train_step : 10551, loss1 : 0.752606, loss2 : 2.756166
train_step : 10552, loss1 : 1.315048, loss2 : 0.684456
train_step : 10553, loss1 : 1.239285, loss2 : 1.043030
train_step : 10554, loss1 : 2.573336, loss2 : 0.790570
train_step : 10555, loss1 : 1.190558, loss2 : 2.325813
train_step : 10556, loss1 : 0.804565, loss2 : 0.659439
train_step : 10557, loss1 : 1.558876, loss2 : 1.095871
train_step : 10558, loss1 : 1.036732, loss2 : 0.814186
train_step : 10559, loss1 : 1.383282, loss2 : 1.207757
train_step : 10560, loss1 : 0.721235, loss2 : 0.899796
train_step : 10561, loss1 : 1.032712, loss2 : 1.007970
train_step : 10562, loss1 : 1.590626, loss2 : 1.594139
train_step : 10563, loss1 : 1.195293, loss2 : 1.562626
train_step : 10564, loss1 : 1.454408, loss2 : 0.825461
train_step : 10565, loss1 : 0.972080, loss2 : 1.632585
train_step : 10566, loss1 : 0.805583, loss2 : 0.869466
train_step : 10567, loss1 : 4.150217, loss2 : 1.363340
train_step : 10568, loss1 : 0.767744, loss2 : 1.088627
train_step : 10569, loss1 : 1.172654, loss2 : 0.799385
train_step : 10570, loss1 : 1.077887, loss2 : 0.978782
train_step : 10571, loss1 : 1.110293, loss2 : 0.793488
train_step : 10572, loss1 : 1.269856, loss2 : 1.195345
train_step : 10573, loss1 : 1.171028, loss2 : 1.437601
train_step : 10574, loss1 : 0.864709, loss2 : 1.319099
train_step : 10575, loss1 : 0.631838, loss2 : 0.692117
train_step : 10576, loss1 : 1.819034, loss2 : 0.784254
train_step : 10577, loss1 : 1.251078, loss2 : 1.045677
train_step : 10578, loss1 : 1.090226, loss2 : 0.742650
train_step : 10579, loss1 : 1.080620, loss2 : 1.199239
train_step : 10580, loss1 : 0.963577, loss2 : 0.987543
train_step : 10581, loss1 : 1.305163, loss2 : 1.038375
train_step : 10582, loss1 : 1.810487, loss2 : 0.912274
train_step : 10583, loss1 : 1.651176, loss2 : 1.106302
train_step : 10584, loss1 : 0.703665, loss2 : 1.431343
train_step : 10585, loss1 : 0.845991, loss2 : 1.018668
train_step : 10586, loss1 : 1.404322, loss2 : 1.115366
train_step : 10587, loss1 : 0.751232, loss2 : 1.052417
train_step : 10588, loss1 : 1.487547, loss2 : 1.493691
train_step : 10589, loss1 : 1.497681, loss2 : 0.909740
train_step : 10590, loss1 : 0.663971, loss2 : 1.397874
train_step : 10591, loss1 : 1.249066, loss2 : 0.902829
train_step : 10592, loss1 : 0.878897, loss2 : 0.675758
train_step : 10593, loss1 : 2.198109, loss2 : 1.971130
train_step : 10594, loss1 : 1.232280, loss2 : 1.660430
train_step : 10595, loss1 : 1.021203, loss2 : 1.994768
train_step : 10596, loss1 : 1.674782, loss2 : 2.127048
train_step : 10597, loss1 : 1.377558, loss2 : 1.187405
train_step : 10598, loss1 : 1.219676, loss2 : 1.429767
train_step : 10599, loss1 : 1.717055, loss2 : 1.622668
train_step : 10600, loss1 : 2.362659, loss2 : 1.360825
train_step : 10601, loss1 : 1.944327, loss2 : 1.608159
train_step : 10602, loss1 : 1.820756, loss2 : 1.586314
train_step : 10603, loss1 : 1.328595, loss2 : 1.392815
train_step : 10604, loss1 : 1.201037, loss2 : 0.915169
train_step : 10605, loss1 : 0.603457, loss2 : 2.463022
train_step : 10606, loss1 : 1.844946, loss2 : 0.886250
train_step : 10607, loss1 : 0.862495, loss2 : 1.069185
train_step : 10608, loss1 : 0.754012, loss2 : 0.745786
train_step : 10609, loss1 : 0.936064, loss2 : 1.290787
train_step : 10610, loss1 : 0.823673, loss2 : 1.502411
train_step : 10611, loss1 : 1.522205, loss2 : 1.148223
train_step : 10612, loss1 : 1.316400, loss2 : 0.912441
train_step : 10613, loss1 : 1.397621, loss2 : 1.084821
train_step : 10614, loss1 : 1.409104, loss2 : 1.125746
train_step : 10615, loss1 : 0.646197, loss2 : 0.997656
train_step : 10616, loss1 : 0.724522, loss2 : 1.700577
train_step : 10617, loss1 : 0.973540, loss2 : 1.355352
train_step : 10618, loss1 : 0.867213, loss2 : 1.023869
train_step : 10619, loss1 : 0.642535, loss2 : 1.054810
train_step : 10620, loss1 : 0.703950, loss2 : 1.541699
train_step : 10621, loss1 : 1.391371, loss2 : 1.472001
train_step : 10622, loss1 : 1.054176, loss2 : 1.353855
train_step : 10623, loss1 : 1.067785, loss2 : 0.940699
train_step : 10624, loss1 : 0.863180, loss2 : 1.152256
train_step : 10625, loss1 : 1.218970, loss2 : 1.276696
train_step : 10626, loss1 : 0.950496, loss2 : 1.005103
train_step : 10627, loss1 : 0.825446, loss2 : 0.989029
train_step : 10628, loss1 : 1.099977, loss2 : 1.607697
train_step : 10629, loss1 : 1.540249, loss2 : 1.253320
train_step : 10630, loss1 : 1.513704, loss2 : 0.672759
train_step : 10631, loss1 : 1.286485, loss2 : 1.588259
train_step : 10632, loss1 : 1.249604, loss2 : 1.233202
train_step : 10633, loss1 : 1.119768, loss2 : 1.724980
train_step : 10634, loss1 : 0.819744, loss2 : 1.046336
train_step : 10635, loss1 : 0.802888, loss2 : 1.040088
train_step : 10636, loss1 : 0.940324, loss2 : 1.795748
train_step : 10637, loss1 : 1.158687, loss2 : 0.885572
train_step : 10638, loss1 : 1.316273, loss2 : 1.161875
train_step : 10639, loss1 : 1.059857, loss2 : 1.739858
train_step : 10640, loss1 : 1.356702, loss2 : 1.221171
train_step : 10641, loss1 : 2.269496, loss2 : 1.506994
train_step : 10642, loss1 : 1.766497, loss2 : 1.290436
train_step : 10643, loss1 : 1.935797, loss2 : 2.250828
train_step : 10644, loss1 : 1.687898, loss2 : 1.688652
train_step : 10645, loss1 : 3.171731, loss2 : 1.309262
train_step : 10646, loss1 : 0.715816, loss2 : 1.595421
train_step : 10647, loss1 : 1.605333, loss2 : 1.345265
train_step : 10648, loss1 : 1.343740, loss2 : 0.634147
train_step : 10649, loss1 : 1.033038, loss2 : 1.503549
train_step : 10650, loss1 : 1.817456, loss2 : 0.655948
train_step : 10651, loss1 : 1.402151, loss2 : 1.413773
train_step : 10652, loss1 : 2.012639, loss2 : 0.967356
train_step : 10653, loss1 : 1.556224, loss2 : 1.547975
train_step : 10654, loss1 : 2.464091, loss2 : 1.736067
train_step : 10655, loss1 : 1.292595, loss2 : 1.940080
train_step : 10656, loss1 : 1.276426, loss2 : 1.323891
train_step : 10657, loss1 : 1.535907, loss2 : 1.983841
train_step : 10658, loss1 : 1.787248, loss2 : 1.677580
train_step : 10659, loss1 : 2.270810, loss2 : 1.890175
train_step : 10660, loss1 : 2.929038, loss2 : 0.797351
train_step : 10661, loss1 : 1.684291, loss2 : 2.337394
train_step : 10662, loss1 : 1.036483, loss2 : 1.308438
train_step : 10663, loss1 : 1.745035, loss2 : 1.470541
train_step : 10664, loss1 : 1.520314, loss2 : 0.934519
train_step : 10665, loss1 : 1.023243, loss2 : 1.553998
train_step : 10666, loss1 : 1.297708, loss2 : 1.753492
train_step : 10667, loss1 : 2.407358, loss2 : 1.914913
train_step : 10668, loss1 : 2.027114, loss2 : 1.937191
train_step : 10669, loss1 : 3.580522, loss2 : 3.380503
train_step : 10670, loss1 : 2.801499, loss2 : 3.499015
train_step : 10671, loss1 : 5.309936, loss2 : 2.209110
train_step : 10672, loss1 : 3.998693, loss2 : 3.747538
train_step : 10673, loss1 : 5.215180, loss2 : 2.463179
train_step : 10674, loss1 : 2.518770, loss2 : 1.645407
train_step : 10675, loss1 : 1.744633, loss2 : 3.360697
train_step : 10676, loss1 : 2.879225, loss2 : 1.568838
train_step : 10677, loss1 : 2.405634, loss2 : 1.781068
train_step : 10678, loss1 : 0.923418, loss2 : 3.546448
train_step : 10679, loss1 : 1.468846, loss2 : 1.942454
train_step : 10680, loss1 : 1.812854, loss2 : 1.659056
train_step : 10681, loss1 : 1.537029, loss2 : 0.981951
train_step : 10682, loss1 : 2.363585, loss2 : 0.852183
train_step : 10683, loss1 : 1.632057, loss2 : 1.362746
train_step : 10684, loss1 : 0.926057, loss2 : 0.703411
train_step : 10685, loss1 : 1.308073, loss2 : 0.859474
train_step : 10686, loss1 : 0.857786, loss2 : 1.422179
train_step : 10687, loss1 : 1.228790, loss2 : 1.642905
train_step : 10688, loss1 : 2.010591, loss2 : 1.101795
train_step : 10689, loss1 : 1.187898, loss2 : 1.298123
train_step : 10690, loss1 : 2.037587, loss2 : 4.622983
train_step : 10691, loss1 : 1.359253, loss2 : 1.909200
train_step : 10692, loss1 : 2.230492, loss2 : 1.594379
train_step : 10693, loss1 : 1.659291, loss2 : 1.276382
train_step : 10694, loss1 : 1.776840, loss2 : 1.714492
train_step : 10695, loss1 : 0.811288, loss2 : 1.313880
train_step : 10696, loss1 : 0.733494, loss2 : 2.317101
train_step : 10697, loss1 : 1.952044, loss2 : 2.112403
train_step : 10698, loss1 : 1.504551, loss2 : 0.880275
train_step : 10699, loss1 : 1.746660, loss2 : 1.623147
train_step : 10700, loss1 : 0.936427, loss2 : 1.528066
train_step : 10701, loss1 : 1.580956, loss2 : 2.251735
train_step : 10702, loss1 : 1.867840, loss2 : 2.167158
train_step : 10703, loss1 : 1.402922, loss2 : 1.120314
train_step : 10704, loss1 : 1.142934, loss2 : 1.342809
train_step : 10705, loss1 : 0.756488, loss2 : 1.077174
train_step : 10706, loss1 : 1.384882, loss2 : 1.538650
train_step : 10707, loss1 : 0.636434, loss2 : 0.899217
train_step : 10708, loss1 : 1.604067, loss2 : 1.311089
train_step : 10709, loss1 : 1.824785, loss2 : 1.972213
train_step : 10710, loss1 : 1.488387, loss2 : 2.365130
train_step : 10711, loss1 : 1.353024, loss2 : 1.481628
train_step : 10712, loss1 : 1.891862, loss2 : 2.031621
train_step : 10713, loss1 : 1.641864, loss2 : 1.237595
train_step : 10714, loss1 : 0.864993, loss2 : 0.557692
train_step : 10715, loss1 : 1.435850, loss2 : 0.974470
train_step : 10716, loss1 : 1.261559, loss2 : 1.094674
train_step : 10717, loss1 : 0.927703, loss2 : 1.830525
train_step : 10718, loss1 : 0.913226, loss2 : 1.526667
train_step : 10719, loss1 : 0.748064, loss2 : 1.881183
train_step : 10720, loss1 : 1.549099, loss2 : 2.183280
train_step : 10721, loss1 : 1.943487, loss2 : 1.093679
train_step : 10722, loss1 : 1.812672, loss2 : 1.651763
train_step : 10723, loss1 : 1.677603, loss2 : 1.240473
train_step : 10724, loss1 : 2.726093, loss2 : 0.666963
train_step : 10725, loss1 : 2.055381, loss2 : 1.612826
train_step : 10726, loss1 : 2.101204, loss2 : 1.993707
train_step : 10727, loss1 : 2.799813, loss2 : 1.344039
train_step : 10728, loss1 : 1.924955, loss2 : 1.820490
train_step : 10729, loss1 : 3.484451, loss2 : 1.597903
train_step : 10730, loss1 : 3.801414, loss2 : 3.004414
train_step : 10731, loss1 : 1.370804, loss2 : 1.596383
train_step : 10732, loss1 : 2.203684, loss2 : 1.664586
train_step : 10733, loss1 : 3.815266, loss2 : 1.371738
train_step : 10734, loss1 : 1.623634, loss2 : 1.304116
train_step : 10735, loss1 : 0.851513, loss2 : 1.298739
train_step : 10736, loss1 : 1.337281, loss2 : 1.496896
train_step : 10737, loss1 : 1.473333, loss2 : 2.436740
train_step : 10738, loss1 : 0.649957, loss2 : 0.873747
train_step : 10739, loss1 : 0.912079, loss2 : 1.128637
train_step : 10740, loss1 : 1.420912, loss2 : 0.863981
train_step : 10741, loss1 : 0.960491, loss2 : 1.832784
train_step : 10742, loss1 : 1.292250, loss2 : 0.759218
train_step : 10743, loss1 : 0.582611, loss2 : 1.043706
train_step : 10744, loss1 : 1.099299, loss2 : 0.777574
train_step : 10745, loss1 : 1.447073, loss2 : 1.660988
train_step : 10746, loss1 : 2.771943, loss2 : 1.400789
train_step : 10747, loss1 : 2.083670, loss2 : 2.831306
train_step : 10748, loss1 : 3.150201, loss2 : 2.106413
train_step : 10749, loss1 : 2.476753, loss2 : 2.349726
train_step : 10750, loss1 : 0.844890, loss2 : 0.746168
train_step : 10751, loss1 : 0.990956, loss2 : 0.983995
train_step : 10752, loss1 : 1.248640, loss2 : 1.235301
train_step : 10753, loss1 : 0.939152, loss2 : 1.626328
train_step : 10754, loss1 : 1.384519, loss2 : 1.367749
train_step : 10755, loss1 : 0.829585, loss2 : 1.240737
train_step : 10756, loss1 : 1.842143, loss2 : 1.316163
train_step : 10757, loss1 : 1.891151, loss2 : 1.210443
train_step : 10758, loss1 : 1.361364, loss2 : 0.954570
train_step : 10759, loss1 : 1.447123, loss2 : 2.149855
train_step : 10760, loss1 : 1.631189, loss2 : 1.740828
train_step : 10761, loss1 : 1.660744, loss2 : 1.572886
train_step : 10762, loss1 : 2.463109, loss2 : 1.847008
train_step : 10763, loss1 : 3.196649, loss2 : 2.901384
train_step : 10764, loss1 : 3.501624, loss2 : 3.151036
train_step : 10765, loss1 : 4.316686, loss2 : 5.759878
train_step : 10766, loss1 : 5.017723, loss2 : 5.273154
train_step : 10767, loss1 : 5.970173, loss2 : 5.229586
train_step : 10768, loss1 : 1.806112, loss2 : 3.832988
train_step : 10769, loss1 : 3.462168, loss2 : 2.777893
train_step : 10770, loss1 : 2.525583, loss2 : 2.134927
train_step : 10771, loss1 : 1.553188, loss2 : 1.836090
train_step : 10772, loss1 : 2.189958, loss2 : 4.013572
train_step : 10773, loss1 : 2.965459, loss2 : 3.897433
train_step : 10774, loss1 : 3.122405, loss2 : 2.760861
train_step : 10775, loss1 : 2.256286, loss2 : 2.577231
train_step : 10776, loss1 : 1.363796, loss2 : 1.463984
train_step : 10777, loss1 : 1.673805, loss2 : 1.884132
train_step : 10778, loss1 : 0.866390, loss2 : 1.732595
train_step : 10779, loss1 : 1.277982, loss2 : 0.981249
train_step : 10780, loss1 : 1.517474, loss2 : 1.201618
train_step : 10781, loss1 : 1.919114, loss2 : 1.588390
train_step : 10782, loss1 : 1.888469, loss2 : 1.611115
train_step : 10783, loss1 : 1.187241, loss2 : 0.917912
train_step : 10784, loss1 : 0.713699, loss2 : 1.099936
train_step : 10785, loss1 : 1.978721, loss2 : 0.967318
train_step : 10786, loss1 : 1.801967, loss2 : 0.994969
train_step : 10787, loss1 : 0.612277, loss2 : 1.302933
train_step : 10788, loss1 : 0.893143, loss2 : 0.741756
train_step : 10789, loss1 : 1.432508, loss2 : 1.179268
train_step : 10790, loss1 : 1.038764, loss2 : 0.768386
train_step : 10791, loss1 : 1.287379, loss2 : 1.887183
train_step : 10792, loss1 : 2.422873, loss2 : 2.878190
train_step : 10793, loss1 : 2.167120, loss2 : 3.107708
train_step : 10794, loss1 : 2.390351, loss2 : 2.962753
train_step : 10795, loss1 : 1.875200, loss2 : 2.592576
train_step : 10796, loss1 : 2.840131, loss2 : 1.449692
train_step : 10797, loss1 : 1.057734, loss2 : 0.876061
train_step : 10798, loss1 : 0.831175, loss2 : 0.999681
train_step : 10799, loss1 : 1.301267, loss2 : 0.982608
train_step : 10800, loss1 : 0.864819, loss2 : 0.629676
train_step : 10801, loss1 : 0.963606, loss2 : 1.123528
train_step : 10802, loss1 : 1.196138, loss2 : 0.730952
train_step : 10803, loss1 : 0.877850, loss2 : 0.933180
train_step : 10804, loss1 : 0.958272, loss2 : 0.638927
train_step : 10805, loss1 : 0.934748, loss2 : 0.379767
train_step : 10806, loss1 : 1.133049, loss2 : 1.348958
train_step : 10807, loss1 : 0.933748, loss2 : 1.953313
train_step : 10808, loss1 : 1.301527, loss2 : 1.219873
train_step : 10809, loss1 : 1.165820, loss2 : 1.084944
train_step : 10810, loss1 : 1.260470, loss2 : 1.501540
train_step : 10811, loss1 : 1.310679, loss2 : 1.552615
train_step : 10812, loss1 : 1.195209, loss2 : 1.338046
train_step : 10813, loss1 : 0.944598, loss2 : 1.140464
train_step : 10814, loss1 : 1.039624, loss2 : 1.182763
train_step : 10815, loss1 : 1.433426, loss2 : 0.917652
train_step : 10816, loss1 : 0.896161, loss2 : 0.950681
train_step : 10817, loss1 : 1.008681, loss2 : 0.955674
train_step : 10818, loss1 : 2.099167, loss2 : 0.751158
train_step : 10819, loss1 : 1.288297, loss2 : 1.383385
train_step : 10820, loss1 : 1.224309, loss2 : 1.595216
train_step : 10821, loss1 : 1.082478, loss2 : 1.203104
train_step : 10822, loss1 : 1.028142, loss2 : 1.126751
train_step : 10823, loss1 : 1.075665, loss2 : 1.052671
train_step : 10824, loss1 : 1.749033, loss2 : 1.413105
train_step : 10825, loss1 : 1.149518, loss2 : 0.919271
train_step : 10826, loss1 : 1.596509, loss2 : 2.525227
train_step : 10827, loss1 : 1.854423, loss2 : 1.297050
train_step : 10828, loss1 : 1.828886, loss2 : 1.054709
train_step : 10829, loss1 : 2.086815, loss2 : 1.465190
train_step : 10830, loss1 : 1.565524, loss2 : 2.348584
train_step : 10831, loss1 : 3.479593, loss2 : 2.766156
train_step : 10832, loss1 : 1.986389, loss2 : 2.732558
train_step : 10833, loss1 : 1.276463, loss2 : 2.259003
train_step : 10834, loss1 : 1.729179, loss2 : 1.564488
train_step : 10835, loss1 : 2.662546, loss2 : 2.646251
train_step : 10836, loss1 : 2.560628, loss2 : 2.226614
train_step : 10837, loss1 : 1.962513, loss2 : 2.578492
train_step : 10838, loss1 : 2.863693, loss2 : 2.095000
train_step : 10839, loss1 : 2.655770, loss2 : 2.353659
train_step : 10840, loss1 : 2.082488, loss2 : 2.011315
train_step : 10841, loss1 : 1.578642, loss2 : 1.211396
train_step : 10842, loss1 : 1.390138, loss2 : 1.502099
train_step : 10843, loss1 : 1.352601, loss2 : 1.417050
train_step : 10844, loss1 : 1.532464, loss2 : 1.327924
train_step : 10845, loss1 : 1.704857, loss2 : 2.393884
train_step : 10846, loss1 : 1.945772, loss2 : 1.681712
train_step : 10847, loss1 : 2.987139, loss2 : 1.940672
train_step : 10848, loss1 : 2.102001, loss2 : 1.822948
train_step : 10849, loss1 : 0.980823, loss2 : 1.825538
train_step : 10850, loss1 : 1.950977, loss2 : 0.759656
train_step : 10851, loss1 : 0.734245, loss2 : 0.964049
train_step : 10852, loss1 : 1.224016, loss2 : 1.299889
train_step : 10853, loss1 : 1.044580, loss2 : 1.140428
train_step : 10854, loss1 : 0.537300, loss2 : 1.025195
train_step : 10855, loss1 : 1.506014, loss2 : 1.255293
train_step : 10856, loss1 : 1.000289, loss2 : 1.204211
train_step : 10857, loss1 : 0.922259, loss2 : 1.122471
train_step : 10858, loss1 : 0.850387, loss2 : 0.953879
train_step : 10859, loss1 : 1.191191, loss2 : 1.358900
train_step : 10860, loss1 : 0.893829, loss2 : 1.002853
train_step : 10861, loss1 : 0.949859, loss2 : 1.066773
train_step : 10862, loss1 : 1.493595, loss2 : 1.185930
train_step : 10863, loss1 : 0.784968, loss2 : 0.957845
train_step : 10864, loss1 : 0.891546, loss2 : 0.811543
train_step : 10865, loss1 : 1.102002, loss2 : 0.855026
train_step : 10866, loss1 : 1.137714, loss2 : 1.697322
train_step : 10867, loss1 : 1.128397, loss2 : 1.379805
train_step : 10868, loss1 : 1.123971, loss2 : 1.887759
train_step : 10869, loss1 : 2.484043, loss2 : 1.100971
train_step : 10870, loss1 : 3.060066, loss2 : 2.682135
train_step : 10871, loss1 : 2.738045, loss2 : 1.354341
train_step : 10872, loss1 : 1.509206, loss2 : 2.066014
train_step : 10873, loss1 : 0.989935, loss2 : 0.926150
train_step : 10874, loss1 : 1.278583, loss2 : 1.728168
train_step : 10875, loss1 : 1.833760, loss2 : 1.518554
train_step : 10876, loss1 : 1.547380, loss2 : 1.294756
train_step : 10877, loss1 : 0.902867, loss2 : 0.852935
train_step : 10878, loss1 : 1.040091, loss2 : 1.025729
train_step : 10879, loss1 : 0.969649, loss2 : 0.732363
train_step : 10880, loss1 : 0.720413, loss2 : 0.989952
train_step : 10881, loss1 : 0.927277, loss2 : 1.060176
train_step : 10882, loss1 : 1.165849, loss2 : 1.467871
train_step : 10883, loss1 : 0.949093, loss2 : 0.698940
train_step : 10884, loss1 : 1.192859, loss2 : 1.331271
train_step : 10885, loss1 : 1.616236, loss2 : 1.636392
train_step : 10886, loss1 : 2.042825, loss2 : 2.099062
train_step : 10887, loss1 : 2.399568, loss2 : 2.364382
train_step : 10888, loss1 : 2.516971, loss2 : 2.297159
train_step : 10889, loss1 : 4.976054, loss2 : 1.910072
train_step : 10890, loss1 : 1.390700, loss2 : 2.122256
train_step : 10891, loss1 : 1.808326, loss2 : 1.869730
train_step : 10892, loss1 : 1.266895, loss2 : 2.265220
train_step : 10893, loss1 : 0.888010, loss2 : 2.149189
train_step : 10894, loss1 : 1.549860, loss2 : 2.316489
train_step : 10895, loss1 : 2.059354, loss2 : 1.255906
train_step : 10896, loss1 : 1.741384, loss2 : 3.146420
train_step : 10897, loss1 : 2.130014, loss2 : 2.481831
train_step : 10898, loss1 : 3.057994, loss2 : 2.510965
train_step : 10899, loss1 : 2.644892, loss2 : 3.274016
train_step : 10900, loss1 : 1.255465, loss2 : 3.212051
train_step : 10901, loss1 : 2.598695, loss2 : 1.636354
train_step : 10902, loss1 : 1.860891, loss2 : 1.382623
train_step : 10903, loss1 : 2.061482, loss2 : 1.530077
train_step : 10904, loss1 : 1.966290, loss2 : 1.179246
train_step : 10905, loss1 : 0.645848, loss2 : 1.656665
train_step : 10906, loss1 : 1.672965, loss2 : 0.489459
train_step : 10907, loss1 : 1.286715, loss2 : 1.190149
train_step : 10908, loss1 : 1.529842, loss2 : 0.601243
train_step : 10909, loss1 : 0.720280, loss2 : 0.953436
train_step : 10910, loss1 : 1.144043, loss2 : 0.831627
train_step : 10911, loss1 : 1.898645, loss2 : 1.057722
train_step : 10912, loss1 : 0.910670, loss2 : 1.071853
train_step : 10913, loss1 : 0.943139, loss2 : 2.491205
train_step : 10914, loss1 : 1.853684, loss2 : 1.540811
train_step : 10915, loss1 : 1.915395, loss2 : 1.168793
train_step : 10916, loss1 : 0.756934, loss2 : 1.261814
train_step : 10917, loss1 : 0.757001, loss2 : 0.742586
train_step : 10918, loss1 : 0.656583, loss2 : 0.860598
train_step : 10919, loss1 : 1.028886, loss2 : 1.728208
train_step : 10920, loss1 : 0.672524, loss2 : 0.621430
train_step : 10921, loss1 : 0.887255, loss2 : 1.435368
train_step : 10922, loss1 : 1.508171, loss2 : 0.854555
train_step : 10923, loss1 : 1.383430, loss2 : 1.835599
train_step : 10924, loss1 : 1.687280, loss2 : 1.468234
train_step : 10925, loss1 : 1.391590, loss2 : 1.949130
train_step : 10926, loss1 : 2.696112, loss2 : 2.385653
train_step : 10927, loss1 : 1.416089, loss2 : 2.459119
train_step : 10928, loss1 : 2.077048, loss2 : 2.056295
train_step : 10929, loss1 : 2.278979, loss2 : 1.019061
train_step : 10930, loss1 : 1.332578, loss2 : 1.684481
train_step : 10931, loss1 : 1.744546, loss2 : 2.462457
train_step : 10932, loss1 : 1.667076, loss2 : 2.617834
train_step : 10933, loss1 : 1.587512, loss2 : 2.921098
train_step : 10934, loss1 : 3.462105, loss2 : 2.667439
train_step : 10935, loss1 : 2.284292, loss2 : 0.861628
train_step : 10936, loss1 : 1.988109, loss2 : 2.326115
train_step : 10937, loss1 : 1.165129, loss2 : 1.165936
train_step : 10938, loss1 : 0.770657, loss2 : 1.018713
train_step : 10939, loss1 : 0.790318, loss2 : 0.802330
train_step : 10940, loss1 : 0.754697, loss2 : 0.822517
train_step : 10941, loss1 : 1.135837, loss2 : 1.192849
train_step : 10942, loss1 : 1.550269, loss2 : 0.832353
train_step : 10943, loss1 : 0.915565, loss2 : 1.017289
train_step : 10944, loss1 : 1.387747, loss2 : 1.074641
train_step : 10945, loss1 : 1.369966, loss2 : 1.380896
train_step : 10946, loss1 : 0.842024, loss2 : 1.597567
train_step : 10947, loss1 : 0.923621, loss2 : 0.661363
train_step : 10948, loss1 : 1.103974, loss2 : 1.543518
train_step : 10949, loss1 : 0.887013, loss2 : 1.181717
train_step : 10950, loss1 : 1.216727, loss2 : 0.879062
train_step : 10951, loss1 : 2.035097, loss2 : 0.939463
train_step : 10952, loss1 : 1.673331, loss2 : 1.063524
train_step : 10953, loss1 : 0.866227, loss2 : 0.495456
train_step : 10954, loss1 : 1.133871, loss2 : 1.019427
train_step : 10955, loss1 : 0.884373, loss2 : 1.117041
train_step : 10956, loss1 : 1.152862, loss2 : 0.983618
train_step : 10957, loss1 : 0.820521, loss2 : 1.052624
train_step : 10958, loss1 : 0.792084, loss2 : 0.998464
train_step : 10959, loss1 : 1.224418, loss2 : 1.134840
train_step : 10960, loss1 : 1.198905, loss2 : 1.562077
train_step : 10961, loss1 : 1.691210, loss2 : 1.317127
train_step : 10962, loss1 : 1.993588, loss2 : 1.887889
train_step : 10963, loss1 : 1.761892, loss2 : 1.549943
train_step : 10964, loss1 : 1.251629, loss2 : 1.221208
train_step : 10965, loss1 : 0.784007, loss2 : 0.922377
train_step : 10966, loss1 : 0.883015, loss2 : 0.602996
train_step : 10967, loss1 : 1.288256, loss2 : 1.362654
train_step : 10968, loss1 : 0.917636, loss2 : 1.428287
train_step : 10969, loss1 : 1.185920, loss2 : 0.895270
train_step : 10970, loss1 : 1.550148, loss2 : 1.389019
train_step : 10971, loss1 : 2.178172, loss2 : 2.020749
train_step : 10972, loss1 : 2.262855, loss2 : 2.149083
train_step : 10973, loss1 : 2.180332, loss2 : 6.189125
train_step : 10974, loss1 : 2.278167, loss2 : 2.069654
train_step : 10975, loss1 : 1.812033, loss2 : 1.964692
train_step : 10976, loss1 : 1.068682, loss2 : 1.587602
train_step : 10977, loss1 : 1.078803, loss2 : 1.742734
train_step : 10978, loss1 : 1.222691, loss2 : 1.309464
train_step : 10979, loss1 : 0.794080, loss2 : 0.522961
train_step : 10980, loss1 : 1.208603, loss2 : 0.857232
train_step : 10981, loss1 : 1.203027, loss2 : 0.926787
train_step : 10982, loss1 : 1.103114, loss2 : 1.451566
train_step : 10983, loss1 : 1.141125, loss2 : 1.279198
train_step : 10984, loss1 : 1.504769, loss2 : 1.131435
train_step : 10985, loss1 : 0.874048, loss2 : 1.106369
train_step : 10986, loss1 : 1.017004, loss2 : 0.792973
train_step : 10987, loss1 : 0.645340, loss2 : 1.159185
train_step : 10988, loss1 : 1.340901, loss2 : 1.359564
train_step : 10989, loss1 : 0.707667, loss2 : 0.972012
train_step : 10990, loss1 : 1.073029, loss2 : 1.124767
train_step : 10991, loss1 : 1.295237, loss2 : 1.255853
train_step : 10992, loss1 : 1.272412, loss2 : 1.548549
train_step : 10993, loss1 : 1.400851, loss2 : 1.836118
train_step : 10994, loss1 : 0.816563, loss2 : 0.712627
train_step : 10995, loss1 : 1.933062, loss2 : 0.539074
train_step : 10996, loss1 : 0.868280, loss2 : 1.612399
train_step : 10997, loss1 : 2.122245, loss2 : 1.309599
train_step : 10998, loss1 : 1.525761, loss2 : 1.439539
train_step : 10999, loss1 : 1.292354, loss2 : 1.847824
train_step : 11000, loss1 : 0.836884, loss2 : 0.942358
train_step : 11001, loss1 : 1.472150, loss2 : 0.453817
train_step : 11002, loss1 : 1.091053, loss2 : 0.586625
train_step : 11003, loss1 : 1.182058, loss2 : 1.808998
train_step : 11004, loss1 : 1.793499, loss2 : 1.933500
train_step : 11005, loss1 : 1.406346, loss2 : 1.898917
train_step : 11006, loss1 : 1.041722, loss2 : 2.083617
train_step : 11007, loss1 : 2.121539, loss2 : 2.001087
train_step : 11008, loss1 : 1.744521, loss2 : 2.614951
train_step : 11009, loss1 : 1.559851, loss2 : 2.430167
train_step : 11010, loss1 : 1.777117, loss2 : 1.226160
train_step : 11011, loss1 : 1.033126, loss2 : 1.154878
train_step : 11012, loss1 : 1.250921, loss2 : 1.212240
train_step : 11013, loss1 : 0.801193, loss2 : 0.576149
train_step : 11014, loss1 : 1.670682, loss2 : 1.981571
train_step : 11015, loss1 : 1.120547, loss2 : 0.972215
train_step : 11016, loss1 : 1.475756, loss2 : 0.654979
train_step : 11017, loss1 : 1.561631, loss2 : 1.193005
train_step : 11018, loss1 : 0.554745, loss2 : 0.888347
train_step : 11019, loss1 : 0.781041, loss2 : 1.427278
train_step : 11020, loss1 : 1.541291, loss2 : 1.419259
train_step : 11021, loss1 : 1.722915, loss2 : 0.958311
train_step : 11022, loss1 : 1.427048, loss2 : 1.980479
train_step : 11023, loss1 : 2.271607, loss2 : 2.415094
train_step : 11024, loss1 : 2.807473, loss2 : 3.664580
train_step : 11025, loss1 : 2.453234, loss2 : 1.358705
train_step : 11026, loss1 : 2.204722, loss2 : 2.038532
train_step : 11027, loss1 : 2.029490, loss2 : 0.593735
train_step : 11028, loss1 : 0.742923, loss2 : 1.437475
train_step : 11029, loss1 : 1.104098, loss2 : 2.186539
train_step : 11030, loss1 : 1.421719, loss2 : 1.333505
train_step : 11031, loss1 : 1.593145, loss2 : 0.605136
train_step : 11032, loss1 : 0.940378, loss2 : 1.005937
train_step : 11033, loss1 : 0.991750, loss2 : 0.869090
train_step : 11034, loss1 : 0.850690, loss2 : 0.770082
train_step : 11035, loss1 : 1.445653, loss2 : 0.520836
train_step : 11036, loss1 : 1.523635, loss2 : 1.792851
train_step : 11037, loss1 : 1.666191, loss2 : 1.828203
train_step : 11038, loss1 : 2.569506, loss2 : 1.182460
train_step : 11039, loss1 : 2.107631, loss2 : 2.385408
train_step : 11040, loss1 : 2.278449, loss2 : 2.812625
train_step : 11041, loss1 : 2.036355, loss2 : 1.762508
train_step : 11042, loss1 : 1.298578, loss2 : 1.760400
train_step : 11043, loss1 : 1.145714, loss2 : 2.114787
train_step : 11044, loss1 : 0.935500, loss2 : 2.375149
train_step : 11045, loss1 : 1.325683, loss2 : 2.120317
train_step : 11046, loss1 : 2.299946, loss2 : 1.519598
train_step : 11047, loss1 : 1.257318, loss2 : 1.358439
train_step : 11048, loss1 : 0.808929, loss2 : 1.215861
train_step : 11049, loss1 : 0.845495, loss2 : 1.164938
train_step : 11050, loss1 : 1.081897, loss2 : 1.176627
train_step : 11051, loss1 : 0.747137, loss2 : 0.987961
train_step : 11052, loss1 : 0.471840, loss2 : 1.089723
train_step : 11053, loss1 : 0.958407, loss2 : 1.266535
train_step : 11054, loss1 : 0.760559, loss2 : 0.988185
train_step : 11055, loss1 : 0.842576, loss2 : 1.322038
train_step : 11056, loss1 : 0.926190, loss2 : 0.599097
train_step : 11057, loss1 : 0.657812, loss2 : 0.561817
train_step : 11058, loss1 : 1.714308, loss2 : 0.948997
train_step : 11059, loss1 : 1.040912, loss2 : 1.418525
train_step : 11060, loss1 : 1.158497, loss2 : 0.955751
train_step : 11061, loss1 : 2.097763, loss2 : 1.091592
train_step : 11062, loss1 : 1.554816, loss2 : 2.415996
train_step : 11063, loss1 : 0.788446, loss2 : 1.040137
train_step : 11064, loss1 : 1.064197, loss2 : 0.642339
train_step : 11065, loss1 : 0.781959, loss2 : 2.513484
train_step : 11066, loss1 : 1.488471, loss2 : 1.617460
train_step : 11067, loss1 : 0.858305, loss2 : 0.874229
train_step : 11068, loss1 : 0.726922, loss2 : 0.708802
train_step : 11069, loss1 : 0.653309, loss2 : 0.515311
train_step : 11070, loss1 : 0.958288, loss2 : 1.477670
train_step : 11071, loss1 : 1.914110, loss2 : 1.852236
train_step : 11072, loss1 : 2.874379, loss2 : 1.315430
train_step : 11073, loss1 : 2.123841, loss2 : 2.205540
train_step : 11074, loss1 : 2.178635, loss2 : 2.363174
train_step : 11075, loss1 : 1.161240, loss2 : 2.193046
train_step : 11076, loss1 : 0.789415, loss2 : 0.442433
train_step : 11077, loss1 : 0.998313, loss2 : 1.167978
train_step : 11078, loss1 : 1.068147, loss2 : 0.383455
train_step : 11079, loss1 : 0.853000, loss2 : 0.879810
train_step : 11080, loss1 : 0.976774, loss2 : 0.672928
train_step : 11081, loss1 : 1.231271, loss2 : 1.683007
train_step : 11082, loss1 : 1.484781, loss2 : 1.474608
train_step : 11083, loss1 : 1.784902, loss2 : 1.171671
train_step : 11084, loss1 : 1.110671, loss2 : 0.904631
train_step : 11085, loss1 : 0.749277, loss2 : 0.933910
train_step : 11086, loss1 : 1.389564, loss2 : 1.769965
train_step : 11087, loss1 : 1.191134, loss2 : 0.980679
train_step : 11088, loss1 : 1.238575, loss2 : 1.184615
train_step : 11089, loss1 : 0.563191, loss2 : 1.442907
train_step : 11090, loss1 : 1.342661, loss2 : 0.886454
train_step : 11091, loss1 : 1.948047, loss2 : 1.393313
train_step : 11092, loss1 : 3.547589, loss2 : 4.318876
train_step : 11093, loss1 : 5.835337, loss2 : 6.733750
train_step : 11094, loss1 : 2.410794, loss2 : 3.108920
train_step : 11095, loss1 : 2.579123, loss2 : 2.332852
train_step : 11096, loss1 : 1.363890, loss2 : 1.256357
train_step : 11097, loss1 : 1.166992, loss2 : 1.797548
train_step : 11098, loss1 : 2.143671, loss2 : 1.712946
train_step : 11099, loss1 : 0.993356, loss2 : 1.673762
train_step : 11100, loss1 : 0.661949, loss2 : 1.074509
train_step : 11101, loss1 : 1.170107, loss2 : 0.919949
train_step : 11102, loss1 : 1.691740, loss2 : 1.397519
train_step : 11103, loss1 : 1.191577, loss2 : 1.147324
train_step : 11104, loss1 : 0.981886, loss2 : 0.630975
train_step : 11105, loss1 : 1.299806, loss2 : 3.158989
train_step : 11106, loss1 : 1.192124, loss2 : 0.891968
train_step : 11107, loss1 : 0.785075, loss2 : 0.529372
train_step : 11108, loss1 : 1.317395, loss2 : 1.089440
train_step : 11109, loss1 : 1.008221, loss2 : 0.551391
train_step : 11110, loss1 : 1.106604, loss2 : 2.078496
train_step : 11111, loss1 : 1.169633, loss2 : 1.346908
train_step : 11112, loss1 : 2.350850, loss2 : 1.874811
train_step : 11113, loss1 : 1.471474, loss2 : 2.940928
train_step : 11114, loss1 : 1.434709, loss2 : 1.772210
train_step : 11115, loss1 : 1.162145, loss2 : 1.474906
train_step : 11116, loss1 : 1.658603, loss2 : 2.260946
train_step : 11117, loss1 : 2.071099, loss2 : 2.755497
train_step : 11118, loss1 : 1.543813, loss2 : 3.602400
train_step : 11119, loss1 : 2.406740, loss2 : 2.256030
train_step : 11120, loss1 : 0.725869, loss2 : 1.586776
train_step : 11121, loss1 : 1.397727, loss2 : 1.597864
train_step : 11122, loss1 : 1.552761, loss2 : 2.096241
train_step : 11123, loss1 : 1.955604, loss2 : 1.859398
train_step : 11124, loss1 : 0.486119, loss2 : 0.732641
train_step : 11125, loss1 : 1.239110, loss2 : 0.916983
train_step : 11126, loss1 : 0.608009, loss2 : 2.067878
train_step : 11127, loss1 : 2.218115, loss2 : 1.906746
train_step : 11128, loss1 : 1.605693, loss2 : 1.562019
train_step : 11129, loss1 : 1.756779, loss2 : 1.629582
train_step : 11130, loss1 : 1.526736, loss2 : 1.918488
train_step : 11131, loss1 : 1.043749, loss2 : 0.901349
train_step : 11132, loss1 : 1.101141, loss2 : 0.810782
train_step : 11133, loss1 : 1.431535, loss2 : 1.018040
train_step : 11134, loss1 : 1.422480, loss2 : 1.464580
train_step : 11135, loss1 : 1.215307, loss2 : 1.390414
train_step : 11136, loss1 : 1.291148, loss2 : 1.760293
train_step : 11137, loss1 : 1.465536, loss2 : 1.809683
train_step : 11138, loss1 : 0.543307, loss2 : 1.621426
train_step : 11139, loss1 : 0.951756, loss2 : 1.467584
train_step : 11140, loss1 : 0.929834, loss2 : 1.607188
train_step : 11141, loss1 : 1.218028, loss2 : 1.289168
train_step : 11142, loss1 : 0.706545, loss2 : 1.221114
train_step : 11143, loss1 : 0.755562, loss2 : 0.502331
train_step : 11144, loss1 : 1.132017, loss2 : 1.000078
train_step : 11145, loss1 : 1.722182, loss2 : 1.266688
train_step : 11146, loss1 : 2.055197, loss2 : 1.999479
train_step : 11147, loss1 : 1.570974, loss2 : 1.555512
train_step : 11148, loss1 : 1.023209, loss2 : 1.141183
train_step : 11149, loss1 : 1.356519, loss2 : 1.329635
train_step : 11150, loss1 : 1.060267, loss2 : 1.281717
train_step : 11151, loss1 : 1.928370, loss2 : 1.076800
train_step : 11152, loss1 : 0.775999, loss2 : 1.057386
train_step : 11153, loss1 : 1.061741, loss2 : 1.014066
train_step : 11154, loss1 : 2.280485, loss2 : 1.368535
train_step : 11155, loss1 : 1.126429, loss2 : 1.223287
train_step : 11156, loss1 : 0.989341, loss2 : 0.920119
train_step : 11157, loss1 : 0.710283, loss2 : 1.495611
train_step : 11158, loss1 : 0.669363, loss2 : 1.460278
train_step : 11159, loss1 : 1.251638, loss2 : 0.658464
train_step : 11160, loss1 : 0.900461, loss2 : 1.522133
train_step : 11161, loss1 : 2.180578, loss2 : 2.304107
train_step : 11162, loss1 : 2.810558, loss2 : 1.106032
train_step : 11163, loss1 : 1.826222, loss2 : 3.098864
train_step : 11164, loss1 : 1.717003, loss2 : 2.322299
train_step : 11165, loss1 : 2.233502, loss2 : 2.948091
train_step : 11166, loss1 : 2.047062, loss2 : 1.822097
train_step : 11167, loss1 : 3.580010, loss2 : 2.715563
train_step : 11168, loss1 : 3.142783, loss2 : 4.619304
train_step : 11169, loss1 : 4.186372, loss2 : 4.248717
train_step : 11170, loss1 : 2.594566, loss2 : 2.726387
train_step : 11171, loss1 : 2.170812, loss2 : 2.063054
train_step : 11172, loss1 : 1.097143, loss2 : 1.107108
train_step : 11173, loss1 : 0.926539, loss2 : 1.360046
train_step : 11174, loss1 : 1.039648, loss2 : 1.065594
train_step : 11175, loss1 : 4.197468, loss2 : 1.320407
train_step : 11176, loss1 : 1.731994, loss2 : 1.881374
train_step : 11177, loss1 : 1.527621, loss2 : 2.289227
train_step : 11178, loss1 : 2.015506, loss2 : 1.454342
train_step : 11179, loss1 : 0.748462, loss2 : 1.247527
train_step : 11180, loss1 : 0.891857, loss2 : 0.957512
train_step : 11181, loss1 : 0.974146, loss2 : 1.024169
train_step : 11182, loss1 : 0.933065, loss2 : 1.073958
train_step : 11183, loss1 : 1.233078, loss2 : 0.610244
train_step : 11184, loss1 : 0.597925, loss2 : 0.941578
train_step : 11185, loss1 : 1.356577, loss2 : 1.109640
train_step : 11186, loss1 : 1.580594, loss2 : 1.661665
train_step : 11187, loss1 : 2.319806, loss2 : 1.381351
train_step : 11188, loss1 : 1.148803, loss2 : 1.465220
train_step : 11189, loss1 : 1.918989, loss2 : 1.024149
train_step : 11190, loss1 : 1.442388, loss2 : 1.239296
train_step : 11191, loss1 : 1.197828, loss2 : 1.303322
train_step : 11192, loss1 : 2.166216, loss2 : 1.536766
train_step : 11193, loss1 : 1.758870, loss2 : 1.329761
train_step : 11194, loss1 : 1.173835, loss2 : 1.907136
train_step : 11195, loss1 : 1.239349, loss2 : 0.773254
train_step : 11196, loss1 : 0.898962, loss2 : 1.126786
train_step : 11197, loss1 : 0.880470, loss2 : 1.244594
train_step : 11198, loss1 : 1.432097, loss2 : 1.043410
train_step : 11199, loss1 : 0.912224, loss2 : 1.464370
train_step : 11200, loss1 : 1.514492, loss2 : 1.388910
train_step : 11201, loss1 : 1.115844, loss2 : 1.000934
train_step : 11202, loss1 : 1.128504, loss2 : 1.023670
train_step : 11203, loss1 : 1.178669, loss2 : 1.747180
train_step : 11204, loss1 : 1.098119, loss2 : 0.939682
train_step : 11205, loss1 : 0.974623, loss2 : 1.167247
train_step : 11206, loss1 : 1.759408, loss2 : 1.159690
train_step : 11207, loss1 : 0.942813, loss2 : 2.079987
train_step : 11208, loss1 : 1.494054, loss2 : 0.838433
train_step : 11209, loss1 : 1.205850, loss2 : 0.943977
train_step : 11210, loss1 : 1.408345, loss2 : 1.186141
train_step : 11211, loss1 : 0.584529, loss2 : 1.115821
train_step : 11212, loss1 : 1.130955, loss2 : 0.952057
train_step : 11213, loss1 : 1.738642, loss2 : 1.000929
train_step : 11214, loss1 : 0.606523, loss2 : 0.981927
train_step : 11215, loss1 : 1.283998, loss2 : 0.737367
train_step : 11216, loss1 : 1.634089, loss2 : 0.611857
train_step : 11217, loss1 : 1.702973, loss2 : 1.510142
train_step : 11218, loss1 : 0.833911, loss2 : 1.077008
train_step : 11219, loss1 : 1.162312, loss2 : 1.069088
train_step : 11220, loss1 : 0.817144, loss2 : 1.253892
train_step : 11221, loss1 : 0.984966, loss2 : 0.999079
train_step : 11222, loss1 : 0.913648, loss2 : 1.060613
train_step : 11223, loss1 : 1.556819, loss2 : 0.685634
train_step : 11224, loss1 : 1.258665, loss2 : 1.208266
train_step : 11225, loss1 : 1.906395, loss2 : 0.996965
train_step : 11226, loss1 : 0.956945, loss2 : 0.957145
train_step : 11227, loss1 : 1.075064, loss2 : 0.883512
train_step : 11228, loss1 : 1.560525, loss2 : 1.078275
train_step : 11229, loss1 : 1.392885, loss2 : 0.684191
train_step : 11230, loss1 : 1.346512, loss2 : 0.918972
train_step : 11231, loss1 : 2.210113, loss2 : 1.131581
train_step : 11232, loss1 : 0.759306, loss2 : 1.541468
train_step : 11233, loss1 : 1.935027, loss2 : 1.561153
train_step : 11234, loss1 : 1.783268, loss2 : 0.964860
train_step : 11235, loss1 : 1.544689, loss2 : 1.098579
train_step : 11236, loss1 : 1.358056, loss2 : 1.976050
train_step : 11237, loss1 : 1.247612, loss2 : 1.030685
train_step : 11238, loss1 : 0.777017, loss2 : 0.904157
train_step : 11239, loss1 : 1.286458, loss2 : 1.029751
train_step : 11240, loss1 : 0.887076, loss2 : 1.154877
train_step : 11241, loss1 : 1.230789, loss2 : 1.259439
train_step : 11242, loss1 : 1.327629, loss2 : 1.336527
train_step : 11243, loss1 : 1.689679, loss2 : 1.269238
train_step : 11244, loss1 : 1.401380, loss2 : 1.976717
train_step : 11245, loss1 : 1.143468, loss2 : 1.062226
train_step : 11246, loss1 : 0.986079, loss2 : 1.454425
train_step : 11247, loss1 : 2.215537, loss2 : 1.111490
train_step : 11248, loss1 : 1.197452, loss2 : 1.274276
train_step : 11249, loss1 : 1.315570, loss2 : 1.193784
train_step : 11250, loss1 : 1.248577, loss2 : 1.490043
train_step : 11251, loss1 : 0.936108, loss2 : 0.973193
train_step : 11252, loss1 : 1.433387, loss2 : 1.540641
train_step : 11253, loss1 : 1.097724, loss2 : 1.441491
train_step : 11254, loss1 : 1.338880, loss2 : 1.585434
train_step : 11255, loss1 : 1.028944, loss2 : 0.952161
train_step : 11256, loss1 : 1.135209, loss2 : 1.152145
train_step : 11257, loss1 : 1.025420, loss2 : 1.326212
train_step : 11258, loss1 : 0.893591, loss2 : 1.102703
train_step : 11259, loss1 : 1.336242, loss2 : 0.704094
train_step : 11260, loss1 : 0.746062, loss2 : 1.234647
train_step : 11261, loss1 : 1.184849, loss2 : 2.987056
train_step : 11262, loss1 : 1.768496, loss2 : 2.951019
train_step : 11263, loss1 : 2.578257, loss2 : 1.786572
train_step : 11264, loss1 : 2.899685, loss2 : 2.137476
train_step : 11265, loss1 : 2.476206, loss2 : 2.809692
train_step : 11266, loss1 : 4.001633, loss2 : 1.255782
train_step : 11267, loss1 : 2.581726, loss2 : 2.143507
train_step : 11268, loss1 : 1.903508, loss2 : 1.213057
train_step : 11269, loss1 : 1.633312, loss2 : 1.391359
train_step : 11270, loss1 : 1.945792, loss2 : 1.712961
train_step : 11271, loss1 : 1.168895, loss2 : 1.787053
train_step : 11272, loss1 : 1.360458, loss2 : 1.740827
train_step : 11273, loss1 : 2.124848, loss2 : 1.731622
train_step : 11274, loss1 : 0.902611, loss2 : 1.015434
train_step : 11275, loss1 : 0.944268, loss2 : 1.145144
train_step : 11276, loss1 : 0.995952, loss2 : 1.060932
train_step : 11277, loss1 : 1.437197, loss2 : 1.176021
train_step : 11278, loss1 : 1.367839, loss2 : 1.300129
train_step : 11279, loss1 : 1.481370, loss2 : 1.810990
train_step : 11280, loss1 : 2.229379, loss2 : 2.626723
train_step : 11281, loss1 : 1.890916, loss2 : 3.154058
train_step : 11282, loss1 : 1.518991, loss2 : 1.701487
train_step : 11283, loss1 : 1.440190, loss2 : 2.595197
train_step : 11284, loss1 : 2.629671, loss2 : 2.253268
train_step : 11285, loss1 : 1.624618, loss2 : 1.000471
train_step : 11286, loss1 : 1.231000, loss2 : 2.381015
train_step : 11287, loss1 : 0.784536, loss2 : 0.673143
train_step : 11288, loss1 : 1.283816, loss2 : 0.779819
train_step : 11289, loss1 : 1.389929, loss2 : 0.705715
train_step : 11290, loss1 : 1.341428, loss2 : 2.273529
train_step : 11291, loss1 : 0.805845, loss2 : 0.893643
train_step : 11292, loss1 : 1.021308, loss2 : 1.290896
train_step : 11293, loss1 : 2.020320, loss2 : 2.026606
train_step : 11294, loss1 : 2.329436, loss2 : 3.416192
train_step : 11295, loss1 : 1.176507, loss2 : 1.780686
train_step : 11296, loss1 : 1.578709, loss2 : 2.493941
train_step : 11297, loss1 : 2.228842, loss2 : 1.264001
train_step : 11298, loss1 : 0.728929, loss2 : 1.160276
train_step : 11299, loss1 : 1.544773, loss2 : 1.934077
train_step : 11300, loss1 : 1.732494, loss2 : 4.292861
train_step : 11301, loss1 : 2.560256, loss2 : 2.615886
train_step : 11302, loss1 : 2.266206, loss2 : 0.820665
train_step : 11303, loss1 : 2.726729, loss2 : 3.222888
train_step : 11304, loss1 : 1.178117, loss2 : 2.177227
train_step : 11305, loss1 : 0.675733, loss2 : 1.330405
train_step : 11306, loss1 : 1.496343, loss2 : 1.015513
train_step : 11307, loss1 : 1.298006, loss2 : 0.865730
train_step : 11308, loss1 : 1.044899, loss2 : 0.651332
train_step : 11309, loss1 : 1.388397, loss2 : 1.373499
train_step : 11310, loss1 : 1.252272, loss2 : 1.220667
train_step : 11311, loss1 : 1.146170, loss2 : 1.377893
train_step : 11312, loss1 : 1.407423, loss2 : 0.913864
train_step : 11313, loss1 : 0.555257, loss2 : 1.039990
train_step : 11314, loss1 : 0.656439, loss2 : 1.100385
train_step : 11315, loss1 : 0.674792, loss2 : 1.026557
train_step : 11316, loss1 : 1.361176, loss2 : 1.534246
train_step : 11317, loss1 : 1.161327, loss2 : 1.457933
train_step : 11318, loss1 : 1.476477, loss2 : 1.146611
train_step : 11319, loss1 : 1.182307, loss2 : 1.399516
train_step : 11320, loss1 : 0.918441, loss2 : 3.616165
train_step : 11321, loss1 : 1.025725, loss2 : 1.841674
train_step : 11322, loss1 : 0.769632, loss2 : 1.770258
train_step : 11323, loss1 : 1.204862, loss2 : 1.615011
train_step : 11324, loss1 : 1.278980, loss2 : 1.234852
train_step : 11325, loss1 : 1.164778, loss2 : 1.323139
train_step : 11326, loss1 : 1.998108, loss2 : 1.632525
train_step : 11327, loss1 : 2.311141, loss2 : 2.386813
train_step : 11328, loss1 : 1.276355, loss2 : 2.926037
train_step : 11329, loss1 : 3.510602, loss2 : 2.151566
train_step : 11330, loss1 : 3.967691, loss2 : 3.365531
train_step : 11331, loss1 : 2.359131, loss2 : 2.027249
train_step : 11332, loss1 : 2.070150, loss2 : 2.566293
train_step : 11333, loss1 : 1.957560, loss2 : 1.656747
train_step : 11334, loss1 : 1.686298, loss2 : 2.272590
train_step : 11335, loss1 : 1.235398, loss2 : 1.208690
train_step : 11336, loss1 : 0.925953, loss2 : 1.230349
train_step : 11337, loss1 : 1.090649, loss2 : 1.169836
train_step : 11338, loss1 : 3.392754, loss2 : 0.989592
train_step : 11339, loss1 : 1.838915, loss2 : 1.961225
train_step : 11340, loss1 : 1.725814, loss2 : 1.345384
train_step : 11341, loss1 : 1.521089, loss2 : 0.955284
train_step : 11342, loss1 : 0.515275, loss2 : 1.525224
train_step : 11343, loss1 : 1.287928, loss2 : 1.040962
train_step : 11344, loss1 : 1.184381, loss2 : 2.557309
train_step : 11345, loss1 : 1.755311, loss2 : 1.774898
train_step : 11346, loss1 : 2.077927, loss2 : 1.813158
train_step : 11347, loss1 : 0.881075, loss2 : 1.069894
train_step : 11348, loss1 : 0.710447, loss2 : 1.523053
train_step : 11349, loss1 : 0.717347, loss2 : 0.607228
train_step : 11350, loss1 : 1.254604, loss2 : 1.189793
train_step : 11351, loss1 : 2.348667, loss2 : 1.284045
train_step : 11352, loss1 : 2.062203, loss2 : 1.753940
train_step : 11353, loss1 : 2.275127, loss2 : 2.231241
train_step : 11354, loss1 : 2.666284, loss2 : 2.446746
train_step : 11355, loss1 : 4.467254, loss2 : 4.043791
train_step : 11356, loss1 : 2.994007, loss2 : 2.689773
train_step : 11357, loss1 : 2.591812, loss2 : 3.925291
train_step : 11358, loss1 : 2.047531, loss2 : 1.271200
train_step : 11359, loss1 : 2.578525, loss2 : 1.568217
train_step : 11360, loss1 : 1.119783, loss2 : 1.316293
train_step : 11361, loss1 : 1.649744, loss2 : 1.132487
train_step : 11362, loss1 : 1.360380, loss2 : 2.664506
train_step : 11363, loss1 : 1.310277, loss2 : 1.354730
train_step : 11364, loss1 : 1.777267, loss2 : 4.140861
train_step : 11365, loss1 : 1.640897, loss2 : 1.239402
train_step : 11366, loss1 : 1.142409, loss2 : 1.749724
train_step : 11367, loss1 : 1.549430, loss2 : 1.938701
train_step : 11368, loss1 : 1.064049, loss2 : 1.499251
train_step : 11369, loss1 : 1.678574, loss2 : 1.001133
train_step : 11370, loss1 : 0.804255, loss2 : 0.543422
train_step : 11371, loss1 : 1.115991, loss2 : 1.925253
train_step : 11372, loss1 : 1.359351, loss2 : 0.661056
train_step : 11373, loss1 : 1.767667, loss2 : 1.472457
train_step : 11374, loss1 : 1.073880, loss2 : 2.326258
train_step : 11375, loss1 : 2.295078, loss2 : 1.736884
train_step : 11376, loss1 : 2.043040, loss2 : 1.554983
train_step : 11377, loss1 : 1.356762, loss2 : 1.198633
train_step : 11378, loss1 : 0.596716, loss2 : 1.429980
train_step : 11379, loss1 : 1.155822, loss2 : 1.010760
train_step : 11380, loss1 : 0.883005, loss2 : 1.297249
train_step : 11381, loss1 : 1.459794, loss2 : 1.189434
train_step : 11382, loss1 : 1.965124, loss2 : 1.537270
train_step : 11383, loss1 : 1.981193, loss2 : 1.255619
train_step : 11384, loss1 : 2.093381, loss2 : 1.000588
train_step : 11385, loss1 : 2.241593, loss2 : 1.088492
train_step : 11386, loss1 : 2.478929, loss2 : 0.764713
train_step : 11387, loss1 : 2.207375, loss2 : 1.172783
train_step : 11388, loss1 : 0.878106, loss2 : 0.598635
train_step : 11389, loss1 : 2.953585, loss2 : 0.894084
train_step : 11390, loss1 : 0.699181, loss2 : 0.856546
train_step : 11391, loss1 : 2.227438, loss2 : 1.658320
train_step : 11392, loss1 : 1.638521, loss2 : 1.459848
train_step : 11393, loss1 : 0.695775, loss2 : 1.685202
train_step : 11394, loss1 : 1.260024, loss2 : 1.231826
train_step : 11395, loss1 : 0.778474, loss2 : 1.504251
train_step : 11396, loss1 : 1.075856, loss2 : 1.751394
train_step : 11397, loss1 : 0.853585, loss2 : 1.439592
train_step : 11398, loss1 : 0.997893, loss2 : 1.196299
train_step : 11399, loss1 : 1.112651, loss2 : 1.304242
train_step : 11400, loss1 : 1.263246, loss2 : 1.460763
train_step : 11401, loss1 : 1.076785, loss2 : 1.578695
train_step : 11402, loss1 : 1.668547, loss2 : 1.486149
train_step : 11403, loss1 : 0.738364, loss2 : 1.525814
train_step : 11404, loss1 : 2.013507, loss2 : 1.634621
train_step : 11405, loss1 : 1.425447, loss2 : 1.414337
train_step : 11406, loss1 : 0.966878, loss2 : 0.695314
train_step : 11407, loss1 : 1.473631, loss2 : 1.381770
train_step : 11408, loss1 : 1.294051, loss2 : 0.858925
train_step : 11409, loss1 : 0.980025, loss2 : 1.428650
train_step : 11410, loss1 : 1.509402, loss2 : 1.037182
train_step : 11411, loss1 : 0.879318, loss2 : 1.232796
train_step : 11412, loss1 : 1.095468, loss2 : 1.412661
train_step : 11413, loss1 : 1.386456, loss2 : 1.308313
train_step : 11414, loss1 : 0.988863, loss2 : 0.815300
train_step : 11415, loss1 : 1.029310, loss2 : 1.291832
train_step : 11416, loss1 : 0.790240, loss2 : 1.434630
train_step : 11417, loss1 : 1.256570, loss2 : 0.729978
train_step : 11418, loss1 : 1.462024, loss2 : 1.051479
train_step : 11419, loss1 : 0.556464, loss2 : 0.618325
train_step : 11420, loss1 : 1.116614, loss2 : 1.638330
train_step : 11421, loss1 : 1.242350, loss2 : 0.805027
train_step : 11422, loss1 : 0.965976, loss2 : 1.531364
train_step : 11423, loss1 : 1.025377, loss2 : 1.654905
train_step : 11424, loss1 : 1.627043, loss2 : 0.930142
train_step : 11425, loss1 : 2.801494, loss2 : 2.451354
train_step : 11426, loss1 : 4.311976, loss2 : 4.714465
train_step : 11427, loss1 : 4.790006, loss2 : 5.366422
train_step : 11428, loss1 : 2.972944, loss2 : 2.750242
train_step : 11429, loss1 : 1.447284, loss2 : 3.410601
train_step : 11430, loss1 : 2.247969, loss2 : 1.834135
train_step : 11431, loss1 : 2.308992, loss2 : 3.679399
train_step : 11432, loss1 : 1.655620, loss2 : 1.552430
train_step : 11433, loss1 : 2.620382, loss2 : 1.948259
train_step : 11434, loss1 : 1.545702, loss2 : 1.511712
train_step : 11435, loss1 : 0.863238, loss2 : 0.871590
train_step : 11436, loss1 : 0.907021, loss2 : 1.004502
train_step : 11437, loss1 : 1.384431, loss2 : 1.125723
train_step : 11438, loss1 : 0.882907, loss2 : 2.029553
train_step : 11439, loss1 : 1.683312, loss2 : 0.719094
train_step : 11440, loss1 : 1.279744, loss2 : 1.483041
train_step : 11441, loss1 : 1.366198, loss2 : 1.180121
train_step : 11442, loss1 : 1.197521, loss2 : 1.602095
train_step : 11443, loss1 : 1.779773, loss2 : 3.080309
train_step : 11444, loss1 : 2.105787, loss2 : 1.178986
train_step : 11445, loss1 : 1.188643, loss2 : 1.474465
train_step : 11446, loss1 : 2.070492, loss2 : 0.896118
train_step : 11447, loss1 : 1.223346, loss2 : 1.679705
train_step : 11448, loss1 : 1.173117, loss2 : 1.489095
train_step : 11449, loss1 : 1.235889, loss2 : 1.559012
train_step : 11450, loss1 : 2.047864, loss2 : 0.853748
train_step : 11451, loss1 : 1.100163, loss2 : 1.669341
train_step : 11452, loss1 : 1.127704, loss2 : 1.178152
train_step : 11453, loss1 : 0.983691, loss2 : 1.359731
train_step : 11454, loss1 : 1.200637, loss2 : 0.843807
train_step : 11455, loss1 : 1.717004, loss2 : 1.509196
train_step : 11456, loss1 : 1.680427, loss2 : 0.773893
train_step : 11457, loss1 : 0.989993, loss2 : 1.718077
train_step : 11458, loss1 : 1.386093, loss2 : 0.774827
train_step : 11459, loss1 : 0.675410, loss2 : 1.238948
train_step : 11460, loss1 : 1.283387, loss2 : 0.829091
train_step : 11461, loss1 : 0.842581, loss2 : 1.226202
train_step : 11462, loss1 : 0.974979, loss2 : 1.208306
train_step : 11463, loss1 : 1.753399, loss2 : 1.277905
train_step : 11464, loss1 : 0.885526, loss2 : 1.040367
train_step : 11465, loss1 : 1.673303, loss2 : 1.212847
train_step : 11466, loss1 : 1.062427, loss2 : 2.301809
train_step : 11467, loss1 : 2.931455, loss2 : 3.523849
train_step : 11468, loss1 : 0.817829, loss2 : 1.124456
train_step : 11469, loss1 : 1.119125, loss2 : 0.838428
train_step : 11470, loss1 : 1.620340, loss2 : 1.885828
train_step : 11471, loss1 : 3.565808, loss2 : 1.555298
train_step : 11472, loss1 : 1.093306, loss2 : 1.051306
train_step : 11473, loss1 : 0.489970, loss2 : 0.906551
train_step : 11474, loss1 : 1.152448, loss2 : 1.542446
train_step : 11475, loss1 : 1.052520, loss2 : 1.470931
train_step : 11476, loss1 : 1.279855, loss2 : 1.967219
train_step : 11477, loss1 : 2.210150, loss2 : 2.960267
train_step : 11478, loss1 : 1.476512, loss2 : 1.216386
train_step : 11479, loss1 : 1.472282, loss2 : 1.995145
train_step : 11480, loss1 : 0.788801, loss2 : 1.526821
train_step : 11481, loss1 : 1.325464, loss2 : 0.681192
train_step : 11482, loss1 : 0.645812, loss2 : 1.590879
train_step : 11483, loss1 : 1.221225, loss2 : 0.731317
train_step : 11484, loss1 : 1.379108, loss2 : 1.973428
train_step : 11485, loss1 : 2.319906, loss2 : 2.658965
train_step : 11486, loss1 : 2.285262, loss2 : 2.425518
train_step : 11487, loss1 : 1.863634, loss2 : 1.751974
train_step : 11488, loss1 : 1.293120, loss2 : 1.162622
train_step : 11489, loss1 : 1.182346, loss2 : 0.727596
train_step : 11490, loss1 : 1.212395, loss2 : 1.208173
train_step : 11491, loss1 : 1.026156, loss2 : 1.554935
train_step : 11492, loss1 : 1.826324, loss2 : 0.719191
train_step : 11493, loss1 : 1.226817, loss2 : 1.105636
train_step : 11494, loss1 : 0.807139, loss2 : 1.153794
train_step : 11495, loss1 : 0.562198, loss2 : 1.640750
train_step : 11496, loss1 : 0.839367, loss2 : 0.773191
train_step : 11497, loss1 : 1.129544, loss2 : 0.953353
train_step : 11498, loss1 : 0.940803, loss2 : 1.230208
train_step : 11499, loss1 : 1.157622, loss2 : 0.591605
train_step : 11500, loss1 : 0.819363, loss2 : 0.574408
train_step : 11501, loss1 : 1.125106, loss2 : 1.188889
train_step : 11502, loss1 : 1.162162, loss2 : 0.980797
train_step : 11503, loss1 : 0.829362, loss2 : 0.717187
train_step : 11504, loss1 : 0.965398, loss2 : 1.414460
train_step : 11505, loss1 : 1.509809, loss2 : 1.301122
train_step : 11506, loss1 : 1.206576, loss2 : 1.238818
train_step : 11507, loss1 : 0.961768, loss2 : 1.792550
train_step : 11508, loss1 : 2.003264, loss2 : 1.365039
train_step : 11509, loss1 : 1.789098, loss2 : 1.666855
train_step : 11510, loss1 : 1.234341, loss2 : 2.620651
train_step : 11511, loss1 : 0.925624, loss2 : 0.307764
train_step : 11512, loss1 : 0.813278, loss2 : 0.986931
train_step : 11513, loss1 : 1.167827, loss2 : 1.239145
train_step : 11514, loss1 : 0.441817, loss2 : 0.863926
train_step : 11515, loss1 : 0.720517, loss2 : 2.218055
train_step : 11516, loss1 : 1.245006, loss2 : 1.110882
train_step : 11517, loss1 : 0.861766, loss2 : 0.967046
train_step : 11518, loss1 : 0.999934, loss2 : 1.392594
train_step : 11519, loss1 : 1.019155, loss2 : 1.211758
train_step : 11520, loss1 : 4.668887, loss2 : 1.141650
train_step : 11521, loss1 : 2.101735, loss2 : 1.891594
train_step : 11522, loss1 : 2.754479, loss2 : 4.541065
train_step : 11523, loss1 : 3.759691, loss2 : 3.122573
train_step : 11524, loss1 : 2.545063, loss2 : 2.566785
train_step : 11525, loss1 : 2.764239, loss2 : 1.582710
train_step : 11526, loss1 : 3.891436, loss2 : 2.140789
train_step : 11527, loss1 : 1.945430, loss2 : 3.625557
train_step : 11528, loss1 : 2.566904, loss2 : 0.997007
train_step : 11529, loss1 : 1.506792, loss2 : 1.006455
train_step : 11530, loss1 : 1.667766, loss2 : 0.875218
train_step : 11531, loss1 : 0.747748, loss2 : 1.019542
train_step : 11532, loss1 : 2.084711, loss2 : 1.209199
train_step : 11533, loss1 : 0.900998, loss2 : 1.294192
train_step : 11534, loss1 : 0.997877, loss2 : 1.582853
train_step : 11535, loss1 : 1.062690, loss2 : 0.975006
train_step : 11536, loss1 : 0.776819, loss2 : 0.869009
train_step : 11537, loss1 : 0.865255, loss2 : 2.006763
train_step : 11538, loss1 : 0.817469, loss2 : 0.856009
train_step : 11539, loss1 : 0.870464, loss2 : 1.212590
train_step : 11540, loss1 : 1.189124, loss2 : 0.581373
train_step : 11541, loss1 : 1.052145, loss2 : 1.314178
train_step : 11542, loss1 : 1.428339, loss2 : 1.614723
train_step : 11543, loss1 : 0.926717, loss2 : 1.296397
train_step : 11544, loss1 : 1.310578, loss2 : 1.400130
train_step : 11545, loss1 : 0.864315, loss2 : 1.738920
train_step : 11546, loss1 : 0.699744, loss2 : 0.759748
train_step : 11547, loss1 : 2.746961, loss2 : 1.254560
train_step : 11548, loss1 : 2.588560, loss2 : 4.200343
train_step : 11549, loss1 : 3.130775, loss2 : 3.237504
train_step : 11550, loss1 : 2.567056, loss2 : 1.890403
train_step : 11551, loss1 : 1.326674, loss2 : 1.351107
train_step : 11552, loss1 : 1.182305, loss2 : 2.369607
train_step : 11553, loss1 : 1.273786, loss2 : 1.618937
train_step : 11554, loss1 : 1.338477, loss2 : 1.389272
train_step : 11555, loss1 : 2.340846, loss2 : 0.855094
train_step : 11556, loss1 : 1.082197, loss2 : 2.250132
train_step : 11557, loss1 : 1.382532, loss2 : 1.536694
train_step : 11558, loss1 : 2.231034, loss2 : 2.466195
train_step : 11559, loss1 : 1.710515, loss2 : 2.666185
train_step : 11560, loss1 : 1.142468, loss2 : 1.528261
train_step : 11561, loss1 : 1.354926, loss2 : 0.939900
train_step : 11562, loss1 : 1.526952, loss2 : 2.013427
train_step : 11563, loss1 : 1.070594, loss2 : 2.487071
train_step : 11564, loss1 : 0.506024, loss2 : 0.660060
train_step : 11565, loss1 : 1.124269, loss2 : 1.173279
train_step : 11566, loss1 : 1.684498, loss2 : 1.055487
train_step : 11567, loss1 : 0.804896, loss2 : 1.313580
train_step : 11568, loss1 : 1.221093, loss2 : 1.323325
train_step : 11569, loss1 : 2.236410, loss2 : 2.995258
train_step : 11570, loss1 : 3.324965, loss2 : 2.668016
train_step : 11571, loss1 : 2.493651, loss2 : 2.122841
train_step : 11572, loss1 : 1.749455, loss2 : 2.576315
train_step : 11573, loss1 : 1.837299, loss2 : 1.746832
train_step : 11574, loss1 : 1.175643, loss2 : 1.662755
train_step : 11575, loss1 : 1.961384, loss2 : 1.054022
train_step : 11576, loss1 : 1.554517, loss2 : 1.426276
train_step : 11577, loss1 : 2.183724, loss2 : 6.267288
train_step : 11578, loss1 : 2.198174, loss2 : 1.991044
train_step : 11579, loss1 : 1.781357, loss2 : 0.692322
train_step : 11580, loss1 : 1.909413, loss2 : 1.070156
train_step : 11581, loss1 : 1.428202, loss2 : 2.987724
train_step : 11582, loss1 : 1.608950, loss2 : 1.893417
train_step : 11583, loss1 : 0.935385, loss2 : 0.934038
train_step : 11584, loss1 : 1.642066, loss2 : 1.121688
train_step : 11585, loss1 : 0.794769, loss2 : 0.923437
train_step : 11586, loss1 : 0.750079, loss2 : 0.806006
train_step : 11587, loss1 : 1.032109, loss2 : 0.998652
train_step : 11588, loss1 : 0.927423, loss2 : 1.227550
train_step : 11589, loss1 : 2.016396, loss2 : 1.115854
train_step : 11590, loss1 : 1.177719, loss2 : 0.885470
train_step : 11591, loss1 : 0.744781, loss2 : 1.692124
train_step : 11592, loss1 : 0.790021, loss2 : 1.193350
train_step : 11593, loss1 : 1.113419, loss2 : 0.786961
train_step : 11594, loss1 : 1.179279, loss2 : 1.700664
train_step : 11595, loss1 : 1.557541, loss2 : 0.656845
train_step : 11596, loss1 : 1.246076, loss2 : 1.646749
train_step : 11597, loss1 : 1.791140, loss2 : 2.028995
train_step : 11598, loss1 : 3.142080, loss2 : 1.165558
train_step : 11599, loss1 : 2.594775, loss2 : 1.215897
train_step : 11600, loss1 : 0.991450, loss2 : 1.429929
train_step : 11601, loss1 : 1.177209, loss2 : 1.194085
train_step : 11602, loss1 : 0.832777, loss2 : 1.282584
train_step : 11603, loss1 : 1.089206, loss2 : 1.029116
train_step : 11604, loss1 : 1.410772, loss2 : 0.912366
train_step : 11605, loss1 : 0.964496, loss2 : 1.309647
train_step : 11606, loss1 : 0.866238, loss2 : 1.331176
train_step : 11607, loss1 : 1.039323, loss2 : 0.961882
train_step : 11608, loss1 : 0.603575, loss2 : 0.944327
train_step : 11609, loss1 : 1.135749, loss2 : 0.689314
train_step : 11610, loss1 : 0.992560, loss2 : 1.723702
train_step : 11611, loss1 : 1.788953, loss2 : 3.000963
train_step : 11612, loss1 : 1.553985, loss2 : 2.382200
train_step : 11613, loss1 : 2.139497, loss2 : 1.137623
train_step : 11614, loss1 : 0.905209, loss2 : 1.114336
train_step : 11615, loss1 : 1.677201, loss2 : 0.708064
train_step : 11616, loss1 : 1.754985, loss2 : 0.612284
train_step : 11617, loss1 : 1.395059, loss2 : 1.591652
train_step : 11618, loss1 : 0.761852, loss2 : 0.874484
train_step : 11619, loss1 : 1.605023, loss2 : 1.238976
train_step : 11620, loss1 : 1.045870, loss2 : 1.112593
train_step : 11621, loss1 : 2.239630, loss2 : 1.747725
train_step : 11622, loss1 : 1.712951, loss2 : 1.223331
train_step : 11623, loss1 : 1.890849, loss2 : 1.535539
train_step : 11624, loss1 : 1.448254, loss2 : 1.186609
train_step : 11625, loss1 : 1.098246, loss2 : 1.448669
train_step : 11626, loss1 : 1.687408, loss2 : 0.579944
train_step : 11627, loss1 : 1.744035, loss2 : 0.815459
train_step : 11628, loss1 : 1.004458, loss2 : 1.019483
train_step : 11629, loss1 : 0.764060, loss2 : 1.194432
train_step : 11630, loss1 : 0.926182, loss2 : 0.780367
train_step : 11631, loss1 : 1.304643, loss2 : 2.075906
train_step : 11632, loss1 : 2.058441, loss2 : 2.144878
train_step : 11633, loss1 : 2.075102, loss2 : 1.842499
train_step : 11634, loss1 : 0.855671, loss2 : 1.758222
train_step : 11635, loss1 : 0.453698, loss2 : 1.592754
train_step : 11636, loss1 : 1.528255, loss2 : 0.855130
train_step : 11637, loss1 : 1.295642, loss2 : 1.481823
train_step : 11638, loss1 : 1.333085, loss2 : 0.605548
train_step : 11639, loss1 : 0.862893, loss2 : 0.824899
train_step : 11640, loss1 : 1.298117, loss2 : 0.964188
train_step : 11641, loss1 : 0.810641, loss2 : 1.415533
train_step : 11642, loss1 : 0.884834, loss2 : 1.061252
train_step : 11643, loss1 : 1.157582, loss2 : 1.080082
train_step : 11644, loss1 : 2.388426, loss2 : 1.524183
train_step : 11645, loss1 : 1.455586, loss2 : 3.241658
train_step : 11646, loss1 : 2.569349, loss2 : 1.607020
train_step : 11647, loss1 : 1.440558, loss2 : 3.116411
train_step : 11648, loss1 : 2.402806, loss2 : 1.499226
train_step : 11649, loss1 : 1.611799, loss2 : 0.818102
train_step : 11650, loss1 : 1.928340, loss2 : 1.649524
train_step : 11651, loss1 : 1.029749, loss2 : 2.257353
train_step : 11652, loss1 : 0.884092, loss2 : 1.175770
train_step : 11653, loss1 : 1.577703, loss2 : 0.848784
train_step : 11654, loss1 : 1.291708, loss2 : 0.714098
train_step : 11655, loss1 : 1.106634, loss2 : 0.997137
train_step : 11656, loss1 : 0.729684, loss2 : 1.545035
train_step : 11657, loss1 : 1.630682, loss2 : 1.676792
train_step : 11658, loss1 : 1.302994, loss2 : 1.052981
train_step : 11659, loss1 : 0.993475, loss2 : 0.606919
train_step : 11660, loss1 : 0.736808, loss2 : 1.255269
train_step : 11661, loss1 : 2.273497, loss2 : 1.235245
train_step : 11662, loss1 : 1.243180, loss2 : 1.091453
train_step : 11663, loss1 : 1.463041, loss2 : 1.371716
train_step : 11664, loss1 : 1.224695, loss2 : 0.883888
train_step : 11665, loss1 : 0.842153, loss2 : 1.519884
train_step : 11666, loss1 : 0.493275, loss2 : 0.705928
train_step : 11667, loss1 : 1.061420, loss2 : 0.718703
train_step : 11668, loss1 : 1.116650, loss2 : 1.278108
train_step : 11669, loss1 : 1.888478, loss2 : 1.485637
train_step : 11670, loss1 : 1.490060, loss2 : 2.001122
train_step : 11671, loss1 : 1.922437, loss2 : 0.904280
train_step : 11672, loss1 : 0.813305, loss2 : 1.980539
train_step : 11673, loss1 : 0.850401, loss2 : 1.669721
train_step : 11674, loss1 : 1.270504, loss2 : 1.299987
train_step : 11675, loss1 : 1.133935, loss2 : 1.619451
train_step : 11676, loss1 : 1.908885, loss2 : 1.136940
train_step : 11677, loss1 : 2.024342, loss2 : 2.184314
train_step : 11678, loss1 : 0.872183, loss2 : 1.792083
train_step : 11679, loss1 : 1.461336, loss2 : 1.435665
train_step : 11680, loss1 : 1.260617, loss2 : 0.956758
train_step : 11681, loss1 : 1.474871, loss2 : 1.120332
train_step : 11682, loss1 : 1.644029, loss2 : 0.424021
train_step : 11683, loss1 : 1.438766, loss2 : 1.771178
train_step : 11684, loss1 : 1.903789, loss2 : 1.973026
train_step : 11685, loss1 : 2.102848, loss2 : 3.542982
train_step : 11686, loss1 : 3.550805, loss2 : 4.257784
train_step : 11687, loss1 : 3.571497, loss2 : 2.773468
train_step : 11688, loss1 : 1.886172, loss2 : 2.132400
train_step : 11689, loss1 : 2.430700, loss2 : 2.101453
train_step : 11690, loss1 : 2.002224, loss2 : 2.405983
train_step : 11691, loss1 : 2.077576, loss2 : 2.319123
train_step : 11692, loss1 : 0.860223, loss2 : 1.830140
train_step : 11693, loss1 : 1.216802, loss2 : 2.811616
train_step : 11694, loss1 : 1.490941, loss2 : 1.438858
train_step : 11695, loss1 : 1.276419, loss2 : 0.482748
train_step : 11696, loss1 : 0.832331, loss2 : 1.032602
train_step : 11697, loss1 : 1.537313, loss2 : 1.116863
train_step : 11698, loss1 : 0.611410, loss2 : 2.180745
train_step : 11699, loss1 : 3.127970, loss2 : 1.337287
train_step : 11700, loss1 : 1.844335, loss2 : 2.465228
train_step : 11701, loss1 : 1.887118, loss2 : 1.509494
train_step : 11702, loss1 : 0.941635, loss2 : 0.931087
train_step : 11703, loss1 : 1.377370, loss2 : 0.984147
train_step : 11704, loss1 : 1.131487, loss2 : 0.778484
train_step : 11705, loss1 : 0.973921, loss2 : 0.894944
train_step : 11706, loss1 : 1.878717, loss2 : 1.316569
train_step : 11707, loss1 : 0.946415, loss2 : 0.709224
train_step : 11708, loss1 : 0.836567, loss2 : 1.819450
train_step : 11709, loss1 : 1.384329, loss2 : 1.075437
train_step : 11710, loss1 : 0.997390, loss2 : 2.097466
train_step : 11711, loss1 : 0.637865, loss2 : 2.188425
train_step : 11712, loss1 : 1.744227, loss2 : 1.300711
train_step : 11713, loss1 : 0.929593, loss2 : 2.035115
train_step : 11714, loss1 : 1.843308, loss2 : 1.899854
train_step : 11715, loss1 : 2.130618, loss2 : 1.577802
train_step : 11716, loss1 : 1.732894, loss2 : 1.610393
train_step : 11717, loss1 : 1.366679, loss2 : 1.904920
train_step : 11718, loss1 : 1.801968, loss2 : 1.390486
train_step : 11719, loss1 : 1.546616, loss2 : 0.645324
train_step : 11720, loss1 : 1.445727, loss2 : 1.590066
train_step : 11721, loss1 : 1.468485, loss2 : 1.329180
train_step : 11722, loss1 : 1.789049, loss2 : 2.403262
train_step : 11723, loss1 : 3.068605, loss2 : 2.202615
train_step : 11724, loss1 : 2.947317, loss2 : 3.673215
train_step : 11725, loss1 : 2.179280, loss2 : 2.046375
train_step : 11726, loss1 : 1.320456, loss2 : 1.901538
train_step : 11727, loss1 : 1.657633, loss2 : 1.465486
train_step : 11728, loss1 : 1.754740, loss2 : 1.021565
train_step : 11729, loss1 : 0.839927, loss2 : 1.026543
train_step : 11730, loss1 : 1.143236, loss2 : 1.491003
train_step : 11731, loss1 : 0.838515, loss2 : 1.006782
train_step : 11732, loss1 : 1.173255, loss2 : 1.129375
train_step : 11733, loss1 : 1.133865, loss2 : 0.827708
train_step : 11734, loss1 : 0.929417, loss2 : 0.694003
train_step : 11735, loss1 : 1.355341, loss2 : 1.187370
train_step : 11736, loss1 : 1.210319, loss2 : 1.443965
train_step : 11737, loss1 : 0.531653, loss2 : 1.107218
train_step : 11738, loss1 : 0.826821, loss2 : 1.102848
train_step : 11739, loss1 : 0.499941, loss2 : 0.728447
train_step : 11740, loss1 : 1.040133, loss2 : 0.660062
train_step : 11741, loss1 : 1.463290, loss2 : 1.326100
train_step : 11742, loss1 : 1.249760, loss2 : 1.230039
train_step : 11743, loss1 : 1.085783, loss2 : 1.218346
train_step : 11744, loss1 : 0.467663, loss2 : 1.274149
train_step : 11745, loss1 : 1.167147, loss2 : 0.782605
train_step : 11746, loss1 : 1.226197, loss2 : 1.784912
train_step : 11747, loss1 : 0.913733, loss2 : 0.675927
train_step : 11748, loss1 : 1.006840, loss2 : 1.716411
train_step : 11749, loss1 : 1.057850, loss2 : 1.010994
train_step : 11750, loss1 : 1.240567, loss2 : 4.460666
train_step : 11751, loss1 : 1.360939, loss2 : 1.273397
train_step : 11752, loss1 : 1.457334, loss2 : 1.945008
train_step : 11753, loss1 : 2.595589, loss2 : 1.537606
train_step : 11754, loss1 : 1.531272, loss2 : 1.725051
train_step : 11755, loss1 : 0.990287, loss2 : 2.027208
train_step : 11756, loss1 : 1.058098, loss2 : 1.576001
train_step : 11757, loss1 : 1.171449, loss2 : 1.536533
train_step : 11758, loss1 : 1.192063, loss2 : 1.676100
train_step : 11759, loss1 : 0.934772, loss2 : 1.157857
train_step : 11760, loss1 : 0.994412, loss2 : 1.133022
train_step : 11761, loss1 : 0.477157, loss2 : 1.110532
train_step : 11762, loss1 : 1.678132, loss2 : 0.751819
train_step : 11763, loss1 : 1.066871, loss2 : 0.951066
train_step : 11764, loss1 : 1.131328, loss2 : 0.707495
train_step : 11765, loss1 : 1.002192, loss2 : 1.247292
train_step : 11766, loss1 : 1.533638, loss2 : 0.836239
train_step : 11767, loss1 : 1.323529, loss2 : 2.058589
train_step : 11768, loss1 : 0.517745, loss2 : 0.984605
train_step : 11769, loss1 : 1.062130, loss2 : 1.061394
train_step : 11770, loss1 : 0.776284, loss2 : 0.671126
train_step : 11771, loss1 : 2.266943, loss2 : 0.988924
train_step : 11772, loss1 : 1.135793, loss2 : 0.979735
train_step : 11773, loss1 : 2.373503, loss2 : 1.051599
train_step : 11774, loss1 : 1.355310, loss2 : 1.170609
train_step : 11775, loss1 : 1.567232, loss2 : 1.517910
train_step : 11776, loss1 : 1.619429, loss2 : 2.384757
train_step : 11777, loss1 : 1.700209, loss2 : 1.699438
train_step : 11778, loss1 : 1.124431, loss2 : 1.070238
train_step : 11779, loss1 : 0.953302, loss2 : 1.055260
train_step : 11780, loss1 : 0.951552, loss2 : 1.184555
train_step : 11781, loss1 : 0.816820, loss2 : 1.053661
train_step : 11782, loss1 : 2.200431, loss2 : 1.172445
train_step : 11783, loss1 : 1.726437, loss2 : 1.358421
train_step : 11784, loss1 : 1.099066, loss2 : 1.038390
train_step : 11785, loss1 : 1.067329, loss2 : 0.746701
train_step : 11786, loss1 : 1.138255, loss2 : 0.815724
train_step : 11787, loss1 : 1.182894, loss2 : 1.164648
train_step : 11788, loss1 : 1.686473, loss2 : 0.645462
train_step : 11789, loss1 : 1.243983, loss2 : 0.845840
train_step : 11790, loss1 : 1.266116, loss2 : 1.310627
train_step : 11791, loss1 : 0.904375, loss2 : 1.680713
train_step : 11792, loss1 : 1.135355, loss2 : 1.342944
train_step : 11793, loss1 : 0.827942, loss2 : 0.953773
train_step : 11794, loss1 : 0.811601, loss2 : 0.764468
train_step : 11795, loss1 : 0.574165, loss2 : 1.109323
train_step : 11796, loss1 : 0.638901, loss2 : 1.136226
train_step : 11797, loss1 : 1.130099, loss2 : 1.612528
train_step : 11798, loss1 : 1.804044, loss2 : 1.247539
train_step : 11799, loss1 : 1.658784, loss2 : 0.656074
train_step : 11800, loss1 : 0.792812, loss2 : 0.584295
train_step : 11801, loss1 : 0.503433, loss2 : 1.153160
train_step : 11802, loss1 : 1.502928, loss2 : 1.089670
train_step : 11803, loss1 : 0.782112, loss2 : 1.268774
train_step : 11804, loss1 : 0.700992, loss2 : 1.450164
train_step : 11805, loss1 : 0.784509, loss2 : 2.160699
train_step : 11806, loss1 : 0.889367, loss2 : 0.685226
train_step : 11807, loss1 : 1.068701, loss2 : 0.882904
train_step : 11808, loss1 : 1.790957, loss2 : 1.681525
train_step : 11809, loss1 : 0.693427, loss2 : 1.111215
train_step : 11810, loss1 : 1.624652, loss2 : 0.828943
train_step : 11811, loss1 : 1.902952, loss2 : 1.007688
train_step : 11812, loss1 : 1.515214, loss2 : 1.545946
train_step : 11813, loss1 : 1.059991, loss2 : 0.754856
train_step : 11814, loss1 : 1.648388, loss2 : 1.067269
train_step : 11815, loss1 : 1.563537, loss2 : 1.245566
train_step : 11816, loss1 : 1.317978, loss2 : 1.083399
train_step : 11817, loss1 : 1.149805, loss2 : 1.315684
train_step : 11818, loss1 : 1.201710, loss2 : 0.854041
train_step : 11819, loss1 : 1.073491, loss2 : 0.522888
train_step : 11820, loss1 : 1.124836, loss2 : 0.521622
train_step : 11821, loss1 : 1.279963, loss2 : 1.234360
train_step : 11822, loss1 : 1.326034, loss2 : 0.586376
train_step : 11823, loss1 : 1.151283, loss2 : 1.168859
train_step : 11824, loss1 : 1.976439, loss2 : 0.468376
train_step : 11825, loss1 : 2.745449, loss2 : 1.193767
train_step : 11826, loss1 : 2.078803, loss2 : 2.405822
train_step : 11827, loss1 : 2.242679, loss2 : 1.899903
train_step : 11828, loss1 : 1.771326, loss2 : 1.655241
train_step : 11829, loss1 : 1.236773, loss2 : 1.023227
train_step : 11830, loss1 : 1.515024, loss2 : 1.054214
train_step : 11831, loss1 : 2.700855, loss2 : 1.730540
train_step : 11832, loss1 : 1.516717, loss2 : 2.229387
train_step : 11833, loss1 : 1.644933, loss2 : 0.846858
train_step : 11834, loss1 : 0.762446, loss2 : 1.210511
train_step : 11835, loss1 : 1.162801, loss2 : 1.221839
train_step : 11836, loss1 : 1.390686, loss2 : 1.218321
train_step : 11837, loss1 : 0.600385, loss2 : 1.196123
train_step : 11838, loss1 : 1.648386, loss2 : 0.493470
train_step : 11839, loss1 : 1.265479, loss2 : 1.441107
train_step : 11840, loss1 : 1.425741, loss2 : 1.405535
train_step : 11841, loss1 : 1.739659, loss2 : 1.532649
train_step : 11842, loss1 : 1.349486, loss2 : 0.842163
train_step : 11843, loss1 : 1.409461, loss2 : 1.311940
train_step : 11844, loss1 : 1.184023, loss2 : 1.126366
train_step : 11845, loss1 : 1.715034, loss2 : 1.126463
train_step : 11846, loss1 : 1.088029, loss2 : 0.807342
train_step : 11847, loss1 : 1.008324, loss2 : 1.425108
train_step : 11848, loss1 : 1.569597, loss2 : 1.665599
train_step : 11849, loss1 : 1.008026, loss2 : 1.219547
train_step : 11850, loss1 : 1.037888, loss2 : 1.171294
train_step : 11851, loss1 : 1.026362, loss2 : 0.898912
train_step : 11852, loss1 : 2.071103, loss2 : 1.687137
train_step : 11853, loss1 : 1.195631, loss2 : 1.276536
train_step : 11854, loss1 : 1.677589, loss2 : 1.925728
train_step : 11855, loss1 : 2.746110, loss2 : 2.354538
train_step : 11856, loss1 : 4.395401, loss2 : 4.741885
train_step : 11857, loss1 : 5.180533, loss2 : 7.495789
train_step : 11858, loss1 : 4.703740, loss2 : 4.208436
train_step : 11859, loss1 : 4.578464, loss2 : 6.058192
train_step : 11860, loss1 : 2.617028, loss2 : 3.371981
train_step : 11861, loss1 : 4.175775, loss2 : 3.863052
train_step : 11862, loss1 : 2.169624, loss2 : 4.063434
train_step : 11863, loss1 : 2.620595, loss2 : 3.230546
train_step : 11864, loss1 : 2.404809, loss2 : 2.468929
train_step : 11865, loss1 : 3.384713, loss2 : 3.124772
train_step : 11866, loss1 : 2.739905, loss2 : 2.905000
train_step : 11867, loss1 : 4.400102, loss2 : 2.849099
train_step : 11868, loss1 : 3.455600, loss2 : 1.431922
train_step : 11869, loss1 : 2.077417, loss2 : 1.471023
train_step : 11870, loss1 : 0.981623, loss2 : 1.190296
train_step : 11871, loss1 : 1.244237, loss2 : 1.170553
train_step : 11872, loss1 : 1.444992, loss2 : 1.501433
train_step : 11873, loss1 : 1.468401, loss2 : 3.529115
train_step : 11874, loss1 : 3.410566, loss2 : 3.224733
train_step : 11875, loss1 : 3.564258, loss2 : 2.536840
train_step : 11876, loss1 : 2.383069, loss2 : 5.730032
train_step : 11877, loss1 : 3.172791, loss2 : 3.211875
train_step : 11878, loss1 : 5.045484, loss2 : 3.511039
train_step : 11879, loss1 : 4.201588, loss2 : 3.566864
train_step : 11880, loss1 : 4.820818, loss2 : 3.720451
train_step : 11881, loss1 : 3.459644, loss2 : 3.971782
train_step : 11882, loss1 : 4.049894, loss2 : 6.258173
train_step : 11883, loss1 : 5.645706, loss2 : 4.431597
train_step : 11884, loss1 : 4.084865, loss2 : 5.988884
train_step : 11885, loss1 : 3.156966, loss2 : 4.714814
train_step : 11886, loss1 : 3.362396, loss2 : 4.153238
train_step : 11887, loss1 : 2.021311, loss2 : 2.463781
train_step : 11888, loss1 : 2.727092, loss2 : 1.336546
train_step : 11889, loss1 : 2.194373, loss2 : 0.787032
train_step : 11890, loss1 : 1.211038, loss2 : 1.739662
train_step : 11891, loss1 : 0.815907, loss2 : 1.153937
train_step : 11892, loss1 : 0.592075, loss2 : 1.814530
train_step : 11893, loss1 : 1.149796, loss2 : 1.625859
train_step : 11894, loss1 : 1.688528, loss2 : 2.090241
train_step : 11895, loss1 : 1.965073, loss2 : 1.957359
train_step : 11896, loss1 : 1.448290, loss2 : 1.694704
train_step : 11897, loss1 : 1.169121, loss2 : 1.751034
train_step : 11898, loss1 : 0.866361, loss2 : 1.115210
train_step : 11899, loss1 : 2.991772, loss2 : 0.738631
train_step : 11900, loss1 : 0.808916, loss2 : 1.123551
train_step : 11901, loss1 : 1.523565, loss2 : 0.901969
train_step : 11902, loss1 : 1.962857, loss2 : 2.553043
train_step : 11903, loss1 : 3.409012, loss2 : 2.952465
train_step : 11904, loss1 : 2.052180, loss2 : 2.666765
train_step : 11905, loss1 : 2.821605, loss2 : 3.977179
train_step : 11906, loss1 : 1.775951, loss2 : 2.180653
train_step : 11907, loss1 : 1.897789, loss2 : 2.447145
train_step : 11908, loss1 : 1.643682, loss2 : 1.103223
train_step : 11909, loss1 : 1.212904, loss2 : 1.380123
train_step : 11910, loss1 : 1.001094, loss2 : 1.203770
train_step : 11911, loss1 : 1.444644, loss2 : 1.061669
train_step : 11912, loss1 : 0.627498, loss2 : 1.097526
train_step : 11913, loss1 : 0.873285, loss2 : 1.169219
train_step : 11914, loss1 : 1.502826, loss2 : 0.609953
train_step : 11915, loss1 : 1.233912, loss2 : 1.322596
train_step : 11916, loss1 : 1.095362, loss2 : 0.890092
train_step : 11917, loss1 : 1.103768, loss2 : 1.724650
train_step : 11918, loss1 : 1.089037, loss2 : 6.330048
train_step : 11919, loss1 : 2.654155, loss2 : 1.922584
train_step : 11920, loss1 : 1.873558, loss2 : 1.428139
train_step : 11921, loss1 : 1.793141, loss2 : 2.157293
train_step : 11922, loss1 : 2.177943, loss2 : 1.683983
train_step : 11923, loss1 : 2.934245, loss2 : 3.927628
train_step : 11924, loss1 : 1.986458, loss2 : 2.135445
train_step : 11925, loss1 : 1.971047, loss2 : 1.436437
train_step : 11926, loss1 : 1.434883, loss2 : 0.888261
train_step : 11927, loss1 : 1.924106, loss2 : 1.026488
train_step : 11928, loss1 : 1.558422, loss2 : 2.478275
train_step : 11929, loss1 : 1.343628, loss2 : 1.597119
train_step : 11930, loss1 : 1.527701, loss2 : 0.809133
train_step : 11931, loss1 : 1.048195, loss2 : 1.136655
train_step : 11932, loss1 : 1.230857, loss2 : 1.832854
train_step : 11933, loss1 : 1.049878, loss2 : 1.258252
train_step : 11934, loss1 : 1.229341, loss2 : 0.932507
train_step : 11935, loss1 : 1.175813, loss2 : 1.823817
train_step : 11936, loss1 : 2.260296, loss2 : 2.170153
train_step : 11937, loss1 : 2.336273, loss2 : 2.695565
train_step : 11938, loss1 : 2.870176, loss2 : 2.493355
train_step : 11939, loss1 : 2.333077, loss2 : 2.440129
train_step : 11940, loss1 : 0.852274, loss2 : 0.649439
train_step : 11941, loss1 : 1.460232, loss2 : 2.013948
train_step : 11942, loss1 : 1.228036, loss2 : 0.682867
train_step : 11943, loss1 : 1.409899, loss2 : 1.982395
train_step : 11944, loss1 : 1.219641, loss2 : 1.038078
train_step : 11945, loss1 : 1.747509, loss2 : 0.986040
train_step : 11946, loss1 : 1.391841, loss2 : 2.139451
train_step : 11947, loss1 : 1.154590, loss2 : 1.030280
train_step : 11948, loss1 : 1.518005, loss2 : 1.484391
train_step : 11949, loss1 : 1.046187, loss2 : 1.236839
train_step : 11950, loss1 : 1.436631, loss2 : 1.241889
train_step : 11951, loss1 : 2.140774, loss2 : 1.149584
train_step : 11952, loss1 : 2.754379, loss2 : 1.332878
train_step : 11953, loss1 : 3.101524, loss2 : 3.717603
train_step : 11954, loss1 : 3.054989, loss2 : 5.055769
train_step : 11955, loss1 : 2.394689, loss2 : 3.974018
train_step : 11956, loss1 : 3.335937, loss2 : 1.580361
train_step : 11957, loss1 : 2.885781, loss2 : 2.347215
train_step : 11958, loss1 : 3.410362, loss2 : 3.192003
train_step : 11959, loss1 : 2.030216, loss2 : 3.026143
train_step : 11960, loss1 : 2.391656, loss2 : 3.351117
train_step : 11961, loss1 : 1.034505, loss2 : 1.240895
train_step : 11962, loss1 : 0.847651, loss2 : 0.969555
train_step : 11963, loss1 : 1.613445, loss2 : 0.774447
train_step : 11964, loss1 : 1.237437, loss2 : 1.666209
train_step : 11965, loss1 : 1.828565, loss2 : 2.558554
train_step : 11966, loss1 : 0.803764, loss2 : 1.184026
train_step : 11967, loss1 : 1.451901, loss2 : 1.096300
train_step : 11968, loss1 : 0.862959, loss2 : 0.916843
train_step : 11969, loss1 : 1.758779, loss2 : 0.729174
train_step : 11970, loss1 : 1.513029, loss2 : 1.422910
train_step : 11971, loss1 : 1.802229, loss2 : 1.497232
train_step : 11972, loss1 : 1.823087, loss2 : 0.966304
train_step : 11973, loss1 : 1.710834, loss2 : 1.344361
train_step : 11974, loss1 : 1.797311, loss2 : 1.166148
train_step : 11975, loss1 : 2.308211, loss2 : 1.393445
train_step : 11976, loss1 : 1.772655, loss2 : 1.694847
train_step : 11977, loss1 : 3.232569, loss2 : 1.665197
train_step : 11978, loss1 : 2.580643, loss2 : 2.280742
train_step : 11979, loss1 : 2.632879, loss2 : 1.668898
train_step : 11980, loss1 : 1.727955, loss2 : 1.273434
train_step : 11981, loss1 : 1.607152, loss2 : 1.131712
train_step : 11982, loss1 : 0.526778, loss2 : 0.963966
train_step : 11983, loss1 : 2.299675, loss2 : 1.074682
train_step : 11984, loss1 : 0.942031, loss2 : 0.410461
train_step : 11985, loss1 : 0.898204, loss2 : 1.110970
train_step : 11986, loss1 : 0.469900, loss2 : 0.894137
train_step : 11987, loss1 : 0.583378, loss2 : 2.447828
train_step : 11988, loss1 : 1.872241, loss2 : 1.385557
train_step : 11989, loss1 : 1.202221, loss2 : 1.620668
train_step : 11990, loss1 : 1.874476, loss2 : 0.696180
train_step : 11991, loss1 : 0.922456, loss2 : 1.807360
train_step : 11992, loss1 : 0.783230, loss2 : 0.789745
train_step : 11993, loss1 : 2.107680, loss2 : 2.899749
train_step : 11994, loss1 : 2.816129, loss2 : 2.449726
train_step : 11995, loss1 : 2.713060, loss2 : 1.638134
train_step : 11996, loss1 : 2.053412, loss2 : 2.246841
train_step : 11997, loss1 : 1.823255, loss2 : 1.526662
train_step : 11998, loss1 : 1.433264, loss2 : 1.493580
train_step : 11999, loss1 : 1.077237, loss2 : 1.857778
train_step : 12000, loss1 : 1.654527, loss2 : 1.510016
train_step : 12001, loss1 : 1.289184, loss2 : 1.043650
train_step : 12002, loss1 : 1.768595, loss2 : 1.317302
train_step : 12003, loss1 : 1.781585, loss2 : 1.936169
train_step : 12004, loss1 : 0.864399, loss2 : 0.928132
train_step : 12005, loss1 : 0.984062, loss2 : 1.174105
train_step : 12006, loss1 : 1.938669, loss2 : 0.844306
train_step : 12007, loss1 : 1.258160, loss2 : 1.182732
train_step : 12008, loss1 : 2.216357, loss2 : 1.109252
train_step : 12009, loss1 : 1.042962, loss2 : 1.043421
train_step : 12010, loss1 : 0.997522, loss2 : 1.047855
train_step : 12011, loss1 : 1.925413, loss2 : 1.362506
train_step : 12012, loss1 : 1.461687, loss2 : 1.579668
train_step : 12013, loss1 : 1.511113, loss2 : 1.704018
train_step : 12014, loss1 : 1.226071, loss2 : 1.920618
train_step : 12015, loss1 : 2.800973, loss2 : 1.355208
train_step : 12016, loss1 : 1.814781, loss2 : 1.632633
train_step : 12017, loss1 : 1.106673, loss2 : 1.286782
train_step : 12018, loss1 : 1.718550, loss2 : 0.680323
train_step : 12019, loss1 : 1.471662, loss2 : 1.044461
train_step : 12020, loss1 : 1.209687, loss2 : 1.074930
train_step : 12021, loss1 : 0.472836, loss2 : 0.980405
train_step : 12022, loss1 : 1.191884, loss2 : 0.543096
train_step : 12023, loss1 : 0.718871, loss2 : 1.164048
train_step : 12024, loss1 : 1.017854, loss2 : 1.272195
train_step : 12025, loss1 : 1.121509, loss2 : 2.287278
train_step : 12026, loss1 : 0.812441, loss2 : 1.768227
train_step : 12027, loss1 : 3.279508, loss2 : 1.557069
train_step : 12028, loss1 : 2.685942, loss2 : 2.114848
train_step : 12029, loss1 : 0.829965, loss2 : 0.546213
train_step : 12030, loss1 : 1.123806, loss2 : 1.172251
train_step : 12031, loss1 : 1.341847, loss2 : 1.067395
train_step : 12032, loss1 : 1.267368, loss2 : 0.473273
train_step : 12033, loss1 : 2.344786, loss2 : 1.642204
train_step : 12034, loss1 : 1.326198, loss2 : 1.113523
train_step : 12035, loss1 : 1.674510, loss2 : 1.562357
train_step : 12036, loss1 : 1.428724, loss2 : 1.221107
train_step : 12037, loss1 : 1.267596, loss2 : 1.322944
train_step : 12038, loss1 : 1.518100, loss2 : 0.848257
train_step : 12039, loss1 : 1.183728, loss2 : 0.813631
train_step : 12040, loss1 : 0.925952, loss2 : 1.947537
train_step : 12041, loss1 : 1.389805, loss2 : 2.361325
train_step : 12042, loss1 : 1.332354, loss2 : 1.745656
train_step : 12043, loss1 : 1.842279, loss2 : 2.107400
train_step : 12044, loss1 : 2.255421, loss2 : 1.748659
train_step : 12045, loss1 : 1.166524, loss2 : 0.723936
train_step : 12046, loss1 : 1.357253, loss2 : 0.694648
train_step : 12047, loss1 : 0.978275, loss2 : 1.068370
train_step : 12048, loss1 : 0.987278, loss2 : 1.134644
train_step : 12049, loss1 : 2.012879, loss2 : 1.394526
train_step : 12050, loss1 : 1.770541, loss2 : 1.228525
train_step : 12051, loss1 : 0.572745, loss2 : 1.911053
train_step : 12052, loss1 : 1.294906, loss2 : 1.054530
train_step : 12053, loss1 : 1.111284, loss2 : 2.278690
train_step : 12054, loss1 : 1.005579, loss2 : 1.082805
train_step : 12055, loss1 : 1.256289, loss2 : 0.801842
train_step : 12056, loss1 : 0.860064, loss2 : 1.094738
train_step : 12057, loss1 : 1.142561, loss2 : 1.190836
train_step : 12058, loss1 : 0.826665, loss2 : 0.925491
train_step : 12059, loss1 : 0.972374, loss2 : 0.911706
train_step : 12060, loss1 : 0.972534, loss2 : 1.087797
train_step : 12061, loss1 : 1.325982, loss2 : 1.129846
train_step : 12062, loss1 : 1.424795, loss2 : 0.962380
train_step : 12063, loss1 : 1.344132, loss2 : 0.934226
train_step : 12064, loss1 : 1.653267, loss2 : 1.045958
train_step : 12065, loss1 : 1.025360, loss2 : 1.214670
train_step : 12066, loss1 : 0.881806, loss2 : 1.174580
train_step : 12067, loss1 : 0.821487, loss2 : 1.743515
train_step : 12068, loss1 : 1.370624, loss2 : 1.131252
train_step : 12069, loss1 : 1.753653, loss2 : 1.508669
train_step : 12070, loss1 : 0.887919, loss2 : 1.456776
train_step : 12071, loss1 : 1.038348, loss2 : 1.014495
train_step : 12072, loss1 : 0.883734, loss2 : 0.948415
train_step : 12073, loss1 : 1.079407, loss2 : 0.906592
train_step : 12074, loss1 : 0.740310, loss2 : 1.097648
train_step : 12075, loss1 : 1.699091, loss2 : 0.875615
train_step : 12076, loss1 : 1.187565, loss2 : 0.697388
train_step : 12077, loss1 : 0.979553, loss2 : 1.245936
train_step : 12078, loss1 : 1.567133, loss2 : 1.022254
train_step : 12079, loss1 : 1.119992, loss2 : 2.539431
train_step : 12080, loss1 : 1.569025, loss2 : 1.337532
train_step : 12081, loss1 : 1.461703, loss2 : 0.913337
train_step : 12082, loss1 : 1.305852, loss2 : 0.817360
train_step : 12083, loss1 : 0.853470, loss2 : 0.828195
train_step : 12084, loss1 : 1.379102, loss2 : 1.098265
train_step : 12085, loss1 : 1.725031, loss2 : 1.466589
train_step : 12086, loss1 : 1.930136, loss2 : 1.401826
train_step : 12087, loss1 : 1.735759, loss2 : 1.781644
train_step : 12088, loss1 : 1.136868, loss2 : 1.271253
train_step : 12089, loss1 : 1.161343, loss2 : 2.002505
train_step : 12090, loss1 : 1.030755, loss2 : 1.061414
train_step : 12091, loss1 : 1.945655, loss2 : 1.694531
train_step : 12092, loss1 : 0.999071, loss2 : 1.332089
train_step : 12093, loss1 : 1.060884, loss2 : 4.120135
train_step : 12094, loss1 : 1.204284, loss2 : 1.763388
train_step : 12095, loss1 : 2.303832, loss2 : 1.712910
train_step : 12096, loss1 : 2.146916, loss2 : 1.276412
train_step : 12097, loss1 : 2.334823, loss2 : 2.095094
train_step : 12098, loss1 : 2.030011, loss2 : 1.973590
train_step : 12099, loss1 : 1.622646, loss2 : 1.993351
train_step : 12100, loss1 : 1.750052, loss2 : 2.637759
train_step : 12101, loss1 : 1.843367, loss2 : 3.179993
train_step : 12102, loss1 : 2.843825, loss2 : 2.581167
train_step : 12103, loss1 : 2.803470, loss2 : 1.603797
train_step : 12104, loss1 : 2.116360, loss2 : 2.392597
train_step : 12105, loss1 : 0.651573, loss2 : 2.082918
train_step : 12106, loss1 : 1.233393, loss2 : 1.947816
train_step : 12107, loss1 : 1.174307, loss2 : 0.703608
train_step : 12108, loss1 : 0.553978, loss2 : 1.134275
train_step : 12109, loss1 : 0.857189, loss2 : 0.968333
train_step : 12110, loss1 : 2.025237, loss2 : 1.429330
train_step : 12111, loss1 : 0.982874, loss2 : 0.622671
train_step : 12112, loss1 : 1.369872, loss2 : 1.626848
train_step : 12113, loss1 : 1.418543, loss2 : 1.366202
train_step : 12114, loss1 : 1.303741, loss2 : 1.726262
train_step : 12115, loss1 : 1.529073, loss2 : 3.263754
train_step : 12116, loss1 : 1.246437, loss2 : 1.569789
train_step : 12117, loss1 : 1.336274, loss2 : 1.739531
train_step : 12118, loss1 : 0.981002, loss2 : 1.276110
train_step : 12119, loss1 : 1.826777, loss2 : 1.114682
train_step : 12120, loss1 : 2.177426, loss2 : 1.214421
train_step : 12121, loss1 : 2.543750, loss2 : 1.454514
train_step : 12122, loss1 : 2.493547, loss2 : 1.848809
train_step : 12123, loss1 : 2.398995, loss2 : 1.580795
train_step : 12124, loss1 : 2.305936, loss2 : 1.940203
train_step : 12125, loss1 : 2.032233, loss2 : 1.884132
train_step : 12126, loss1 : 1.795083, loss2 : 1.488526
train_step : 12127, loss1 : 1.323817, loss2 : 1.872358
train_step : 12128, loss1 : 1.126942, loss2 : 0.766200
train_step : 12129, loss1 : 1.157252, loss2 : 0.701988
train_step : 12130, loss1 : 0.759375, loss2 : 1.539307
train_step : 12131, loss1 : 0.891546, loss2 : 0.892586
train_step : 12132, loss1 : 0.935439, loss2 : 0.913155
train_step : 12133, loss1 : 1.277375, loss2 : 1.584274
train_step : 12134, loss1 : 2.284230, loss2 : 0.717967
train_step : 12135, loss1 : 1.280024, loss2 : 1.220685
train_step : 12136, loss1 : 1.074017, loss2 : 1.765864
train_step : 12137, loss1 : 1.314971, loss2 : 0.961983
train_step : 12138, loss1 : 1.214618, loss2 : 0.860401
train_step : 12139, loss1 : 0.718604, loss2 : 0.879106
train_step : 12140, loss1 : 1.016899, loss2 : 1.064912
train_step : 12141, loss1 : 1.726467, loss2 : 1.125352
train_step : 12142, loss1 : 1.406723, loss2 : 1.177222
train_step : 12143, loss1 : 1.580603, loss2 : 1.467533
train_step : 12144, loss1 : 1.285907, loss2 : 1.167361
train_step : 12145, loss1 : 1.569002, loss2 : 1.149053
train_step : 12146, loss1 : 0.985649, loss2 : 0.573085
train_step : 12147, loss1 : 1.785865, loss2 : 1.777565
train_step : 12148, loss1 : 1.063630, loss2 : 1.061767
train_step : 12149, loss1 : 0.566777, loss2 : 2.152569
train_step : 12150, loss1 : 0.733066, loss2 : 0.794241
train_step : 12151, loss1 : 0.666492, loss2 : 1.103260
train_step : 12152, loss1 : 1.047097, loss2 : 1.653359
train_step : 12153, loss1 : 1.385373, loss2 : 2.411501
train_step : 12154, loss1 : 2.279176, loss2 : 1.779963
train_step : 12155, loss1 : 1.486364, loss2 : 1.961226
train_step : 12156, loss1 : 0.827357, loss2 : 1.424975
train_step : 12157, loss1 : 1.070455, loss2 : 1.518058
train_step : 12158, loss1 : 1.085731, loss2 : 1.557273
train_step : 12159, loss1 : 1.268843, loss2 : 1.061716
train_step : 12160, loss1 : 0.795210, loss2 : 0.843799
train_step : 12161, loss1 : 0.983868, loss2 : 1.394095
train_step : 12162, loss1 : 1.255203, loss2 : 0.746270
train_step : 12163, loss1 : 1.039617, loss2 : 1.079797
train_step : 12164, loss1 : 1.856041, loss2 : 0.655290
train_step : 12165, loss1 : 0.491022, loss2 : 1.285122
train_step : 12166, loss1 : 1.682058, loss2 : 1.453512
train_step : 12167, loss1 : 0.895270, loss2 : 1.829691
train_step : 12168, loss1 : 1.546979, loss2 : 1.636730
train_step : 12169, loss1 : 1.717193, loss2 : 1.052583
train_step : 12170, loss1 : 0.798243, loss2 : 1.742267
train_step : 12171, loss1 : 1.159503, loss2 : 0.678557
train_step : 12172, loss1 : 1.719450, loss2 : 1.390970
train_step : 12173, loss1 : 2.354772, loss2 : 2.619321
train_step : 12174, loss1 : 2.260598, loss2 : 1.700582
train_step : 12175, loss1 : 2.260646, loss2 : 1.546780
train_step : 12176, loss1 : 2.204161, loss2 : 2.009247
train_step : 12177, loss1 : 1.240327, loss2 : 1.811335
train_step : 12178, loss1 : 1.290929, loss2 : 1.742087
train_step : 12179, loss1 : 2.066801, loss2 : 1.472191
train_step : 12180, loss1 : 1.547875, loss2 : 1.602063
train_step : 12181, loss1 : 1.345818, loss2 : 1.262835
train_step : 12182, loss1 : 1.345392, loss2 : 1.245594
train_step : 12183, loss1 : 1.080323, loss2 : 1.934480
train_step : 12184, loss1 : 2.198646, loss2 : 1.138926
train_step : 12185, loss1 : 1.575437, loss2 : 1.277971
train_step : 12186, loss1 : 1.109785, loss2 : 1.129630
train_step : 12187, loss1 : 1.098931, loss2 : 1.228613
train_step : 12188, loss1 : 1.011281, loss2 : 1.759618
train_step : 12189, loss1 : 1.235187, loss2 : 1.105269
train_step : 12190, loss1 : 1.472461, loss2 : 1.195178
train_step : 12191, loss1 : 1.046511, loss2 : 1.267448
train_step : 12192, loss1 : 1.289092, loss2 : 0.804794
train_step : 12193, loss1 : 1.768082, loss2 : 0.690749
train_step : 12194, loss1 : 1.524135, loss2 : 1.473221
train_step : 12195, loss1 : 0.997141, loss2 : 1.591429
train_step : 12196, loss1 : 1.236222, loss2 : 1.396036
train_step : 12197, loss1 : 1.617867, loss2 : 2.144288
train_step : 12198, loss1 : 1.528058, loss2 : 2.222631
train_step : 12199, loss1 : 1.257632, loss2 : 2.297822
train_step : 12200, loss1 : 1.553840, loss2 : 0.453163
train_step : 12201, loss1 : 1.033527, loss2 : 0.787625
train_step : 12202, loss1 : 1.857400, loss2 : 1.308361
train_step : 12203, loss1 : 0.901679, loss2 : 1.124798
train_step : 12204, loss1 : 1.628216, loss2 : 1.051999
train_step : 12205, loss1 : 0.884173, loss2 : 1.956293
train_step : 12206, loss1 : 1.832774, loss2 : 1.684766
train_step : 12207, loss1 : 2.796236, loss2 : 3.716551
train_step : 12208, loss1 : 3.637115, loss2 : 5.011974
train_step : 12209, loss1 : 3.733144, loss2 : 3.444236
train_step : 12210, loss1 : 3.486859, loss2 : 2.462070
train_step : 12211, loss1 : 1.249148, loss2 : 2.758985
train_step : 12212, loss1 : 1.218628, loss2 : 1.516240
train_step : 12213, loss1 : 1.043923, loss2 : 1.506753
train_step : 12214, loss1 : 1.059991, loss2 : 0.728683
train_step : 12215, loss1 : 2.569162, loss2 : 0.836100
train_step : 12216, loss1 : 1.053022, loss2 : 1.644053
train_step : 12217, loss1 : 0.529579, loss2 : 1.022674
train_step : 12218, loss1 : 1.135626, loss2 : 1.704369
train_step : 12219, loss1 : 1.763476, loss2 : 1.668684
train_step : 12220, loss1 : 1.490772, loss2 : 1.255916
train_step : 12221, loss1 : 1.453588, loss2 : 1.868920
train_step : 12222, loss1 : 2.927314, loss2 : 1.530393
train_step : 12223, loss1 : 1.379713, loss2 : 2.055623
train_step : 12224, loss1 : 0.853702, loss2 : 0.735812
train_step : 12225, loss1 : 1.399151, loss2 : 0.967382
train_step : 12226, loss1 : 1.163824, loss2 : 1.214844
train_step : 12227, loss1 : 0.886911, loss2 : 0.607655
train_step : 12228, loss1 : 0.863432, loss2 : 1.186388
train_step : 12229, loss1 : 1.074548, loss2 : 1.167642
train_step : 12230, loss1 : 0.767851, loss2 : 1.440485
train_step : 12231, loss1 : 0.925411, loss2 : 0.918340
train_step : 12232, loss1 : 1.633032, loss2 : 0.781772
train_step : 12233, loss1 : 1.709550, loss2 : 1.103644
train_step : 12234, loss1 : 0.723146, loss2 : 2.103501
train_step : 12235, loss1 : 1.329621, loss2 : 1.083701
train_step : 12236, loss1 : 1.274945, loss2 : 1.164314
train_step : 12237, loss1 : 1.599809, loss2 : 0.489151
train_step : 12238, loss1 : 1.725749, loss2 : 1.430127
train_step : 12239, loss1 : 1.737733, loss2 : 1.367297
train_step : 12240, loss1 : 2.864396, loss2 : 1.297085
train_step : 12241, loss1 : 1.731488, loss2 : 1.797816
train_step : 12242, loss1 : 1.635480, loss2 : 1.928385
train_step : 12243, loss1 : 1.853053, loss2 : 1.929459
train_step : 12244, loss1 : 1.414298, loss2 : 1.119847
train_step : 12245, loss1 : 0.819721, loss2 : 1.137734
train_step : 12246, loss1 : 0.877832, loss2 : 0.894119
train_step : 12247, loss1 : 1.466179, loss2 : 1.057796
train_step : 12248, loss1 : 0.735755, loss2 : 0.827121
train_step : 12249, loss1 : 1.015744, loss2 : 0.776312
train_step : 12250, loss1 : 1.039961, loss2 : 1.052478
train_step : 12251, loss1 : 1.324630, loss2 : 1.461495
train_step : 12252, loss1 : 0.989909, loss2 : 1.305601
train_step : 12253, loss1 : 2.259083, loss2 : 2.365952
train_step : 12254, loss1 : 3.114842, loss2 : 2.362898
train_step : 12255, loss1 : 1.784582, loss2 : 2.242986
train_step : 12256, loss1 : 1.684264, loss2 : 2.442713
train_step : 12257, loss1 : 1.720712, loss2 : 2.592474
train_step : 12258, loss1 : 2.441464, loss2 : 1.672641
train_step : 12259, loss1 : 1.576081, loss2 : 2.301487
train_step : 12260, loss1 : 2.624194, loss2 : 1.424527
train_step : 12261, loss1 : 1.696764, loss2 : 2.153840
train_step : 12262, loss1 : 2.178341, loss2 : 3.136907
train_step : 12263, loss1 : 2.981246, loss2 : 2.038992
train_step : 12264, loss1 : 2.611872, loss2 : 1.827057
train_step : 12265, loss1 : 1.401280, loss2 : 2.447979
train_step : 12266, loss1 : 1.940866, loss2 : 2.965878
train_step : 12267, loss1 : 2.614192, loss2 : 1.630966
train_step : 12268, loss1 : 0.937784, loss2 : 1.747611
train_step : 12269, loss1 : 1.233463, loss2 : 2.589933
train_step : 12270, loss1 : 1.468105, loss2 : 1.581442
train_step : 12271, loss1 : 1.725470, loss2 : 1.466075
train_step : 12272, loss1 : 2.015201, loss2 : 1.514568
train_step : 12273, loss1 : 2.073528, loss2 : 1.608918
train_step : 12274, loss1 : 2.080414, loss2 : 2.573616
train_step : 12275, loss1 : 1.738905, loss2 : 0.886881
train_step : 12276, loss1 : 0.873808, loss2 : 1.540946
train_step : 12277, loss1 : 1.521161, loss2 : 0.831485
train_step : 12278, loss1 : 0.530526, loss2 : 0.896218
train_step : 12279, loss1 : 1.264101, loss2 : 0.765109
train_step : 12280, loss1 : 1.266672, loss2 : 1.871629
train_step : 12281, loss1 : 0.875642, loss2 : 0.847650
train_step : 12282, loss1 : 1.130018, loss2 : 0.770613
train_step : 12283, loss1 : 1.237188, loss2 : 1.228242
train_step : 12284, loss1 : 1.311959, loss2 : 1.584798
train_step : 12285, loss1 : 2.148927, loss2 : 1.787389
train_step : 12286, loss1 : 1.807903, loss2 : 1.586594
train_step : 12287, loss1 : 1.433219, loss2 : 1.318328
train_step : 12288, loss1 : 0.856153, loss2 : 2.351360
train_step : 12289, loss1 : 1.952048, loss2 : 2.962585
train_step : 12290, loss1 : 1.621212, loss2 : 1.292458
train_step : 12291, loss1 : 1.247197, loss2 : 0.903368
train_step : 12292, loss1 : 0.800754, loss2 : 1.281523
train_step : 12293, loss1 : 1.599645, loss2 : 1.742540
train_step : 12294, loss1 : 1.509376, loss2 : 1.874369
train_step : 12295, loss1 : 1.327582, loss2 : 0.870459
train_step : 12296, loss1 : 1.215581, loss2 : 1.674340
train_step : 12297, loss1 : 1.004157, loss2 : 1.258830
train_step : 12298, loss1 : 1.232696, loss2 : 1.018963
train_step : 12299, loss1 : 1.402225, loss2 : 1.210465
train_step : 12300, loss1 : 1.393824, loss2 : 2.113536
train_step : 12301, loss1 : 0.886307, loss2 : 1.146389
train_step : 12302, loss1 : 1.484696, loss2 : 1.203801
train_step : 12303, loss1 : 1.058036, loss2 : 0.849406
train_step : 12304, loss1 : 0.804449, loss2 : 1.577701
train_step : 12305, loss1 : 0.854306, loss2 : 0.804800
train_step : 12306, loss1 : 0.870128, loss2 : 1.300048
train_step : 12307, loss1 : 0.592463, loss2 : 1.312536
train_step : 12308, loss1 : 1.633679, loss2 : 1.141559
train_step : 12309, loss1 : 0.817757, loss2 : 0.770137
train_step : 12310, loss1 : 0.984473, loss2 : 1.911365
train_step : 12311, loss1 : 1.495154, loss2 : 2.200620
train_step : 12312, loss1 : 1.187802, loss2 : 1.674345
train_step : 12313, loss1 : 2.317841, loss2 : 1.502226
train_step : 12314, loss1 : 1.479340, loss2 : 1.223289
train_step : 12315, loss1 : 1.051430, loss2 : 0.746230
train_step : 12316, loss1 : 1.730679, loss2 : 1.452738
train_step : 12317, loss1 : 1.223344, loss2 : 0.519822
train_step : 12318, loss1 : 1.279471, loss2 : 1.176214
train_step : 12319, loss1 : 0.988958, loss2 : 1.083321
train_step : 12320, loss1 : 1.438440, loss2 : 1.546236
train_step : 12321, loss1 : 1.563138, loss2 : 1.391530
train_step : 12322, loss1 : 0.986961, loss2 : 0.847785
train_step : 12323, loss1 : 1.021673, loss2 : 1.576014
train_step : 12324, loss1 : 1.119948, loss2 : 0.800526
train_step : 12325, loss1 : 0.723396, loss2 : 1.537410
train_step : 12326, loss1 : 1.268518, loss2 : 1.009819
train_step : 12327, loss1 : 1.070099, loss2 : 1.771645
train_step : 12328, loss1 : 1.139264, loss2 : 1.989397
train_step : 12329, loss1 : 2.613267, loss2 : 1.443128
train_step : 12330, loss1 : 2.067250, loss2 : 1.607268
train_step : 12331, loss1 : 0.760426, loss2 : 1.395015
train_step : 12332, loss1 : 1.168371, loss2 : 0.749328
train_step : 12333, loss1 : 1.651951, loss2 : 1.295086
train_step : 12334, loss1 : 1.884114, loss2 : 1.934391
train_step : 12335, loss1 : 2.172789, loss2 : 0.836112
train_step : 12336, loss1 : 1.101150, loss2 : 0.899250
train_step : 12337, loss1 : 1.086510, loss2 : 1.280405
train_step : 12338, loss1 : 1.360728, loss2 : 1.032358
train_step : 12339, loss1 : 1.952755, loss2 : 1.180762
train_step : 12340, loss1 : 0.939498, loss2 : 0.948729
train_step : 12341, loss1 : 0.909264, loss2 : 1.561912
train_step : 12342, loss1 : 1.429337, loss2 : 1.051954
train_step : 12343, loss1 : 0.601564, loss2 : 0.758937
train_step : 12344, loss1 : 1.578614, loss2 : 1.427021
train_step : 12345, loss1 : 1.282128, loss2 : 0.950518
train_step : 12346, loss1 : 0.863478, loss2 : 2.145302
train_step : 12347, loss1 : 1.163763, loss2 : 1.072569
train_step : 12348, loss1 : 0.621394, loss2 : 2.035055
train_step : 12349, loss1 : 1.721126, loss2 : 1.205756
train_step : 12350, loss1 : 1.087363, loss2 : 1.313588
train_step : 12351, loss1 : 1.659411, loss2 : 0.762475
train_step : 12352, loss1 : 1.878096, loss2 : 1.490814
train_step : 12353, loss1 : 2.891075, loss2 : 1.969790
train_step : 12354, loss1 : 3.081522, loss2 : 1.750317
train_step : 12355, loss1 : 1.090623, loss2 : 2.436408
train_step : 12356, loss1 : 2.211412, loss2 : 1.750746
train_step : 12357, loss1 : 2.397558, loss2 : 2.357794
train_step : 12358, loss1 : 2.102477, loss2 : 1.708141
train_step : 12359, loss1 : 1.087504, loss2 : 1.190156
train_step : 12360, loss1 : 1.408015, loss2 : 1.079756
train_step : 12361, loss1 : 1.320883, loss2 : 1.059133
train_step : 12362, loss1 : 2.426932, loss2 : 1.909593
train_step : 12363, loss1 : 1.341572, loss2 : 2.786070
train_step : 12364, loss1 : 2.630646, loss2 : 1.248128
train_step : 12365, loss1 : 1.189229, loss2 : 0.683522
train_step : 12366, loss1 : 1.169188, loss2 : 1.650742
train_step : 12367, loss1 : 1.081117, loss2 : 1.518542
train_step : 12368, loss1 : 1.675860, loss2 : 1.173313
train_step : 12369, loss1 : 1.102350, loss2 : 1.650843
train_step : 12370, loss1 : 0.647605, loss2 : 1.275619
train_step : 12371, loss1 : 1.160491, loss2 : 2.684948
train_step : 12372, loss1 : 1.404693, loss2 : 1.182973
train_step : 12373, loss1 : 1.199598, loss2 : 0.754816
train_step : 12374, loss1 : 0.932976, loss2 : 1.535860
train_step : 12375, loss1 : 1.655357, loss2 : 2.058215
train_step : 12376, loss1 : 2.544941, loss2 : 2.012693
train_step : 12377, loss1 : 2.808738, loss2 : 1.677821
train_step : 12378, loss1 : 1.811117, loss2 : 1.524341
train_step : 12379, loss1 : 2.798029, loss2 : 1.825843
train_step : 12380, loss1 : 1.635376, loss2 : 0.995390
train_step : 12381, loss1 : 1.000662, loss2 : 1.529146
train_step : 12382, loss1 : 1.204252, loss2 : 1.581072
train_step : 12383, loss1 : 1.351378, loss2 : 2.701166
train_step : 12384, loss1 : 2.271523, loss2 : 2.185567
train_step : 12385, loss1 : 1.094125, loss2 : 1.164311
train_step : 12386, loss1 : 0.726020, loss2 : 0.997883
train_step : 12387, loss1 : 1.230860, loss2 : 0.781119
train_step : 12388, loss1 : 1.053584, loss2 : 1.623197
train_step : 12389, loss1 : 1.149243, loss2 : 2.396068
train_step : 12390, loss1 : 0.977474, loss2 : 1.152808
train_step : 12391, loss1 : 1.120148, loss2 : 0.831155
train_step : 12392, loss1 : 1.242955, loss2 : 1.633538
train_step : 12393, loss1 : 1.557731, loss2 : 1.770968
train_step : 12394, loss1 : 0.834867, loss2 : 2.417465
train_step : 12395, loss1 : 1.881066, loss2 : 1.545466
train_step : 12396, loss1 : 1.281795, loss2 : 2.417037
train_step : 12397, loss1 : 1.072793, loss2 : 1.743012
train_step : 12398, loss1 : 0.691103, loss2 : 1.742509
train_step : 12399, loss1 : 0.755498, loss2 : 1.014508
train_step : 12400, loss1 : 1.346355, loss2 : 0.983460
train_step : 12401, loss1 : 0.905308, loss2 : 1.126033
train_step : 12402, loss1 : 0.960298, loss2 : 0.924548
train_step : 12403, loss1 : 1.506600, loss2 : 1.233068
train_step : 12404, loss1 : 0.416287, loss2 : 1.881676
train_step : 12405, loss1 : 1.312035, loss2 : 1.211329
train_step : 12406, loss1 : 1.029862, loss2 : 1.765129
train_step : 12407, loss1 : 1.146883, loss2 : 1.940284
train_step : 12408, loss1 : 1.619410, loss2 : 1.408129
train_step : 12409, loss1 : 1.102514, loss2 : 1.408066
train_step : 12410, loss1 : 0.716946, loss2 : 2.290761
train_step : 12411, loss1 : 1.568119, loss2 : 0.747979
train_step : 12412, loss1 : 1.267784, loss2 : 2.311293
train_step : 12413, loss1 : 1.952744, loss2 : 2.232404
train_step : 12414, loss1 : 0.798266, loss2 : 0.933278
train_step : 12415, loss1 : 0.869747, loss2 : 1.393355
train_step : 12416, loss1 : 1.162513, loss2 : 1.555255
train_step : 12417, loss1 : 1.683131, loss2 : 1.979954
train_step : 12418, loss1 : 1.868086, loss2 : 1.910504
train_step : 12419, loss1 : 0.734261, loss2 : 1.249860
train_step : 12420, loss1 : 1.272575, loss2 : 1.241770
train_step : 12421, loss1 : 0.873502, loss2 : 0.454203
train_step : 12422, loss1 : 1.295840, loss2 : 0.761653
train_step : 12423, loss1 : 0.965598, loss2 : 1.076898
train_step : 12424, loss1 : 1.076935, loss2 : 1.203000
train_step : 12425, loss1 : 1.216045, loss2 : 1.065140
train_step : 12426, loss1 : 1.314127, loss2 : 1.220229
train_step : 12427, loss1 : 1.698837, loss2 : 1.983900
train_step : 12428, loss1 : 1.906415, loss2 : 1.841702
train_step : 12429, loss1 : 1.444551, loss2 : 1.041335
train_step : 12430, loss1 : 1.128542, loss2 : 0.982705
train_step : 12431, loss1 : 1.243555, loss2 : 1.718780
train_step : 12432, loss1 : 1.845863, loss2 : 1.961150
train_step : 12433, loss1 : 0.562865, loss2 : 1.531410
train_step : 12434, loss1 : 0.876427, loss2 : 1.024655
train_step : 12435, loss1 : 0.769886, loss2 : 0.919186
train_step : 12436, loss1 : 1.228335, loss2 : 0.790553
train_step : 12437, loss1 : 1.029953, loss2 : 0.724520
train_step : 12438, loss1 : 2.977053, loss2 : 2.253455
train_step : 12439, loss1 : 2.064647, loss2 : 4.351878
train_step : 12440, loss1 : 1.995909, loss2 : 1.621609
train_step : 12441, loss1 : 1.945775, loss2 : 2.934489
train_step : 12442, loss1 : 1.485825, loss2 : 1.505551
train_step : 12443, loss1 : 1.744782, loss2 : 1.781539
train_step : 12444, loss1 : 1.589901, loss2 : 1.496572
train_step : 12445, loss1 : 2.237287, loss2 : 2.507804
train_step : 12446, loss1 : 2.048249, loss2 : 1.259435
train_step : 12447, loss1 : 2.003879, loss2 : 1.291007
train_step : 12448, loss1 : 1.688554, loss2 : 1.690419
train_step : 12449, loss1 : 2.846101, loss2 : 3.732481
train_step : 12450, loss1 : 1.342479, loss2 : 3.044418
train_step : 12451, loss1 : 0.976831, loss2 : 2.343620
train_step : 12452, loss1 : 0.542765, loss2 : 1.473942
train_step : 12453, loss1 : 1.463391, loss2 : 0.492249
train_step : 12454, loss1 : 1.315348, loss2 : 1.103766
train_step : 12455, loss1 : 1.399705, loss2 : 1.674514
train_step : 12456, loss1 : 1.264799, loss2 : 1.939685
train_step : 12457, loss1 : 0.796942, loss2 : 1.361341
train_step : 12458, loss1 : 0.930247, loss2 : 1.065272
train_step : 12459, loss1 : 1.322910, loss2 : 0.741409
train_step : 12460, loss1 : 0.628509, loss2 : 1.854029
train_step : 12461, loss1 : 1.324146, loss2 : 1.562597
train_step : 12462, loss1 : 1.284889, loss2 : 0.943376
train_step : 12463, loss1 : 1.922690, loss2 : 0.950984
train_step : 12464, loss1 : 1.400016, loss2 : 1.689996
train_step : 12465, loss1 : 1.111560, loss2 : 1.209730
train_step : 12466, loss1 : 1.752437, loss2 : 1.118318
train_step : 12467, loss1 : 1.529883, loss2 : 1.074091
train_step : 12468, loss1 : 1.513145, loss2 : 1.368802
train_step : 12469, loss1 : 1.569177, loss2 : 1.480987
train_step : 12470, loss1 : 1.756014, loss2 : 1.631012
train_step : 12471, loss1 : 1.499551, loss2 : 1.438433
train_step : 12472, loss1 : 1.677063, loss2 : 2.186518
train_step : 12473, loss1 : 1.075628, loss2 : 1.030238
train_step : 12474, loss1 : 1.552883, loss2 : 0.985810
train_step : 12475, loss1 : 1.540635, loss2 : 0.782212
train_step : 12476, loss1 : 2.577310, loss2 : 1.748213
train_step : 12477, loss1 : 2.019401, loss2 : 2.660326
train_step : 12478, loss1 : 4.047103, loss2 : 2.819464
train_step : 12479, loss1 : 2.716784, loss2 : 4.221108
train_step : 12480, loss1 : 3.973171, loss2 : 4.115504
train_step : 12481, loss1 : 2.049662, loss2 : 3.455483
train_step : 12482, loss1 : 4.209309, loss2 : 2.837173
train_step : 12483, loss1 : 2.366963, loss2 : 3.751567
train_step : 12484, loss1 : 2.400305, loss2 : 3.124560
train_step : 12485, loss1 : 2.094374, loss2 : 1.955658
train_step : 12486, loss1 : 2.323257, loss2 : 1.846559
train_step : 12487, loss1 : 1.533057, loss2 : 1.814117
train_step : 12488, loss1 : 1.276614, loss2 : 1.865368
train_step : 12489, loss1 : 0.993751, loss2 : 1.007141
train_step : 12490, loss1 : 0.744641, loss2 : 1.185466
train_step : 12491, loss1 : 1.038713, loss2 : 3.853846
train_step : 12492, loss1 : 1.342612, loss2 : 1.531740
train_step : 12493, loss1 : 1.441344, loss2 : 1.192060
train_step : 12494, loss1 : 1.003858, loss2 : 0.581161
train_step : 12495, loss1 : 1.504001, loss2 : 0.925215
train_step : 12496, loss1 : 2.026999, loss2 : 0.679657
train_step : 12497, loss1 : 1.198887, loss2 : 0.967610
train_step : 12498, loss1 : 2.746027, loss2 : 0.976610
train_step : 12499, loss1 : 1.404025, loss2 : 1.119517
train_step : 12500, loss1 : 1.489618, loss2 : 0.882058
train_step : 12501, loss1 : 1.939028, loss2 : 0.900782
train_step : 12502, loss1 : 0.918673, loss2 : 0.682301
train_step : 12503, loss1 : 1.362163, loss2 : 0.742139
train_step : 12504, loss1 : 0.823745, loss2 : 1.441076
train_step : 12505, loss1 : 1.771790, loss2 : 0.990093
train_step : 12506, loss1 : 1.602679, loss2 : 1.220632
train_step : 12507, loss1 : 1.467209, loss2 : 1.527095
train_step : 12508, loss1 : 2.160517, loss2 : 1.970333
train_step : 12509, loss1 : 0.969085, loss2 : 2.053229
train_step : 12510, loss1 : 1.320321, loss2 : 2.003244
train_step : 12511, loss1 : 1.000094, loss2 : 1.278387
train_step : 12512, loss1 : 2.169275, loss2 : 1.383465
train_step : 12513, loss1 : 1.853240, loss2 : 0.903979
train_step : 12514, loss1 : 1.324731, loss2 : 1.335389
train_step : 12515, loss1 : 1.281970, loss2 : 0.870883
train_step : 12516, loss1 : 1.257377, loss2 : 1.044327
train_step : 12517, loss1 : 0.971000, loss2 : 0.804122
train_step : 12518, loss1 : 1.821521, loss2 : 1.180192
train_step : 12519, loss1 : 1.643525, loss2 : 2.307325
train_step : 12520, loss1 : 2.251513, loss2 : 1.447085
train_step : 12521, loss1 : 1.306337, loss2 : 1.480607
train_step : 12522, loss1 : 1.186031, loss2 : 1.297811
train_step : 12523, loss1 : 1.496747, loss2 : 1.443957
train_step : 12524, loss1 : 1.094063, loss2 : 2.766015
train_step : 12525, loss1 : 0.605707, loss2 : 1.206178
train_step : 12526, loss1 : 0.735490, loss2 : 1.528245
train_step : 12527, loss1 : 0.845022, loss2 : 1.205056
train_step : 12528, loss1 : 1.101560, loss2 : 1.279572
train_step : 12529, loss1 : 1.645072, loss2 : 0.597746
train_step : 12530, loss1 : 0.794788, loss2 : 1.018949
train_step : 12531, loss1 : 0.826518, loss2 : 0.774494
train_step : 12532, loss1 : 1.448074, loss2 : 1.652538
train_step : 12533, loss1 : 0.951767, loss2 : 1.611094
train_step : 12534, loss1 : 1.396109, loss2 : 1.455487
train_step : 12535, loss1 : 1.315041, loss2 : 6.154096
train_step : 12536, loss1 : 1.499305, loss2 : 1.070460
train_step : 12537, loss1 : 1.562989, loss2 : 1.921388
train_step : 12538, loss1 : 1.635921, loss2 : 1.767361
train_step : 12539, loss1 : 1.156276, loss2 : 1.311297
train_step : 12540, loss1 : 1.384903, loss2 : 1.884039
train_step : 12541, loss1 : 0.994611, loss2 : 2.123312
train_step : 12542, loss1 : 1.261996, loss2 : 1.284119
train_step : 12543, loss1 : 0.611881, loss2 : 1.224066
train_step : 12544, loss1 : 1.667726, loss2 : 1.037742
train_step : 12545, loss1 : 1.161106, loss2 : 0.900385
train_step : 12546, loss1 : 1.676351, loss2 : 1.947489
train_step : 12547, loss1 : 1.533451, loss2 : 1.692856
train_step : 12548, loss1 : 1.562453, loss2 : 1.896701
train_step : 12549, loss1 : 1.446220, loss2 : 2.228812
train_step : 12550, loss1 : 1.717121, loss2 : 1.790661
train_step : 12551, loss1 : 1.703943, loss2 : 1.227698
train_step : 12552, loss1 : 2.193984, loss2 : 1.630274
train_step : 12553, loss1 : 2.502814, loss2 : 1.795809
train_step : 12554, loss1 : 1.187935, loss2 : 1.568278
train_step : 12555, loss1 : 1.016478, loss2 : 1.264830
train_step : 12556, loss1 : 0.820125, loss2 : 2.549446
train_step : 12557, loss1 : 1.219090, loss2 : 1.203220
train_step : 12558, loss1 : 1.169151, loss2 : 1.248481
train_step : 12559, loss1 : 2.096754, loss2 : 1.248090
train_step : 12560, loss1 : 0.783975, loss2 : 1.601082
train_step : 12561, loss1 : 1.142455, loss2 : 1.755189
train_step : 12562, loss1 : 1.570176, loss2 : 0.782869
train_step : 12563, loss1 : 1.355275, loss2 : 1.425644
train_step : 12564, loss1 : 1.269519, loss2 : 0.726815
train_step : 12565, loss1 : 1.263867, loss2 : 1.165097
train_step : 12566, loss1 : 0.668583, loss2 : 1.229222
train_step : 12567, loss1 : 1.625314, loss2 : 1.213312
train_step : 12568, loss1 : 0.905235, loss2 : 1.259706
train_step : 12569, loss1 : 1.124397, loss2 : 1.096446
train_step : 12570, loss1 : 1.090876, loss2 : 0.665222
train_step : 12571, loss1 : 1.175308, loss2 : 2.338985
train_step : 12572, loss1 : 1.713107, loss2 : 2.426038
train_step : 12573, loss1 : 2.561340, loss2 : 2.023215
train_step : 12574, loss1 : 2.680198, loss2 : 1.418642
train_step : 12575, loss1 : 1.838624, loss2 : 2.260390
train_step : 12576, loss1 : 2.591011, loss2 : 1.241737
train_step : 12577, loss1 : 1.693428, loss2 : 1.543148
train_step : 12578, loss1 : 1.368097, loss2 : 1.203910
train_step : 12579, loss1 : 2.169933, loss2 : 1.525689
train_step : 12580, loss1 : 0.948096, loss2 : 1.197705
train_step : 12581, loss1 : 0.753060, loss2 : 1.025056
train_step : 12582, loss1 : 1.003000, loss2 : 2.136153
train_step : 12583, loss1 : 0.749140, loss2 : 1.124922
train_step : 12584, loss1 : 1.438001, loss2 : 1.157388
train_step : 12585, loss1 : 1.642391, loss2 : 1.481772
train_step : 12586, loss1 : 2.038098, loss2 : 1.633875
train_step : 12587, loss1 : 1.189551, loss2 : 0.917607
train_step : 12588, loss1 : 1.037048, loss2 : 1.264701
train_step : 12589, loss1 : 1.262731, loss2 : 1.292033
train_step : 12590, loss1 : 0.918770, loss2 : 1.206283
train_step : 12591, loss1 : 1.228486, loss2 : 0.953031
train_step : 12592, loss1 : 1.186845, loss2 : 1.444905
train_step : 12593, loss1 : 0.812041, loss2 : 0.634578
train_step : 12594, loss1 : 1.087531, loss2 : 1.079903
train_step : 12595, loss1 : 1.216750, loss2 : 0.687654
train_step : 12596, loss1 : 0.810083, loss2 : 1.172123
train_step : 12597, loss1 : 0.950644, loss2 : 1.312708
train_step : 12598, loss1 : 1.997792, loss2 : 1.193420
train_step : 12599, loss1 : 1.498819, loss2 : 1.929363
train_step : 12600, loss1 : 1.719208, loss2 : 2.335856
train_step : 12601, loss1 : 2.028326, loss2 : 2.634399
train_step : 12602, loss1 : 2.549836, loss2 : 2.739799
train_step : 12603, loss1 : 3.174967, loss2 : 2.962512
train_step : 12604, loss1 : 3.018062, loss2 : 6.056094
train_step : 12605, loss1 : 2.522017, loss2 : 2.434866
train_step : 12606, loss1 : 2.246236, loss2 : 1.967857
train_step : 12607, loss1 : 1.475865, loss2 : 1.098808
train_step : 12608, loss1 : 1.221907, loss2 : 1.883398
train_step : 12609, loss1 : 2.330616, loss2 : 1.175232
train_step : 12610, loss1 : 1.145474, loss2 : 0.818712
train_step : 12611, loss1 : 1.079461, loss2 : 1.551806
train_step : 12612, loss1 : 1.294844, loss2 : 0.800810
train_step : 12613, loss1 : 0.958786, loss2 : 0.728895
train_step : 12614, loss1 : 0.651783, loss2 : 3.166490
train_step : 12615, loss1 : 1.183480, loss2 : 2.033487
train_step : 12616, loss1 : 0.964081, loss2 : 1.259924
train_step : 12617, loss1 : 1.053738, loss2 : 1.205061
train_step : 12618, loss1 : 1.393981, loss2 : 0.838133
train_step : 12619, loss1 : 1.963162, loss2 : 1.505181
train_step : 12620, loss1 : 1.161793, loss2 : 0.908193
train_step : 12621, loss1 : 1.550713, loss2 : 0.926395
train_step : 12622, loss1 : 0.898156, loss2 : 1.327601
train_step : 12623, loss1 : 1.126765, loss2 : 1.540875
train_step : 12624, loss1 : 1.212127, loss2 : 0.747401
train_step : 12625, loss1 : 0.872418, loss2 : 1.883796
train_step : 12626, loss1 : 0.753669, loss2 : 0.422430
train_step : 12627, loss1 : 1.987032, loss2 : 1.118560
train_step : 12628, loss1 : 1.586540, loss2 : 1.503121
train_step : 12629, loss1 : 1.450815, loss2 : 1.717645
train_step : 12630, loss1 : 1.510080, loss2 : 1.800439
train_step : 12631, loss1 : 1.663740, loss2 : 1.420588
train_step : 12632, loss1 : 0.811704, loss2 : 1.080126
train_step : 12633, loss1 : 0.759474, loss2 : 0.603844
train_step : 12634, loss1 : 0.758837, loss2 : 1.251162
train_step : 12635, loss1 : 0.813550, loss2 : 1.084232
train_step : 12636, loss1 : 1.450773, loss2 : 1.603608
train_step : 12637, loss1 : 1.116511, loss2 : 0.895771
train_step : 12638, loss1 : 1.900004, loss2 : 2.059758
train_step : 12639, loss1 : 1.973931, loss2 : 1.998547
train_step : 12640, loss1 : 1.521302, loss2 : 1.364525
train_step : 12641, loss1 : 1.332112, loss2 : 1.330285
train_step : 12642, loss1 : 0.946344, loss2 : 2.042132
train_step : 12643, loss1 : 0.972332, loss2 : 1.591830
train_step : 12644, loss1 : 1.251046, loss2 : 0.935934
train_step : 12645, loss1 : 1.501177, loss2 : 1.120746
train_step : 12646, loss1 : 1.849127, loss2 : 2.148963
train_step : 12647, loss1 : 1.147394, loss2 : 1.820999
train_step : 12648, loss1 : 1.360182, loss2 : 1.729076
train_step : 12649, loss1 : 2.816481, loss2 : 2.515847
train_step : 12650, loss1 : 2.304010, loss2 : 1.504665
train_step : 12651, loss1 : 0.983119, loss2 : 1.805000
train_step : 12652, loss1 : 0.831650, loss2 : 1.132472
train_step : 12653, loss1 : 1.555279, loss2 : 0.625685
train_step : 12654, loss1 : 1.825898, loss2 : 1.662991
train_step : 12655, loss1 : 0.569543, loss2 : 1.565724
train_step : 12656, loss1 : 0.332983, loss2 : 1.462485
train_step : 12657, loss1 : 1.479576, loss2 : 1.557433
train_step : 12658, loss1 : 0.600677, loss2 : 1.195285
train_step : 12659, loss1 : 1.428256, loss2 : 0.934148
train_step : 12660, loss1 : 1.063923, loss2 : 1.017335
train_step : 12661, loss1 : 1.268769, loss2 : 1.028188
train_step : 12662, loss1 : 1.165264, loss2 : 1.179007
train_step : 12663, loss1 : 0.966481, loss2 : 1.844573
train_step : 12664, loss1 : 1.023099, loss2 : 1.292571
train_step : 12665, loss1 : 1.974155, loss2 : 0.831164
train_step : 12666, loss1 : 1.160997, loss2 : 0.851363
train_step : 12667, loss1 : 1.629129, loss2 : 1.735058
train_step : 12668, loss1 : 1.680599, loss2 : 1.229671
train_step : 12669, loss1 : 1.186617, loss2 : 1.079727
train_step : 12670, loss1 : 1.537271, loss2 : 0.941373
train_step : 12671, loss1 : 1.652467, loss2 : 1.008877
train_step : 12672, loss1 : 0.753168, loss2 : 2.060291
train_step : 12673, loss1 : 1.609880, loss2 : 0.818143
train_step : 12674, loss1 : 1.904964, loss2 : 1.261392
train_step : 12675, loss1 : 1.234905, loss2 : 0.736620
train_step : 12676, loss1 : 0.883992, loss2 : 2.387892
train_step : 12677, loss1 : 2.263306, loss2 : 1.432797
train_step : 12678, loss1 : 1.187204, loss2 : 1.942893
train_step : 12679, loss1 : 1.407212, loss2 : 1.779102
train_step : 12680, loss1 : 0.749362, loss2 : 1.024362
train_step : 12681, loss1 : 0.772774, loss2 : 1.367966
train_step : 12682, loss1 : 1.637307, loss2 : 1.040658
train_step : 12683, loss1 : 0.881125, loss2 : 1.010355
train_step : 12684, loss1 : 1.622877, loss2 : 0.964379
train_step : 12685, loss1 : 1.422162, loss2 : 1.239892
train_step : 12686, loss1 : 1.556768, loss2 : 0.645949
train_step : 12687, loss1 : 1.014248, loss2 : 1.079304
train_step : 12688, loss1 : 1.309963, loss2 : 1.419897
train_step : 12689, loss1 : 2.320846, loss2 : 0.499525
train_step : 12690, loss1 : 1.168274, loss2 : 1.530648
train_step : 12691, loss1 : 1.688157, loss2 : 1.160531
train_step : 12692, loss1 : 1.103785, loss2 : 1.077287
train_step : 12693, loss1 : 3.246468, loss2 : 1.290409
train_step : 12694, loss1 : 1.566595, loss2 : 1.868100
train_step : 12695, loss1 : 2.283608, loss2 : 2.153404
train_step : 12696, loss1 : 2.404374, loss2 : 3.673149
train_step : 12697, loss1 : 2.088203, loss2 : 2.191010
train_step : 12698, loss1 : 3.018627, loss2 : 2.460836
train_step : 12699, loss1 : 2.766144, loss2 : 2.156332
train_step : 12700, loss1 : 2.579601, loss2 : 3.352835
train_step : 12701, loss1 : 1.838546, loss2 : 2.176831
train_step : 12702, loss1 : 2.133532, loss2 : 1.738959
train_step : 12703, loss1 : 2.266914, loss2 : 2.030763
train_step : 12704, loss1 : 2.064397, loss2 : 2.026640
train_step : 12705, loss1 : 2.069093, loss2 : 2.106415
train_step : 12706, loss1 : 3.384771, loss2 : 3.131109
train_step : 12707, loss1 : 1.276081, loss2 : 1.658008
train_step : 12708, loss1 : 1.819058, loss2 : 1.309126
train_step : 12709, loss1 : 2.557077, loss2 : 0.829842
train_step : 12710, loss1 : 4.186983, loss2 : 1.881701
train_step : 12711, loss1 : 1.914524, loss2 : 1.860104
train_step : 12712, loss1 : 1.187189, loss2 : 1.812698
train_step : 12713, loss1 : 1.559949, loss2 : 1.503824
train_step : 12714, loss1 : 1.768302, loss2 : 1.510884
train_step : 12715, loss1 : 1.227004, loss2 : 1.302598
train_step : 12716, loss1 : 0.408406, loss2 : 1.069023
train_step : 12717, loss1 : 0.969712, loss2 : 1.722531
train_step : 12718, loss1 : 1.921653, loss2 : 1.733867
train_step : 12719, loss1 : 1.426788, loss2 : 1.082448
train_step : 12720, loss1 : 2.479932, loss2 : 1.630564
train_step : 12721, loss1 : 0.844552, loss2 : 1.438622
train_step : 12722, loss1 : 1.505802, loss2 : 1.638201
train_step : 12723, loss1 : 1.692495, loss2 : 1.662872
train_step : 12724, loss1 : 2.517030, loss2 : 3.587286
train_step : 12725, loss1 : 3.613746, loss2 : 3.228972
train_step : 12726, loss1 : 3.534901, loss2 : 3.663857
train_step : 12727, loss1 : 1.149407, loss2 : 0.819552
train_step : 12728, loss1 : 1.491274, loss2 : 1.465255
train_step : 12729, loss1 : 1.579149, loss2 : 1.128907
train_step : 12730, loss1 : 2.262472, loss2 : 0.934289
train_step : 12731, loss1 : 1.523567, loss2 : 2.414611
train_step : 12732, loss1 : 2.946457, loss2 : 2.171062
train_step : 12733, loss1 : 3.668246, loss2 : 1.886746
train_step : 12734, loss1 : 4.534021, loss2 : 4.315832
train_step : 12735, loss1 : 1.892249, loss2 : 3.573522
train_step : 12736, loss1 : 2.354431, loss2 : 2.700326
train_step : 12737, loss1 : 3.247666, loss2 : 6.022548
train_step : 12738, loss1 : 7.743247, loss2 : 4.332877
train_step : 12739, loss1 : 2.804420, loss2 : 3.349611
train_step : 12740, loss1 : 2.309646, loss2 : 3.054800
train_step : 12741, loss1 : 1.191372, loss2 : 1.034374
train_step : 12742, loss1 : 1.416279, loss2 : 1.480684
train_step : 12743, loss1 : 2.525162, loss2 : 1.446612
train_step : 12744, loss1 : 1.467642, loss2 : 1.431777
train_step : 12745, loss1 : 1.559542, loss2 : 1.595895
train_step : 12746, loss1 : 1.070641, loss2 : 2.010661
train_step : 12747, loss1 : 0.871058, loss2 : 1.172693
train_step : 12748, loss1 : 0.829278, loss2 : 1.687633
train_step : 12749, loss1 : 0.826535, loss2 : 1.606741
train_step : 12750, loss1 : 1.445565, loss2 : 0.718194
train_step : 12751, loss1 : 1.532156, loss2 : 0.998476
train_step : 12752, loss1 : 1.452182, loss2 : 2.035762
train_step : 12753, loss1 : 2.685690, loss2 : 2.058310
train_step : 12754, loss1 : 3.091486, loss2 : 2.742193
train_step : 12755, loss1 : 2.307913, loss2 : 2.227326
train_step : 12756, loss1 : 2.116641, loss2 : 1.561255
train_step : 12757, loss1 : 1.820082, loss2 : 1.181722
train_step : 12758, loss1 : 1.251279, loss2 : 2.045466
train_step : 12759, loss1 : 1.511707, loss2 : 1.657509
train_step : 12760, loss1 : 1.755204, loss2 : 0.934671
train_step : 12761, loss1 : 1.968790, loss2 : 1.316913
train_step : 12762, loss1 : 1.656333, loss2 : 1.375503
train_step : 12763, loss1 : 1.219232, loss2 : 1.342094
train_step : 12764, loss1 : 0.608890, loss2 : 1.047843
train_step : 12765, loss1 : 0.714164, loss2 : 1.553010
train_step : 12766, loss1 : 2.068669, loss2 : 1.388671
train_step : 12767, loss1 : 1.695130, loss2 : 1.278434
train_step : 12768, loss1 : 0.789067, loss2 : 1.671556
train_step : 12769, loss1 : 1.153347, loss2 : 1.577191
train_step : 12770, loss1 : 1.484545, loss2 : 1.743944
train_step : 12771, loss1 : 1.608657, loss2 : 1.501469
train_step : 12772, loss1 : 1.004424, loss2 : 1.719465
train_step : 12773, loss1 : 0.545249, loss2 : 0.701653
train_step : 12774, loss1 : 1.918344, loss2 : 0.962411
train_step : 12775, loss1 : 2.039038, loss2 : 1.072816
train_step : 12776, loss1 : 1.764540, loss2 : 0.970932
train_step : 12777, loss1 : 0.835545, loss2 : 1.391731
train_step : 12778, loss1 : 1.268942, loss2 : 0.767664
train_step : 12779, loss1 : 0.976702, loss2 : 1.780911
train_step : 12780, loss1 : 1.040884, loss2 : 0.863559
train_step : 12781, loss1 : 0.610945, loss2 : 1.591592
train_step : 12782, loss1 : 1.228161, loss2 : 0.796290
train_step : 12783, loss1 : 0.629703, loss2 : 1.407737
train_step : 12784, loss1 : 1.881394, loss2 : 1.611782
train_step : 12785, loss1 : 1.466347, loss2 : 0.383086
train_step : 12786, loss1 : 0.994161, loss2 : 1.332184
train_step : 12787, loss1 : 0.808977, loss2 : 0.816177
train_step : 12788, loss1 : 1.049060, loss2 : 1.684306
train_step : 12789, loss1 : 0.769585, loss2 : 1.208281
train_step : 12790, loss1 : 0.971535, loss2 : 2.153422
train_step : 12791, loss1 : 1.361160, loss2 : 1.884059
train_step : 12792, loss1 : 1.121351, loss2 : 1.744182
train_step : 12793, loss1 : 2.146136, loss2 : 2.448149
train_step : 12794, loss1 : 1.825328, loss2 : 1.465753
train_step : 12795, loss1 : 1.416579, loss2 : 2.454944
train_step : 12796, loss1 : 1.196505, loss2 : 0.977637
train_step : 12797, loss1 : 1.777629, loss2 : 1.311693
train_step : 12798, loss1 : 1.536518, loss2 : 1.382068
train_step : 12799, loss1 : 1.119014, loss2 : 1.207356
train_step : 12800, loss1 : 1.093865, loss2 : 1.024611
train_step : 12801, loss1 : 1.400541, loss2 : 1.337942
train_step : 12802, loss1 : 2.665959, loss2 : 2.254909
train_step : 12803, loss1 : 1.859027, loss2 : 2.836179
train_step : 12804, loss1 : 2.303620, loss2 : 1.544804
train_step : 12805, loss1 : 2.654227, loss2 : 1.912383
train_step : 12806, loss1 : 1.687145, loss2 : 2.094013
train_step : 12807, loss1 : 0.553801, loss2 : 1.058053
train_step : 12808, loss1 : 1.234745, loss2 : 1.032636
train_step : 12809, loss1 : 1.410409, loss2 : 1.427109
train_step : 12810, loss1 : 1.216421, loss2 : 1.326552
train_step : 12811, loss1 : 1.211313, loss2 : 1.048159
train_step : 12812, loss1 : 0.890897, loss2 : 1.264500
train_step : 12813, loss1 : 2.446346, loss2 : 1.006245
train_step : 12814, loss1 : 1.676347, loss2 : 1.018086
train_step : 12815, loss1 : 1.730905, loss2 : 2.207040
train_step : 12816, loss1 : 2.730144, loss2 : 1.733319
train_step : 12817, loss1 : 2.976442, loss2 : 2.624429
train_step : 12818, loss1 : 3.825749, loss2 : 3.893898
train_step : 12819, loss1 : 3.786798, loss2 : 4.200802
train_step : 12820, loss1 : 4.610499, loss2 : 3.108010
train_step : 12821, loss1 : 1.615051, loss2 : 3.672435
train_step : 12822, loss1 : 3.818045, loss2 : 2.620464
train_step : 12823, loss1 : 2.690417, loss2 : 0.904971
train_step : 12824, loss1 : 1.857859, loss2 : 2.270422
train_step : 12825, loss1 : 0.774257, loss2 : 0.790191
train_step : 12826, loss1 : 1.299801, loss2 : 1.349234
train_step : 12827, loss1 : 1.343396, loss2 : 1.238296
train_step : 12828, loss1 : 1.061364, loss2 : 1.637417
train_step : 12829, loss1 : 0.709139, loss2 : 0.944823
train_step : 12830, loss1 : 2.053505, loss2 : 1.142352
train_step : 12831, loss1 : 0.521230, loss2 : 0.662236
train_step : 12832, loss1 : 0.719922, loss2 : 1.087819
train_step : 12833, loss1 : 0.950321, loss2 : 1.306807
train_step : 12834, loss1 : 1.187092, loss2 : 0.900574
train_step : 12835, loss1 : 1.583980, loss2 : 1.151832
train_step : 12836, loss1 : 1.040695, loss2 : 1.074365
train_step : 12837, loss1 : 1.197101, loss2 : 1.047672
train_step : 12838, loss1 : 1.277511, loss2 : 0.712478
train_step : 12839, loss1 : 1.177846, loss2 : 1.408332
train_step : 12840, loss1 : 2.453896, loss2 : 3.186028
train_step : 12841, loss1 : 2.661737, loss2 : 2.652073
train_step : 12842, loss1 : 0.876311, loss2 : 0.788683
train_step : 12843, loss1 : 0.616799, loss2 : 1.026858
train_step : 12844, loss1 : 0.694983, loss2 : 0.915615
train_step : 12845, loss1 : 1.758850, loss2 : 1.052502
train_step : 12846, loss1 : 1.014620, loss2 : 0.685341
train_step : 12847, loss1 : 1.187134, loss2 : 1.631410
train_step : 12848, loss1 : 1.001390, loss2 : 2.032742
train_step : 12849, loss1 : 0.874749, loss2 : 0.993336
train_step : 12850, loss1 : 1.914833, loss2 : 0.864101
train_step : 12851, loss1 : 1.092797, loss2 : 1.193113
train_step : 12852, loss1 : 1.200586, loss2 : 0.916930
train_step : 12853, loss1 : 1.428137, loss2 : 1.073464
train_step : 12854, loss1 : 0.830330, loss2 : 0.974392
train_step : 12855, loss1 : 0.836600, loss2 : 0.814798
train_step : 12856, loss1 : 1.198632, loss2 : 1.665633
train_step : 12857, loss1 : 0.640394, loss2 : 0.661267
train_step : 12858, loss1 : 1.202798, loss2 : 1.070103
train_step : 12859, loss1 : 1.161450, loss2 : 1.221478
train_step : 12860, loss1 : 2.666819, loss2 : 1.674277
train_step : 12861, loss1 : 2.124168, loss2 : 0.917541
train_step : 12862, loss1 : 0.769808, loss2 : 2.133688
train_step : 12863, loss1 : 0.793431, loss2 : 1.496917
train_step : 12864, loss1 : 1.398674, loss2 : 1.608128
train_step : 12865, loss1 : 1.575693, loss2 : 0.912671
train_step : 12866, loss1 : 1.320154, loss2 : 1.157259
train_step : 12867, loss1 : 2.853425, loss2 : 1.713718
train_step : 12868, loss1 : 2.033524, loss2 : 1.211846
train_step : 12869, loss1 : 2.299982, loss2 : 1.743148
train_step : 12870, loss1 : 1.232557, loss2 : 0.814923
train_step : 12871, loss1 : 0.736283, loss2 : 1.606811
train_step : 12872, loss1 : 0.944285, loss2 : 1.056457
train_step : 12873, loss1 : 1.177748, loss2 : 2.889786
train_step : 12874, loss1 : 0.972333, loss2 : 0.814057
train_step : 12875, loss1 : 1.393237, loss2 : 1.119032
train_step : 12876, loss1 : 1.634788, loss2 : 0.878208
train_step : 12877, loss1 : 1.378253, loss2 : 0.690338
train_step : 12878, loss1 : 1.328330, loss2 : 0.934930
train_step : 12879, loss1 : 1.440289, loss2 : 1.357118
train_step : 12880, loss1 : 0.883869, loss2 : 3.796242
train_step : 12881, loss1 : 1.489500, loss2 : 1.418588
train_step : 12882, loss1 : 1.191526, loss2 : 0.850396
train_step : 12883, loss1 : 0.757265, loss2 : 0.777563
train_step : 12884, loss1 : 1.434035, loss2 : 0.788563
train_step : 12885, loss1 : 1.554613, loss2 : 0.706417
train_step : 12886, loss1 : 1.061008, loss2 : 0.825836
train_step : 12887, loss1 : 1.048675, loss2 : 1.440928
train_step : 12888, loss1 : 1.155583, loss2 : 1.179646
train_step : 12889, loss1 : 1.869630, loss2 : 0.435052
train_step : 12890, loss1 : 0.989052, loss2 : 0.820178
train_step : 12891, loss1 : 0.692961, loss2 : 1.087792
train_step : 12892, loss1 : 0.911074, loss2 : 1.151476
train_step : 12893, loss1 : 1.387685, loss2 : 1.481691
train_step : 12894, loss1 : 1.409995, loss2 : 0.964441
train_step : 12895, loss1 : 1.688765, loss2 : 1.766231
train_step : 12896, loss1 : 1.891601, loss2 : 1.717568
train_step : 12897, loss1 : 1.164623, loss2 : 1.508811
train_step : 12898, loss1 : 1.182180, loss2 : 1.369467
train_step : 12899, loss1 : 1.183240, loss2 : 0.824361
train_step : 12900, loss1 : 1.510213, loss2 : 0.794840
train_step : 12901, loss1 : 0.988013, loss2 : 1.129174
train_step : 12902, loss1 : 0.729688, loss2 : 2.085087
train_step : 12903, loss1 : 1.132532, loss2 : 0.765490
train_step : 12904, loss1 : 1.525607, loss2 : 1.235726
train_step : 12905, loss1 : 0.820978, loss2 : 1.892264
train_step : 12906, loss1 : 2.138895, loss2 : 0.689647
train_step : 12907, loss1 : 1.177939, loss2 : 1.324711
train_step : 12908, loss1 : 1.099939, loss2 : 0.641485
train_step : 12909, loss1 : 1.353152, loss2 : 0.697186
train_step : 12910, loss1 : 0.658596, loss2 : 0.591513
train_step : 12911, loss1 : 1.424681, loss2 : 1.571035
train_step : 12912, loss1 : 0.729582, loss2 : 0.625947
train_step : 12913, loss1 : 1.402513, loss2 : 1.024716
train_step : 12914, loss1 : 1.503027, loss2 : 0.857632
train_step : 12915, loss1 : 1.072187, loss2 : 1.454907
train_step : 12916, loss1 : 1.167905, loss2 : 1.122591
train_step : 12917, loss1 : 0.830360, loss2 : 1.123017
train_step : 12918, loss1 : 1.405351, loss2 : 1.450335
train_step : 12919, loss1 : 2.308646, loss2 : 2.713969
train_step : 12920, loss1 : 1.741126, loss2 : 2.798330
train_step : 12921, loss1 : 2.195325, loss2 : 1.196642
train_step : 12922, loss1 : 2.172922, loss2 : 2.161275
train_step : 12923, loss1 : 2.315137, loss2 : 1.972268
train_step : 12924, loss1 : 1.200397, loss2 : 1.277197
train_step : 12925, loss1 : 1.373317, loss2 : 0.930408
train_step : 12926, loss1 : 1.520989, loss2 : 1.129702
train_step : 12927, loss1 : 1.190962, loss2 : 2.106419
train_step : 12928, loss1 : 1.517504, loss2 : 1.870096
train_step : 12929, loss1 : 1.424829, loss2 : 1.055278
train_step : 12930, loss1 : 1.310451, loss2 : 1.932279
train_step : 12931, loss1 : 1.128104, loss2 : 1.652106
train_step : 12932, loss1 : 1.485917, loss2 : 1.461819
train_step : 12933, loss1 : 0.815634, loss2 : 0.876119
train_step : 12934, loss1 : 1.056666, loss2 : 0.889362
train_step : 12935, loss1 : 1.605717, loss2 : 1.267896
train_step : 12936, loss1 : 1.090965, loss2 : 1.124885
train_step : 12937, loss1 : 1.119044, loss2 : 1.688850
train_step : 12938, loss1 : 1.153585, loss2 : 0.742421
train_step : 12939, loss1 : 0.790014, loss2 : 1.657445
train_step : 12940, loss1 : 1.949956, loss2 : 1.198220
train_step : 12941, loss1 : 1.128906, loss2 : 1.270836
train_step : 12942, loss1 : 1.346798, loss2 : 0.995931
train_step : 12943, loss1 : 1.685352, loss2 : 1.259944
train_step : 12944, loss1 : 1.535992, loss2 : 1.007146
train_step : 12945, loss1 : 1.620508, loss2 : 2.083831
train_step : 12946, loss1 : 1.927220, loss2 : 0.934075
train_step : 12947, loss1 : 0.662813, loss2 : 1.138149
train_step : 12948, loss1 : 1.668429, loss2 : 0.997759
train_step : 12949, loss1 : 0.544137, loss2 : 1.455947
train_step : 12950, loss1 : 0.827088, loss2 : 0.864695
train_step : 12951, loss1 : 0.816924, loss2 : 0.845445
train_step : 12952, loss1 : 1.595902, loss2 : 0.888370
train_step : 12953, loss1 : 0.811303, loss2 : 0.998234
train_step : 12954, loss1 : 1.115358, loss2 : 0.836766
train_step : 12955, loss1 : 1.573425, loss2 : 1.596802
train_step : 12956, loss1 : 1.772465, loss2 : 1.929938
train_step : 12957, loss1 : 1.775552, loss2 : 1.814521
train_step : 12958, loss1 : 1.531483, loss2 : 1.285565
train_step : 12959, loss1 : 0.971156, loss2 : 1.788427
train_step : 12960, loss1 : 1.459758, loss2 : 1.410454
train_step : 12961, loss1 : 0.806375, loss2 : 1.944514
train_step : 12962, loss1 : 2.508964, loss2 : 1.755729
train_step : 12963, loss1 : 3.349236, loss2 : 2.210308
train_step : 12964, loss1 : 1.903634, loss2 : 2.718486
train_step : 12965, loss1 : 2.130935, loss2 : 2.189647
train_step : 12966, loss1 : 3.017633, loss2 : 2.000779
train_step : 12967, loss1 : 1.933876, loss2 : 1.446324
train_step : 12968, loss1 : 0.908151, loss2 : 1.938761
train_step : 12969, loss1 : 1.769370, loss2 : 1.766606
train_step : 12970, loss1 : 0.807786, loss2 : 0.699737
train_step : 12971, loss1 : 1.656349, loss2 : 1.495985
train_step : 12972, loss1 : 2.581819, loss2 : 1.441802
train_step : 12973, loss1 : 1.434496, loss2 : 1.810020
train_step : 12974, loss1 : 0.655055, loss2 : 0.812218
train_step : 12975, loss1 : 0.876785, loss2 : 3.549401
train_step : 12976, loss1 : 1.241516, loss2 : 1.048029
train_step : 12977, loss1 : 1.835883, loss2 : 1.831986
train_step : 12978, loss1 : 2.758215, loss2 : 1.736676
train_step : 12979, loss1 : 1.127986, loss2 : 0.936015
train_step : 12980, loss1 : 1.004879, loss2 : 1.022201
train_step : 12981, loss1 : 1.355470, loss2 : 2.605108
train_step : 12982, loss1 : 1.605990, loss2 : 1.604623
train_step : 12983, loss1 : 1.299446, loss2 : 1.013422
train_step : 12984, loss1 : 0.738189, loss2 : 0.547892
train_step : 12985, loss1 : 1.382776, loss2 : 0.921482
train_step : 12986, loss1 : 1.253928, loss2 : 1.262659
train_step : 12987, loss1 : 1.495582, loss2 : 1.024287
train_step : 12988, loss1 : 0.922345, loss2 : 0.616811
train_step : 12989, loss1 : 0.714257, loss2 : 0.969363
train_step : 12990, loss1 : 1.443776, loss2 : 1.004774
train_step : 12991, loss1 : 1.020649, loss2 : 1.049116
train_step : 12992, loss1 : 1.068323, loss2 : 0.936550
train_step : 12993, loss1 : 1.167434, loss2 : 1.400044
train_step : 12994, loss1 : 0.795164, loss2 : 0.770475
train_step : 12995, loss1 : 1.157654, loss2 : 0.762056
train_step : 12996, loss1 : 0.857297, loss2 : 1.329646
train_step : 12997, loss1 : 1.026183, loss2 : 0.791722
train_step : 12998, loss1 : 1.586270, loss2 : 1.266712
train_step : 12999, loss1 : 1.792103, loss2 : 1.312779
train_step : 13000, loss1 : 1.002963, loss2 : 1.446069
train_step : 13001, loss1 : 0.800240, loss2 : 0.885905
train_step : 13002, loss1 : 0.739741, loss2 : 2.281776
train_step : 13003, loss1 : 1.274355, loss2 : 1.151565
train_step : 13004, loss1 : 0.828237, loss2 : 1.173886
train_step : 13005, loss1 : 1.084948, loss2 : 0.961083
train_step : 13006, loss1 : 0.803404, loss2 : 0.817415
train_step : 13007, loss1 : 1.264767, loss2 : 1.940000
train_step : 13008, loss1 : 1.375330, loss2 : 0.822949
train_step : 13009, loss1 : 1.420604, loss2 : 0.874041
train_step : 13010, loss1 : 1.227711, loss2 : 0.930110
train_step : 13011, loss1 : 1.509499, loss2 : 2.185029
train_step : 13012, loss1 : 1.815359, loss2 : 2.332156
train_step : 13013, loss1 : 1.863272, loss2 : 2.054066
train_step : 13014, loss1 : 2.109149, loss2 : 1.468306
train_step : 13015, loss1 : 1.312020, loss2 : 1.397861
train_step : 13016, loss1 : 1.612419, loss2 : 1.256264
train_step : 13017, loss1 : 0.893607, loss2 : 1.100519
train_step : 13018, loss1 : 1.527833, loss2 : 2.078074
train_step : 13019, loss1 : 0.683569, loss2 : 0.794204
train_step : 13020, loss1 : 1.434155, loss2 : 0.811477
train_step : 13021, loss1 : 0.934379, loss2 : 0.684922
train_step : 13022, loss1 : 0.649505, loss2 : 1.809960
train_step : 13023, loss1 : 0.727062, loss2 : 1.593552
train_step : 13024, loss1 : 0.835897, loss2 : 0.939904
train_step : 13025, loss1 : 1.219693, loss2 : 1.878172
train_step : 13026, loss1 : 1.347823, loss2 : 1.673649
train_step : 13027, loss1 : 1.713753, loss2 : 1.561340
train_step : 13028, loss1 : 0.907738, loss2 : 0.812820
train_step : 13029, loss1 : 1.177872, loss2 : 1.416109
train_step : 13030, loss1 : 0.803525, loss2 : 0.757894
train_step : 13031, loss1 : 1.492216, loss2 : 0.766913
train_step : 13032, loss1 : 0.998169, loss2 : 0.576155
train_step : 13033, loss1 : 1.902509, loss2 : 1.231173
train_step : 13034, loss1 : 1.299605, loss2 : 1.980520
train_step : 13035, loss1 : 1.320081, loss2 : 1.001202
train_step : 13036, loss1 : 1.822173, loss2 : 1.213068
train_step : 13037, loss1 : 1.128406, loss2 : 2.043655
train_step : 13038, loss1 : 1.092342, loss2 : 1.259518
train_step : 13039, loss1 : 0.876342, loss2 : 1.379612
train_step : 13040, loss1 : 0.722380, loss2 : 1.014732
train_step : 13041, loss1 : 1.264018, loss2 : 0.645597
train_step : 13042, loss1 : 0.969364, loss2 : 1.250606
train_step : 13043, loss1 : 1.387877, loss2 : 1.369093
train_step : 13044, loss1 : 1.266940, loss2 : 1.065119
train_step : 13045, loss1 : 1.126120, loss2 : 1.737739
train_step : 13046, loss1 : 1.314710, loss2 : 1.283486
train_step : 13047, loss1 : 1.498458, loss2 : 1.675575
train_step : 13048, loss1 : 1.310092, loss2 : 1.417460
train_step : 13049, loss1 : 1.213546, loss2 : 1.385564
train_step : 13050, loss1 : 1.343313, loss2 : 0.814026
train_step : 13051, loss1 : 1.585040, loss2 : 1.251541
train_step : 13052, loss1 : 1.770885, loss2 : 1.441732
train_step : 13053, loss1 : 0.811897, loss2 : 1.596570
train_step : 13054, loss1 : 1.884673, loss2 : 0.989585
train_step : 13055, loss1 : 1.343256, loss2 : 1.718684
train_step : 13056, loss1 : 0.566506, loss2 : 1.323218
train_step : 13057, loss1 : 0.846648, loss2 : 1.134164
train_step : 13058, loss1 : 1.555908, loss2 : 1.482252
train_step : 13059, loss1 : 0.824972, loss2 : 1.203932
train_step : 13060, loss1 : 1.996190, loss2 : 1.461566
train_step : 13061, loss1 : 2.522216, loss2 : 1.981027
train_step : 13062, loss1 : 1.508745, loss2 : 2.883960
train_step : 13063, loss1 : 1.032128, loss2 : 1.629648
train_step : 13064, loss1 : 0.678266, loss2 : 0.791142
train_step : 13065, loss1 : 0.923821, loss2 : 0.641196
train_step : 13066, loss1 : 1.030224, loss2 : 1.730936
train_step : 13067, loss1 : 1.779866, loss2 : 1.509889
train_step : 13068, loss1 : 0.627034, loss2 : 1.505698
train_step : 13069, loss1 : 1.326890, loss2 : 1.227295
train_step : 13070, loss1 : 1.348553, loss2 : 2.087069
train_step : 13071, loss1 : 2.504197, loss2 : 1.742036
train_step : 13072, loss1 : 2.807935, loss2 : 2.802017
train_step : 13073, loss1 : 2.522238, loss2 : 1.420071
train_step : 13074, loss1 : 1.706539, loss2 : 2.029780
train_step : 13075, loss1 : 1.570493, loss2 : 1.296535
train_step : 13076, loss1 : 1.269079, loss2 : 1.640740
train_step : 13077, loss1 : 1.896121, loss2 : 1.050983
train_step : 13078, loss1 : 1.331860, loss2 : 1.150888
train_step : 13079, loss1 : 0.916734, loss2 : 0.830482
train_step : 13080, loss1 : 0.956107, loss2 : 0.994261
train_step : 13081, loss1 : 0.749778, loss2 : 1.686053
train_step : 13082, loss1 : 0.602696, loss2 : 1.122869
train_step : 13083, loss1 : 0.839042, loss2 : 0.751967
train_step : 13084, loss1 : 1.261693, loss2 : 0.524984
train_step : 13085, loss1 : 1.266643, loss2 : 1.717934
train_step : 13086, loss1 : 1.278132, loss2 : 1.450182
train_step : 13087, loss1 : 2.258837, loss2 : 1.535038
train_step : 13088, loss1 : 2.257623, loss2 : 1.973468
train_step : 13089, loss1 : 1.093836, loss2 : 1.654563
train_step : 13090, loss1 : 1.847257, loss2 : 1.437368
train_step : 13091, loss1 : 1.295909, loss2 : 1.047496
train_step : 13092, loss1 : 2.521813, loss2 : 2.017195
train_step : 13093, loss1 : 1.394641, loss2 : 1.914207
train_step : 13094, loss1 : 3.715790, loss2 : 1.095659
train_step : 13095, loss1 : 1.713193, loss2 : 1.739338
train_step : 13096, loss1 : 1.419324, loss2 : 0.775852
train_step : 13097, loss1 : 0.845225, loss2 : 1.019500
train_step : 13098, loss1 : 1.368487, loss2 : 1.694744
train_step : 13099, loss1 : 1.919379, loss2 : 2.112595
train_step : 13100, loss1 : 4.074347, loss2 : 2.960605
train_step : 13101, loss1 : 3.269124, loss2 : 3.782539
train_step : 13102, loss1 : 2.712819, loss2 : 2.515967
train_step : 13103, loss1 : 2.079373, loss2 : 2.010632
train_step : 13104, loss1 : 2.712714, loss2 : 1.375555
train_step : 13105, loss1 : 2.144033, loss2 : 1.593211
train_step : 13106, loss1 : 1.697869, loss2 : 2.234282
train_step : 13107, loss1 : 1.827831, loss2 : 1.494174
train_step : 13108, loss1 : 1.713974, loss2 : 1.543268
train_step : 13109, loss1 : 1.695700, loss2 : 1.647858
train_step : 13110, loss1 : 0.425837, loss2 : 0.908793
train_step : 13111, loss1 : 1.046185, loss2 : 0.999277
train_step : 13112, loss1 : 1.136680, loss2 : 2.005487
train_step : 13113, loss1 : 1.226854, loss2 : 1.014828
train_step : 13114, loss1 : 1.636918, loss2 : 1.792953
train_step : 13115, loss1 : 0.975256, loss2 : 0.982438
train_step : 13116, loss1 : 0.775652, loss2 : 1.116471
train_step : 13117, loss1 : 1.208900, loss2 : 2.063198
train_step : 13118, loss1 : 1.458364, loss2 : 1.369710
train_step : 13119, loss1 : 0.667219, loss2 : 1.354033
train_step : 13120, loss1 : 1.899348, loss2 : 1.160380
train_step : 13121, loss1 : 1.141335, loss2 : 4.913373
train_step : 13122, loss1 : 0.855709, loss2 : 2.101551
train_step : 13123, loss1 : 1.055188, loss2 : 1.345079
train_step : 13124, loss1 : 1.149096, loss2 : 1.462289
train_step : 13125, loss1 : 2.315497, loss2 : 1.489584
train_step : 13126, loss1 : 1.909790, loss2 : 2.023135
train_step : 13127, loss1 : 1.918900, loss2 : 1.331740
train_step : 13128, loss1 : 2.236040, loss2 : 1.373486
train_step : 13129, loss1 : 1.541531, loss2 : 2.046904
train_step : 13130, loss1 : 2.833894, loss2 : 1.022071
train_step : 13131, loss1 : 1.165863, loss2 : 1.801258
train_step : 13132, loss1 : 0.577280, loss2 : 3.239766
train_step : 13133, loss1 : 1.885156, loss2 : 1.544325
train_step : 13134, loss1 : 2.027646, loss2 : 1.743323
train_step : 13135, loss1 : 1.009013, loss2 : 2.858144
train_step : 13136, loss1 : 1.840932, loss2 : 2.679345
train_step : 13137, loss1 : 1.740380, loss2 : 2.392267
train_step : 13138, loss1 : 2.162772, loss2 : 1.955123
train_step : 13139, loss1 : 2.024365, loss2 : 1.995252
train_step : 13140, loss1 : 1.474620, loss2 : 1.306823
train_step : 13141, loss1 : 0.727168, loss2 : 1.372465
train_step : 13142, loss1 : 0.981539, loss2 : 1.761820
train_step : 13143, loss1 : 1.166143, loss2 : 2.026347
train_step : 13144, loss1 : 1.839976, loss2 : 1.334953
train_step : 13145, loss1 : 1.105041, loss2 : 1.398268
train_step : 13146, loss1 : 1.246434, loss2 : 1.328636
train_step : 13147, loss1 : 1.477069, loss2 : 1.115063
train_step : 13148, loss1 : 1.210715, loss2 : 0.989516
train_step : 13149, loss1 : 1.077507, loss2 : 0.903172
train_step : 13150, loss1 : 1.249445, loss2 : 0.892842
train_step : 13151, loss1 : 0.659041, loss2 : 0.833733
train_step : 13152, loss1 : 0.674127, loss2 : 1.462017
train_step : 13153, loss1 : 0.849300, loss2 : 0.804707
train_step : 13154, loss1 : 0.917239, loss2 : 1.736846
train_step : 13155, loss1 : 1.778866, loss2 : 1.079692
train_step : 13156, loss1 : 1.473123, loss2 : 0.989435
train_step : 13157, loss1 : 1.364388, loss2 : 1.379394
train_step : 13158, loss1 : 2.392487, loss2 : 1.316761
train_step : 13159, loss1 : 2.254048, loss2 : 2.079741
train_step : 13160, loss1 : 1.143871, loss2 : 3.138072
train_step : 13161, loss1 : 1.630008, loss2 : 1.980693
train_step : 13162, loss1 : 1.285083, loss2 : 2.014358
train_step : 13163, loss1 : 0.986254, loss2 : 1.223969
train_step : 13164, loss1 : 0.832105, loss2 : 1.831237
train_step : 13165, loss1 : 1.625777, loss2 : 2.117616
train_step : 13166, loss1 : 2.600403, loss2 : 1.938963
train_step : 13167, loss1 : 3.459635, loss2 : 1.415990
train_step : 13168, loss1 : 2.538934, loss2 : 3.435137
train_step : 13169, loss1 : 3.344872, loss2 : 2.865343
train_step : 13170, loss1 : 2.022634, loss2 : 2.708844
train_step : 13171, loss1 : 1.135680, loss2 : 2.070133
train_step : 13172, loss1 : 0.841082, loss2 : 1.317715
train_step : 13173, loss1 : 0.564054, loss2 : 1.060517
train_step : 13174, loss1 : 1.806612, loss2 : 1.247312
train_step : 13175, loss1 : 0.782798, loss2 : 2.400846
train_step : 13176, loss1 : 1.462497, loss2 : 1.720612
train_step : 13177, loss1 : 1.648790, loss2 : 1.308551
train_step : 13178, loss1 : 0.434381, loss2 : 1.336454
train_step : 13179, loss1 : 1.510084, loss2 : 0.826927
train_step : 13180, loss1 : 0.779086, loss2 : 1.377476
train_step : 13181, loss1 : 0.729691, loss2 : 0.970241
train_step : 13182, loss1 : 0.662407, loss2 : 0.987480
train_step : 13183, loss1 : 1.326272, loss2 : 1.893269
train_step : 13184, loss1 : 1.672416, loss2 : 1.195435
train_step : 13185, loss1 : 0.537636, loss2 : 0.869253
train_step : 13186, loss1 : 0.869625, loss2 : 0.680709
train_step : 13187, loss1 : 0.461900, loss2 : 0.921573
train_step : 13188, loss1 : 1.105871, loss2 : 1.417636
train_step : 13189, loss1 : 1.158608, loss2 : 0.850324
train_step : 13190, loss1 : 1.902539, loss2 : 1.200281
train_step : 13191, loss1 : 2.457831, loss2 : 2.461202
train_step : 13192, loss1 : 1.189233, loss2 : 2.373486
train_step : 13193, loss1 : 1.927906, loss2 : 2.116079
train_step : 13194, loss1 : 0.705933, loss2 : 0.894552
train_step : 13195, loss1 : 0.605750, loss2 : 1.246693
train_step : 13196, loss1 : 1.344798, loss2 : 1.226195
train_step : 13197, loss1 : 0.888602, loss2 : 1.198553
train_step : 13198, loss1 : 0.522813, loss2 : 1.639128
train_step : 13199, loss1 : 1.357021, loss2 : 1.189525
train_step : 13200, loss1 : 1.758802, loss2 : 0.892234
train_step : 13201, loss1 : 0.708761, loss2 : 0.668216
train_step : 13202, loss1 : 1.199200, loss2 : 0.665338
train_step : 13203, loss1 : 0.707846, loss2 : 1.087322
train_step : 13204, loss1 : 1.696019, loss2 : 1.243697
train_step : 13205, loss1 : 1.816530, loss2 : 1.385355
train_step : 13206, loss1 : 1.427223, loss2 : 0.990780
train_step : 13207, loss1 : 1.422007, loss2 : 1.431836
train_step : 13208, loss1 : 1.891266, loss2 : 1.294387
train_step : 13209, loss1 : 0.769821, loss2 : 0.956336
train_step : 13210, loss1 : 1.487462, loss2 : 1.173124
train_step : 13211, loss1 : 1.842412, loss2 : 1.395917
train_step : 13212, loss1 : 2.141706, loss2 : 2.815905
train_step : 13213, loss1 : 3.329725, loss2 : 2.693589
train_step : 13214, loss1 : 4.347224, loss2 : 3.642563
train_step : 13215, loss1 : 4.271250, loss2 : 3.479543
train_step : 13216, loss1 : 1.655460, loss2 : 2.737931
train_step : 13217, loss1 : 3.008322, loss2 : 2.423480
train_step : 13218, loss1 : 2.354869, loss2 : 1.003041
train_step : 13219, loss1 : 1.701720, loss2 : 1.901206
train_step : 13220, loss1 : 0.956012, loss2 : 1.477465
train_step : 13221, loss1 : 1.483668, loss2 : 1.010087
train_step : 13222, loss1 : 0.573479, loss2 : 1.575927
train_step : 13223, loss1 : 1.033423, loss2 : 1.398242
train_step : 13224, loss1 : 1.408144, loss2 : 0.699190
train_step : 13225, loss1 : 0.344513, loss2 : 1.141448
train_step : 13226, loss1 : 1.372990, loss2 : 1.022559
train_step : 13227, loss1 : 0.512736, loss2 : 1.031981
train_step : 13228, loss1 : 1.142681, loss2 : 1.725543
train_step : 13229, loss1 : 1.076051, loss2 : 1.371961
train_step : 13230, loss1 : 0.896662, loss2 : 0.824549
train_step : 13231, loss1 : 0.689810, loss2 : 1.288926
train_step : 13232, loss1 : 1.278919, loss2 : 1.239237
train_step : 13233, loss1 : 1.205748, loss2 : 0.925817
train_step : 13234, loss1 : 0.966156, loss2 : 0.568623
train_step : 13235, loss1 : 1.471962, loss2 : 0.868686
train_step : 13236, loss1 : 2.254095, loss2 : 0.799750
train_step : 13237, loss1 : 1.081049, loss2 : 1.151465
train_step : 13238, loss1 : 0.909208, loss2 : 1.154154
train_step : 13239, loss1 : 1.317717, loss2 : 1.168308
train_step : 13240, loss1 : 1.646646, loss2 : 1.037082
train_step : 13241, loss1 : 1.134593, loss2 : 0.704661
train_step : 13242, loss1 : 0.830598, loss2 : 0.829085
train_step : 13243, loss1 : 0.920738, loss2 : 1.195137
train_step : 13244, loss1 : 1.061959, loss2 : 1.115160
train_step : 13245, loss1 : 1.564632, loss2 : 0.682781
train_step : 13246, loss1 : 1.182842, loss2 : 1.136756
train_step : 13247, loss1 : 1.071281, loss2 : 1.273563
train_step : 13248, loss1 : 1.759278, loss2 : 1.275029
train_step : 13249, loss1 : 1.547710, loss2 : 1.239802
train_step : 13250, loss1 : 1.573269, loss2 : 1.552889
train_step : 13251, loss1 : 2.381509, loss2 : 3.063322
train_step : 13252, loss1 : 3.350782, loss2 : 3.460759
train_step : 13253, loss1 : 3.209902, loss2 : 2.714480
train_step : 13254, loss1 : 2.535868, loss2 : 2.696022
train_step : 13255, loss1 : 3.680695, loss2 : 2.982877
train_step : 13256, loss1 : 2.048323, loss2 : 1.850102
train_step : 13257, loss1 : 1.708190, loss2 : 2.167019
train_step : 13258, loss1 : 2.374283, loss2 : 2.011152
train_step : 13259, loss1 : 2.742625, loss2 : 1.945423
train_step : 13260, loss1 : 1.711238, loss2 : 2.214560
train_step : 13261, loss1 : 1.033118, loss2 : 1.656125
train_step : 13262, loss1 : 1.416196, loss2 : 0.892500
train_step : 13263, loss1 : 1.205993, loss2 : 2.664577
train_step : 13264, loss1 : 2.135009, loss2 : 1.927799
train_step : 13265, loss1 : 2.667785, loss2 : 3.736714
train_step : 13266, loss1 : 3.830173, loss2 : 3.044638
train_step : 13267, loss1 : 4.735774, loss2 : 3.637724
train_step : 13268, loss1 : 0.927406, loss2 : 3.007541
train_step : 13269, loss1 : 1.674155, loss2 : 1.902094
train_step : 13270, loss1 : 2.120688, loss2 : 1.094081
train_step : 13271, loss1 : 1.322348, loss2 : 1.739892
train_step : 13272, loss1 : 1.466606, loss2 : 1.201091
train_step : 13273, loss1 : 1.207657, loss2 : 1.409718
train_step : 13274, loss1 : 1.395941, loss2 : 0.764567
train_step : 13275, loss1 : 1.524123, loss2 : 1.264191
train_step : 13276, loss1 : 1.036266, loss2 : 0.903587
train_step : 13277, loss1 : 1.075770, loss2 : 0.849773
train_step : 13278, loss1 : 1.203887, loss2 : 1.053132
train_step : 13279, loss1 : 1.180998, loss2 : 1.776228
train_step : 13280, loss1 : 1.031160, loss2 : 1.290180
train_step : 13281, loss1 : 2.076549, loss2 : 1.491135
train_step : 13282, loss1 : 3.806138, loss2 : 1.896301
train_step : 13283, loss1 : 3.027366, loss2 : 3.445055
train_step : 13284, loss1 : 1.232386, loss2 : 1.123650
train_step : 13285, loss1 : 1.613082, loss2 : 2.193182
train_step : 13286, loss1 : 2.010169, loss2 : 2.417295
train_step : 13287, loss1 : 1.297121, loss2 : 2.513258
train_step : 13288, loss1 : 0.960119, loss2 : 2.224230
train_step : 13289, loss1 : 1.074191, loss2 : 1.749937
train_step : 13290, loss1 : 1.110001, loss2 : 1.153821
train_step : 13291, loss1 : 0.840076, loss2 : 1.727741
train_step : 13292, loss1 : 0.716938, loss2 : 1.098400
train_step : 13293, loss1 : 1.015265, loss2 : 0.469977
train_step : 13294, loss1 : 1.510002, loss2 : 0.755884
train_step : 13295, loss1 : 0.706816, loss2 : 1.375857
train_step : 13296, loss1 : 1.378191, loss2 : 1.329069
train_step : 13297, loss1 : 1.575708, loss2 : 1.276404
train_step : 13298, loss1 : 1.466704, loss2 : 4.816807
train_step : 13299, loss1 : 1.928666, loss2 : 2.018314
train_step : 13300, loss1 : 2.187148, loss2 : 2.210335
train_step : 13301, loss1 : 1.119860, loss2 : 1.216490
train_step : 13302, loss1 : 1.239030, loss2 : 1.450658
train_step : 13303, loss1 : 0.606293, loss2 : 3.128129
train_step : 13304, loss1 : 1.000290, loss2 : 1.127933
train_step : 13305, loss1 : 1.307929, loss2 : 1.442608
train_step : 13306, loss1 : 3.083010, loss2 : 2.020784
train_step : 13307, loss1 : 3.566026, loss2 : 3.170452
train_step : 13308, loss1 : 4.891048, loss2 : 2.924341
train_step : 13309, loss1 : 3.575244, loss2 : 5.191546
train_step : 13310, loss1 : 4.510611, loss2 : 4.240849
train_step : 13311, loss1 : 2.685236, loss2 : 3.138919
train_step : 13312, loss1 : 2.814143, loss2 : 2.628586
train_step : 13313, loss1 : 1.849336, loss2 : 2.515320
train_step : 13314, loss1 : 2.702471, loss2 : 3.003589
train_step : 13315, loss1 : 2.646275, loss2 : 3.849029
train_step : 13316, loss1 : 3.451100, loss2 : 4.074051
train_step : 13317, loss1 : 2.013126, loss2 : 0.684231
train_step : 13318, loss1 : 1.091660, loss2 : 1.289413
train_step : 13319, loss1 : 0.954275, loss2 : 1.076999
train_step : 13320, loss1 : 1.407946, loss2 : 1.437316
train_step : 13321, loss1 : 0.969343, loss2 : 0.921944
train_step : 13322, loss1 : 0.845221, loss2 : 2.616665
train_step : 13323, loss1 : 0.921887, loss2 : 0.946151
train_step : 13324, loss1 : 2.708219, loss2 : 1.562390
train_step : 13325, loss1 : 0.785570, loss2 : 1.102006
train_step : 13326, loss1 : 1.462223, loss2 : 0.653193
train_step : 13327, loss1 : 1.752755, loss2 : 1.100743
train_step : 13328, loss1 : 1.365120, loss2 : 1.106802
train_step : 13329, loss1 : 1.907688, loss2 : 0.956876
train_step : 13330, loss1 : 0.578770, loss2 : 0.854883
train_step : 13331, loss1 : 1.496000, loss2 : 1.088642
train_step : 13332, loss1 : 0.845283, loss2 : 1.407206
train_step : 13333, loss1 : 0.898157, loss2 : 1.154227
train_step : 13334, loss1 : 1.444605, loss2 : 0.924933
train_step : 13335, loss1 : 0.424331, loss2 : 0.844826
train_step : 13336, loss1 : 1.235895, loss2 : 3.083787
train_step : 13337, loss1 : 1.890880, loss2 : 1.127465
train_step : 13338, loss1 : 1.281943, loss2 : 1.646385
train_step : 13339, loss1 : 1.092569, loss2 : 1.515041
train_step : 13340, loss1 : 0.834242, loss2 : 1.007914
train_step : 13341, loss1 : 0.517785, loss2 : 0.928805
train_step : 13342, loss1 : 1.383400, loss2 : 0.690955
train_step : 13343, loss1 : 1.150877, loss2 : 0.670006
train_step : 13344, loss1 : 1.941037, loss2 : 1.160575
train_step : 13345, loss1 : 1.448154, loss2 : 1.274649
train_step : 13346, loss1 : 0.823639, loss2 : 1.757280
train_step : 13347, loss1 : 1.412450, loss2 : 1.057399
train_step : 13348, loss1 : 0.758392, loss2 : 1.444530
train_step : 13349, loss1 : 1.431696, loss2 : 2.984117
train_step : 13350, loss1 : 0.686044, loss2 : 1.176198
train_step : 13351, loss1 : 0.981375, loss2 : 0.644001
train_step : 13352, loss1 : 1.347936, loss2 : 1.018450
train_step : 13353, loss1 : 1.590926, loss2 : 0.949974
train_step : 13354, loss1 : 1.537237, loss2 : 1.286745
train_step : 13355, loss1 : 1.492079, loss2 : 1.209214
train_step : 13356, loss1 : 1.216672, loss2 : 1.082864
train_step : 13357, loss1 : 0.954185, loss2 : 1.884044
train_step : 13358, loss1 : 1.032031, loss2 : 2.102184
train_step : 13359, loss1 : 1.410918, loss2 : 1.176633
train_step : 13360, loss1 : 1.340222, loss2 : 2.070200
train_step : 13361, loss1 : 1.137475, loss2 : 0.870785
train_step : 13362, loss1 : 0.768250, loss2 : 1.269579
train_step : 13363, loss1 : 0.870304, loss2 : 0.593722
train_step : 13364, loss1 : 0.661785, loss2 : 1.150526
train_step : 13365, loss1 : 1.837803, loss2 : 1.154579
train_step : 13366, loss1 : 1.283716, loss2 : 0.985679
train_step : 13367, loss1 : 1.022411, loss2 : 2.126024
train_step : 13368, loss1 : 0.835083, loss2 : 0.962516
train_step : 13369, loss1 : 0.589638, loss2 : 1.972587
train_step : 13370, loss1 : 1.457362, loss2 : 0.820976
train_step : 13371, loss1 : 0.434531, loss2 : 0.976177
train_step : 13372, loss1 : 1.150796, loss2 : 1.332469
train_step : 13373, loss1 : 1.044327, loss2 : 1.336748
train_step : 13374, loss1 : 1.624302, loss2 : 0.759817
train_step : 13375, loss1 : 1.075579, loss2 : 0.961522
train_step : 13376, loss1 : 1.738979, loss2 : 0.946811
train_step : 13377, loss1 : 0.994081, loss2 : 1.072786
train_step : 13378, loss1 : 0.648605, loss2 : 0.783160
train_step : 13379, loss1 : 1.592267, loss2 : 1.005368
train_step : 13380, loss1 : 1.558721, loss2 : 2.448501
train_step : 13381, loss1 : 0.643863, loss2 : 1.377998
train_step : 13382, loss1 : 1.338878, loss2 : 0.841916
train_step : 13383, loss1 : 0.920182, loss2 : 0.757664
train_step : 13384, loss1 : 0.959288, loss2 : 0.673529
train_step : 13385, loss1 : 1.295101, loss2 : 1.168454
train_step : 13386, loss1 : 1.095362, loss2 : 0.845950
train_step : 13387, loss1 : 1.331904, loss2 : 1.355401
train_step : 13388, loss1 : 1.058330, loss2 : 1.198944
train_step : 13389, loss1 : 0.813559, loss2 : 1.049661
train_step : 13390, loss1 : 0.983100, loss2 : 1.910470
train_step : 13391, loss1 : 1.246777, loss2 : 1.024086
train_step : 13392, loss1 : 1.542901, loss2 : 0.915429
train_step : 13393, loss1 : 1.101810, loss2 : 1.345794
train_step : 13394, loss1 : 1.326012, loss2 : 0.947074
train_step : 13395, loss1 : 2.143387, loss2 : 1.543763
train_step : 13396, loss1 : 1.376024, loss2 : 1.421134
train_step : 13397, loss1 : 1.297255, loss2 : 1.687281
train_step : 13398, loss1 : 1.265402, loss2 : 0.835548
train_step : 13399, loss1 : 1.455139, loss2 : 1.225584
train_step : 13400, loss1 : 1.059061, loss2 : 0.656518
train_step : 13401, loss1 : 0.981610, loss2 : 1.348909
train_step : 13402, loss1 : 0.982745, loss2 : 1.824342
train_step : 13403, loss1 : 1.643009, loss2 : 1.380816
train_step : 13404, loss1 : 1.857398, loss2 : 1.480469
train_step : 13405, loss1 : 1.693247, loss2 : 1.481051
train_step : 13406, loss1 : 1.409628, loss2 : 1.863341
train_step : 13407, loss1 : 1.149139, loss2 : 1.267238
train_step : 13408, loss1 : 1.191035, loss2 : 0.900589
train_step : 13409, loss1 : 0.780879, loss2 : 1.296527
train_step : 13410, loss1 : 0.892301, loss2 : 1.131384
train_step : 13411, loss1 : 1.138241, loss2 : 1.012517
train_step : 13412, loss1 : 1.119532, loss2 : 0.869101
train_step : 13413, loss1 : 1.917885, loss2 : 1.485453
train_step : 13414, loss1 : 0.959796, loss2 : 1.119395
train_step : 13415, loss1 : 0.510090, loss2 : 0.899998
train_step : 13416, loss1 : 1.235880, loss2 : 0.708323
train_step : 13417, loss1 : 1.178094, loss2 : 1.607355
train_step : 13418, loss1 : 1.540920, loss2 : 1.644770
train_step : 13419, loss1 : 1.159789, loss2 : 0.703139
train_step : 13420, loss1 : 0.829158, loss2 : 1.570347
train_step : 13421, loss1 : 1.044121, loss2 : 1.340209
train_step : 13422, loss1 : 1.148342, loss2 : 1.155254
train_step : 13423, loss1 : 1.209698, loss2 : 1.589727
train_step : 13424, loss1 : 1.623616, loss2 : 1.078974
train_step : 13425, loss1 : 0.950827, loss2 : 1.034222
train_step : 13426, loss1 : 0.820679, loss2 : 1.087805
train_step : 13427, loss1 : 1.133813, loss2 : 1.067535
train_step : 13428, loss1 : 0.566042, loss2 : 1.449271
train_step : 13429, loss1 : 2.065860, loss2 : 0.957918
train_step : 13430, loss1 : 1.176584, loss2 : 0.977765
train_step : 13431, loss1 : 1.027378, loss2 : 1.983929
train_step : 13432, loss1 : 1.091896, loss2 : 1.213573
train_step : 13433, loss1 : 0.818460, loss2 : 2.302211
train_step : 13434, loss1 : 1.590949, loss2 : 1.821390
train_step : 13435, loss1 : 0.613098, loss2 : 1.340934
train_step : 13436, loss1 : 1.186121, loss2 : 0.918120
train_step : 13437, loss1 : 1.519970, loss2 : 1.484414
train_step : 13438, loss1 : 1.678925, loss2 : 1.547169
train_step : 13439, loss1 : 1.562533, loss2 : 1.167065
train_step : 13440, loss1 : 2.028880, loss2 : 1.374365
train_step : 13441, loss1 : 1.059869, loss2 : 1.807512
train_step : 13442, loss1 : 1.605103, loss2 : 1.039538
train_step : 13443, loss1 : 3.282724, loss2 : 1.835091
train_step : 13444, loss1 : 1.257631, loss2 : 4.021998
train_step : 13445, loss1 : 1.815067, loss2 : 2.531796
train_step : 13446, loss1 : 1.393958, loss2 : 1.132737
train_step : 13447, loss1 : 1.247049, loss2 : 1.239778
train_step : 13448, loss1 : 1.573655, loss2 : 1.064789
train_step : 13449, loss1 : 0.887985, loss2 : 1.340015
train_step : 13450, loss1 : 1.254036, loss2 : 1.385118
train_step : 13451, loss1 : 1.377101, loss2 : 1.004830
train_step : 13452, loss1 : 1.319593, loss2 : 1.010936
train_step : 13453, loss1 : 0.997619, loss2 : 1.841287
train_step : 13454, loss1 : 1.176337, loss2 : 1.570985
train_step : 13455, loss1 : 1.643522, loss2 : 0.819133
train_step : 13456, loss1 : 1.063797, loss2 : 2.448136
train_step : 13457, loss1 : 1.086399, loss2 : 1.081783
train_step : 13458, loss1 : 1.310847, loss2 : 0.711599
train_step : 13459, loss1 : 0.834676, loss2 : 1.473692
train_step : 13460, loss1 : 1.471029, loss2 : 0.666902
train_step : 13461, loss1 : 1.422403, loss2 : 1.352508
train_step : 13462, loss1 : 1.433007, loss2 : 1.597674
train_step : 13463, loss1 : 1.401504, loss2 : 2.111994
train_step : 13464, loss1 : 1.488626, loss2 : 1.314394
train_step : 13465, loss1 : 1.091232, loss2 : 1.191516
train_step : 13466, loss1 : 1.192699, loss2 : 0.929607
train_step : 13467, loss1 : 1.767002, loss2 : 1.485278
train_step : 13468, loss1 : 0.933200, loss2 : 1.384062
train_step : 13469, loss1 : 0.582849, loss2 : 1.189845
train_step : 13470, loss1 : 0.773621, loss2 : 1.646239
train_step : 13471, loss1 : 1.344897, loss2 : 1.102194
train_step : 13472, loss1 : 1.177895, loss2 : 0.788761
train_step : 13473, loss1 : 1.225083, loss2 : 0.974662
train_step : 13474, loss1 : 0.643427, loss2 : 1.417528
train_step : 13475, loss1 : 0.969760, loss2 : 1.102219
train_step : 13476, loss1 : 1.476291, loss2 : 1.428526
train_step : 13477, loss1 : 1.139028, loss2 : 0.733851
train_step : 13478, loss1 : 1.131660, loss2 : 1.407349
train_step : 13479, loss1 : 1.106925, loss2 : 1.254146
train_step : 13480, loss1 : 1.273367, loss2 : 0.840237
train_step : 13481, loss1 : 0.923228, loss2 : 0.726117
train_step : 13482, loss1 : 1.793043, loss2 : 1.924052
train_step : 13483, loss1 : 1.225184, loss2 : 1.216614
train_step : 13484, loss1 : 0.738144, loss2 : 1.415239
train_step : 13485, loss1 : 1.211508, loss2 : 1.372570
train_step : 13486, loss1 : 1.226926, loss2 : 1.155893
train_step : 13487, loss1 : 1.839287, loss2 : 1.458249
train_step : 13488, loss1 : 1.150554, loss2 : 1.095471
train_step : 13489, loss1 : 1.309912, loss2 : 0.770628
train_step : 13490, loss1 : 0.853758, loss2 : 0.683792
train_step : 13491, loss1 : 1.305562, loss2 : 1.134579
train_step : 13492, loss1 : 1.771310, loss2 : 2.037535
train_step : 13493, loss1 : 1.197677, loss2 : 1.355721
train_step : 13494, loss1 : 0.931275, loss2 : 1.229399
train_step : 13495, loss1 : 1.600565, loss2 : 1.969583
train_step : 13496, loss1 : 2.509939, loss2 : 1.994557
train_step : 13497, loss1 : 2.196268, loss2 : 2.233775
train_step : 13498, loss1 : 1.731231, loss2 : 1.907553
train_step : 13499, loss1 : 1.329261, loss2 : 1.090655
train_step : 13500, loss1 : 1.041131, loss2 : 1.681683
train_step : 13501, loss1 : 0.478100, loss2 : 1.427137
train_step : 13502, loss1 : 0.944213, loss2 : 0.981144
train_step : 13503, loss1 : 1.278850, loss2 : 0.971331
train_step : 13504, loss1 : 1.244296, loss2 : 1.589045
train_step : 13505, loss1 : 1.561181, loss2 : 3.334635
train_step : 13506, loss1 : 3.520888, loss2 : 3.989262
train_step : 13507, loss1 : 4.487922, loss2 : 4.216294
train_step : 13508, loss1 : 6.129454, loss2 : 5.882215
train_step : 13509, loss1 : 5.418288, loss2 : 6.186310
train_step : 13510, loss1 : 8.161113, loss2 : 8.006952
train_step : 13511, loss1 : 5.497359, loss2 : 5.496256
train_step : 13512, loss1 : 5.228607, loss2 : 9.076281
train_step : 13513, loss1 : 3.962341, loss2 : 4.969999
train_step : 13514, loss1 : 3.947552, loss2 : 4.948909
train_step : 13515, loss1 : 3.309478, loss2 : 1.677380
train_step : 13516, loss1 : 4.030255, loss2 : 3.722747
train_step : 13517, loss1 : 3.322272, loss2 : 4.283666
train_step : 13518, loss1 : 4.030428, loss2 : 3.912743
train_step : 13519, loss1 : 2.353976, loss2 : 3.192105
train_step : 13520, loss1 : 2.613233, loss2 : 2.689580
train_step : 13521, loss1 : 2.218266, loss2 : 2.584336
train_step : 13522, loss1 : 3.741496, loss2 : 2.476183
train_step : 13523, loss1 : 1.885560, loss2 : 2.633202
train_step : 13524, loss1 : 2.497487, loss2 : 1.896150
train_step : 13525, loss1 : 2.726480, loss2 : 1.390717
train_step : 13526, loss1 : 1.556328, loss2 : 2.441817
train_step : 13527, loss1 : 2.130063, loss2 : 1.464597
train_step : 13528, loss1 : 1.294700, loss2 : 1.930883
train_step : 13529, loss1 : 1.494856, loss2 : 0.994394
train_step : 13530, loss1 : 0.989809, loss2 : 2.664450
train_step : 13531, loss1 : 1.378038, loss2 : 0.851019
train_step : 13532, loss1 : 1.093995, loss2 : 1.443844
train_step : 13533, loss1 : 1.256721, loss2 : 1.555622
train_step : 13534, loss1 : 1.536776, loss2 : 1.539295
train_step : 13535, loss1 : 0.933956, loss2 : 1.057117
train_step : 13536, loss1 : 1.173184, loss2 : 1.178712
train_step : 13537, loss1 : 1.173921, loss2 : 0.990486
train_step : 13538, loss1 : 1.619993, loss2 : 0.966615
train_step : 13539, loss1 : 1.158314, loss2 : 1.595221
train_step : 13540, loss1 : 1.352169, loss2 : 0.970129
train_step : 13541, loss1 : 1.432877, loss2 : 1.172002
train_step : 13542, loss1 : 1.503906, loss2 : 1.680786
train_step : 13543, loss1 : 0.926868, loss2 : 0.660264
train_step : 13544, loss1 : 0.994367, loss2 : 0.931989
train_step : 13545, loss1 : 1.021949, loss2 : 0.901487
train_step : 13546, loss1 : 0.860772, loss2 : 0.917623
train_step : 13547, loss1 : 1.034832, loss2 : 0.970636
train_step : 13548, loss1 : 1.358534, loss2 : 1.329175
train_step : 13549, loss1 : 2.273094, loss2 : 0.768604
train_step : 13550, loss1 : 1.002241, loss2 : 0.989470
train_step : 13551, loss1 : 2.131374, loss2 : 0.728200
train_step : 13552, loss1 : 1.151433, loss2 : 2.044789
train_step : 13553, loss1 : 1.008564, loss2 : 1.398654
train_step : 13554, loss1 : 1.039758, loss2 : 1.978031
train_step : 13555, loss1 : 1.044848, loss2 : 0.590608
train_step : 13556, loss1 : 0.927456, loss2 : 0.543758
train_step : 13557, loss1 : 0.880017, loss2 : 1.318716
train_step : 13558, loss1 : 1.942214, loss2 : 1.449603
train_step : 13559, loss1 : 1.155257, loss2 : 1.517303
train_step : 13560, loss1 : 0.948625, loss2 : 1.235565
train_step : 13561, loss1 : 0.873397, loss2 : 0.860037
train_step : 13562, loss1 : 1.614654, loss2 : 0.677606
train_step : 13563, loss1 : 1.726789, loss2 : 2.592402
train_step : 13564, loss1 : 1.445481, loss2 : 1.027150
train_step : 13565, loss1 : 1.735891, loss2 : 1.454910
train_step : 13566, loss1 : 1.478307, loss2 : 0.892751
train_step : 13567, loss1 : 1.030702, loss2 : 1.250445
train_step : 13568, loss1 : 1.577874, loss2 : 0.414168
train_step : 13569, loss1 : 1.694654, loss2 : 1.252761
train_step : 13570, loss1 : 1.998071, loss2 : 1.124933
train_step : 13571, loss1 : 0.729076, loss2 : 1.508072
train_step : 13572, loss1 : 1.419116, loss2 : 1.593841
train_step : 13573, loss1 : 1.050449, loss2 : 1.304669
train_step : 13574, loss1 : 1.263837, loss2 : 1.132826
train_step : 13575, loss1 : 1.894004, loss2 : 1.054205
train_step : 13576, loss1 : 1.173504, loss2 : 1.349364
train_step : 13577, loss1 : 1.670606, loss2 : 0.902633
train_step : 13578, loss1 : 2.221711, loss2 : 2.055457
train_step : 13579, loss1 : 1.501942, loss2 : 2.447706
train_step : 13580, loss1 : 1.207046, loss2 : 1.912726
train_step : 13581, loss1 : 1.481086, loss2 : 1.376791
train_step : 13582, loss1 : 0.555905, loss2 : 1.042244
train_step : 13583, loss1 : 0.770504, loss2 : 0.957623
train_step : 13584, loss1 : 0.676110, loss2 : 1.106403
train_step : 13585, loss1 : 1.114478, loss2 : 0.738571
train_step : 13586, loss1 : 0.701844, loss2 : 1.083840
train_step : 13587, loss1 : 0.895544, loss2 : 1.314236
train_step : 13588, loss1 : 1.405934, loss2 : 0.886403
train_step : 13589, loss1 : 1.408487, loss2 : 0.693772
train_step : 13590, loss1 : 2.977009, loss2 : 1.908802
train_step : 13591, loss1 : 1.543009, loss2 : 1.337157
train_step : 13592, loss1 : 1.166901, loss2 : 1.295022
train_step : 13593, loss1 : 1.072306, loss2 : 1.472549
train_step : 13594, loss1 : 1.163260, loss2 : 1.592712
train_step : 13595, loss1 : 1.173625, loss2 : 1.195360
train_step : 13596, loss1 : 0.983688, loss2 : 1.296799
train_step : 13597, loss1 : 1.671525, loss2 : 0.923169
train_step : 13598, loss1 : 0.646513, loss2 : 0.876128
train_step : 13599, loss1 : 1.087089, loss2 : 0.575521
train_step : 13600, loss1 : 1.073680, loss2 : 1.650337
train_step : 13601, loss1 : 1.456938, loss2 : 0.818881
train_step : 13602, loss1 : 1.454806, loss2 : 1.640702
train_step : 13603, loss1 : 1.653235, loss2 : 1.172233
train_step : 13604, loss1 : 0.834408, loss2 : 0.945484
train_step : 13605, loss1 : 1.213609, loss2 : 0.889545
train_step : 13606, loss1 : 0.992393, loss2 : 1.320550
train_step : 13607, loss1 : 2.541539, loss2 : 1.516662
train_step : 13608, loss1 : 1.465978, loss2 : 1.561787
train_step : 13609, loss1 : 1.255844, loss2 : 1.405517
train_step : 13610, loss1 : 0.857815, loss2 : 0.591108
train_step : 13611, loss1 : 1.041771, loss2 : 0.999063
train_step : 13612, loss1 : 0.601119, loss2 : 1.553223
train_step : 13613, loss1 : 1.362084, loss2 : 0.876061
train_step : 13614, loss1 : 2.109350, loss2 : 0.769440
train_step : 13615, loss1 : 0.902693, loss2 : 1.294422
train_step : 13616, loss1 : 0.562774, loss2 : 1.984240
train_step : 13617, loss1 : 1.558556, loss2 : 0.873334
train_step : 13618, loss1 : 1.128667, loss2 : 0.982606
train_step : 13619, loss1 : 1.099512, loss2 : 1.198752
train_step : 13620, loss1 : 1.172462, loss2 : 1.180572
train_step : 13621, loss1 : 1.406963, loss2 : 1.503673
train_step : 13622, loss1 : 3.442635, loss2 : 2.052710
train_step : 13623, loss1 : 4.929831, loss2 : 2.834015
train_step : 13624, loss1 : 4.048963, loss2 : 3.147024
train_step : 13625, loss1 : 2.624010, loss2 : 3.415377
train_step : 13626, loss1 : 4.387174, loss2 : 4.210644
train_step : 13627, loss1 : 2.203422, loss2 : 3.231751
train_step : 13628, loss1 : 3.245447, loss2 : 2.127127
train_step : 13629, loss1 : 2.045278, loss2 : 1.777585
train_step : 13630, loss1 : 1.487723, loss2 : 1.094451
train_step : 13631, loss1 : 1.344573, loss2 : 1.375017
train_step : 13632, loss1 : 1.338771, loss2 : 1.468315
train_step : 13633, loss1 : 1.350878, loss2 : 1.472700
train_step : 13634, loss1 : 1.254179, loss2 : 1.393789
train_step : 13635, loss1 : 0.588180, loss2 : 0.725995
train_step : 13636, loss1 : 1.806486, loss2 : 1.588783
train_step : 13637, loss1 : 1.123690, loss2 : 2.135785
train_step : 13638, loss1 : 1.834515, loss2 : 1.605740
train_step : 13639, loss1 : 1.437810, loss2 : 1.225559
train_step : 13640, loss1 : 0.846098, loss2 : 1.922290
train_step : 13641, loss1 : 1.735693, loss2 : 1.539232
train_step : 13642, loss1 : 1.456745, loss2 : 1.065447
train_step : 13643, loss1 : 0.834569, loss2 : 1.266312
train_step : 13644, loss1 : 1.439284, loss2 : 1.054865
train_step : 13645, loss1 : 1.277876, loss2 : 1.239817
train_step : 13646, loss1 : 1.734701, loss2 : 1.624494
train_step : 13647, loss1 : 0.514314, loss2 : 1.175615
train_step : 13648, loss1 : 1.177757, loss2 : 0.770334
train_step : 13649, loss1 : 0.874569, loss2 : 0.990297
train_step : 13650, loss1 : 1.158136, loss2 : 1.164306
train_step : 13651, loss1 : 0.979318, loss2 : 1.000882
train_step : 13652, loss1 : 1.206729, loss2 : 0.788700
train_step : 13653, loss1 : 1.428189, loss2 : 1.353127
train_step : 13654, loss1 : 0.835533, loss2 : 2.292317
train_step : 13655, loss1 : 1.642645, loss2 : 1.132547
train_step : 13656, loss1 : 1.302336, loss2 : 1.578876
train_step : 13657, loss1 : 2.294563, loss2 : 1.160243
train_step : 13658, loss1 : 0.771725, loss2 : 1.288519
train_step : 13659, loss1 : 1.165427, loss2 : 0.908589
train_step : 13660, loss1 : 1.002479, loss2 : 1.218161
train_step : 13661, loss1 : 0.797836, loss2 : 0.731761
train_step : 13662, loss1 : 0.950075, loss2 : 1.058485
train_step : 13663, loss1 : 1.405235, loss2 : 0.653988
train_step : 13664, loss1 : 0.644797, loss2 : 1.616384
train_step : 13665, loss1 : 1.324888, loss2 : 1.182736
train_step : 13666, loss1 : 0.904070, loss2 : 1.043370
train_step : 13667, loss1 : 1.180692, loss2 : 1.177798
train_step : 13668, loss1 : 1.064560, loss2 : 0.862710
train_step : 13669, loss1 : 0.663194, loss2 : 0.914846
train_step : 13670, loss1 : 1.785026, loss2 : 1.698495
train_step : 13671, loss1 : 1.422197, loss2 : 1.413834
train_step : 13672, loss1 : 0.803655, loss2 : 1.210047
train_step : 13673, loss1 : 1.227307, loss2 : 0.936850
train_step : 13674, loss1 : 0.699594, loss2 : 1.059257
train_step : 13675, loss1 : 0.800319, loss2 : 0.976824
train_step : 13676, loss1 : 0.413261, loss2 : 1.065320
train_step : 13677, loss1 : 0.710414, loss2 : 0.659252
train_step : 13678, loss1 : 1.206704, loss2 : 1.150139
train_step : 13679, loss1 : 2.178154, loss2 : 1.287216
train_step : 13680, loss1 : 0.362649, loss2 : 1.844423
train_step : 13681, loss1 : 0.959684, loss2 : 0.737329
train_step : 13682, loss1 : 1.282040, loss2 : 1.476493
train_step : 13683, loss1 : 0.939755, loss2 : 1.106446
train_step : 13684, loss1 : 1.094110, loss2 : 1.765091
train_step : 13685, loss1 : 1.664347, loss2 : 1.563873
train_step : 13686, loss1 : 1.978226, loss2 : 1.008755
train_step : 13687, loss1 : 1.063957, loss2 : 1.018416
train_step : 13688, loss1 : 1.292560, loss2 : 2.061965
train_step : 13689, loss1 : 1.510838, loss2 : 0.725985
train_step : 13690, loss1 : 1.225025, loss2 : 1.317328
train_step : 13691, loss1 : 1.090157, loss2 : 1.427709
train_step : 13692, loss1 : 1.290399, loss2 : 1.227586
train_step : 13693, loss1 : 0.914914, loss2 : 1.370289
train_step : 13694, loss1 : 1.211018, loss2 : 0.898426
train_step : 13695, loss1 : 1.173998, loss2 : 1.781714
train_step : 13696, loss1 : 1.928701, loss2 : 1.140787
train_step : 13697, loss1 : 1.491986, loss2 : 2.105361
train_step : 13698, loss1 : 1.730430, loss2 : 1.447154
train_step : 13699, loss1 : 2.093170, loss2 : 1.153228
train_step : 13700, loss1 : 1.095610, loss2 : 0.680698
train_step : 13701, loss1 : 0.970909, loss2 : 1.408579
train_step : 13702, loss1 : 0.972768, loss2 : 1.658534
train_step : 13703, loss1 : 0.877221, loss2 : 1.470209
train_step : 13704, loss1 : 1.950758, loss2 : 1.153766
train_step : 13705, loss1 : 0.826287, loss2 : 1.023183
train_step : 13706, loss1 : 1.006337, loss2 : 1.450464
train_step : 13707, loss1 : 1.964702, loss2 : 0.892002
train_step : 13708, loss1 : 0.725259, loss2 : 1.022255
train_step : 13709, loss1 : 1.543967, loss2 : 0.634235
train_step : 13710, loss1 : 1.374470, loss2 : 1.216472
train_step : 13711, loss1 : 1.033459, loss2 : 1.494877
train_step : 13712, loss1 : 1.439784, loss2 : 1.108247
train_step : 13713, loss1 : 0.840283, loss2 : 0.850510
train_step : 13714, loss1 : 1.087952, loss2 : 1.009219
train_step : 13715, loss1 : 2.232467, loss2 : 1.931706
train_step : 13716, loss1 : 2.014689, loss2 : 1.161199
train_step : 13717, loss1 : 1.361873, loss2 : 0.630772
train_step : 13718, loss1 : 1.748621, loss2 : 0.436573
train_step : 13719, loss1 : 0.959968, loss2 : 1.744645
train_step : 13720, loss1 : 0.848284, loss2 : 0.801338
train_step : 13721, loss1 : 1.967854, loss2 : 1.300477
train_step : 13722, loss1 : 2.442014, loss2 : 0.644285
train_step : 13723, loss1 : 1.447802, loss2 : 0.780162
train_step : 13724, loss1 : 0.734726, loss2 : 1.084947
train_step : 13725, loss1 : 1.145070, loss2 : 0.743057
train_step : 13726, loss1 : 1.058168, loss2 : 1.233283
train_step : 13727, loss1 : 1.577168, loss2 : 1.298657
train_step : 13728, loss1 : 1.332120, loss2 : 1.809089
train_step : 13729, loss1 : 1.296671, loss2 : 0.815795
train_step : 13730, loss1 : 1.002664, loss2 : 1.713084
train_step : 13731, loss1 : 0.923941, loss2 : 1.103047
train_step : 13732, loss1 : 0.813224, loss2 : 0.666210
train_step : 13733, loss1 : 1.482613, loss2 : 2.261181
train_step : 13734, loss1 : 2.303482, loss2 : 0.843800
train_step : 13735, loss1 : 0.770016, loss2 : 1.810442
train_step : 13736, loss1 : 0.723521, loss2 : 1.032715
train_step : 13737, loss1 : 0.870631, loss2 : 1.496380
train_step : 13738, loss1 : 1.518774, loss2 : 1.197997
train_step : 13739, loss1 : 1.442357, loss2 : 1.653421
train_step : 13740, loss1 : 0.833566, loss2 : 2.282117
train_step : 13741, loss1 : 2.345058, loss2 : 1.143675
train_step : 13742, loss1 : 1.693022, loss2 : 1.376598
train_step : 13743, loss1 : 1.274322, loss2 : 1.316310
train_step : 13744, loss1 : 1.170967, loss2 : 1.190839
train_step : 13745, loss1 : 1.083850, loss2 : 1.468797
train_step : 13746, loss1 : 1.871267, loss2 : 0.944347
train_step : 13747, loss1 : 1.129659, loss2 : 1.483204
train_step : 13748, loss1 : 1.622061, loss2 : 0.603366
train_step : 13749, loss1 : 1.483238, loss2 : 1.329964
train_step : 13750, loss1 : 2.116672, loss2 : 2.367230
train_step : 13751, loss1 : 2.798257, loss2 : 1.254350
train_step : 13752, loss1 : 2.048312, loss2 : 1.977182
train_step : 13753, loss1 : 1.048739, loss2 : 2.296412
train_step : 13754, loss1 : 2.739136, loss2 : 2.923854
train_step : 13755, loss1 : 2.515136, loss2 : 2.490211
train_step : 13756, loss1 : 2.288032, loss2 : 2.623755
train_step : 13757, loss1 : 1.542610, loss2 : 2.416785
train_step : 13758, loss1 : 1.383185, loss2 : 2.658845
train_step : 13759, loss1 : 1.183979, loss2 : 0.841853
train_step : 13760, loss1 : 0.571308, loss2 : 0.658443
train_step : 13761, loss1 : 0.475347, loss2 : 1.243210
train_step : 13762, loss1 : 1.446896, loss2 : 0.734258
train_step : 13763, loss1 : 0.999263, loss2 : 1.163635
train_step : 13764, loss1 : 1.802646, loss2 : 1.805861
train_step : 13765, loss1 : 1.052000, loss2 : 1.025681
train_step : 13766, loss1 : 1.469604, loss2 : 1.263488
train_step : 13767, loss1 : 1.598198, loss2 : 1.477785
train_step : 13768, loss1 : 1.069311, loss2 : 1.455292
train_step : 13769, loss1 : 1.949419, loss2 : 1.869951
train_step : 13770, loss1 : 0.842170, loss2 : 0.885406
train_step : 13771, loss1 : 1.109708, loss2 : 1.173250
train_step : 13772, loss1 : 0.822741, loss2 : 0.744146
train_step : 13773, loss1 : 0.834567, loss2 : 1.474311
train_step : 13774, loss1 : 1.622028, loss2 : 1.257229
train_step : 13775, loss1 : 1.468765, loss2 : 1.840839
train_step : 13776, loss1 : 1.822117, loss2 : 1.016749
train_step : 13777, loss1 : 1.213483, loss2 : 1.562529
train_step : 13778, loss1 : 0.942455, loss2 : 0.658302
train_step : 13779, loss1 : 0.921937, loss2 : 1.487780
train_step : 13780, loss1 : 0.964089, loss2 : 1.356894
train_step : 13781, loss1 : 1.764526, loss2 : 1.384971
train_step : 13782, loss1 : 1.148210, loss2 : 0.954949
train_step : 13783, loss1 : 1.432456, loss2 : 1.259796
train_step : 13784, loss1 : 1.439081, loss2 : 1.556790
train_step : 13785, loss1 : 0.473145, loss2 : 0.873452
train_step : 13786, loss1 : 1.268191, loss2 : 1.074685
train_step : 13787, loss1 : 0.800381, loss2 : 1.171124
train_step : 13788, loss1 : 2.184832, loss2 : 1.632068
train_step : 13789, loss1 : 2.572582, loss2 : 2.006437
train_step : 13790, loss1 : 1.891762, loss2 : 2.672967
train_step : 13791, loss1 : 2.041443, loss2 : 1.769268
train_step : 13792, loss1 : 1.032840, loss2 : 1.451734
train_step : 13793, loss1 : 1.042561, loss2 : 1.182571
train_step : 13794, loss1 : 1.289285, loss2 : 1.400636
train_step : 13795, loss1 : 0.706243, loss2 : 1.248846
train_step : 13796, loss1 : 0.791908, loss2 : 1.318946
train_step : 13797, loss1 : 1.230824, loss2 : 0.961742
train_step : 13798, loss1 : 0.646529, loss2 : 1.471276
train_step : 13799, loss1 : 0.666671, loss2 : 1.490753
train_step : 13800, loss1 : 1.159616, loss2 : 1.400235
train_step : 13801, loss1 : 0.881745, loss2 : 0.629667
train_step : 13802, loss1 : 0.766371, loss2 : 1.498166
train_step : 13803, loss1 : 1.081564, loss2 : 1.134459
train_step : 13804, loss1 : 1.141118, loss2 : 0.942644
train_step : 13805, loss1 : 1.156375, loss2 : 0.683202
train_step : 13806, loss1 : 0.990911, loss2 : 1.333184
train_step : 13807, loss1 : 1.437059, loss2 : 1.166305
train_step : 13808, loss1 : 1.247259, loss2 : 0.894225
train_step : 13809, loss1 : 1.096657, loss2 : 1.230377
train_step : 13810, loss1 : 0.982302, loss2 : 0.789712
train_step : 13811, loss1 : 1.154430, loss2 : 1.080689
train_step : 13812, loss1 : 0.967809, loss2 : 1.537530
train_step : 13813, loss1 : 0.748331, loss2 : 1.781900
train_step : 13814, loss1 : 1.028676, loss2 : 0.797848
train_step : 13815, loss1 : 1.294123, loss2 : 0.993262
train_step : 13816, loss1 : 0.776276, loss2 : 1.248527
train_step : 13817, loss1 : 1.581791, loss2 : 1.183694
train_step : 13818, loss1 : 0.795520, loss2 : 1.013128
train_step : 13819, loss1 : 0.955307, loss2 : 1.022677
train_step : 13820, loss1 : 1.693154, loss2 : 0.987961
train_step : 13821, loss1 : 1.465527, loss2 : 1.664371
train_step : 13822, loss1 : 0.888303, loss2 : 1.076805
train_step : 13823, loss1 : 1.729793, loss2 : 2.134514
train_step : 13824, loss1 : 1.282191, loss2 : 1.288222
train_step : 13825, loss1 : 1.024045, loss2 : 0.881773
train_step : 13826, loss1 : 1.062384, loss2 : 1.063437
train_step : 13827, loss1 : 1.841544, loss2 : 1.136202
train_step : 13828, loss1 : 1.550889, loss2 : 1.295666
train_step : 13829, loss1 : 1.225771, loss2 : 1.104216
train_step : 13830, loss1 : 0.484325, loss2 : 1.594566
train_step : 13831, loss1 : 1.823098, loss2 : 0.504708
train_step : 13832, loss1 : 1.263713, loss2 : 1.335759
train_step : 13833, loss1 : 0.900031, loss2 : 0.873600
train_step : 13834, loss1 : 1.013339, loss2 : 3.381903
train_step : 13835, loss1 : 1.034174, loss2 : 1.330907
train_step : 13836, loss1 : 1.452361, loss2 : 2.225480
train_step : 13837, loss1 : 2.421874, loss2 : 2.127019
train_step : 13838, loss1 : 1.156774, loss2 : 1.103905
train_step : 13839, loss1 : 0.750114, loss2 : 1.094848
train_step : 13840, loss1 : 1.019883, loss2 : 0.686149
train_step : 13841, loss1 : 1.282853, loss2 : 1.811744
train_step : 13842, loss1 : 1.410671, loss2 : 0.592311
train_step : 13843, loss1 : 0.867331, loss2 : 1.022774
train_step : 13844, loss1 : 1.731905, loss2 : 1.698979
train_step : 13845, loss1 : 0.728722, loss2 : 2.759474
train_step : 13846, loss1 : 1.689917, loss2 : 1.098220
train_step : 13847, loss1 : 1.041689, loss2 : 1.168440
train_step : 13848, loss1 : 1.041432, loss2 : 1.006750
train_step : 13849, loss1 : 0.992971, loss2 : 1.345841
train_step : 13850, loss1 : 1.286689, loss2 : 1.215085
train_step : 13851, loss1 : 1.285050, loss2 : 0.722239
train_step : 13852, loss1 : 1.055733, loss2 : 1.241512
train_step : 13853, loss1 : 1.011387, loss2 : 1.073156
train_step : 13854, loss1 : 0.800280, loss2 : 1.623616
train_step : 13855, loss1 : 0.907389, loss2 : 1.363374
train_step : 13856, loss1 : 1.797711, loss2 : 1.698125
train_step : 13857, loss1 : 0.748616, loss2 : 0.950931
train_step : 13858, loss1 : 1.134785, loss2 : 1.094642
train_step : 13859, loss1 : 1.060729, loss2 : 0.701712
train_step : 13860, loss1 : 1.048157, loss2 : 1.110473
train_step : 13861, loss1 : 1.637619, loss2 : 1.768138
train_step : 13862, loss1 : 1.144396, loss2 : 1.445921
train_step : 13863, loss1 : 0.887375, loss2 : 1.121572
train_step : 13864, loss1 : 1.673014, loss2 : 1.096632
train_step : 13865, loss1 : 1.449236, loss2 : 1.276894
train_step : 13866, loss1 : 1.371634, loss2 : 1.172265
train_step : 13867, loss1 : 1.736589, loss2 : 1.281841
train_step : 13868, loss1 : 1.266548, loss2 : 0.941829
train_step : 13869, loss1 : 1.320009, loss2 : 0.885090
train_step : 13870, loss1 : 1.014472, loss2 : 1.337239
train_step : 13871, loss1 : 1.301185, loss2 : 1.796925
train_step : 13872, loss1 : 1.224717, loss2 : 1.508952
train_step : 13873, loss1 : 1.634468, loss2 : 1.371504
train_step : 13874, loss1 : 1.421083, loss2 : 0.712154
train_step : 13875, loss1 : 1.498834, loss2 : 0.774559
train_step : 13876, loss1 : 0.649236, loss2 : 1.625828
train_step : 13877, loss1 : 1.540827, loss2 : 3.108743
train_step : 13878, loss1 : 1.543871, loss2 : 1.705924
train_step : 13879, loss1 : 1.593558, loss2 : 1.918978
train_step : 13880, loss1 : 1.405300, loss2 : 2.158612
train_step : 13881, loss1 : 0.839982, loss2 : 2.233308
train_step : 13882, loss1 : 2.570093, loss2 : 1.249359
train_step : 13883, loss1 : 2.904795, loss2 : 1.952686
train_step : 13884, loss1 : 4.382501, loss2 : 3.685979
train_step : 13885, loss1 : 5.940342, loss2 : 3.843213
train_step : 13886, loss1 : 2.802781, loss2 : 2.094010
train_step : 13887, loss1 : 1.259066, loss2 : 2.897341
train_step : 13888, loss1 : 1.372722, loss2 : 1.955951
train_step : 13889, loss1 : 1.720608, loss2 : 2.089525
train_step : 13890, loss1 : 2.604269, loss2 : 1.367692
train_step : 13891, loss1 : 2.648494, loss2 : 2.460603
train_step : 13892, loss1 : 2.124935, loss2 : 3.130985
train_step : 13893, loss1 : 3.875928, loss2 : 2.065140
train_step : 13894, loss1 : 1.275964, loss2 : 1.714505
train_step : 13895, loss1 : 1.047933, loss2 : 1.652038
train_step : 13896, loss1 : 1.505390, loss2 : 1.196151
train_step : 13897, loss1 : 1.770123, loss2 : 1.133312
train_step : 13898, loss1 : 1.768239, loss2 : 0.512965
train_step : 13899, loss1 : 1.257191, loss2 : 1.741613
train_step : 13900, loss1 : 0.859118, loss2 : 2.115319
train_step : 13901, loss1 : 1.527526, loss2 : 1.111482
train_step : 13902, loss1 : 1.564180, loss2 : 1.051169
train_step : 13903, loss1 : 1.781568, loss2 : 1.501835
train_step : 13904, loss1 : 1.817401, loss2 : 0.919251
train_step : 13905, loss1 : 1.412984, loss2 : 1.799471
train_step : 13906, loss1 : 1.864099, loss2 : 0.750380
train_step : 13907, loss1 : 0.710343, loss2 : 0.912054
train_step : 13908, loss1 : 1.847902, loss2 : 1.120387
train_step : 13909, loss1 : 1.214227, loss2 : 1.067961
train_step : 13910, loss1 : 1.429695, loss2 : 0.856559
train_step : 13911, loss1 : 1.392618, loss2 : 0.684577
train_step : 13912, loss1 : 0.736567, loss2 : 2.335035
train_step : 13913, loss1 : 2.292004, loss2 : 2.313509
train_step : 13914, loss1 : 2.187984, loss2 : 1.744567
train_step : 13915, loss1 : 0.823145, loss2 : 1.850945
train_step : 13916, loss1 : 2.290365, loss2 : 0.513079
train_step : 13917, loss1 : 0.915849, loss2 : 0.959504
train_step : 13918, loss1 : 0.943993, loss2 : 1.437037
train_step : 13919, loss1 : 0.721803, loss2 : 1.172060
train_step : 13920, loss1 : 0.877018, loss2 : 1.043833
train_step : 13921, loss1 : 1.290792, loss2 : 1.403489
train_step : 13922, loss1 : 1.591109, loss2 : 1.058166
train_step : 13923, loss1 : 0.957530, loss2 : 1.274401
train_step : 13924, loss1 : 1.118733, loss2 : 1.462405
train_step : 13925, loss1 : 0.881132, loss2 : 1.264131
train_step : 13926, loss1 : 1.005732, loss2 : 1.214726
train_step : 13927, loss1 : 1.046847, loss2 : 0.583243
train_step : 13928, loss1 : 1.192367, loss2 : 1.040821
train_step : 13929, loss1 : 1.542910, loss2 : 0.620304
train_step : 13930, loss1 : 0.898253, loss2 : 0.964051
train_step : 13931, loss1 : 1.281838, loss2 : 0.937165
train_step : 13932, loss1 : 1.121514, loss2 : 1.084522
train_step : 13933, loss1 : 1.390528, loss2 : 0.922982
train_step : 13934, loss1 : 0.628027, loss2 : 0.954737
train_step : 13935, loss1 : 1.044319, loss2 : 0.527503
train_step : 13936, loss1 : 1.044518, loss2 : 0.827395
train_step : 13937, loss1 : 0.758146, loss2 : 1.678653
train_step : 13938, loss1 : 1.311050, loss2 : 0.779445
train_step : 13939, loss1 : 1.293393, loss2 : 1.696750
train_step : 13940, loss1 : 1.305174, loss2 : 1.403107
train_step : 13941, loss1 : 1.464788, loss2 : 1.164816
train_step : 13942, loss1 : 1.160571, loss2 : 1.028875
train_step : 13943, loss1 : 1.704897, loss2 : 0.925714
train_step : 13944, loss1 : 1.629749, loss2 : 1.555076
train_step : 13945, loss1 : 2.006304, loss2 : 1.315037
train_step : 13946, loss1 : 2.087228, loss2 : 2.212769
train_step : 13947, loss1 : 0.698905, loss2 : 1.217194
train_step : 13948, loss1 : 1.234735, loss2 : 1.423712
train_step : 13949, loss1 : 1.783567, loss2 : 0.910733
train_step : 13950, loss1 : 1.245994, loss2 : 1.347158
train_step : 13951, loss1 : 1.292159, loss2 : 1.545652
train_step : 13952, loss1 : 2.178008, loss2 : 1.176599
train_step : 13953, loss1 : 1.198067, loss2 : 0.957472
train_step : 13954, loss1 : 1.069550, loss2 : 1.131593
train_step : 13955, loss1 : 0.714319, loss2 : 0.874271
train_step : 13956, loss1 : 0.936276, loss2 : 1.325595
train_step : 13957, loss1 : 1.188584, loss2 : 1.441524
train_step : 13958, loss1 : 0.956225, loss2 : 0.830382
train_step : 13959, loss1 : 1.088375, loss2 : 1.278192
train_step : 13960, loss1 : 1.246957, loss2 : 2.941466
train_step : 13961, loss1 : 2.280641, loss2 : 2.566494
train_step : 13962, loss1 : 0.630549, loss2 : 0.625335
train_step : 13963, loss1 : 0.882858, loss2 : 0.717143
train_step : 13964, loss1 : 1.050869, loss2 : 0.947949
train_step : 13965, loss1 : 1.191796, loss2 : 1.579445
train_step : 13966, loss1 : 1.748292, loss2 : 1.169775
train_step : 13967, loss1 : 0.937421, loss2 : 1.509654
train_step : 13968, loss1 : 1.718715, loss2 : 0.814137
train_step : 13969, loss1 : 1.115107, loss2 : 1.068401
train_step : 13970, loss1 : 1.139607, loss2 : 1.150315
train_step : 13971, loss1 : 1.011270, loss2 : 0.496934
train_step : 13972, loss1 : 1.159110, loss2 : 1.337853
train_step : 13973, loss1 : 1.062855, loss2 : 0.978641
train_step : 13974, loss1 : 2.004948, loss2 : 0.700593
train_step : 13975, loss1 : 1.513895, loss2 : 1.423447
train_step : 13976, loss1 : 1.607667, loss2 : 2.418592
train_step : 13977, loss1 : 0.902346, loss2 : 1.115073
train_step : 13978, loss1 : 1.041672, loss2 : 1.143169
train_step : 13979, loss1 : 0.898803, loss2 : 1.646444
train_step : 13980, loss1 : 1.765295, loss2 : 0.437191
train_step : 13981, loss1 : 1.215896, loss2 : 1.249662
train_step : 13982, loss1 : 1.455174, loss2 : 1.582410
train_step : 13983, loss1 : 0.816330, loss2 : 0.922910
train_step : 13984, loss1 : 0.529744, loss2 : 0.900418
train_step : 13985, loss1 : 1.212964, loss2 : 1.094409
train_step : 13986, loss1 : 1.256471, loss2 : 0.818596
train_step : 13987, loss1 : 2.947250, loss2 : 0.915607
train_step : 13988, loss1 : 1.570907, loss2 : 1.134472
train_step : 13989, loss1 : 1.284323, loss2 : 1.336978
train_step : 13990, loss1 : 1.250322, loss2 : 1.516374
train_step : 13991, loss1 : 0.908016, loss2 : 1.396179
train_step : 13992, loss1 : 1.686958, loss2 : 1.800090
train_step : 13993, loss1 : 0.992099, loss2 : 2.752047
train_step : 13994, loss1 : 1.316217, loss2 : 1.281367
train_step : 13995, loss1 : 1.132365, loss2 : 0.974012
train_step : 13996, loss1 : 0.999651, loss2 : 0.652993
train_step : 13997, loss1 : 0.999296, loss2 : 0.881217
train_step : 13998, loss1 : 1.354634, loss2 : 0.772149
train_step : 13999, loss1 : 0.631282, loss2 : 0.646700
train_step : 14000, loss1 : 1.156946, loss2 : 1.111169
train_step : 14001, loss1 : 1.217884, loss2 : 1.310567
train_step : 14002, loss1 : 1.965330, loss2 : 1.467021
train_step : 14003, loss1 : 1.749466, loss2 : 2.008648
train_step : 14004, loss1 : 2.230244, loss2 : 1.873482
train_step : 14005, loss1 : 1.786096, loss2 : 1.984763
train_step : 14006, loss1 : 2.193055, loss2 : 2.203294
train_step : 14007, loss1 : 1.659977, loss2 : 2.937582
train_step : 14008, loss1 : 3.560694, loss2 : 2.136799
train_step : 14009, loss1 : 1.843141, loss2 : 2.264363
train_step : 14010, loss1 : 2.667436, loss2 : 2.785805
train_step : 14011, loss1 : 1.724130, loss2 : 2.604573
train_step : 14012, loss1 : 1.958306, loss2 : 1.427814
train_step : 14013, loss1 : 1.654164, loss2 : 1.597547
train_step : 14014, loss1 : 1.442868, loss2 : 1.055680
train_step : 14015, loss1 : 1.335191, loss2 : 1.164778
train_step : 14016, loss1 : 1.448539, loss2 : 1.113088
train_step : 14017, loss1 : 0.965544, loss2 : 1.364849
train_step : 14018, loss1 : 0.734560, loss2 : 1.704746
train_step : 14019, loss1 : 1.228167, loss2 : 0.882657
train_step : 14020, loss1 : 0.603350, loss2 : 1.712899
train_step : 14021, loss1 : 0.888430, loss2 : 1.098462
train_step : 14022, loss1 : 1.039945, loss2 : 1.708699
train_step : 14023, loss1 : 0.736556, loss2 : 0.957994
train_step : 14024, loss1 : 2.008933, loss2 : 1.452047
train_step : 14025, loss1 : 2.038466, loss2 : 2.143483
train_step : 14026, loss1 : 1.557683, loss2 : 1.169256
train_step : 14027, loss1 : 1.195657, loss2 : 0.950126
train_step : 14028, loss1 : 1.596784, loss2 : 0.800441
train_step : 14029, loss1 : 0.938342, loss2 : 1.342540
train_step : 14030, loss1 : 0.956281, loss2 : 1.431674
train_step : 14031, loss1 : 1.252978, loss2 : 1.398398
train_step : 14032, loss1 : 1.174499, loss2 : 0.791514
train_step : 14033, loss1 : 0.693352, loss2 : 0.858232
train_step : 14034, loss1 : 1.844164, loss2 : 1.046246
train_step : 14035, loss1 : 1.503892, loss2 : 0.774502
train_step : 14036, loss1 : 1.434494, loss2 : 0.772126
train_step : 14037, loss1 : 1.522909, loss2 : 1.554688
train_step : 14038, loss1 : 0.807590, loss2 : 0.932324
train_step : 14039, loss1 : 1.915458, loss2 : 1.765161
train_step : 14040, loss1 : 1.651398, loss2 : 2.424550
train_step : 14041, loss1 : 3.401680, loss2 : 1.601199
train_step : 14042, loss1 : 3.362535, loss2 : 3.196808
train_step : 14043, loss1 : 1.839821, loss2 : 1.598684
train_step : 14044, loss1 : 1.681463, loss2 : 1.366375
train_step : 14045, loss1 : 2.179599, loss2 : 1.068738
train_step : 14046, loss1 : 1.295203, loss2 : 1.363583
train_step : 14047, loss1 : 0.529419, loss2 : 0.709971
train_step : 14048, loss1 : 0.930538, loss2 : 0.652317
train_step : 14049, loss1 : 0.902473, loss2 : 1.271298
train_step : 14050, loss1 : 0.894730, loss2 : 2.323168
train_step : 14051, loss1 : 1.304628, loss2 : 1.055207
train_step : 14052, loss1 : 1.611022, loss2 : 1.223775
train_step : 14053, loss1 : 1.486323, loss2 : 1.766413
train_step : 14054, loss1 : 1.734223, loss2 : 0.832171
train_step : 14055, loss1 : 0.838028, loss2 : 1.023161
train_step : 14056, loss1 : 1.198401, loss2 : 1.146629
train_step : 14057, loss1 : 1.402578, loss2 : 0.821375
train_step : 14058, loss1 : 1.511218, loss2 : 1.116476
train_step : 14059, loss1 : 1.660467, loss2 : 1.075798
train_step : 14060, loss1 : 1.233652, loss2 : 1.488725
train_step : 14061, loss1 : 1.513113, loss2 : 1.229064
train_step : 14062, loss1 : 1.098868, loss2 : 0.758653
train_step : 14063, loss1 : 1.167625, loss2 : 0.908589
train_step : 14064, loss1 : 2.239979, loss2 : 1.237298
train_step : 14065, loss1 : 1.715675, loss2 : 0.956573
train_step : 14066, loss1 : 0.874513, loss2 : 0.832547
train_step : 14067, loss1 : 0.966207, loss2 : 0.962122
train_step : 14068, loss1 : 0.963128, loss2 : 1.363554
train_step : 14069, loss1 : 0.651890, loss2 : 0.845745
train_step : 14070, loss1 : 0.925804, loss2 : 1.259406
train_step : 14071, loss1 : 0.704234, loss2 : 0.965049
train_step : 14072, loss1 : 0.874545, loss2 : 0.990485
train_step : 14073, loss1 : 3.586366, loss2 : 1.575517
train_step : 14074, loss1 : 1.017308, loss2 : 1.874372
train_step : 14075, loss1 : 2.081568, loss2 : 1.721157
train_step : 14076, loss1 : 1.824265, loss2 : 1.367324
train_step : 14077, loss1 : 1.745289, loss2 : 2.633159
train_step : 14078, loss1 : 1.080850, loss2 : 1.336965
train_step : 14079, loss1 : 1.622170, loss2 : 2.025910
train_step : 14080, loss1 : 1.684131, loss2 : 1.347587
train_step : 14081, loss1 : 2.109022, loss2 : 1.334937
train_step : 14082, loss1 : 1.013619, loss2 : 1.303941
train_step : 14083, loss1 : 0.928272, loss2 : 1.258766
train_step : 14084, loss1 : 0.882368, loss2 : 2.119764
train_step : 14085, loss1 : 2.610764, loss2 : 1.475697
train_step : 14086, loss1 : 1.375584, loss2 : 1.313314
train_step : 14087, loss1 : 0.838830, loss2 : 1.287022
train_step : 14088, loss1 : 1.682558, loss2 : 1.666417
train_step : 14089, loss1 : 1.856562, loss2 : 1.988752
train_step : 14090, loss1 : 1.358468, loss2 : 1.904629
train_step : 14091, loss1 : 0.982169, loss2 : 0.949140
train_step : 14092, loss1 : 1.114479, loss2 : 1.171152
train_step : 14093, loss1 : 1.215851, loss2 : 1.486230
train_step : 14094, loss1 : 1.480267, loss2 : 1.668184
train_step : 14095, loss1 : 2.119912, loss2 : 1.224844
train_step : 14096, loss1 : 1.654938, loss2 : 1.592162
train_step : 14097, loss1 : 0.834861, loss2 : 1.355015
train_step : 14098, loss1 : 1.124872, loss2 : 1.166664
train_step : 14099, loss1 : 2.189138, loss2 : 1.248139
train_step : 14100, loss1 : 1.347554, loss2 : 2.185232
train_step : 14101, loss1 : 2.265129, loss2 : 1.879607
train_step : 14102, loss1 : 2.814240, loss2 : 2.053980
train_step : 14103, loss1 : 2.507429, loss2 : 2.883132
train_step : 14104, loss1 : 1.126814, loss2 : 1.608275
train_step : 14105, loss1 : 0.868399, loss2 : 1.770633
train_step : 14106, loss1 : 1.334826, loss2 : 1.190760
train_step : 14107, loss1 : 0.781237, loss2 : 0.746349
train_step : 14108, loss1 : 1.915009, loss2 : 1.069339
train_step : 14109, loss1 : 1.593758, loss2 : 0.813595
train_step : 14110, loss1 : 1.413719, loss2 : 1.562999
train_step : 14111, loss1 : 1.985922, loss2 : 0.719533
train_step : 14112, loss1 : 1.735028, loss2 : 1.390632
train_step : 14113, loss1 : 1.042528, loss2 : 1.939482
train_step : 14114, loss1 : 2.005234, loss2 : 1.304233
train_step : 14115, loss1 : 1.297007, loss2 : 1.598126
train_step : 14116, loss1 : 1.473113, loss2 : 0.629333
train_step : 14117, loss1 : 1.074233, loss2 : 1.478769
train_step : 14118, loss1 : 0.535981, loss2 : 1.685239
train_step : 14119, loss1 : 1.289423, loss2 : 0.976891
train_step : 14120, loss1 : 0.973083, loss2 : 0.595155
train_step : 14121, loss1 : 1.624757, loss2 : 1.175514
train_step : 14122, loss1 : 1.266588, loss2 : 2.045633
train_step : 14123, loss1 : 1.994720, loss2 : 1.622395
train_step : 14124, loss1 : 1.705018, loss2 : 1.733790
train_step : 14125, loss1 : 0.573820, loss2 : 1.646716
train_step : 14126, loss1 : 1.351201, loss2 : 1.496095
train_step : 14127, loss1 : 2.034129, loss2 : 0.707859
train_step : 14128, loss1 : 1.138013, loss2 : 1.208249
train_step : 14129, loss1 : 1.714031, loss2 : 0.545583
train_step : 14130, loss1 : 0.746285, loss2 : 1.102913
train_step : 14131, loss1 : 1.348747, loss2 : 0.850489
train_step : 14132, loss1 : 1.743659, loss2 : 0.821940
train_step : 14133, loss1 : 1.437137, loss2 : 1.978073
train_step : 14134, loss1 : 2.824797, loss2 : 2.947052
train_step : 14135, loss1 : 1.696980, loss2 : 1.003359
train_step : 14136, loss1 : 0.860323, loss2 : 0.939252
train_step : 14137, loss1 : 1.098166, loss2 : 0.562795
train_step : 14138, loss1 : 1.234066, loss2 : 1.221194
train_step : 14139, loss1 : 0.529164, loss2 : 1.014907
train_step : 14140, loss1 : 0.890204, loss2 : 1.013163
train_step : 14141, loss1 : 1.436777, loss2 : 1.197504
train_step : 14142, loss1 : 0.673877, loss2 : 1.010491
train_step : 14143, loss1 : 0.806577, loss2 : 1.192177
train_step : 14144, loss1 : 0.643868, loss2 : 1.012491
train_step : 14145, loss1 : 0.711199, loss2 : 1.019947
train_step : 14146, loss1 : 0.972618, loss2 : 1.501274
train_step : 14147, loss1 : 2.054739, loss2 : 1.891009
train_step : 14148, loss1 : 0.779457, loss2 : 1.591288
train_step : 14149, loss1 : 1.652987, loss2 : 1.464188
train_step : 14150, loss1 : 1.117801, loss2 : 0.855450
train_step : 14151, loss1 : 1.645065, loss2 : 1.930853
train_step : 14152, loss1 : 1.399364, loss2 : 0.806457
train_step : 14153, loss1 : 1.159290, loss2 : 0.996285
train_step : 14154, loss1 : 1.677549, loss2 : 1.235459
train_step : 14155, loss1 : 1.293513, loss2 : 1.918810
train_step : 14156, loss1 : 1.803835, loss2 : 1.080896
train_step : 14157, loss1 : 0.933585, loss2 : 1.301275
train_step : 14158, loss1 : 1.566253, loss2 : 0.715418
train_step : 14159, loss1 : 1.010026, loss2 : 1.091654
train_step : 14160, loss1 : 1.205340, loss2 : 0.557495
train_step : 14161, loss1 : 1.499786, loss2 : 0.579750
train_step : 14162, loss1 : 1.109447, loss2 : 1.140298
train_step : 14163, loss1 : 1.866788, loss2 : 1.633933
train_step : 14164, loss1 : 2.289741, loss2 : 0.769126
train_step : 14165, loss1 : 1.704064, loss2 : 2.063423
train_step : 14166, loss1 : 1.666506, loss2 : 0.904937
train_step : 14167, loss1 : 0.704386, loss2 : 0.757312
train_step : 14168, loss1 : 1.667073, loss2 : 0.977359
train_step : 14169, loss1 : 1.310601, loss2 : 1.251423
train_step : 14170, loss1 : 1.149745, loss2 : 1.121222
train_step : 14171, loss1 : 0.582393, loss2 : 1.035304
train_step : 14172, loss1 : 1.429561, loss2 : 0.739056
train_step : 14173, loss1 : 1.473950, loss2 : 1.629885
train_step : 14174, loss1 : 1.234374, loss2 : 1.290441
train_step : 14175, loss1 : 1.725556, loss2 : 1.599214
train_step : 14176, loss1 : 1.945022, loss2 : 2.036180
train_step : 14177, loss1 : 1.348132, loss2 : 1.505123
train_step : 14178, loss1 : 2.884353, loss2 : 1.708884
train_step : 14179, loss1 : 3.576180, loss2 : 4.073026
train_step : 14180, loss1 : 2.444134, loss2 : 3.079780
train_step : 14181, loss1 : 2.512902, loss2 : 2.183523
train_step : 14182, loss1 : 3.125377, loss2 : 3.214067
train_step : 14183, loss1 : 3.827757, loss2 : 3.089102
train_step : 14184, loss1 : 2.661024, loss2 : 3.029268
train_step : 14185, loss1 : 3.277195, loss2 : 3.258821
train_step : 14186, loss1 : 2.065075, loss2 : 2.091460
train_step : 14187, loss1 : 1.841246, loss2 : 1.685323
train_step : 14188, loss1 : 2.364296, loss2 : 2.472313
train_step : 14189, loss1 : 2.833048, loss2 : 4.542153
train_step : 14190, loss1 : 2.332468, loss2 : 2.994164
train_step : 14191, loss1 : 1.807020, loss2 : 2.797737
train_step : 14192, loss1 : 2.425793, loss2 : 2.443334
train_step : 14193, loss1 : 4.429859, loss2 : 2.418983
train_step : 14194, loss1 : 1.626678, loss2 : 1.436865
train_step : 14195, loss1 : 1.348779, loss2 : 1.054809
train_step : 14196, loss1 : 1.984424, loss2 : 0.946781
train_step : 14197, loss1 : 2.792197, loss2 : 1.460858
train_step : 14198, loss1 : 0.966812, loss2 : 0.909682
train_step : 14199, loss1 : 0.523103, loss2 : 1.594290
train_step : 14200, loss1 : 0.831411, loss2 : 1.426827
train_step : 14201, loss1 : 0.854652, loss2 : 0.956382
train_step : 14202, loss1 : 1.964785, loss2 : 1.136282
train_step : 14203, loss1 : 1.495875, loss2 : 0.932114
train_step : 14204, loss1 : 1.318815, loss2 : 0.774857
train_step : 14205, loss1 : 0.721104, loss2 : 1.968738
train_step : 14206, loss1 : 2.212900, loss2 : 2.114483
train_step : 14207, loss1 : 3.327909, loss2 : 1.766169
train_step : 14208, loss1 : 1.998680, loss2 : 1.955198
train_step : 14209, loss1 : 2.130546, loss2 : 2.551182
train_step : 14210, loss1 : 2.136565, loss2 : 2.042819
train_step : 14211, loss1 : 2.451510, loss2 : 2.082002
train_step : 14212, loss1 : 2.899990, loss2 : 3.223676
train_step : 14213, loss1 : 1.933012, loss2 : 1.469169
train_step : 14214, loss1 : 2.081080, loss2 : 1.867867
train_step : 14215, loss1 : 2.018990, loss2 : 1.673148
train_step : 14216, loss1 : 2.408746, loss2 : 1.731885
train_step : 14217, loss1 : 2.175203, loss2 : 2.270817
train_step : 14218, loss1 : 3.819612, loss2 : 1.257841
train_step : 14219, loss1 : 2.695563, loss2 : 0.899416
train_step : 14220, loss1 : 1.783075, loss2 : 0.661933
train_step : 14221, loss1 : 1.060609, loss2 : 0.974992
train_step : 14222, loss1 : 1.131768, loss2 : 1.295600
train_step : 14223, loss1 : 1.063180, loss2 : 1.092247
train_step : 14224, loss1 : 2.212561, loss2 : 1.902554
train_step : 14225, loss1 : 1.230099, loss2 : 1.246185
train_step : 14226, loss1 : 1.259287, loss2 : 1.368783
train_step : 14227, loss1 : 1.588774, loss2 : 1.084448
train_step : 14228, loss1 : 0.721247, loss2 : 0.446761
train_step : 14229, loss1 : 0.837158, loss2 : 0.905701
train_step : 14230, loss1 : 1.661965, loss2 : 1.176834
train_step : 14231, loss1 : 0.907957, loss2 : 1.108802
train_step : 14232, loss1 : 1.384710, loss2 : 1.205539
train_step : 14233, loss1 : 1.165707, loss2 : 1.933828
train_step : 14234, loss1 : 2.889309, loss2 : 1.649163
train_step : 14235, loss1 : 2.383374, loss2 : 2.930145
train_step : 14236, loss1 : 2.434831, loss2 : 1.120998
train_step : 14237, loss1 : 1.946228, loss2 : 2.291894
train_step : 14238, loss1 : 1.399075, loss2 : 1.164817
train_step : 14239, loss1 : 2.132550, loss2 : 2.520593
train_step : 14240, loss1 : 2.714691, loss2 : 2.275847
train_step : 14241, loss1 : 1.199876, loss2 : 2.168589
train_step : 14242, loss1 : 0.992925, loss2 : 1.222495
train_step : 14243, loss1 : 1.343785, loss2 : 0.938103
train_step : 14244, loss1 : 1.438187, loss2 : 1.121081
train_step : 14245, loss1 : 0.917463, loss2 : 1.257112
train_step : 14246, loss1 : 0.862354, loss2 : 1.173163
train_step : 14247, loss1 : 1.348203, loss2 : 2.675892
train_step : 14248, loss1 : 1.921709, loss2 : 1.495645
train_step : 14249, loss1 : 1.114349, loss2 : 1.577167
train_step : 14250, loss1 : 1.575533, loss2 : 0.839543
train_step : 14251, loss1 : 1.362226, loss2 : 1.225174
train_step : 14252, loss1 : 1.152222, loss2 : 1.191571
train_step : 14253, loss1 : 1.521327, loss2 : 1.904119
train_step : 14254, loss1 : 1.190486, loss2 : 2.492022
train_step : 14255, loss1 : 2.016821, loss2 : 2.057190
train_step : 14256, loss1 : 1.130010, loss2 : 0.787184
train_step : 14257, loss1 : 0.864864, loss2 : 0.794126
train_step : 14258, loss1 : 0.597855, loss2 : 1.292906
train_step : 14259, loss1 : 1.335055, loss2 : 0.813381
train_step : 14260, loss1 : 1.492835, loss2 : 1.317791
train_step : 14261, loss1 : 0.783116, loss2 : 1.105820
train_step : 14262, loss1 : 0.970792, loss2 : 1.818563
train_step : 14263, loss1 : 1.493294, loss2 : 0.998341
train_step : 14264, loss1 : 1.163441, loss2 : 0.882500
train_step : 14265, loss1 : 1.147946, loss2 : 0.857673
train_step : 14266, loss1 : 1.160658, loss2 : 1.379833
train_step : 14267, loss1 : 1.962137, loss2 : 1.508286
train_step : 14268, loss1 : 2.462257, loss2 : 2.611827
train_step : 14269, loss1 : 0.815710, loss2 : 1.043475
train_step : 14270, loss1 : 1.109905, loss2 : 0.971373
train_step : 14271, loss1 : 0.722190, loss2 : 1.153558
train_step : 14272, loss1 : 0.921780, loss2 : 1.242261
train_step : 14273, loss1 : 0.800984, loss2 : 1.091770
train_step : 14274, loss1 : 1.169592, loss2 : 0.768800
train_step : 14275, loss1 : 1.045097, loss2 : 1.462295
train_step : 14276, loss1 : 1.770321, loss2 : 1.142998
train_step : 14277, loss1 : 1.581261, loss2 : 1.145171
train_step : 14278, loss1 : 0.722405, loss2 : 0.896958
train_step : 14279, loss1 : 1.760763, loss2 : 1.342378
train_step : 14280, loss1 : 1.571900, loss2 : 2.122385
train_step : 14281, loss1 : 1.229097, loss2 : 1.386268
train_step : 14282, loss1 : 1.018307, loss2 : 0.853312
train_step : 14283, loss1 : 0.742667, loss2 : 1.160886
train_step : 14284, loss1 : 1.200630, loss2 : 1.204195
train_step : 14285, loss1 : 0.835060, loss2 : 1.325238
train_step : 14286, loss1 : 1.361362, loss2 : 1.458596
train_step : 14287, loss1 : 0.817678, loss2 : 1.731585
train_step : 14288, loss1 : 2.375546, loss2 : 0.879657
train_step : 14289, loss1 : 0.799979, loss2 : 1.170355
train_step : 14290, loss1 : 1.685120, loss2 : 1.634735
train_step : 14291, loss1 : 0.856576, loss2 : 1.351147
train_step : 14292, loss1 : 0.592241, loss2 : 2.067624
train_step : 14293, loss1 : 1.019057, loss2 : 1.723242
train_step : 14294, loss1 : 1.222437, loss2 : 1.706989
train_step : 14295, loss1 : 2.255833, loss2 : 1.677082
train_step : 14296, loss1 : 1.334754, loss2 : 1.070879
train_step : 14297, loss1 : 1.051419, loss2 : 1.272202
train_step : 14298, loss1 : 1.188216, loss2 : 1.050874
train_step : 14299, loss1 : 1.188503, loss2 : 1.141030
train_step : 14300, loss1 : 0.866080, loss2 : 1.179147
train_step : 14301, loss1 : 1.210986, loss2 : 0.617780
train_step : 14302, loss1 : 0.833699, loss2 : 1.287675
train_step : 14303, loss1 : 1.581724, loss2 : 1.243990
train_step : 14304, loss1 : 0.930361, loss2 : 1.151218
train_step : 14305, loss1 : 1.435080, loss2 : 1.669676
train_step : 14306, loss1 : 1.719973, loss2 : 1.112859
train_step : 14307, loss1 : 0.942683, loss2 : 1.597324
train_step : 14308, loss1 : 1.312239, loss2 : 1.218188
train_step : 14309, loss1 : 1.388590, loss2 : 1.387455
train_step : 14310, loss1 : 1.504380, loss2 : 1.757643
train_step : 14311, loss1 : 2.316544, loss2 : 2.396627
train_step : 14312, loss1 : 1.777911, loss2 : 2.628411
train_step : 14313, loss1 : 2.213185, loss2 : 2.376904
train_step : 14314, loss1 : 2.256684, loss2 : 2.296433
train_step : 14315, loss1 : 1.528347, loss2 : 1.953265
train_step : 14316, loss1 : 1.373331, loss2 : 1.593798
train_step : 14317, loss1 : 1.978885, loss2 : 1.937251
train_step : 14318, loss1 : 1.469727, loss2 : 2.566929
train_step : 14319, loss1 : 1.228784, loss2 : 1.977537
train_step : 14320, loss1 : 1.114404, loss2 : 0.923210
train_step : 14321, loss1 : 1.150151, loss2 : 0.949917
train_step : 14322, loss1 : 1.161013, loss2 : 0.905284
train_step : 14323, loss1 : 1.678260, loss2 : 0.768506
train_step : 14324, loss1 : 1.138746, loss2 : 0.942742
train_step : 14325, loss1 : 1.004188, loss2 : 0.847759
train_step : 14326, loss1 : 1.189839, loss2 : 0.644636
train_step : 14327, loss1 : 1.237975, loss2 : 2.507909
train_step : 14328, loss1 : 1.170871, loss2 : 0.990889
train_step : 14329, loss1 : 1.055661, loss2 : 1.272634
train_step : 14330, loss1 : 1.105610, loss2 : 1.194066
train_step : 14331, loss1 : 1.403576, loss2 : 1.568661
train_step : 14332, loss1 : 1.386174, loss2 : 1.186681
train_step : 14333, loss1 : 0.467985, loss2 : 1.727286
train_step : 14334, loss1 : 1.222213, loss2 : 0.868075
train_step : 14335, loss1 : 0.757043, loss2 : 0.723651
train_step : 14336, loss1 : 1.073638, loss2 : 1.005437
train_step : 14337, loss1 : 1.165771, loss2 : 1.426805
train_step : 14338, loss1 : 1.566831, loss2 : 1.544759
train_step : 14339, loss1 : 1.898069, loss2 : 1.078524
train_step : 14340, loss1 : 1.391246, loss2 : 0.972952
train_step : 14341, loss1 : 1.543134, loss2 : 1.217194
train_step : 14342, loss1 : 1.411074, loss2 : 2.445658
train_step : 14343, loss1 : 1.883858, loss2 : 0.770479
train_step : 14344, loss1 : 1.926848, loss2 : 2.388087
train_step : 14345, loss1 : 2.208100, loss2 : 0.804897
train_step : 14346, loss1 : 0.757146, loss2 : 1.131441
train_step : 14347, loss1 : 1.490650, loss2 : 0.790638
train_step : 14348, loss1 : 1.314762, loss2 : 0.821560
train_step : 14349, loss1 : 1.306507, loss2 : 1.109653
train_step : 14350, loss1 : 0.666952, loss2 : 0.970509
train_step : 14351, loss1 : 1.465757, loss2 : 1.239618
train_step : 14352, loss1 : 1.221450, loss2 : 0.673141
train_step : 14353, loss1 : 0.648116, loss2 : 1.924797
train_step : 14354, loss1 : 1.158580, loss2 : 0.860098
train_step : 14355, loss1 : 1.719594, loss2 : 2.058770
train_step : 14356, loss1 : 1.027094, loss2 : 1.809666
train_step : 14357, loss1 : 1.480812, loss2 : 2.026446
train_step : 14358, loss1 : 1.810704, loss2 : 1.236149
train_step : 14359, loss1 : 1.338417, loss2 : 1.212578
train_step : 14360, loss1 : 1.102272, loss2 : 1.407202
train_step : 14361, loss1 : 0.846785, loss2 : 1.198935
train_step : 14362, loss1 : 1.958174, loss2 : 1.637648
train_step : 14363, loss1 : 2.698949, loss2 : 2.854630
train_step : 14364, loss1 : 3.822967, loss2 : 3.379171
train_step : 14365, loss1 : 3.978929, loss2 : 3.475113
train_step : 14366, loss1 : 3.608565, loss2 : 2.256282
train_step : 14367, loss1 : 3.108342, loss2 : 3.550497
train_step : 14368, loss1 : 2.148796, loss2 : 1.261468
train_step : 14369, loss1 : 1.620206, loss2 : 0.893260
train_step : 14370, loss1 : 2.290417, loss2 : 0.804929
train_step : 14371, loss1 : 1.123422, loss2 : 1.013194
train_step : 14372, loss1 : 1.131547, loss2 : 1.099537
train_step : 14373, loss1 : 1.004383, loss2 : 2.161605
train_step : 14374, loss1 : 1.841754, loss2 : 1.834021
train_step : 14375, loss1 : 2.157807, loss2 : 1.414284
train_step : 14376, loss1 : 1.281908, loss2 : 2.073606
train_step : 14377, loss1 : 0.899839, loss2 : 1.180803
train_step : 14378, loss1 : 0.847381, loss2 : 2.912776
train_step : 14379, loss1 : 0.930561, loss2 : 1.097031
train_step : 14380, loss1 : 2.242360, loss2 : 1.110871
train_step : 14381, loss1 : 0.926983, loss2 : 0.977115
train_step : 14382, loss1 : 1.049759, loss2 : 0.679129
train_step : 14383, loss1 : 1.186379, loss2 : 1.072945
train_step : 14384, loss1 : 0.744770, loss2 : 1.475032
train_step : 14385, loss1 : 0.548965, loss2 : 0.977902
train_step : 14386, loss1 : 0.776348, loss2 : 1.263032
train_step : 14387, loss1 : 0.785658, loss2 : 0.981261
train_step : 14388, loss1 : 1.028247, loss2 : 0.901166
train_step : 14389, loss1 : 1.036389, loss2 : 0.414987
train_step : 14390, loss1 : 0.996828, loss2 : 1.460241
train_step : 14391, loss1 : 1.228257, loss2 : 2.488912
train_step : 14392, loss1 : 1.148069, loss2 : 1.190480
train_step : 14393, loss1 : 0.984525, loss2 : 1.215806
train_step : 14394, loss1 : 1.121949, loss2 : 1.826982
train_step : 14395, loss1 : 1.038482, loss2 : 1.910672
train_step : 14396, loss1 : 0.901272, loss2 : 1.252927
train_step : 14397, loss1 : 1.065022, loss2 : 1.476466
train_step : 14398, loss1 : 1.213061, loss2 : 1.268430
train_step : 14399, loss1 : 1.339603, loss2 : 1.037503
train_step : 14400, loss1 : 1.497499, loss2 : 0.619108
train_step : 14401, loss1 : 1.225212, loss2 : 0.943360
train_step : 14402, loss1 : 1.464499, loss2 : 0.742416
train_step : 14403, loss1 : 0.781445, loss2 : 1.324374
train_step : 14404, loss1 : 0.660500, loss2 : 1.217710
train_step : 14405, loss1 : 1.078465, loss2 : 1.473164
train_step : 14406, loss1 : 0.764262, loss2 : 1.910193
train_step : 14407, loss1 : 0.677098, loss2 : 1.862493
train_step : 14408, loss1 : 1.130445, loss2 : 1.841353
train_step : 14409, loss1 : 0.791169, loss2 : 1.041078
train_step : 14410, loss1 : 1.290230, loss2 : 0.708665
train_step : 14411, loss1 : 1.847186, loss2 : 1.527090
train_step : 14412, loss1 : 2.683126, loss2 : 2.162108
train_step : 14413, loss1 : 3.288078, loss2 : 1.938498
train_step : 14414, loss1 : 2.341763, loss2 : 1.743393
train_step : 14415, loss1 : 1.130821, loss2 : 1.073056
train_step : 14416, loss1 : 1.055666, loss2 : 0.918905
train_step : 14417, loss1 : 1.337657, loss2 : 0.966538
train_step : 14418, loss1 : 0.907941, loss2 : 1.676294
train_step : 14419, loss1 : 1.101677, loss2 : 1.453151
train_step : 14420, loss1 : 2.295412, loss2 : 1.858717
train_step : 14421, loss1 : 1.743662, loss2 : 1.332870
train_step : 14422, loss1 : 0.959861, loss2 : 1.492369
train_step : 14423, loss1 : 1.067636, loss2 : 1.288002
train_step : 14424, loss1 : 1.836548, loss2 : 0.788408
train_step : 14425, loss1 : 1.299564, loss2 : 1.828209
train_step : 14426, loss1 : 1.161941, loss2 : 1.264484
train_step : 14427, loss1 : 0.870057, loss2 : 0.775516
train_step : 14428, loss1 : 1.341746, loss2 : 0.865415
train_step : 14429, loss1 : 1.111553, loss2 : 1.244372
train_step : 14430, loss1 : 2.510729, loss2 : 1.315263
train_step : 14431, loss1 : 2.184144, loss2 : 2.565359
train_step : 14432, loss1 : 1.867489, loss2 : 3.009486
train_step : 14433, loss1 : 2.420799, loss2 : 3.535142
train_step : 14434, loss1 : 2.543026, loss2 : 2.616031
train_step : 14435, loss1 : 3.910171, loss2 : 0.859733
train_step : 14436, loss1 : 1.134564, loss2 : 2.068514
train_step : 14437, loss1 : 1.747037, loss2 : 1.827222
train_step : 14438, loss1 : 1.261951, loss2 : 2.741653
train_step : 14439, loss1 : 1.927877, loss2 : 1.741746
train_step : 14440, loss1 : 5.081886, loss2 : 2.740921
train_step : 14441, loss1 : 1.961073, loss2 : 2.643469
train_step : 14442, loss1 : 1.560640, loss2 : 2.758609
train_step : 14443, loss1 : 2.151495, loss2 : 2.720491
train_step : 14444, loss1 : 1.975511, loss2 : 2.945117
train_step : 14445, loss1 : 2.807518, loss2 : 2.673364
train_step : 14446, loss1 : 2.674273, loss2 : 2.279034
train_step : 14447, loss1 : 2.413806, loss2 : 4.190227
train_step : 14448, loss1 : 4.175669, loss2 : 4.060778
train_step : 14449, loss1 : 4.053244, loss2 : 3.100242
train_step : 14450, loss1 : 1.496521, loss2 : 1.655452
train_step : 14451, loss1 : 1.433367, loss2 : 1.285140
train_step : 14452, loss1 : 1.579388, loss2 : 0.926802
train_step : 14453, loss1 : 1.260182, loss2 : 0.540075
train_step : 14454, loss1 : 1.320750, loss2 : 0.662661
train_step : 14455, loss1 : 1.624322, loss2 : 1.258602
train_step : 14456, loss1 : 1.096149, loss2 : 1.593340
train_step : 14457, loss1 : 1.327178, loss2 : 1.011578
train_step : 14458, loss1 : 1.676982, loss2 : 1.663072
train_step : 14459, loss1 : 1.021164, loss2 : 1.538297
train_step : 14460, loss1 : 1.475598, loss2 : 0.906726
train_step : 14461, loss1 : 0.850424, loss2 : 1.077557
train_step : 14462, loss1 : 0.930337, loss2 : 1.059534
train_step : 14463, loss1 : 1.006297, loss2 : 1.294771
train_step : 14464, loss1 : 1.038462, loss2 : 0.824239
train_step : 14465, loss1 : 1.585883, loss2 : 1.195159
train_step : 14466, loss1 : 1.885370, loss2 : 1.504384
train_step : 14467, loss1 : 1.139253, loss2 : 1.967922
train_step : 14468, loss1 : 1.113010, loss2 : 1.116189
train_step : 14469, loss1 : 1.341964, loss2 : 0.737301
train_step : 14470, loss1 : 2.506730, loss2 : 1.066644
train_step : 14471, loss1 : 1.301235, loss2 : 2.075536
train_step : 14472, loss1 : 1.082472, loss2 : 2.432475
train_step : 14473, loss1 : 1.446507, loss2 : 1.274255
train_step : 14474, loss1 : 1.037298, loss2 : 2.008018
train_step : 14475, loss1 : 1.622686, loss2 : 1.620810
train_step : 14476, loss1 : 0.845601, loss2 : 0.731798
train_step : 14477, loss1 : 1.045305, loss2 : 2.808515
train_step : 14478, loss1 : 0.982476, loss2 : 1.064875
train_step : 14479, loss1 : 2.208953, loss2 : 1.350110
train_step : 14480, loss1 : 3.733249, loss2 : 3.211285
train_step : 14481, loss1 : 2.611429, loss2 : 2.287775
train_step : 14482, loss1 : 1.591865, loss2 : 2.264478
train_step : 14483, loss1 : 1.643222, loss2 : 1.531194
train_step : 14484, loss1 : 1.696504, loss2 : 1.870121
train_step : 14485, loss1 : 1.788542, loss2 : 1.806221
train_step : 14486, loss1 : 2.183278, loss2 : 1.118744
train_step : 14487, loss1 : 1.350354, loss2 : 1.700370
train_step : 14488, loss1 : 0.997555, loss2 : 1.912676
train_step : 14489, loss1 : 2.190070, loss2 : 1.947382
train_step : 14490, loss1 : 2.936152, loss2 : 2.310274
train_step : 14491, loss1 : 1.629505, loss2 : 1.444091
train_step : 14492, loss1 : 1.505465, loss2 : 1.139933
train_step : 14493, loss1 : 1.033386, loss2 : 5.305826
train_step : 14494, loss1 : 1.137465, loss2 : 1.001156
train_step : 14495, loss1 : 1.611931, loss2 : 0.930238
train_step : 14496, loss1 : 1.583735, loss2 : 1.820318
train_step : 14497, loss1 : 1.211522, loss2 : 1.233797
train_step : 14498, loss1 : 0.834110, loss2 : 0.617470
train_step : 14499, loss1 : 0.981231, loss2 : 0.658876
train_step : 14500, loss1 : 1.248387, loss2 : 2.563139
train_step : 14501, loss1 : 0.493891, loss2 : 1.210082
train_step : 14502, loss1 : 1.350533, loss2 : 1.183429
train_step : 14503, loss1 : 1.001862, loss2 : 1.036607
train_step : 14504, loss1 : 1.781425, loss2 : 0.733774
train_step : 14505, loss1 : 2.015152, loss2 : 1.386403
train_step : 14506, loss1 : 0.997545, loss2 : 1.581539
train_step : 14507, loss1 : 0.621657, loss2 : 1.075314
train_step : 14508, loss1 : 1.466216, loss2 : 1.165247
train_step : 14509, loss1 : 1.007889, loss2 : 1.503100
train_step : 14510, loss1 : 2.393557, loss2 : 2.501505
train_step : 14511, loss1 : 1.573741, loss2 : 0.747277
train_step : 14512, loss1 : 0.817371, loss2 : 0.956627
train_step : 14513, loss1 : 1.306470, loss2 : 0.710179
train_step : 14514, loss1 : 1.475718, loss2 : 1.346020
train_step : 14515, loss1 : 1.157052, loss2 : 1.619036
train_step : 14516, loss1 : 2.145519, loss2 : 1.578067
train_step : 14517, loss1 : 1.857040, loss2 : 1.932214
train_step : 14518, loss1 : 1.534807, loss2 : 0.964880
train_step : 14519, loss1 : 1.164478, loss2 : 1.719383
train_step : 14520, loss1 : 1.205805, loss2 : 0.895659
train_step : 14521, loss1 : 1.295730, loss2 : 1.182394
train_step : 14522, loss1 : 1.283399, loss2 : 1.203393
train_step : 14523, loss1 : 2.152521, loss2 : 1.660930
train_step : 14524, loss1 : 1.574645, loss2 : 1.406101
train_step : 14525, loss1 : 1.199059, loss2 : 1.054904
train_step : 14526, loss1 : 0.967691, loss2 : 10.461297
train_step : 14527, loss1 : 1.255419, loss2 : 0.923765
train_step : 14528, loss1 : 1.915948, loss2 : 0.601628
train_step : 14529, loss1 : 1.671575, loss2 : 0.821535
train_step : 14530, loss1 : 0.897086, loss2 : 0.943491
train_step : 14531, loss1 : 1.079019, loss2 : 1.613900
train_step : 14532, loss1 : 0.897198, loss2 : 1.272203
train_step : 14533, loss1 : 0.792720, loss2 : 1.244963
train_step : 14534, loss1 : 1.239384, loss2 : 0.944611
train_step : 14535, loss1 : 1.346252, loss2 : 0.834104
train_step : 14536, loss1 : 1.228319, loss2 : 1.184956
train_step : 14537, loss1 : 1.087773, loss2 : 1.110373
train_step : 14538, loss1 : 1.521022, loss2 : 0.544864
train_step : 14539, loss1 : 0.733233, loss2 : 1.715507
train_step : 14540, loss1 : 1.200719, loss2 : 0.809819
train_step : 14541, loss1 : 0.855161, loss2 : 0.979699
train_step : 14542, loss1 : 1.115869, loss2 : 1.245495
train_step : 14543, loss1 : 1.177197, loss2 : 1.704652
train_step : 14544, loss1 : 0.760397, loss2 : 1.523898
train_step : 14545, loss1 : 0.649265, loss2 : 1.747223
train_step : 14546, loss1 : 1.447984, loss2 : 1.227003
train_step : 14547, loss1 : 0.935201, loss2 : 1.073170
train_step : 14548, loss1 : 1.471594, loss2 : 1.559689
train_step : 14549, loss1 : 1.180651, loss2 : 1.457538
train_step : 14550, loss1 : 2.115795, loss2 : 1.491930
train_step : 14551, loss1 : 1.978158, loss2 : 1.927383
train_step : 14552, loss1 : 2.304551, loss2 : 2.113173
train_step : 14553, loss1 : 1.758388, loss2 : 1.097677
train_step : 14554, loss1 : 1.313087, loss2 : 0.739738
train_step : 14555, loss1 : 1.331006, loss2 : 1.521424
train_step : 14556, loss1 : 1.250157, loss2 : 0.944169
train_step : 14557, loss1 : 0.638455, loss2 : 1.469229
train_step : 14558, loss1 : 1.154719, loss2 : 1.424762
train_step : 14559, loss1 : 0.920465, loss2 : 1.344190
train_step : 14560, loss1 : 1.950358, loss2 : 1.242767
train_step : 14561, loss1 : 1.553564, loss2 : 1.252733
train_step : 14562, loss1 : 2.118474, loss2 : 0.989757
train_step : 14563, loss1 : 1.386334, loss2 : 1.256653
train_step : 14564, loss1 : 1.166500, loss2 : 2.115440
train_step : 14565, loss1 : 0.970334, loss2 : 1.457791
train_step : 14566, loss1 : 1.072034, loss2 : 0.984188
train_step : 14567, loss1 : 1.021025, loss2 : 1.015486
train_step : 14568, loss1 : 1.521001, loss2 : 1.416212
train_step : 14569, loss1 : 2.379216, loss2 : 1.210696
train_step : 14570, loss1 : 0.693010, loss2 : 1.015206
train_step : 14571, loss1 : 1.082305, loss2 : 1.336117
train_step : 14572, loss1 : 1.636085, loss2 : 0.939831
train_step : 14573, loss1 : 1.446395, loss2 : 1.087235
train_step : 14574, loss1 : 0.905167, loss2 : 1.553649
train_step : 14575, loss1 : 1.404870, loss2 : 1.487135
train_step : 14576, loss1 : 1.626351, loss2 : 1.377189
train_step : 14577, loss1 : 1.967253, loss2 : 0.992448
train_step : 14578, loss1 : 0.996960, loss2 : 1.515236
train_step : 14579, loss1 : 1.782266, loss2 : 0.781013
train_step : 14580, loss1 : 0.829269, loss2 : 1.856782
train_step : 14581, loss1 : 1.042043, loss2 : 2.353659
train_step : 14582, loss1 : 1.165719, loss2 : 1.207939
train_step : 14583, loss1 : 2.272243, loss2 : 1.604743
train_step : 14584, loss1 : 2.014205, loss2 : 2.092328
train_step : 14585, loss1 : 1.479922, loss2 : 1.483596
train_step : 14586, loss1 : 1.428993, loss2 : 2.157570
train_step : 14587, loss1 : 1.398669, loss2 : 1.039420
train_step : 14588, loss1 : 1.482535, loss2 : 1.668323
train_step : 14589, loss1 : 1.900860, loss2 : 1.366987
train_step : 14590, loss1 : 1.985193, loss2 : 3.958862
train_step : 14591, loss1 : 0.938191, loss2 : 0.653743
train_step : 14592, loss1 : 0.622406, loss2 : 0.970739
train_step : 14593, loss1 : 0.714821, loss2 : 1.185089
train_step : 14594, loss1 : 1.103368, loss2 : 0.622807
train_step : 14595, loss1 : 0.609843, loss2 : 1.205476
train_step : 14596, loss1 : 0.948561, loss2 : 1.633115
train_step : 14597, loss1 : 0.725864, loss2 : 0.994862
train_step : 14598, loss1 : 0.572371, loss2 : 1.090182
train_step : 14599, loss1 : 0.997803, loss2 : 0.949408
train_step : 14600, loss1 : 1.789101, loss2 : 2.472360
train_step : 14601, loss1 : 2.619832, loss2 : 4.151201
train_step : 14602, loss1 : 4.214713, loss2 : 1.464198
train_step : 14603, loss1 : 2.124172, loss2 : 2.877250
train_step : 14604, loss1 : 2.661674, loss2 : 1.825249
train_step : 14605, loss1 : 3.440423, loss2 : 2.433269
train_step : 14606, loss1 : 1.197619, loss2 : 2.220727
train_step : 14607, loss1 : 1.544507, loss2 : 0.917068
train_step : 14608, loss1 : 1.112603, loss2 : 0.995218
train_step : 14609, loss1 : 1.931725, loss2 : 1.451912
train_step : 14610, loss1 : 1.346321, loss2 : 1.679294
train_step : 14611, loss1 : 1.196893, loss2 : 1.822971
train_step : 14612, loss1 : 1.886000, loss2 : 1.941145
train_step : 14613, loss1 : 2.453055, loss2 : 2.346552
train_step : 14614, loss1 : 1.748810, loss2 : 2.045630
train_step : 14615, loss1 : 0.806291, loss2 : 1.361448
train_step : 14616, loss1 : 0.895745, loss2 : 1.327028
train_step : 14617, loss1 : 1.658886, loss2 : 1.201568
train_step : 14618, loss1 : 1.220089, loss2 : 1.170493
train_step : 14619, loss1 : 0.467838, loss2 : 1.294404
train_step : 14620, loss1 : 0.898862, loss2 : 1.253675
train_step : 14621, loss1 : 1.249958, loss2 : 0.931554
train_step : 14622, loss1 : 1.622299, loss2 : 0.513697
train_step : 14623, loss1 : 1.165082, loss2 : 1.173362
train_step : 14624, loss1 : 0.923276, loss2 : 1.011904
train_step : 14625, loss1 : 1.215427, loss2 : 0.849718
train_step : 14626, loss1 : 0.607808, loss2 : 1.248817
train_step : 14627, loss1 : 2.029281, loss2 : 1.394997
train_step : 14628, loss1 : 1.776029, loss2 : 2.386925
train_step : 14629, loss1 : 0.987446, loss2 : 0.757136
train_step : 14630, loss1 : 1.758993, loss2 : 0.992335
train_step : 14631, loss1 : 2.129047, loss2 : 1.848076
train_step : 14632, loss1 : 2.230054, loss2 : 2.092454
train_step : 14633, loss1 : 1.873485, loss2 : 1.577066
train_step : 14634, loss1 : 2.321239, loss2 : 1.492114
train_step : 14635, loss1 : 1.330011, loss2 : 1.348873
train_step : 14636, loss1 : 2.303317, loss2 : 0.956662
train_step : 14637, loss1 : 1.233526, loss2 : 2.095887
train_step : 14638, loss1 : 1.354383, loss2 : 0.846901
train_step : 14639, loss1 : 1.131573, loss2 : 1.030676
train_step : 14640, loss1 : 1.927817, loss2 : 1.106193
train_step : 14641, loss1 : 1.499141, loss2 : 1.641717
train_step : 14642, loss1 : 0.805917, loss2 : 1.459139
train_step : 14643, loss1 : 1.072362, loss2 : 0.715447
train_step : 14644, loss1 : 1.004523, loss2 : 2.601467
train_step : 14645, loss1 : 1.195443, loss2 : 1.481888
train_step : 14646, loss1 : 2.276061, loss2 : 1.346009
train_step : 14647, loss1 : 2.115197, loss2 : 1.813405
train_step : 14648, loss1 : 2.333628, loss2 : 2.262175
train_step : 14649, loss1 : 4.134149, loss2 : 2.736017
train_step : 14650, loss1 : 1.491238, loss2 : 1.289130
train_step : 14651, loss1 : 0.920079, loss2 : 1.911957
train_step : 14652, loss1 : 0.764101, loss2 : 1.057366
train_step : 14653, loss1 : 1.095107, loss2 : 1.298842
train_step : 14654, loss1 : 1.887343, loss2 : 2.068088
train_step : 14655, loss1 : 1.253130, loss2 : 1.311985
train_step : 14656, loss1 : 1.980090, loss2 : 1.231943
train_step : 14657, loss1 : 1.635998, loss2 : 1.788553
train_step : 14658, loss1 : 1.691362, loss2 : 2.175065
train_step : 14659, loss1 : 2.486491, loss2 : 3.667615
train_step : 14660, loss1 : 2.448124, loss2 : 4.046708
train_step : 14661, loss1 : 2.610388, loss2 : 4.640155
train_step : 14662, loss1 : 5.455256, loss2 : 5.645449
train_step : 14663, loss1 : 4.345121, loss2 : 2.057800
train_step : 14664, loss1 : 2.059502, loss2 : 3.105072
train_step : 14665, loss1 : 1.731667, loss2 : 1.419573
train_step : 14666, loss1 : 1.939078, loss2 : 1.230384
train_step : 14667, loss1 : 1.455472, loss2 : 1.639525
train_step : 14668, loss1 : 1.058754, loss2 : 1.590942
train_step : 14669, loss1 : 0.882003, loss2 : 2.100111
train_step : 14670, loss1 : 1.153564, loss2 : 1.457140
train_step : 14671, loss1 : 1.445098, loss2 : 0.868689
train_step : 14672, loss1 : 1.267757, loss2 : 0.622832
train_step : 14673, loss1 : 2.079929, loss2 : 1.528646
train_step : 14674, loss1 : 1.133151, loss2 : 1.214661
train_step : 14675, loss1 : 0.969479, loss2 : 1.348898
train_step : 14676, loss1 : 0.680731, loss2 : 1.123961
train_step : 14677, loss1 : 0.628683, loss2 : 0.808643
train_step : 14678, loss1 : 1.157320, loss2 : 0.854054
train_step : 14679, loss1 : 1.640363, loss2 : 0.799743
train_step : 14680, loss1 : 1.574654, loss2 : 0.905629
train_step : 14681, loss1 : 1.275333, loss2 : 0.767028
train_step : 14682, loss1 : 1.216118, loss2 : 1.294298
train_step : 14683, loss1 : 0.520971, loss2 : 1.687619
train_step : 14684, loss1 : 1.145106, loss2 : 0.743965
train_step : 14685, loss1 : 0.874389, loss2 : 1.174817
train_step : 14686, loss1 : 1.481528, loss2 : 1.444765
train_step : 14687, loss1 : 2.120941, loss2 : 2.193326
train_step : 14688, loss1 : 1.185944, loss2 : 1.697366
train_step : 14689, loss1 : 0.714902, loss2 : 1.685465
train_step : 14690, loss1 : 1.909707, loss2 : 0.867976
train_step : 14691, loss1 : 0.773588, loss2 : 1.515055
train_step : 14692, loss1 : 0.959734, loss2 : 1.635550
train_step : 14693, loss1 : 1.365761, loss2 : 1.368758
train_step : 14694, loss1 : 1.568911, loss2 : 1.337603
train_step : 14695, loss1 : 2.591809, loss2 : 1.687549
train_step : 14696, loss1 : 2.559060, loss2 : 1.551709
train_step : 14697, loss1 : 2.061217, loss2 : 1.181972
train_step : 14698, loss1 : 1.111086, loss2 : 1.439508
train_step : 14699, loss1 : 1.485916, loss2 : 1.703332
train_step : 14700, loss1 : 2.096784, loss2 : 1.185398
train_step : 14701, loss1 : 2.390712, loss2 : 1.581383
train_step : 14702, loss1 : 1.706933, loss2 : 1.940143
train_step : 14703, loss1 : 1.864515, loss2 : 1.785931
train_step : 14704, loss1 : 2.859463, loss2 : 2.311377
train_step : 14705, loss1 : 4.035305, loss2 : 3.110636
train_step : 14706, loss1 : 3.782235, loss2 : 4.112744
train_step : 14707, loss1 : 2.532019, loss2 : 2.244005
train_step : 14708, loss1 : 2.696955, loss2 : 2.110556
train_step : 14709, loss1 : 1.030782, loss2 : 1.713534
train_step : 14710, loss1 : 1.176114, loss2 : 1.354632
train_step : 14711, loss1 : 0.988453, loss2 : 0.853536
train_step : 14712, loss1 : 1.181530, loss2 : 0.984986
train_step : 14713, loss1 : 1.516110, loss2 : 1.476724
train_step : 14714, loss1 : 1.876006, loss2 : 1.363104
train_step : 14715, loss1 : 1.905699, loss2 : 2.354186
train_step : 14716, loss1 : 2.494287, loss2 : 3.411832
train_step : 14717, loss1 : 1.619376, loss2 : 2.314669
train_step : 14718, loss1 : 1.708583, loss2 : 1.850250
train_step : 14719, loss1 : 0.718673, loss2 : 2.421541
train_step : 14720, loss1 : 1.572205, loss2 : 1.126838
train_step : 14721, loss1 : 1.039159, loss2 : 1.146715
train_step : 14722, loss1 : 1.103839, loss2 : 0.900797
train_step : 14723, loss1 : 1.179444, loss2 : 0.821305
train_step : 14724, loss1 : 1.258938, loss2 : 0.629457
train_step : 14725, loss1 : 1.192622, loss2 : 2.241892
train_step : 14726, loss1 : 0.925787, loss2 : 0.772076
train_step : 14727, loss1 : 1.608514, loss2 : 1.210933
train_step : 14728, loss1 : 1.572896, loss2 : 2.127173
train_step : 14729, loss1 : 1.370974, loss2 : 1.866806
train_step : 14730, loss1 : 2.041622, loss2 : 3.530848
train_step : 14731, loss1 : 2.955487, loss2 : 2.330591
train_step : 14732, loss1 : 2.831915, loss2 : 2.358520
train_step : 14733, loss1 : 4.315299, loss2 : 4.099731
train_step : 14734, loss1 : 4.113941, loss2 : 5.879183
train_step : 14735, loss1 : 4.792423, loss2 : 4.341653
train_step : 14736, loss1 : 1.944739, loss2 : 3.428593
train_step : 14737, loss1 : 1.525039, loss2 : 1.394653
train_step : 14738, loss1 : 0.882176, loss2 : 1.958257
train_step : 14739, loss1 : 0.834484, loss2 : 0.974663
train_step : 14740, loss1 : 1.144463, loss2 : 0.873225
train_step : 14741, loss1 : 0.985677, loss2 : 1.365306
train_step : 14742, loss1 : 0.860154, loss2 : 1.441136
train_step : 14743, loss1 : 1.633898, loss2 : 1.233793
train_step : 14744, loss1 : 1.154731, loss2 : 2.354925
train_step : 14745, loss1 : 1.422181, loss2 : 1.451644
train_step : 14746, loss1 : 0.595465, loss2 : 1.758554
train_step : 14747, loss1 : 1.386821, loss2 : 1.739250
train_step : 14748, loss1 : 1.128891, loss2 : 1.175509
train_step : 14749, loss1 : 1.471592, loss2 : 1.747510
train_step : 14750, loss1 : 1.273192, loss2 : 1.892475
train_step : 14751, loss1 : 1.359292, loss2 : 2.091881
train_step : 14752, loss1 : 1.485082, loss2 : 1.465417
train_step : 14753, loss1 : 1.208383, loss2 : 1.198174
train_step : 14754, loss1 : 1.982264, loss2 : 1.027776
train_step : 14755, loss1 : 0.769805, loss2 : 0.829442
train_step : 14756, loss1 : 2.136517, loss2 : 0.996817
train_step : 14757, loss1 : 0.838667, loss2 : 0.898587
train_step : 14758, loss1 : 1.144262, loss2 : 2.002521
train_step : 14759, loss1 : 0.897566, loss2 : 2.029705
train_step : 14760, loss1 : 1.820670, loss2 : 1.670530
train_step : 14761, loss1 : 3.145025, loss2 : 2.895911
train_step : 14762, loss1 : 4.525696, loss2 : 2.980108
train_step : 14763, loss1 : 2.953491, loss2 : 2.349941
train_step : 14764, loss1 : 0.835165, loss2 : 0.845550
train_step : 14765, loss1 : 1.375230, loss2 : 1.165509
train_step : 14766, loss1 : 1.200903, loss2 : 2.606210
train_step : 14767, loss1 : 2.138939, loss2 : 3.096552
train_step : 14768, loss1 : 1.837521, loss2 : 2.419006
train_step : 14769, loss1 : 1.540712, loss2 : 1.484440
train_step : 14770, loss1 : 1.464362, loss2 : 1.176417
train_step : 14771, loss1 : 1.644144, loss2 : 3.183739
train_step : 14772, loss1 : 1.897634, loss2 : 2.429635
train_step : 14773, loss1 : 1.024932, loss2 : 2.400339
train_step : 14774, loss1 : 1.306781, loss2 : 0.945997
train_step : 14775, loss1 : 1.409360, loss2 : 1.531942
train_step : 14776, loss1 : 0.522704, loss2 : 1.004879
train_step : 14777, loss1 : 1.831033, loss2 : 0.901155
train_step : 14778, loss1 : 0.857186, loss2 : 1.773715
train_step : 14779, loss1 : 1.423478, loss2 : 1.151335
train_step : 14780, loss1 : 1.650173, loss2 : 1.170977
train_step : 14781, loss1 : 1.200644, loss2 : 1.228259
train_step : 14782, loss1 : 0.791543, loss2 : 0.888896
train_step : 14783, loss1 : 1.045767, loss2 : 1.012429
train_step : 14784, loss1 : 0.814801, loss2 : 0.703033
train_step : 14785, loss1 : 1.287403, loss2 : 0.794752
train_step : 14786, loss1 : 1.542922, loss2 : 1.444278
train_step : 14787, loss1 : 2.110367, loss2 : 1.261760
train_step : 14788, loss1 : 1.614566, loss2 : 0.850848
train_step : 14789, loss1 : 1.473837, loss2 : 1.192006
train_step : 14790, loss1 : 1.729432, loss2 : 1.128692
train_step : 14791, loss1 : 0.977453, loss2 : 0.867388
train_step : 14792, loss1 : 0.814750, loss2 : 1.191304
train_step : 14793, loss1 : 1.021972, loss2 : 2.379058
train_step : 14794, loss1 : 1.223306, loss2 : 0.626859
train_step : 14795, loss1 : 1.528510, loss2 : 0.754652
train_step : 14796, loss1 : 1.958942, loss2 : 2.256358
train_step : 14797, loss1 : 1.418877, loss2 : 1.527830
train_step : 14798, loss1 : 2.564730, loss2 : 0.919118
train_step : 14799, loss1 : 0.857842, loss2 : 1.759525
train_step : 14800, loss1 : 1.198839, loss2 : 1.176529
train_step : 14801, loss1 : 0.938372, loss2 : 1.102364
train_step : 14802, loss1 : 1.350440, loss2 : 0.770109
train_step : 14803, loss1 : 1.305593, loss2 : 1.386751
train_step : 14804, loss1 : 1.668800, loss2 : 1.444919
train_step : 14805, loss1 : 1.028756, loss2 : 1.188126
train_step : 14806, loss1 : 1.142680, loss2 : 0.894127
train_step : 14807, loss1 : 1.020063, loss2 : 1.061948
train_step : 14808, loss1 : 1.210736, loss2 : 0.715482
train_step : 14809, loss1 : 0.969849, loss2 : 0.986562
train_step : 14810, loss1 : 1.965499, loss2 : 1.123363
train_step : 14811, loss1 : 1.176502, loss2 : 2.003704
train_step : 14812, loss1 : 1.933598, loss2 : 1.164087
train_step : 14813, loss1 : 1.336365, loss2 : 1.451747
train_step : 14814, loss1 : 1.095495, loss2 : 1.679963
train_step : 14815, loss1 : 1.495220, loss2 : 1.000605
train_step : 14816, loss1 : 0.676353, loss2 : 1.804941
train_step : 14817, loss1 : 1.101399, loss2 : 0.728268
train_step : 14818, loss1 : 1.170801, loss2 : 1.401747
train_step : 14819, loss1 : 0.863422, loss2 : 0.622223
train_step : 14820, loss1 : 1.254993, loss2 : 0.756063
train_step : 14821, loss1 : 0.926475, loss2 : 1.644550
train_step : 14822, loss1 : 1.195199, loss2 : 1.225972
train_step : 14823, loss1 : 1.243920, loss2 : 0.969971
train_step : 14824, loss1 : 1.063462, loss2 : 1.227974
train_step : 14825, loss1 : 1.393809, loss2 : 0.460969
train_step : 14826, loss1 : 0.696851, loss2 : 2.030091
train_step : 14827, loss1 : 1.421675, loss2 : 1.237552
train_step : 14828, loss1 : 0.833818, loss2 : 1.241777
train_step : 14829, loss1 : 1.222033, loss2 : 1.159167
train_step : 14830, loss1 : 1.109028, loss2 : 1.123616
train_step : 14831, loss1 : 2.263786, loss2 : 1.417811
train_step : 14832, loss1 : 1.499785, loss2 : 1.637540
train_step : 14833, loss1 : 1.875801, loss2 : 0.875876
train_step : 14834, loss1 : 1.490722, loss2 : 0.839336
train_step : 14835, loss1 : 1.520739, loss2 : 1.553667
train_step : 14836, loss1 : 1.951939, loss2 : 1.531124
train_step : 14837, loss1 : 1.700076, loss2 : 1.731478
train_step : 14838, loss1 : 1.704504, loss2 : 1.097793
train_step : 14839, loss1 : 1.076195, loss2 : 1.044340
train_step : 14840, loss1 : 1.175780, loss2 : 1.472995
train_step : 14841, loss1 : 1.072229, loss2 : 0.793996
train_step : 14842, loss1 : 1.287519, loss2 : 1.326596
train_step : 14843, loss1 : 1.075153, loss2 : 1.451430
train_step : 14844, loss1 : 2.064345, loss2 : 1.172650
train_step : 14845, loss1 : 1.444711, loss2 : 1.223941
train_step : 14846, loss1 : 1.025284, loss2 : 2.391639
train_step : 14847, loss1 : 1.281932, loss2 : 1.308184
train_step : 14848, loss1 : 1.072299, loss2 : 1.185825
train_step : 14849, loss1 : 1.114996, loss2 : 0.933881
train_step : 14850, loss1 : 1.859884, loss2 : 0.948172
train_step : 14851, loss1 : 1.260594, loss2 : 1.093581
train_step : 14852, loss1 : 0.956013, loss2 : 1.588661
train_step : 14853, loss1 : 1.196557, loss2 : 1.368931
train_step : 14854, loss1 : 1.275120, loss2 : 4.257117
train_step : 14855, loss1 : 3.762846, loss2 : 2.651409
train_step : 14856, loss1 : 3.480179, loss2 : 2.722168
train_step : 14857, loss1 : 3.098590, loss2 : 2.349239
train_step : 14858, loss1 : 1.625643, loss2 : 2.662439
train_step : 14859, loss1 : 1.273898, loss2 : 1.721570
train_step : 14860, loss1 : 1.164764, loss2 : 2.437540
train_step : 14861, loss1 : 1.548801, loss2 : 1.475086
train_step : 14862, loss1 : 0.841967, loss2 : 0.921903
train_step : 14863, loss1 : 1.909569, loss2 : 2.291006
train_step : 14864, loss1 : 2.748768, loss2 : 1.515167
train_step : 14865, loss1 : 2.909087, loss2 : 2.709989
train_step : 14866, loss1 : 1.901325, loss2 : 2.289789
train_step : 14867, loss1 : 1.285099, loss2 : 1.137090
train_step : 14868, loss1 : 1.378242, loss2 : 1.213281
train_step : 14869, loss1 : 1.248298, loss2 : 2.147864
train_step : 14870, loss1 : 2.388154, loss2 : 1.580142
train_step : 14871, loss1 : 2.192317, loss2 : 1.270224
train_step : 14872, loss1 : 0.934850, loss2 : 1.092824
train_step : 14873, loss1 : 0.975247, loss2 : 1.745828
train_step : 14874, loss1 : 1.181234, loss2 : 0.668400
train_step : 14875, loss1 : 0.973885, loss2 : 1.233234
train_step : 14876, loss1 : 1.433443, loss2 : 0.530573
train_step : 14877, loss1 : 1.282100, loss2 : 0.982286
train_step : 14878, loss1 : 1.824202, loss2 : 0.823304
train_step : 14879, loss1 : 0.910367, loss2 : 1.049151
train_step : 14880, loss1 : 0.880998, loss2 : 1.280889
train_step : 14881, loss1 : 1.322743, loss2 : 1.030180
train_step : 14882, loss1 : 1.032061, loss2 : 1.360463
train_step : 14883, loss1 : 0.813391, loss2 : 0.862281
train_step : 14884, loss1 : 1.150296, loss2 : 0.997744
train_step : 14885, loss1 : 1.362129, loss2 : 1.093647
train_step : 14886, loss1 : 1.391217, loss2 : 1.238613
train_step : 14887, loss1 : 0.995706, loss2 : 0.996306
train_step : 14888, loss1 : 1.807388, loss2 : 0.413052
train_step : 14889, loss1 : 1.557318, loss2 : 1.272047
train_step : 14890, loss1 : 1.146230, loss2 : 1.518411
train_step : 14891, loss1 : 1.846566, loss2 : 1.368150
train_step : 14892, loss1 : 1.106029, loss2 : 0.708573
train_step : 14893, loss1 : 1.723825, loss2 : 1.685401
train_step : 14894, loss1 : 2.000379, loss2 : 1.510831
train_step : 14895, loss1 : 1.198479, loss2 : 1.260171
train_step : 14896, loss1 : 0.818180, loss2 : 0.902877
train_step : 14897, loss1 : 0.923493, loss2 : 0.699093
train_step : 14898, loss1 : 1.446494, loss2 : 0.922275
train_step : 14899, loss1 : 1.007069, loss2 : 0.772175
train_step : 14900, loss1 : 1.151186, loss2 : 1.150983
train_step : 14901, loss1 : 1.713738, loss2 : 1.201646
train_step : 14902, loss1 : 2.201509, loss2 : 1.710992
train_step : 14903, loss1 : 2.265435, loss2 : 1.592393
train_step : 14904, loss1 : 1.279970, loss2 : 0.639547
train_step : 14905, loss1 : 1.065661, loss2 : 3.745829
train_step : 14906, loss1 : 1.232850, loss2 : 1.166537
train_step : 14907, loss1 : 1.773302, loss2 : 2.044467
train_step : 14908, loss1 : 1.420282, loss2 : 2.171054
train_step : 14909, loss1 : 1.860331, loss2 : 2.064019
train_step : 14910, loss1 : 1.953936, loss2 : 1.373418
train_step : 14911, loss1 : 1.695140, loss2 : 1.259815
train_step : 14912, loss1 : 1.394474, loss2 : 0.945439
train_step : 14913, loss1 : 1.412696, loss2 : 1.580006
train_step : 14914, loss1 : 2.844331, loss2 : 1.887237
train_step : 14915, loss1 : 2.831483, loss2 : 1.526059
train_step : 14916, loss1 : 1.448589, loss2 : 1.881011
train_step : 14917, loss1 : 0.938235, loss2 : 1.436197
train_step : 14918, loss1 : 1.188952, loss2 : 1.527858
train_step : 14919, loss1 : 1.985834, loss2 : 1.874567
train_step : 14920, loss1 : 1.754355, loss2 : 1.440660
train_step : 14921, loss1 : 1.215246, loss2 : 1.526961
train_step : 14922, loss1 : 1.148855, loss2 : 0.937829
train_step : 14923, loss1 : 1.473057, loss2 : 1.878881
train_step : 14924, loss1 : 1.591600, loss2 : 1.885794
train_step : 14925, loss1 : 1.490865, loss2 : 1.216333
train_step : 14926, loss1 : 1.710986, loss2 : 1.401622
train_step : 14927, loss1 : 2.276709, loss2 : 1.934468
train_step : 14928, loss1 : 1.235173, loss2 : 1.435040
train_step : 14929, loss1 : 1.146288, loss2 : 1.430148
train_step : 14930, loss1 : 1.199701, loss2 : 1.286128
train_step : 14931, loss1 : 1.549870, loss2 : 1.212572
train_step : 14932, loss1 : 0.988164, loss2 : 1.447398
train_step : 14933, loss1 : 1.522788, loss2 : 1.917347
train_step : 14934, loss1 : 1.282256, loss2 : 1.244650
train_step : 14935, loss1 : 1.233175, loss2 : 1.729814
train_step : 14936, loss1 : 1.495313, loss2 : 1.744514
train_step : 14937, loss1 : 1.999733, loss2 : 1.553090
train_step : 14938, loss1 : 1.962602, loss2 : 0.771402
train_step : 14939, loss1 : 1.664451, loss2 : 1.061828
train_step : 14940, loss1 : 1.631977, loss2 : 0.684982
train_step : 14941, loss1 : 1.145352, loss2 : 1.548766
train_step : 14942, loss1 : 1.156820, loss2 : 1.317781
train_step : 14943, loss1 : 2.118826, loss2 : 1.583806
train_step : 14944, loss1 : 1.023496, loss2 : 1.384708
train_step : 14945, loss1 : 1.624623, loss2 : 1.596151
train_step : 14946, loss1 : 1.848095, loss2 : 2.039915
train_step : 14947, loss1 : 1.238785, loss2 : 1.162146
train_step : 14948, loss1 : 1.577045, loss2 : 1.749880
train_step : 14949, loss1 : 1.238226, loss2 : 1.122300
train_step : 14950, loss1 : 1.202946, loss2 : 0.922447
train_step : 14951, loss1 : 1.058583, loss2 : 2.331436
train_step : 14952, loss1 : 0.833888, loss2 : 1.078943
train_step : 14953, loss1 : 0.769316, loss2 : 1.286469
train_step : 14954, loss1 : 2.704138, loss2 : 2.969482
train_step : 14955, loss1 : 1.596921, loss2 : 2.371258
train_step : 14956, loss1 : 2.145084, loss2 : 2.295809
train_step : 14957, loss1 : 3.255729, loss2 : 2.557605
train_step : 14958, loss1 : 1.511011, loss2 : 1.486828
train_step : 14959, loss1 : 1.080965, loss2 : 1.773954
train_step : 14960, loss1 : 0.709595, loss2 : 1.389890
train_step : 14961, loss1 : 0.981353, loss2 : 1.047584
train_step : 14962, loss1 : 1.463355, loss2 : 0.638044
train_step : 14963, loss1 : 1.423301, loss2 : 1.256233
train_step : 14964, loss1 : 1.270054, loss2 : 0.745651
train_step : 14965, loss1 : 1.026971, loss2 : 0.760713
train_step : 14966, loss1 : 0.457658, loss2 : 1.226929
train_step : 14967, loss1 : 1.181054, loss2 : 1.717778
train_step : 14968, loss1 : 1.162210, loss2 : 0.835613
train_step : 14969, loss1 : 1.192558, loss2 : 1.065890
train_step : 14970, loss1 : 0.771417, loss2 : 0.902329
train_step : 14971, loss1 : 0.701505, loss2 : 1.423181
train_step : 14972, loss1 : 1.040352, loss2 : 0.428062
train_step : 14973, loss1 : 1.056250, loss2 : 1.158072
train_step : 14974, loss1 : 1.045289, loss2 : 1.371056
train_step : 14975, loss1 : 0.941336, loss2 : 1.695701
train_step : 14976, loss1 : 2.023309, loss2 : 2.138498
train_step : 14977, loss1 : 1.959646, loss2 : 1.518393
train_step : 14978, loss1 : 1.650678, loss2 : 1.389062
train_step : 14979, loss1 : 1.870831, loss2 : 1.257221
train_step : 14980, loss1 : 1.417630, loss2 : 1.026862
train_step : 14981, loss1 : 0.907679, loss2 : 0.956128
train_step : 14982, loss1 : 1.556869, loss2 : 0.907524
train_step : 14983, loss1 : 0.627064, loss2 : 0.676835
train_step : 14984, loss1 : 1.078977, loss2 : 0.586802
train_step : 14985, loss1 : 1.784357, loss2 : 1.361367
train_step : 14986, loss1 : 1.212299, loss2 : 1.339822
train_step : 14987, loss1 : 1.819061, loss2 : 1.193085
train_step : 14988, loss1 : 2.309573, loss2 : 1.933781
train_step : 14989, loss1 : 1.726036, loss2 : 2.240305
train_step : 14990, loss1 : 2.005066, loss2 : 1.722545
train_step : 14991, loss1 : 1.646126, loss2 : 0.731288
train_step : 14992, loss1 : 1.597810, loss2 : 1.717651
train_step : 14993, loss1 : 1.191321, loss2 : 1.444177
train_step : 14994, loss1 : 1.257502, loss2 : 0.632595
train_step : 14995, loss1 : 1.228590, loss2 : 0.850431
train_step : 14996, loss1 : 1.450221, loss2 : 1.464952
train_step : 14997, loss1 : 1.090569, loss2 : 1.790563
train_step : 14998, loss1 : 0.812716, loss2 : 1.368425
train_step : 14999, loss1 : 1.016414, loss2 : 0.976802
train_step : 15000, loss1 : 0.864729, loss2 : 0.757416
train_step : 15001, loss1 : 1.023431, loss2 : 1.290562
train_step : 15002, loss1 : 0.647435, loss2 : 0.715882
train_step : 15003, loss1 : 1.183836, loss2 : 1.232873
train_step : 15004, loss1 : 1.152820, loss2 : 1.204054
train_step : 15005, loss1 : 1.481692, loss2 : 2.475614
train_step : 15006, loss1 : 2.128379, loss2 : 1.287685
train_step : 15007, loss1 : 0.938972, loss2 : 1.442179
train_step : 15008, loss1 : 2.008385, loss2 : 0.968706
train_step : 15009, loss1 : 0.861141, loss2 : 2.035759
train_step : 15010, loss1 : 1.076596, loss2 : 0.786757
train_step : 15011, loss1 : 0.595179, loss2 : 1.997049
train_step : 15012, loss1 : 1.057264, loss2 : 1.410818
train_step : 15013, loss1 : 1.830256, loss2 : 1.693249
train_step : 15014, loss1 : 1.670931, loss2 : 1.116141
train_step : 15015, loss1 : 1.308042, loss2 : 2.277513
train_step : 15016, loss1 : 2.295205, loss2 : 1.452241
train_step : 15017, loss1 : 0.902074, loss2 : 3.208723
train_step : 15018, loss1 : 2.072564, loss2 : 2.628293
train_step : 15019, loss1 : 1.894268, loss2 : 1.416729
train_step : 15020, loss1 : 0.991108, loss2 : 0.678462
train_step : 15021, loss1 : 1.114642, loss2 : 0.407650
train_step : 15022, loss1 : 0.869360, loss2 : 0.828316
train_step : 15023, loss1 : 1.681162, loss2 : 1.776979
train_step : 15024, loss1 : 2.682370, loss2 : 1.934535
train_step : 15025, loss1 : 2.465818, loss2 : 1.868940
train_step : 15026, loss1 : 3.147346, loss2 : 2.446145
train_step : 15027, loss1 : 2.743972, loss2 : 2.361603
train_step : 15028, loss1 : 2.426609, loss2 : 4.127782
train_step : 15029, loss1 : 4.609458, loss2 : 1.636732
train_step : 15030, loss1 : 2.536188, loss2 : 2.992625
train_step : 15031, loss1 : 2.191284, loss2 : 2.776454
train_step : 15032, loss1 : 2.014541, loss2 : 3.010301
train_step : 15033, loss1 : 1.983878, loss2 : 1.511022
train_step : 15034, loss1 : 1.713113, loss2 : 1.563168
train_step : 15035, loss1 : 1.363658, loss2 : 1.592948
train_step : 15036, loss1 : 0.572998, loss2 : 1.692339
train_step : 15037, loss1 : 0.596009, loss2 : 0.690641
train_step : 15038, loss1 : 1.190334, loss2 : 2.542322
train_step : 15039, loss1 : 1.371868, loss2 : 2.396822
train_step : 15040, loss1 : 2.515611, loss2 : 1.633171
train_step : 15041, loss1 : 2.690049, loss2 : 1.872129
train_step : 15042, loss1 : 1.071844, loss2 : 1.393293
train_step : 15043, loss1 : 0.844129, loss2 : 0.622861
train_step : 15044, loss1 : 0.554167, loss2 : 0.895946
train_step : 15045, loss1 : 0.709973, loss2 : 1.097700
train_step : 15046, loss1 : 0.734943, loss2 : 1.048380
train_step : 15047, loss1 : 1.020819, loss2 : 0.738385
train_step : 15048, loss1 : 0.817868, loss2 : 1.505289
train_step : 15049, loss1 : 0.823030, loss2 : 0.629149
train_step : 15050, loss1 : 0.663837, loss2 : 1.317006
train_step : 15051, loss1 : 1.511988, loss2 : 0.846237
train_step : 15052, loss1 : 1.599342, loss2 : 1.269724
train_step : 15053, loss1 : 1.463942, loss2 : 1.007365
train_step : 15054, loss1 : 1.139509, loss2 : 1.266607
train_step : 15055, loss1 : 0.982189, loss2 : 0.559072
train_step : 15056, loss1 : 0.831955, loss2 : 0.908307
train_step : 15057, loss1 : 0.716849, loss2 : 1.049580
train_step : 15058, loss1 : 1.456559, loss2 : 1.290063
train_step : 15059, loss1 : 1.083695, loss2 : 1.419362
train_step : 15060, loss1 : 0.840383, loss2 : 2.613276
train_step : 15061, loss1 : 1.418003, loss2 : 1.664327
train_step : 15062, loss1 : 0.798488, loss2 : 0.830320
train_step : 15063, loss1 : 1.178620, loss2 : 1.597264
train_step : 15064, loss1 : 1.116195, loss2 : 1.019813
train_step : 15065, loss1 : 1.009321, loss2 : 1.303972
train_step : 15066, loss1 : 0.882404, loss2 : 1.245432
train_step : 15067, loss1 : 1.074333, loss2 : 0.812922
train_step : 15068, loss1 : 1.439982, loss2 : 0.975489
train_step : 15069, loss1 : 0.827552, loss2 : 1.302770
train_step : 15070, loss1 : 0.749621, loss2 : 0.567701
train_step : 15071, loss1 : 3.478354, loss2 : 1.435440
train_step : 15072, loss1 : 1.150960, loss2 : 0.786044
train_step : 15073, loss1 : 1.477653, loss2 : 1.008947
train_step : 15074, loss1 : 1.145833, loss2 : 1.339114
train_step : 15075, loss1 : 2.017668, loss2 : 1.913654
train_step : 15076, loss1 : 1.495416, loss2 : 2.020391
train_step : 15077, loss1 : 1.505149, loss2 : 1.565347
train_step : 15078, loss1 : 1.840180, loss2 : 2.249086
train_step : 15079, loss1 : 1.870604, loss2 : 1.403281
train_step : 15080, loss1 : 1.478054, loss2 : 1.186588
train_step : 15081, loss1 : 1.559846, loss2 : 1.345865
train_step : 15082, loss1 : 3.071941, loss2 : 1.627578
train_step : 15083, loss1 : 0.936919, loss2 : 1.600303
train_step : 15084, loss1 : 1.334270, loss2 : 1.773268
train_step : 15085, loss1 : 1.490713, loss2 : 1.345422
train_step : 15086, loss1 : 1.257491, loss2 : 1.287284
train_step : 15087, loss1 : 1.425886, loss2 : 1.092186
train_step : 15088, loss1 : 1.170806, loss2 : 0.739767
train_step : 15089, loss1 : 1.850870, loss2 : 1.298170
train_step : 15090, loss1 : 1.592694, loss2 : 1.351001
train_step : 15091, loss1 : 1.148286, loss2 : 0.752507
train_step : 15092, loss1 : 0.944532, loss2 : 0.973854
train_step : 15093, loss1 : 1.345101, loss2 : 1.134856
train_step : 15094, loss1 : 1.172806, loss2 : 2.267277
train_step : 15095, loss1 : 0.799046, loss2 : 1.624177
train_step : 15096, loss1 : 1.164417, loss2 : 0.672746
train_step : 15097, loss1 : 1.221766, loss2 : 1.473342
train_step : 15098, loss1 : 2.351922, loss2 : 1.493603
train_step : 15099, loss1 : 1.642554, loss2 : 2.553425
train_step : 15100, loss1 : 2.122088, loss2 : 1.694204
train_step : 15101, loss1 : 2.239180, loss2 : 1.516340
train_step : 15102, loss1 : 1.751710, loss2 : 1.883095
train_step : 15103, loss1 : 0.921597, loss2 : 1.351449
train_step : 15104, loss1 : 1.659404, loss2 : 1.817627
train_step : 15105, loss1 : 2.404836, loss2 : 1.299623
train_step : 15106, loss1 : 1.732493, loss2 : 2.715646
train_step : 15107, loss1 : 2.244427, loss2 : 1.235462
train_step : 15108, loss1 : 1.275631, loss2 : 1.370832
train_step : 15109, loss1 : 1.200474, loss2 : 1.426589
train_step : 15110, loss1 : 1.361961, loss2 : 1.819695
train_step : 15111, loss1 : 0.614321, loss2 : 0.878190
train_step : 15112, loss1 : 1.495293, loss2 : 1.572062
train_step : 15113, loss1 : 1.896294, loss2 : 1.541450
train_step : 15114, loss1 : 1.178216, loss2 : 0.993678
train_step : 15115, loss1 : 1.712443, loss2 : 0.837818
train_step : 15116, loss1 : 1.274627, loss2 : 2.262481
train_step : 15117, loss1 : 1.691804, loss2 : 1.270563
train_step : 15118, loss1 : 1.763385, loss2 : 3.091640
train_step : 15119, loss1 : 2.262165, loss2 : 3.250142
train_step : 15120, loss1 : 1.394855, loss2 : 1.688945
train_step : 15121, loss1 : 2.573660, loss2 : 0.990546
train_step : 15122, loss1 : 1.842862, loss2 : 1.084143
train_step : 15123, loss1 : 0.968678, loss2 : 1.080129
train_step : 15124, loss1 : 1.193060, loss2 : 0.886177
train_step : 15125, loss1 : 1.422444, loss2 : 1.875006
train_step : 15126, loss1 : 0.514272, loss2 : 1.193727
train_step : 15127, loss1 : 1.376968, loss2 : 1.204516
train_step : 15128, loss1 : 0.868643, loss2 : 0.524506
train_step : 15129, loss1 : 0.870067, loss2 : 1.552588
train_step : 15130, loss1 : 0.820088, loss2 : 1.365051
train_step : 15131, loss1 : 0.801496, loss2 : 1.063240
train_step : 15132, loss1 : 0.694648, loss2 : 0.828796
train_step : 15133, loss1 : 0.692500, loss2 : 1.210430
train_step : 15134, loss1 : 1.522030, loss2 : 1.778047
train_step : 15135, loss1 : 2.197366, loss2 : 1.141504
train_step : 15136, loss1 : 1.090649, loss2 : 0.925290
train_step : 15137, loss1 : 1.335310, loss2 : 1.402309
train_step : 15138, loss1 : 1.115659, loss2 : 1.345680
train_step : 15139, loss1 : 1.158063, loss2 : 1.753909
train_step : 15140, loss1 : 1.308555, loss2 : 1.614026
train_step : 15141, loss1 : 1.454614, loss2 : 2.327922
train_step : 15142, loss1 : 0.621122, loss2 : 0.724117
train_step : 15143, loss1 : 1.676545, loss2 : 1.135622
train_step : 15144, loss1 : 1.557325, loss2 : 1.892834
train_step : 15145, loss1 : 1.486071, loss2 : 1.066858
train_step : 15146, loss1 : 1.501692, loss2 : 1.189911
train_step : 15147, loss1 : 2.322276, loss2 : 1.795825
train_step : 15148, loss1 : 0.997505, loss2 : 1.606585
train_step : 15149, loss1 : 0.677496, loss2 : 1.583475
train_step : 15150, loss1 : 1.026468, loss2 : 1.941222
train_step : 15151, loss1 : 2.230975, loss2 : 1.164441
train_step : 15152, loss1 : 1.743379, loss2 : 2.238366
train_step : 15153, loss1 : 0.822824, loss2 : 1.012400
train_step : 15154, loss1 : 0.626021, loss2 : 1.077154
train_step : 15155, loss1 : 1.366628, loss2 : 1.031699
train_step : 15156, loss1 : 1.163432, loss2 : 1.236547
train_step : 15157, loss1 : 0.746482, loss2 : 1.443524
train_step : 15158, loss1 : 0.749599, loss2 : 0.767180
train_step : 15159, loss1 : 1.633710, loss2 : 1.060109
train_step : 15160, loss1 : 1.913579, loss2 : 1.875561
train_step : 15161, loss1 : 1.093989, loss2 : 2.266136
train_step : 15162, loss1 : 1.236585, loss2 : 1.527819
train_step : 15163, loss1 : 1.366612, loss2 : 1.108667
train_step : 15164, loss1 : 3.715188, loss2 : 1.025224
train_step : 15165, loss1 : 1.215241, loss2 : 1.055146
train_step : 15166, loss1 : 1.051974, loss2 : 0.811673
train_step : 15167, loss1 : 0.780204, loss2 : 2.600209
train_step : 15168, loss1 : 1.408457, loss2 : 1.066521
train_step : 15169, loss1 : 1.182674, loss2 : 1.420964
train_step : 15170, loss1 : 0.675534, loss2 : 1.432109
train_step : 15171, loss1 : 1.532533, loss2 : 1.476457
train_step : 15172, loss1 : 1.796218, loss2 : 1.498473
train_step : 15173, loss1 : 1.144487, loss2 : 1.366119
train_step : 15174, loss1 : 1.753275, loss2 : 1.659469
train_step : 15175, loss1 : 1.392781, loss2 : 0.846466
train_step : 15176, loss1 : 1.927388, loss2 : 1.545665
train_step : 15177, loss1 : 1.847821, loss2 : 0.761407
train_step : 15178, loss1 : 0.991909, loss2 : 0.571612
train_step : 15179, loss1 : 1.097782, loss2 : 1.025030
train_step : 15180, loss1 : 0.971806, loss2 : 1.633334
train_step : 15181, loss1 : 1.084385, loss2 : 0.725971
train_step : 15182, loss1 : 1.332505, loss2 : 1.323649
train_step : 15183, loss1 : 1.425388, loss2 : 1.308327
train_step : 15184, loss1 : 0.887571, loss2 : 1.098051
train_step : 15185, loss1 : 1.050532, loss2 : 1.103655
train_step : 15186, loss1 : 1.248157, loss2 : 2.440394
train_step : 15187, loss1 : 1.306246, loss2 : 1.275924
train_step : 15188, loss1 : 1.537320, loss2 : 1.903283
train_step : 15189, loss1 : 1.177518, loss2 : 1.047618
train_step : 15190, loss1 : 1.329964, loss2 : 1.292011
train_step : 15191, loss1 : 0.992609, loss2 : 0.694832
train_step : 15192, loss1 : 1.100979, loss2 : 0.862700
train_step : 15193, loss1 : 1.788328, loss2 : 1.345394
train_step : 15194, loss1 : 0.965679, loss2 : 1.398601
train_step : 15195, loss1 : 2.117989, loss2 : 1.342017
train_step : 15196, loss1 : 1.073692, loss2 : 0.723784
train_step : 15197, loss1 : 1.667619, loss2 : 1.117447
train_step : 15198, loss1 : 0.898438, loss2 : 1.680430
train_step : 15199, loss1 : 1.581694, loss2 : 1.366982
train_step : 15200, loss1 : 1.212373, loss2 : 1.652281
train_step : 15201, loss1 : 2.401763, loss2 : 2.870255
train_step : 15202, loss1 : 2.067517, loss2 : 1.948918
train_step : 15203, loss1 : 1.162859, loss2 : 1.512668
train_step : 15204, loss1 : 1.198606, loss2 : 1.539922
train_step : 15205, loss1 : 1.061369, loss2 : 0.873460
train_step : 15206, loss1 : 0.812008, loss2 : 1.681766
train_step : 15207, loss1 : 0.621381, loss2 : 2.225165
train_step : 15208, loss1 : 0.904262, loss2 : 0.883762
train_step : 15209, loss1 : 2.185046, loss2 : 1.341416
train_step : 15210, loss1 : 1.673595, loss2 : 0.994382
train_step : 15211, loss1 : 0.825631, loss2 : 0.940889
train_step : 15212, loss1 : 1.913405, loss2 : 0.476896
train_step : 15213, loss1 : 0.613770, loss2 : 1.380540
train_step : 15214, loss1 : 0.852027, loss2 : 1.739052
train_step : 15215, loss1 : 0.973562, loss2 : 1.358010
train_step : 15216, loss1 : 1.473632, loss2 : 0.900865
train_step : 15217, loss1 : 0.759849, loss2 : 1.323674
train_step : 15218, loss1 : 0.892597, loss2 : 1.240555
train_step : 15219, loss1 : 1.155767, loss2 : 1.298983
train_step : 15220, loss1 : 1.826721, loss2 : 1.267485
train_step : 15221, loss1 : 0.969979, loss2 : 0.978184
train_step : 15222, loss1 : 1.090340, loss2 : 1.296803
train_step : 15223, loss1 : 2.376507, loss2 : 1.811299
train_step : 15224, loss1 : 1.594155, loss2 : 1.601408
train_step : 15225, loss1 : 1.434600, loss2 : 1.978367
train_step : 15226, loss1 : 0.799349, loss2 : 0.732302
train_step : 15227, loss1 : 1.060503, loss2 : 0.412075
train_step : 15228, loss1 : 1.084874, loss2 : 0.790066
train_step : 15229, loss1 : 1.023832, loss2 : 1.913315
train_step : 15230, loss1 : 1.264392, loss2 : 0.952210
train_step : 15231, loss1 : 1.070346, loss2 : 0.924102
train_step : 15232, loss1 : 1.441691, loss2 : 2.127233
train_step : 15233, loss1 : 1.731223, loss2 : 0.874991
train_step : 15234, loss1 : 0.970278, loss2 : 0.908308
train_step : 15235, loss1 : 0.539740, loss2 : 1.297514
train_step : 15236, loss1 : 0.912769, loss2 : 1.109863
train_step : 15237, loss1 : 2.561688, loss2 : 1.061166
train_step : 15238, loss1 : 1.237084, loss2 : 0.803648
train_step : 15239, loss1 : 1.244233, loss2 : 1.674832
train_step : 15240, loss1 : 1.219849, loss2 : 1.611385
train_step : 15241, loss1 : 1.153322, loss2 : 1.507969
train_step : 15242, loss1 : 1.287113, loss2 : 0.966305
train_step : 15243, loss1 : 0.967771, loss2 : 0.670112
train_step : 15244, loss1 : 0.880761, loss2 : 2.230231
train_step : 15245, loss1 : 0.481096, loss2 : 0.842795
train_step : 15246, loss1 : 1.621285, loss2 : 1.492162
train_step : 15247, loss1 : 1.097633, loss2 : 0.991619
train_step : 15248, loss1 : 2.062485, loss2 : 1.237910
train_step : 15249, loss1 : 0.958577, loss2 : 2.180606
train_step : 15250, loss1 : 1.040254, loss2 : 2.367280
train_step : 15251, loss1 : 1.311615, loss2 : 1.950651
train_step : 15252, loss1 : 1.534101, loss2 : 1.802879
train_step : 15253, loss1 : 2.027092, loss2 : 1.778598
train_step : 15254, loss1 : 0.596334, loss2 : 0.865160
train_step : 15255, loss1 : 0.707202, loss2 : 1.671452
train_step : 15256, loss1 : 1.748050, loss2 : 1.132210
train_step : 15257, loss1 : 1.792593, loss2 : 1.562657
train_step : 15258, loss1 : 3.285782, loss2 : 2.332550
train_step : 15259, loss1 : 3.806919, loss2 : 3.382218
train_step : 15260, loss1 : 1.759669, loss2 : 3.584778
train_step : 15261, loss1 : 2.887393, loss2 : 2.580477
train_step : 15262, loss1 : 1.156091, loss2 : 1.547120
train_step : 15263, loss1 : 0.616802, loss2 : 0.872575
train_step : 15264, loss1 : 1.018906, loss2 : 1.360713
train_step : 15265, loss1 : 2.341476, loss2 : 2.502477
train_step : 15266, loss1 : 2.493041, loss2 : 2.463504
train_step : 15267, loss1 : 1.006142, loss2 : 1.043415
train_step : 15268, loss1 : 1.001387, loss2 : 1.131777
train_step : 15269, loss1 : 1.900371, loss2 : 1.289585
train_step : 15270, loss1 : 1.217900, loss2 : 0.932894
train_step : 15271, loss1 : 1.311425, loss2 : 0.819106
train_step : 15272, loss1 : 0.790112, loss2 : 1.193458
train_step : 15273, loss1 : 1.953052, loss2 : 2.119253
train_step : 15274, loss1 : 2.589565, loss2 : 1.968596
train_step : 15275, loss1 : 2.776286, loss2 : 2.538038
train_step : 15276, loss1 : 4.625066, loss2 : 4.525681
train_step : 15277, loss1 : 5.148487, loss2 : 4.739407
train_step : 15278, loss1 : 4.940231, loss2 : 3.935192
train_step : 15279, loss1 : 2.352027, loss2 : 3.510244
train_step : 15280, loss1 : 2.689297, loss2 : 2.740682
train_step : 15281, loss1 : 3.102738, loss2 : 2.104142
train_step : 15282, loss1 : 3.449702, loss2 : 2.953914
train_step : 15283, loss1 : 2.577642, loss2 : 2.834074
train_step : 15284, loss1 : 3.963499, loss2 : 3.379587
train_step : 15285, loss1 : 2.509202, loss2 : 3.543660
train_step : 15286, loss1 : 3.527664, loss2 : 3.011032
train_step : 15287, loss1 : 3.681039, loss2 : 2.169499
train_step : 15288, loss1 : 2.409324, loss2 : 2.058883
train_step : 15289, loss1 : 2.225592, loss2 : 2.208611
train_step : 15290, loss1 : 2.339417, loss2 : 1.707718
train_step : 15291, loss1 : 1.302845, loss2 : 1.024719
train_step : 15292, loss1 : 1.217042, loss2 : 1.431454
train_step : 15293, loss1 : 1.103436, loss2 : 1.512983
train_step : 15294, loss1 : 1.131680, loss2 : 2.175397
train_step : 15295, loss1 : 1.767261, loss2 : 2.000929
train_step : 15296, loss1 : 1.459242, loss2 : 1.318619
train_step : 15297, loss1 : 1.041038, loss2 : 0.740693
train_step : 15298, loss1 : 1.124371, loss2 : 0.824636
train_step : 15299, loss1 : 0.712729, loss2 : 2.074071
train_step : 15300, loss1 : 1.777924, loss2 : 3.111749
train_step : 15301, loss1 : 2.150045, loss2 : 3.911096
train_step : 15302, loss1 : 2.765589, loss2 : 2.240251
train_step : 15303, loss1 : 1.673002, loss2 : 1.928528
train_step : 15304, loss1 : 1.706596, loss2 : 1.280661
train_step : 15305, loss1 : 1.881092, loss2 : 0.791799
train_step : 15306, loss1 : 0.707297, loss2 : 2.123868
train_step : 15307, loss1 : 1.216798, loss2 : 0.783581
train_step : 15308, loss1 : 1.121903, loss2 : 0.799668
train_step : 15309, loss1 : 0.969386, loss2 : 0.741986
train_step : 15310, loss1 : 1.439588, loss2 : 1.215650
train_step : 15311, loss1 : 1.411324, loss2 : 1.260900
train_step : 15312, loss1 : 1.049980, loss2 : 0.850348
train_step : 15313, loss1 : 0.638826, loss2 : 1.710432
train_step : 15314, loss1 : 1.193742, loss2 : 1.018893
train_step : 15315, loss1 : 1.476559, loss2 : 1.263310
train_step : 15316, loss1 : 1.352558, loss2 : 1.193605
train_step : 15317, loss1 : 1.379416, loss2 : 1.647874
train_step : 15318, loss1 : 0.915596, loss2 : 1.318186
train_step : 15319, loss1 : 2.527801, loss2 : 1.082670
train_step : 15320, loss1 : 1.830931, loss2 : 2.492437
train_step : 15321, loss1 : 1.125261, loss2 : 3.212335
train_step : 15322, loss1 : 1.367148, loss2 : 1.461467
train_step : 15323, loss1 : 1.591894, loss2 : 1.314733
train_step : 15324, loss1 : 1.586533, loss2 : 0.922767
train_step : 15325, loss1 : 1.111524, loss2 : 1.440053
train_step : 15326, loss1 : 1.455605, loss2 : 0.843662
train_step : 15327, loss1 : 1.135969, loss2 : 1.510348
train_step : 15328, loss1 : 0.832029, loss2 : 1.050848
train_step : 15329, loss1 : 1.183534, loss2 : 1.164304
train_step : 15330, loss1 : 0.772367, loss2 : 1.359702
train_step : 15331, loss1 : 0.940837, loss2 : 1.090506
train_step : 15332, loss1 : 0.893882, loss2 : 0.448740
train_step : 15333, loss1 : 0.861284, loss2 : 1.346869
train_step : 15334, loss1 : 1.232004, loss2 : 2.018886
train_step : 15335, loss1 : 1.366556, loss2 : 0.762833
train_step : 15336, loss1 : 1.217449, loss2 : 1.096640
train_step : 15337, loss1 : 0.780045, loss2 : 1.091738
train_step : 15338, loss1 : 1.000215, loss2 : 1.979879
train_step : 15339, loss1 : 2.138780, loss2 : 0.432084
train_step : 15340, loss1 : 1.492198, loss2 : 1.195521
train_step : 15341, loss1 : 0.782018, loss2 : 1.871395
train_step : 15342, loss1 : 1.598318, loss2 : 1.457046
train_step : 15343, loss1 : 1.013551, loss2 : 1.036098
train_step : 15344, loss1 : 1.376148, loss2 : 1.211367
train_step : 15345, loss1 : 0.815641, loss2 : 0.764584
train_step : 15346, loss1 : 0.901379, loss2 : 0.767835
train_step : 15347, loss1 : 1.864109, loss2 : 0.990766
train_step : 15348, loss1 : 1.175955, loss2 : 1.050839
train_step : 15349, loss1 : 0.927449, loss2 : 0.899968
train_step : 15350, loss1 : 1.289663, loss2 : 0.916694
train_step : 15351, loss1 : 1.249888, loss2 : 1.492412
train_step : 15352, loss1 : 1.028527, loss2 : 1.151918
train_step : 15353, loss1 : 0.814732, loss2 : 0.725418
train_step : 15354, loss1 : 0.699021, loss2 : 2.192767
train_step : 15355, loss1 : 1.180529, loss2 : 1.117057
train_step : 15356, loss1 : 1.172760, loss2 : 1.032461
train_step : 15357, loss1 : 1.407296, loss2 : 1.028651
train_step : 15358, loss1 : 1.300685, loss2 : 1.408966
train_step : 15359, loss1 : 1.380784, loss2 : 1.059646
train_step : 15360, loss1 : 1.991452, loss2 : 2.096227
train_step : 15361, loss1 : 3.345016, loss2 : 1.246172
train_step : 15362, loss1 : 1.128504, loss2 : 3.072231
train_step : 15363, loss1 : 1.271071, loss2 : 1.773790
train_step : 15364, loss1 : 1.777328, loss2 : 1.257701
train_step : 15365, loss1 : 0.966076, loss2 : 1.207942
train_step : 15366, loss1 : 2.584363, loss2 : 1.737998
train_step : 15367, loss1 : 2.135902, loss2 : 2.254803
train_step : 15368, loss1 : 2.160640, loss2 : 1.749757
train_step : 15369, loss1 : 1.533689, loss2 : 1.190602
train_step : 15370, loss1 : 1.400937, loss2 : 0.712824
train_step : 15371, loss1 : 0.719507, loss2 : 1.013835
train_step : 15372, loss1 : 0.470031, loss2 : 1.932163
train_step : 15373, loss1 : 1.626997, loss2 : 0.621272
train_step : 15374, loss1 : 2.268125, loss2 : 0.805471
train_step : 15375, loss1 : 1.244792, loss2 : 1.014004
train_step : 15376, loss1 : 1.072129, loss2 : 0.804884
train_step : 15377, loss1 : 0.774117, loss2 : 1.463907
train_step : 15378, loss1 : 1.270497, loss2 : 1.217711
train_step : 15379, loss1 : 1.321791, loss2 : 1.291831
train_step : 15380, loss1 : 1.388855, loss2 : 0.776832
train_step : 15381, loss1 : 1.036137, loss2 : 1.493711
train_step : 15382, loss1 : 0.846637, loss2 : 1.490102
train_step : 15383, loss1 : 1.376007, loss2 : 1.169440
train_step : 15384, loss1 : 1.011343, loss2 : 1.282008
train_step : 15385, loss1 : 1.165181, loss2 : 0.759967
train_step : 15386, loss1 : 1.084903, loss2 : 1.066555
train_step : 15387, loss1 : 1.500059, loss2 : 1.020299
train_step : 15388, loss1 : 0.833825, loss2 : 0.997363
train_step : 15389, loss1 : 1.215183, loss2 : 0.900734
train_step : 15390, loss1 : 1.190050, loss2 : 1.315294
train_step : 15391, loss1 : 2.329090, loss2 : 2.046584
train_step : 15392, loss1 : 2.290413, loss2 : 1.675625
train_step : 15393, loss1 : 1.188338, loss2 : 1.556520
train_step : 15394, loss1 : 1.311432, loss2 : 1.521557
train_step : 15395, loss1 : 1.270524, loss2 : 1.474042
train_step : 15396, loss1 : 0.762045, loss2 : 0.983280
train_step : 15397, loss1 : 0.734397, loss2 : 1.434228
train_step : 15398, loss1 : 1.568409, loss2 : 1.941609
train_step : 15399, loss1 : 1.155003, loss2 : 0.777633
train_step : 15400, loss1 : 1.025581, loss2 : 1.536824
train_step : 15401, loss1 : 1.585796, loss2 : 1.724345
train_step : 15402, loss1 : 1.147808, loss2 : 1.423067
train_step : 15403, loss1 : 1.215540, loss2 : 0.880132
train_step : 15404, loss1 : 1.923452, loss2 : 1.340831
train_step : 15405, loss1 : 1.023160, loss2 : 1.633891
train_step : 15406, loss1 : 0.912096, loss2 : 0.615595
train_step : 15407, loss1 : 1.554423, loss2 : 1.135104
train_step : 15408, loss1 : 0.587666, loss2 : 1.547533
train_step : 15409, loss1 : 1.406718, loss2 : 0.369249
train_step : 15410, loss1 : 1.196571, loss2 : 1.139631
train_step : 15411, loss1 : 0.700151, loss2 : 0.464161
train_step : 15412, loss1 : 0.937545, loss2 : 1.233428
train_step : 15413, loss1 : 1.112490, loss2 : 1.521568
train_step : 15414, loss1 : 2.844864, loss2 : 2.006592
train_step : 15415, loss1 : 3.401923, loss2 : 2.323179
train_step : 15416, loss1 : 2.623701, loss2 : 3.233551
train_step : 15417, loss1 : 1.890391, loss2 : 2.039021
train_step : 15418, loss1 : 0.877538, loss2 : 1.277657
train_step : 15419, loss1 : 1.762121, loss2 : 0.711165
train_step : 15420, loss1 : 1.567336, loss2 : 0.963070
train_step : 15421, loss1 : 1.025028, loss2 : 0.948633
train_step : 15422, loss1 : 1.094988, loss2 : 1.154391
train_step : 15423, loss1 : 1.341848, loss2 : 0.787236
train_step : 15424, loss1 : 0.896758, loss2 : 0.993800
train_step : 15425, loss1 : 2.148219, loss2 : 1.251012
train_step : 15426, loss1 : 1.532099, loss2 : 1.490196
train_step : 15427, loss1 : 1.352885, loss2 : 1.867110
train_step : 15428, loss1 : 1.447725, loss2 : 1.467314
train_step : 15429, loss1 : 2.166765, loss2 : 2.147843
train_step : 15430, loss1 : 1.328039, loss2 : 1.120137
train_step : 15431, loss1 : 0.893266, loss2 : 1.294843
train_step : 15432, loss1 : 2.244276, loss2 : 1.861353
train_step : 15433, loss1 : 2.647778, loss2 : 2.468073
train_step : 15434, loss1 : 2.210537, loss2 : 1.192331
train_step : 15435, loss1 : 1.461809, loss2 : 4.159108
train_step : 15436, loss1 : 1.737121, loss2 : 2.161209
train_step : 15437, loss1 : 1.886041, loss2 : 2.490189
train_step : 15438, loss1 : 3.123599, loss2 : 2.330334
train_step : 15439, loss1 : 3.081721, loss2 : 2.906423
train_step : 15440, loss1 : 2.419038, loss2 : 2.274697
train_step : 15441, loss1 : 1.919040, loss2 : 2.079503
train_step : 15442, loss1 : 1.158800, loss2 : 1.195845
train_step : 15443, loss1 : 0.795909, loss2 : 1.198532
train_step : 15444, loss1 : 0.720622, loss2 : 1.245057
train_step : 15445, loss1 : 1.381163, loss2 : 1.017576
train_step : 15446, loss1 : 0.952683, loss2 : 0.950514
train_step : 15447, loss1 : 1.661620, loss2 : 0.757766
train_step : 15448, loss1 : 1.109023, loss2 : 1.315820
train_step : 15449, loss1 : 1.297961, loss2 : 1.367173
train_step : 15450, loss1 : 1.295465, loss2 : 1.079860
train_step : 15451, loss1 : 1.281663, loss2 : 1.580601
train_step : 15452, loss1 : 1.400360, loss2 : 2.024929
train_step : 15453, loss1 : 1.925926, loss2 : 1.339025
train_step : 15454, loss1 : 0.763843, loss2 : 1.208226
train_step : 15455, loss1 : 0.884841, loss2 : 1.309630
train_step : 15456, loss1 : 2.325203, loss2 : 1.291744
train_step : 15457, loss1 : 3.396773, loss2 : 2.153501
train_step : 15458, loss1 : 1.838167, loss2 : 1.430683
train_step : 15459, loss1 : 1.053495, loss2 : 1.800573
train_step : 15460, loss1 : 1.793525, loss2 : 1.478892
train_step : 15461, loss1 : 1.346253, loss2 : 1.034014
train_step : 15462, loss1 : 1.603525, loss2 : 1.742406
train_step : 15463, loss1 : 2.693286, loss2 : 1.560438
train_step : 15464, loss1 : 0.595006, loss2 : 1.685946
train_step : 15465, loss1 : 0.848331, loss2 : 1.178210
train_step : 15466, loss1 : 0.927066, loss2 : 1.296111
train_step : 15467, loss1 : 1.157996, loss2 : 1.247059
train_step : 15468, loss1 : 1.411299, loss2 : 1.952029
train_step : 15469, loss1 : 0.848163, loss2 : 1.737131
train_step : 15470, loss1 : 0.705963, loss2 : 1.157263
train_step : 15471, loss1 : 0.969083, loss2 : 1.325327
train_step : 15472, loss1 : 1.203946, loss2 : 1.216432
train_step : 15473, loss1 : 1.431963, loss2 : 1.652799
train_step : 15474, loss1 : 2.508465, loss2 : 1.868672
train_step : 15475, loss1 : 1.423015, loss2 : 1.429910
train_step : 15476, loss1 : 1.478720, loss2 : 1.480183
train_step : 15477, loss1 : 1.387876, loss2 : 1.873290
train_step : 15478, loss1 : 1.580931, loss2 : 1.590011
train_step : 15479, loss1 : 1.265408, loss2 : 1.058695
train_step : 15480, loss1 : 1.135926, loss2 : 0.691369
train_step : 15481, loss1 : 1.272745, loss2 : 0.730418
train_step : 15482, loss1 : 0.880236, loss2 : 0.858076
train_step : 15483, loss1 : 3.023301, loss2 : 1.035475
train_step : 15484, loss1 : 1.686240, loss2 : 0.867721
train_step : 15485, loss1 : 1.044072, loss2 : 1.902022
train_step : 15486, loss1 : 1.653208, loss2 : 1.339297
train_step : 15487, loss1 : 1.648095, loss2 : 1.133780
train_step : 15488, loss1 : 1.756711, loss2 : 0.532866
train_step : 15489, loss1 : 1.480544, loss2 : 0.785912
train_step : 15490, loss1 : 1.119562, loss2 : 0.924258
train_step : 15491, loss1 : 0.632435, loss2 : 0.948711
train_step : 15492, loss1 : 2.738470, loss2 : 0.394744
train_step : 15493, loss1 : 1.335571, loss2 : 0.699283
train_step : 15494, loss1 : 0.853005, loss2 : 1.206274
train_step : 15495, loss1 : 0.600835, loss2 : 0.974172
train_step : 15496, loss1 : 0.742738, loss2 : 1.390301
train_step : 15497, loss1 : 1.344504, loss2 : 0.854655
train_step : 15498, loss1 : 0.745372, loss2 : 0.997523
train_step : 15499, loss1 : 1.134140, loss2 : 0.664858
train_step : 15500, loss1 : 1.180346, loss2 : 1.223753
train_step : 15501, loss1 : 1.007222, loss2 : 1.786620
train_step : 15502, loss1 : 1.253040, loss2 : 0.919801
train_step : 15503, loss1 : 0.832158, loss2 : 1.169605
train_step : 15504, loss1 : 1.056316, loss2 : 2.191110
train_step : 15505, loss1 : 1.474914, loss2 : 1.330805
train_step : 15506, loss1 : 0.918173, loss2 : 0.871981
train_step : 15507, loss1 : 1.860831, loss2 : 0.789815
train_step : 15508, loss1 : 2.046834, loss2 : 1.941262
train_step : 15509, loss1 : 1.524345, loss2 : 1.309438
train_step : 15510, loss1 : 0.946629, loss2 : 1.324351
train_step : 15511, loss1 : 0.328581, loss2 : 1.247358
train_step : 15512, loss1 : 1.423458, loss2 : 1.378530
train_step : 15513, loss1 : 0.944137, loss2 : 1.408814
train_step : 15514, loss1 : 0.893550, loss2 : 1.581257
train_step : 15515, loss1 : 1.244561, loss2 : 1.339694
train_step : 15516, loss1 : 0.710909, loss2 : 1.503037
train_step : 15517, loss1 : 0.811500, loss2 : 1.210013
train_step : 15518, loss1 : 1.327025, loss2 : 1.221478
train_step : 15519, loss1 : 1.898543, loss2 : 1.135140
train_step : 15520, loss1 : 0.815790, loss2 : 1.307888
train_step : 15521, loss1 : 1.315506, loss2 : 0.915729
train_step : 15522, loss1 : 0.943242, loss2 : 1.206986
train_step : 15523, loss1 : 2.187890, loss2 : 2.836214
train_step : 15524, loss1 : 2.615767, loss2 : 2.596788
train_step : 15525, loss1 : 2.602308, loss2 : 3.314973
train_step : 15526, loss1 : 4.041861, loss2 : 2.260849
train_step : 15527, loss1 : 2.195608, loss2 : 2.550996
train_step : 15528, loss1 : 1.726846, loss2 : 0.951622
train_step : 15529, loss1 : 1.316583, loss2 : 1.144074
train_step : 15530, loss1 : 1.048234, loss2 : 1.146110
train_step : 15531, loss1 : 0.874998, loss2 : 0.999832
train_step : 15532, loss1 : 1.753794, loss2 : 1.758868
train_step : 15533, loss1 : 1.427582, loss2 : 1.820379
train_step : 15534, loss1 : 1.531851, loss2 : 1.687150
train_step : 15535, loss1 : 1.632809, loss2 : 1.936456
train_step : 15536, loss1 : 1.487073, loss2 : 1.365321
train_step : 15537, loss1 : 1.381667, loss2 : 1.071190
train_step : 15538, loss1 : 0.904401, loss2 : 1.103107
train_step : 15539, loss1 : 1.029864, loss2 : 0.942772
train_step : 15540, loss1 : 0.696871, loss2 : 1.002352
train_step : 15541, loss1 : 0.547660, loss2 : 0.949899
train_step : 15542, loss1 : 1.130738, loss2 : 0.991789
train_step : 15543, loss1 : 0.882481, loss2 : 0.760314
train_step : 15544, loss1 : 0.785030, loss2 : 0.797905
train_step : 15545, loss1 : 0.904173, loss2 : 0.973017
train_step : 15546, loss1 : 2.311059, loss2 : 1.115677
train_step : 15547, loss1 : 1.366292, loss2 : 1.522860
train_step : 15548, loss1 : 0.785213, loss2 : 0.953402
train_step : 15549, loss1 : 0.911098, loss2 : 0.687839
train_step : 15550, loss1 : 1.452865, loss2 : 1.164833
train_step : 15551, loss1 : 1.115294, loss2 : 1.053853
train_step : 15552, loss1 : 1.464693, loss2 : 1.375140
train_step : 15553, loss1 : 0.474025, loss2 : 0.600285
train_step : 15554, loss1 : 1.229481, loss2 : 1.614239
train_step : 15555, loss1 : 1.307777, loss2 : 1.232703
train_step : 15556, loss1 : 2.626518, loss2 : 0.912093
train_step : 15557, loss1 : 0.972374, loss2 : 3.266609
train_step : 15558, loss1 : 0.984912, loss2 : 0.994552
train_step : 15559, loss1 : 1.182093, loss2 : 1.582098
train_step : 15560, loss1 : 0.864731, loss2 : 1.322335
train_step : 15561, loss1 : 1.451537, loss2 : 1.843161
train_step : 15562, loss1 : 2.317888, loss2 : 1.531657
train_step : 15563, loss1 : 1.106077, loss2 : 2.045952
train_step : 15564, loss1 : 2.222451, loss2 : 1.211709
train_step : 15565, loss1 : 1.132249, loss2 : 1.747820
train_step : 15566, loss1 : 0.585304, loss2 : 0.609138
train_step : 15567, loss1 : 0.860519, loss2 : 1.044435
train_step : 15568, loss1 : 0.964963, loss2 : 0.921112
train_step : 15569, loss1 : 1.020899, loss2 : 1.410438
train_step : 15570, loss1 : 0.602976, loss2 : 1.549828
train_step : 15571, loss1 : 0.957814, loss2 : 1.136261
train_step : 15572, loss1 : 1.778635, loss2 : 0.717523
train_step : 15573, loss1 : 1.223647, loss2 : 0.823918
train_step : 15574, loss1 : 1.424888, loss2 : 0.897653
train_step : 15575, loss1 : 0.885620, loss2 : 1.077465
train_step : 15576, loss1 : 1.172909, loss2 : 1.061877
train_step : 15577, loss1 : 1.778984, loss2 : 0.718053
train_step : 15578, loss1 : 2.665754, loss2 : 1.136935
train_step : 15579, loss1 : 2.080330, loss2 : 1.922488
train_step : 15580, loss1 : 2.520119, loss2 : 3.114254
train_step : 15581, loss1 : 2.595802, loss2 : 3.106236
train_step : 15582, loss1 : 2.746345, loss2 : 2.309181
train_step : 15583, loss1 : 1.510236, loss2 : 2.147025
train_step : 15584, loss1 : 2.603091, loss2 : 2.402545
train_step : 15585, loss1 : 3.276114, loss2 : 2.368103
train_step : 15586, loss1 : 2.806292, loss2 : 2.889157
train_step : 15587, loss1 : 0.557984, loss2 : 0.926808
train_step : 15588, loss1 : 0.772734, loss2 : 2.565629
train_step : 15589, loss1 : 1.406488, loss2 : 1.123902
train_step : 15590, loss1 : 1.133464, loss2 : 1.050179
train_step : 15591, loss1 : 1.201095, loss2 : 0.929261
train_step : 15592, loss1 : 1.020111, loss2 : 0.501357
train_step : 15593, loss1 : 1.012510, loss2 : 1.487150
train_step : 15594, loss1 : 1.182235, loss2 : 1.504508
train_step : 15595, loss1 : 1.513247, loss2 : 1.773857
train_step : 15596, loss1 : 1.550507, loss2 : 1.601013
train_step : 15597, loss1 : 0.775703, loss2 : 1.401687
train_step : 15598, loss1 : 1.075775, loss2 : 1.977482
train_step : 15599, loss1 : 1.466796, loss2 : 1.069221
train_step : 15600, loss1 : 2.273681, loss2 : 1.242693
train_step : 15601, loss1 : 2.032218, loss2 : 2.054005
train_step : 15602, loss1 : 1.303301, loss2 : 2.018458
train_step : 15603, loss1 : 2.146785, loss2 : 1.578114
train_step : 15604, loss1 : 1.365613, loss2 : 1.581871
train_step : 15605, loss1 : 1.779056, loss2 : 1.876702
train_step : 15606, loss1 : 0.919812, loss2 : 1.800787
train_step : 15607, loss1 : 1.822796, loss2 : 1.189262
train_step : 15608, loss1 : 1.586788, loss2 : 1.802857
train_step : 15609, loss1 : 1.751937, loss2 : 0.906764
train_step : 15610, loss1 : 2.045202, loss2 : 2.046604
train_step : 15611, loss1 : 1.064318, loss2 : 2.819983
train_step : 15612, loss1 : 2.733765, loss2 : 3.374886
train_step : 15613, loss1 : 4.255350, loss2 : 3.439929
train_step : 15614, loss1 : 2.994098, loss2 : 2.842177
train_step : 15615, loss1 : 1.713686, loss2 : 2.309862
train_step : 15616, loss1 : 2.626632, loss2 : 1.725093
train_step : 15617, loss1 : 2.765611, loss2 : 2.988029
train_step : 15618, loss1 : 1.978510, loss2 : 2.981727
train_step : 15619, loss1 : 2.868663, loss2 : 1.771162
train_step : 15620, loss1 : 2.222054, loss2 : 2.370158
train_step : 15621, loss1 : 1.524384, loss2 : 1.390829
train_step : 15622, loss1 : 1.696340, loss2 : 1.376822
train_step : 15623, loss1 : 1.288383, loss2 : 4.572567
train_step : 15624, loss1 : 2.771510, loss2 : 2.741915
train_step : 15625, loss1 : 3.151706, loss2 : 1.831509
train_step : 15626, loss1 : 1.206362, loss2 : 1.812720
train_step : 15627, loss1 : 1.020823, loss2 : 1.596029
train_step : 15628, loss1 : 1.940245, loss2 : 1.389700
train_step : 15629, loss1 : 1.018054, loss2 : 0.905924
train_step : 15630, loss1 : 0.770851, loss2 : 0.529378
train_step : 15631, loss1 : 0.678785, loss2 : 0.877874
train_step : 15632, loss1 : 1.140242, loss2 : 1.178751
train_step : 15633, loss1 : 1.425417, loss2 : 0.712702
train_step : 15634, loss1 : 1.102713, loss2 : 0.671772
train_step : 15635, loss1 : 1.826912, loss2 : 1.462122
train_step : 15636, loss1 : 1.082462, loss2 : 1.158105
train_step : 15637, loss1 : 1.400462, loss2 : 0.692358
train_step : 15638, loss1 : 1.116044, loss2 : 1.042006
train_step : 15639, loss1 : 1.089473, loss2 : 0.907759
train_step : 15640, loss1 : 0.765026, loss2 : 1.026102
train_step : 15641, loss1 : 1.552481, loss2 : 1.802054
train_step : 15642, loss1 : 1.040625, loss2 : 1.035315
train_step : 15643, loss1 : 1.718954, loss2 : 1.469813
train_step : 15644, loss1 : 1.277027, loss2 : 1.582026
train_step : 15645, loss1 : 1.015728, loss2 : 1.131890
train_step : 15646, loss1 : 0.720824, loss2 : 0.867125
train_step : 15647, loss1 : 1.104246, loss2 : 0.548803
train_step : 15648, loss1 : 1.541977, loss2 : 1.440869
train_step : 15649, loss1 : 0.713724, loss2 : 0.658879
train_step : 15650, loss1 : 1.721904, loss2 : 1.302640
train_step : 15651, loss1 : 1.432750, loss2 : 1.173059
train_step : 15652, loss1 : 1.286478, loss2 : 1.219926
train_step : 15653, loss1 : 0.983041, loss2 : 1.152295
train_step : 15654, loss1 : 2.221872, loss2 : 1.664618
train_step : 15655, loss1 : 1.362396, loss2 : 1.088696
train_step : 15656, loss1 : 1.044537, loss2 : 1.407587
train_step : 15657, loss1 : 1.005093, loss2 : 0.778494
train_step : 15658, loss1 : 1.047348, loss2 : 1.473691
train_step : 15659, loss1 : 1.448922, loss2 : 1.012938
train_step : 15660, loss1 : 1.922594, loss2 : 1.215249
train_step : 15661, loss1 : 1.339533, loss2 : 0.754511
train_step : 15662, loss1 : 1.162527, loss2 : 0.984425
train_step : 15663, loss1 : 1.102853, loss2 : 1.260389
train_step : 15664, loss1 : 1.318188, loss2 : 1.055869
train_step : 15665, loss1 : 1.177992, loss2 : 1.222702
train_step : 15666, loss1 : 1.951042, loss2 : 1.712143
train_step : 15667, loss1 : 1.263577, loss2 : 1.112809
train_step : 15668, loss1 : 0.786812, loss2 : 1.654370
train_step : 15669, loss1 : 1.304852, loss2 : 1.026705
train_step : 15670, loss1 : 1.676039, loss2 : 2.262703
train_step : 15671, loss1 : 1.903650, loss2 : 0.607761
train_step : 15672, loss1 : 0.858877, loss2 : 2.292007
train_step : 15673, loss1 : 1.794037, loss2 : 1.257646
train_step : 15674, loss1 : 1.017366, loss2 : 1.447648
train_step : 15675, loss1 : 1.118829, loss2 : 1.207752
train_step : 15676, loss1 : 1.097485, loss2 : 0.879885
train_step : 15677, loss1 : 0.906584, loss2 : 0.986617
train_step : 15678, loss1 : 1.361536, loss2 : 1.353725
train_step : 15679, loss1 : 1.294336, loss2 : 2.411082
train_step : 15680, loss1 : 1.494902, loss2 : 1.618666
train_step : 15681, loss1 : 1.417884, loss2 : 1.747277
train_step : 15682, loss1 : 1.443784, loss2 : 1.621140
train_step : 15683, loss1 : 2.078976, loss2 : 1.589974
train_step : 15684, loss1 : 2.535826, loss2 : 2.100347
train_step : 15685, loss1 : 2.326238, loss2 : 2.081969
train_step : 15686, loss1 : 3.310865, loss2 : 2.354681
train_step : 15687, loss1 : 3.551486, loss2 : 3.215370
train_step : 15688, loss1 : 3.277816, loss2 : 2.450986
train_step : 15689, loss1 : 2.600519, loss2 : 2.305873
train_step : 15690, loss1 : 2.062600, loss2 : 1.305818
train_step : 15691, loss1 : 2.256303, loss2 : 2.674831
train_step : 15692, loss1 : 0.920139, loss2 : 1.321631
train_step : 15693, loss1 : 0.877610, loss2 : 1.403658
train_step : 15694, loss1 : 0.935666, loss2 : 1.181065
train_step : 15695, loss1 : 1.509861, loss2 : 1.949239
train_step : 15696, loss1 : 2.822723, loss2 : 3.524841
train_step : 15697, loss1 : 2.033941, loss2 : 2.329314
train_step : 15698, loss1 : 0.777886, loss2 : 0.675182
train_step : 15699, loss1 : 1.390224, loss2 : 1.312919
train_step : 15700, loss1 : 1.187366, loss2 : 1.551588
train_step : 15701, loss1 : 1.793538, loss2 : 0.949568
train_step : 15702, loss1 : 1.959027, loss2 : 1.778340
train_step : 15703, loss1 : 1.648262, loss2 : 0.876661
train_step : 15704, loss1 : 1.141276, loss2 : 0.921855
train_step : 15705, loss1 : 0.762290, loss2 : 1.697157
train_step : 15706, loss1 : 0.819194, loss2 : 0.686187
train_step : 15707, loss1 : 1.574904, loss2 : 0.981173
train_step : 15708, loss1 : 0.954174, loss2 : 1.104226
train_step : 15709, loss1 : 0.949606, loss2 : 0.996320
train_step : 15710, loss1 : 1.721650, loss2 : 1.285648
train_step : 15711, loss1 : 1.044049, loss2 : 0.690620
train_step : 15712, loss1 : 0.978743, loss2 : 1.118199
train_step : 15713, loss1 : 1.309271, loss2 : 1.990484
train_step : 15714, loss1 : 1.279218, loss2 : 1.721903
train_step : 15715, loss1 : 0.800197, loss2 : 0.996865
train_step : 15716, loss1 : 1.403712, loss2 : 0.641230
train_step : 15717, loss1 : 1.516728, loss2 : 0.878925
train_step : 15718, loss1 : 1.356798, loss2 : 1.189966
train_step : 15719, loss1 : 1.203727, loss2 : 1.530735
train_step : 15720, loss1 : 1.766654, loss2 : 2.842740
train_step : 15721, loss1 : 4.553373, loss2 : 2.681004
train_step : 15722, loss1 : 5.487840, loss2 : 5.370669
train_step : 15723, loss1 : 8.100468, loss2 : 6.001146
train_step : 15724, loss1 : 4.366166, loss2 : 2.902207
train_step : 15725, loss1 : 4.480594, loss2 : 3.721079
train_step : 15726, loss1 : 1.764864, loss2 : 3.244206
train_step : 15727, loss1 : 1.326359, loss2 : 2.431934
train_step : 15728, loss1 : 1.047115, loss2 : 0.738712
train_step : 15729, loss1 : 0.960798, loss2 : 1.354606
train_step : 15730, loss1 : 0.785050, loss2 : 1.014735
train_step : 15731, loss1 : 0.902750, loss2 : 1.244698
train_step : 15732, loss1 : 0.695341, loss2 : 1.029129
train_step : 15733, loss1 : 0.915500, loss2 : 0.874422
train_step : 15734, loss1 : 1.046426, loss2 : 2.107750
train_step : 15735, loss1 : 1.442178, loss2 : 1.748187
train_step : 15736, loss1 : 2.864736, loss2 : 1.482951
train_step : 15737, loss1 : 2.111564, loss2 : 3.075821
train_step : 15738, loss1 : 2.435227, loss2 : 0.959685
train_step : 15739, loss1 : 1.140894, loss2 : 1.269986
train_step : 15740, loss1 : 1.004928, loss2 : 1.171837
train_step : 15741, loss1 : 1.203727, loss2 : 0.891328
train_step : 15742, loss1 : 1.350781, loss2 : 1.353739
train_step : 15743, loss1 : 1.016283, loss2 : 1.223845
train_step : 15744, loss1 : 1.502190, loss2 : 1.364032
train_step : 15745, loss1 : 1.157199, loss2 : 1.277626
train_step : 15746, loss1 : 1.023072, loss2 : 0.904110
train_step : 15747, loss1 : 1.597433, loss2 : 1.633366
train_step : 15748, loss1 : 0.837346, loss2 : 1.409543
train_step : 15749, loss1 : 0.885167, loss2 : 1.241186
train_step : 15750, loss1 : 0.826628, loss2 : 0.975983
train_step : 15751, loss1 : 1.465510, loss2 : 1.201414
train_step : 15752, loss1 : 1.507885, loss2 : 0.737796
train_step : 15753, loss1 : 1.224115, loss2 : 0.893788
train_step : 15754, loss1 : 1.959397, loss2 : 0.939882
train_step : 15755, loss1 : 0.606509, loss2 : 0.484996
train_step : 15756, loss1 : 0.626077, loss2 : 1.248765
train_step : 15757, loss1 : 0.921605, loss2 : 1.873004
train_step : 15758, loss1 : 0.702863, loss2 : 0.908688
train_step : 15759, loss1 : 1.469460, loss2 : 1.365375
train_step : 15760, loss1 : 1.426029, loss2 : 1.645483
train_step : 15761, loss1 : 0.945987, loss2 : 2.073286
train_step : 15762, loss1 : 1.405666, loss2 : 1.337695
train_step : 15763, loss1 : 0.688514, loss2 : 1.003257
train_step : 15764, loss1 : 0.910749, loss2 : 1.546514
train_step : 15765, loss1 : 1.219805, loss2 : 1.203394
train_step : 15766, loss1 : 0.965810, loss2 : 0.880895
train_step : 15767, loss1 : 0.836272, loss2 : 0.887546
train_step : 15768, loss1 : 0.944159, loss2 : 1.484476
train_step : 15769, loss1 : 1.356547, loss2 : 1.163419
train_step : 15770, loss1 : 1.813179, loss2 : 0.951897
train_step : 15771, loss1 : 0.922557, loss2 : 1.625663
train_step : 15772, loss1 : 1.354621, loss2 : 1.134148
train_step : 15773, loss1 : 2.898438, loss2 : 1.375269
train_step : 15774, loss1 : 2.666991, loss2 : 1.639807
train_step : 15775, loss1 : 1.731046, loss2 : 1.511082
train_step : 15776, loss1 : 1.314509, loss2 : 2.982394
train_step : 15777, loss1 : 1.701615, loss2 : 2.516216
train_step : 15778, loss1 : 2.097745, loss2 : 1.440756
train_step : 15779, loss1 : 2.036633, loss2 : 2.244772
train_step : 15780, loss1 : 1.228781, loss2 : 2.192540
train_step : 15781, loss1 : 1.254003, loss2 : 2.026776
train_step : 15782, loss1 : 1.739791, loss2 : 1.321525
train_step : 15783, loss1 : 1.019700, loss2 : 0.975585
train_step : 15784, loss1 : 0.690878, loss2 : 0.728845
train_step : 15785, loss1 : 1.202247, loss2 : 0.664671
train_step : 15786, loss1 : 1.390292, loss2 : 1.346707
train_step : 15787, loss1 : 1.342200, loss2 : 2.279500
train_step : 15788, loss1 : 1.602877, loss2 : 1.306533
train_step : 15789, loss1 : 1.263481, loss2 : 1.180738
train_step : 15790, loss1 : 0.600508, loss2 : 1.076054
train_step : 15791, loss1 : 1.267282, loss2 : 1.152932
train_step : 15792, loss1 : 1.315214, loss2 : 0.867579
train_step : 15793, loss1 : 1.196112, loss2 : 0.841247
train_step : 15794, loss1 : 0.842454, loss2 : 1.174952
train_step : 15795, loss1 : 2.322270, loss2 : 0.993391
train_step : 15796, loss1 : 1.251950, loss2 : 1.978057
train_step : 15797, loss1 : 1.789151, loss2 : 0.996519
train_step : 15798, loss1 : 1.600211, loss2 : 0.743684
train_step : 15799, loss1 : 2.904145, loss2 : 1.280630
train_step : 15800, loss1 : 1.069079, loss2 : 0.944312
train_step : 15801, loss1 : 2.561397, loss2 : 1.841467
train_step : 15802, loss1 : 2.493198, loss2 : 1.631516
train_step : 15803, loss1 : 1.408500, loss2 : 1.907161
train_step : 15804, loss1 : 1.858551, loss2 : 1.623648
train_step : 15805, loss1 : 1.203614, loss2 : 2.978259
train_step : 15806, loss1 : 1.834386, loss2 : 2.002589
train_step : 15807, loss1 : 2.731055, loss2 : 1.358487
train_step : 15808, loss1 : 2.131111, loss2 : 3.426367
train_step : 15809, loss1 : 2.788135, loss2 : 4.599213
train_step : 15810, loss1 : 1.461708, loss2 : 3.142784
train_step : 15811, loss1 : 1.973355, loss2 : 1.691729
train_step : 15812, loss1 : 1.360773, loss2 : 1.601718
train_step : 15813, loss1 : 2.669596, loss2 : 1.952813
train_step : 15814, loss1 : 1.723945, loss2 : 2.113195
train_step : 15815, loss1 : 1.690351, loss2 : 2.161604
train_step : 15816, loss1 : 1.840112, loss2 : 2.747262
train_step : 15817, loss1 : 3.070339, loss2 : 2.458334
train_step : 15818, loss1 : 3.394186, loss2 : 2.536788
train_step : 15819, loss1 : 3.215667, loss2 : 3.576758
train_step : 15820, loss1 : 3.289579, loss2 : 3.498113
train_step : 15821, loss1 : 3.473300, loss2 : 2.793456
train_step : 15822, loss1 : 2.180775, loss2 : 1.618719
train_step : 15823, loss1 : 0.720989, loss2 : 1.025297
train_step : 15824, loss1 : 0.985588, loss2 : 0.890716
train_step : 15825, loss1 : 0.828737, loss2 : 1.356581
train_step : 15826, loss1 : 1.649962, loss2 : 1.251196
train_step : 15827, loss1 : 0.819680, loss2 : 1.006989
train_step : 15828, loss1 : 1.141492, loss2 : 0.957403
train_step : 15829, loss1 : 1.811953, loss2 : 0.787724
train_step : 15830, loss1 : 1.150420, loss2 : 0.891135
train_step : 15831, loss1 : 1.243250, loss2 : 1.106932
train_step : 15832, loss1 : 0.942392, loss2 : 0.781078
train_step : 15833, loss1 : 2.082660, loss2 : 1.352352
train_step : 15834, loss1 : 2.024736, loss2 : 1.526460
train_step : 15835, loss1 : 1.554927, loss2 : 1.747325
train_step : 15836, loss1 : 2.464514, loss2 : 2.301801
train_step : 15837, loss1 : 2.569971, loss2 : 1.669568
train_step : 15838, loss1 : 1.953892, loss2 : 1.936266
train_step : 15839, loss1 : 1.351126, loss2 : 1.762945
train_step : 15840, loss1 : 2.825506, loss2 : 1.670239
train_step : 15841, loss1 : 1.090144, loss2 : 1.333866
train_step : 15842, loss1 : 0.913543, loss2 : 1.237123
train_step : 15843, loss1 : 0.890931, loss2 : 0.972710
train_step : 15844, loss1 : 1.663109, loss2 : 1.220534
train_step : 15845, loss1 : 0.880953, loss2 : 1.175621
train_step : 15846, loss1 : 1.781371, loss2 : 1.379285
train_step : 15847, loss1 : 1.026439, loss2 : 1.049796
train_step : 15848, loss1 : 1.526971, loss2 : 1.270082
train_step : 15849, loss1 : 1.445454, loss2 : 5.137886
train_step : 15850, loss1 : 1.833635, loss2 : 1.106724
train_step : 15851, loss1 : 1.776806, loss2 : 2.202913
train_step : 15852, loss1 : 0.825174, loss2 : 0.768324
train_step : 15853, loss1 : 1.387355, loss2 : 1.392720
train_step : 15854, loss1 : 1.486570, loss2 : 0.738599
train_step : 15855, loss1 : 1.011263, loss2 : 0.795257
train_step : 15856, loss1 : 0.980267, loss2 : 0.867459
train_step : 15857, loss1 : 0.770267, loss2 : 1.432604
train_step : 15858, loss1 : 0.609786, loss2 : 0.727544
train_step : 15859, loss1 : 1.043997, loss2 : 1.212097
train_step : 15860, loss1 : 0.605401, loss2 : 1.156368
train_step : 15861, loss1 : 1.619955, loss2 : 0.862967
train_step : 15862, loss1 : 1.022254, loss2 : 0.712405
train_step : 15863, loss1 : 0.780489, loss2 : 0.894321
train_step : 15864, loss1 : 1.122994, loss2 : 1.415907
train_step : 15865, loss1 : 1.078568, loss2 : 1.015583
train_step : 15866, loss1 : 1.336127, loss2 : 2.447761
train_step : 15867, loss1 : 2.008092, loss2 : 2.233368
train_step : 15868, loss1 : 3.490166, loss2 : 1.464664
train_step : 15869, loss1 : 2.375183, loss2 : 1.341620
train_step : 15870, loss1 : 1.264573, loss2 : 1.383429
train_step : 15871, loss1 : 1.634527, loss2 : 1.539670
train_step : 15872, loss1 : 1.065088, loss2 : 0.682730
train_step : 15873, loss1 : 1.452666, loss2 : 0.695539
train_step : 15874, loss1 : 1.142874, loss2 : 1.003389
train_step : 15875, loss1 : 1.643752, loss2 : 0.801689
train_step : 15876, loss1 : 2.443284, loss2 : 0.882722
train_step : 15877, loss1 : 0.845983, loss2 : 1.179852
train_step : 15878, loss1 : 0.669605, loss2 : 0.691255
train_step : 15879, loss1 : 2.633599, loss2 : 3.183993
train_step : 15880, loss1 : 5.994724, loss2 : 4.456574
train_step : 15881, loss1 : 3.503143, loss2 : 2.777764
train_step : 15882, loss1 : 2.676673, loss2 : 2.225191
train_step : 15883, loss1 : 1.994316, loss2 : 1.531308
train_step : 15884, loss1 : 0.929953, loss2 : 1.729948
train_step : 15885, loss1 : 1.481044, loss2 : 0.942266
train_step : 15886, loss1 : 1.371937, loss2 : 1.212093
train_step : 15887, loss1 : 0.794957, loss2 : 1.148939
train_step : 15888, loss1 : 2.916652, loss2 : 1.505966
train_step : 15889, loss1 : 2.007132, loss2 : 1.348174
train_step : 15890, loss1 : 0.936786, loss2 : 1.668329
train_step : 15891, loss1 : 1.789251, loss2 : 0.772979
train_step : 15892, loss1 : 1.930074, loss2 : 0.826436
train_step : 15893, loss1 : 1.366705, loss2 : 1.115008
train_step : 15894, loss1 : 2.172243, loss2 : 2.189883
train_step : 15895, loss1 : 1.182328, loss2 : 1.689881
train_step : 15896, loss1 : 1.362305, loss2 : 0.843954
train_step : 15897, loss1 : 1.400443, loss2 : 1.635183
train_step : 15898, loss1 : 1.317643, loss2 : 1.507302
train_step : 15899, loss1 : 1.537375, loss2 : 1.182785
train_step : 15900, loss1 : 0.946891, loss2 : 1.662582
train_step : 15901, loss1 : 0.867771, loss2 : 0.799240
train_step : 15902, loss1 : 1.219030, loss2 : 1.310077
train_step : 15903, loss1 : 1.887012, loss2 : 2.092050
train_step : 15904, loss1 : 1.724599, loss2 : 1.673295
train_step : 15905, loss1 : 2.016059, loss2 : 1.461545
train_step : 15906, loss1 : 1.170737, loss2 : 1.096591
train_step : 15907, loss1 : 1.059637, loss2 : 4.796078
train_step : 15908, loss1 : 1.538276, loss2 : 0.849861
train_step : 15909, loss1 : 1.830467, loss2 : 1.553432
train_step : 15910, loss1 : 1.433871, loss2 : 1.128392
train_step : 15911, loss1 : 1.624228, loss2 : 1.232422
train_step : 15912, loss1 : 2.421894, loss2 : 1.972566
train_step : 15913, loss1 : 2.736008, loss2 : 1.161434
train_step : 15914, loss1 : 0.753723, loss2 : 1.154005
train_step : 15915, loss1 : 0.843583, loss2 : 1.221805
train_step : 15916, loss1 : 0.883752, loss2 : 1.516909
train_step : 15917, loss1 : 1.235614, loss2 : 1.183695
train_step : 15918, loss1 : 1.435048, loss2 : 2.853553
train_step : 15919, loss1 : 1.466884, loss2 : 2.413208
train_step : 15920, loss1 : 1.425010, loss2 : 2.083109
train_step : 15921, loss1 : 1.814205, loss2 : 2.862653
train_step : 15922, loss1 : 1.024397, loss2 : 1.263786
train_step : 15923, loss1 : 1.784448, loss2 : 1.702169
train_step : 15924, loss1 : 1.865461, loss2 : 1.043505
train_step : 15925, loss1 : 1.289453, loss2 : 1.180567
train_step : 15926, loss1 : 0.692409, loss2 : 1.213392
train_step : 15927, loss1 : 1.511037, loss2 : 0.869273
train_step : 15928, loss1 : 1.474531, loss2 : 1.304666
train_step : 15929, loss1 : 1.146144, loss2 : 2.261792
train_step : 15930, loss1 : 1.224992, loss2 : 1.345799
train_step : 15931, loss1 : 1.279153, loss2 : 1.761773
train_step : 15932, loss1 : 1.780770, loss2 : 2.400659
train_step : 15933, loss1 : 1.705852, loss2 : 1.439749
train_step : 15934, loss1 : 1.365642, loss2 : 1.257504
train_step : 15935, loss1 : 1.760481, loss2 : 1.387295
train_step : 15936, loss1 : 1.389673, loss2 : 1.916906
train_step : 15937, loss1 : 1.209628, loss2 : 1.270056
train_step : 15938, loss1 : 1.675794, loss2 : 0.522905
train_step : 15939, loss1 : 1.253914, loss2 : 1.442563
train_step : 15940, loss1 : 0.923806, loss2 : 0.714657
train_step : 15941, loss1 : 0.901388, loss2 : 0.864848
train_step : 15942, loss1 : 0.585445, loss2 : 1.568268
train_step : 15943, loss1 : 0.890106, loss2 : 1.539666
train_step : 15944, loss1 : 1.367584, loss2 : 1.337305
train_step : 15945, loss1 : 1.574358, loss2 : 1.404545
train_step : 15946, loss1 : 1.452166, loss2 : 1.030614
train_step : 15947, loss1 : 0.835038, loss2 : 1.418748
train_step : 15948, loss1 : 0.768930, loss2 : 1.600392
train_step : 15949, loss1 : 0.370965, loss2 : 1.134135
train_step : 15950, loss1 : 1.045038, loss2 : 0.788345
train_step : 15951, loss1 : 1.223487, loss2 : 0.764862
train_step : 15952, loss1 : 1.430040, loss2 : 1.434652
train_step : 15953, loss1 : 1.808010, loss2 : 1.169191
train_step : 15954, loss1 : 0.850192, loss2 : 1.061788
train_step : 15955, loss1 : 1.460103, loss2 : 1.155554
train_step : 15956, loss1 : 0.488450, loss2 : 0.728869
train_step : 15957, loss1 : 1.696326, loss2 : 0.986175
train_step : 15958, loss1 : 1.796774, loss2 : 1.657587
train_step : 15959, loss1 : 2.621693, loss2 : 2.364582
train_step : 15960, loss1 : 1.864924, loss2 : 1.726111
train_step : 15961, loss1 : 2.313906, loss2 : 1.706618
train_step : 15962, loss1 : 1.701047, loss2 : 1.592177
train_step : 15963, loss1 : 0.845358, loss2 : 2.317764
train_step : 15964, loss1 : 1.584811, loss2 : 1.239876
train_step : 15965, loss1 : 1.590814, loss2 : 1.579666
train_step : 15966, loss1 : 1.739071, loss2 : 0.959175
train_step : 15967, loss1 : 1.168702, loss2 : 1.878753
train_step : 15968, loss1 : 1.463890, loss2 : 1.715416
train_step : 15969, loss1 : 1.171149, loss2 : 2.067642
train_step : 15970, loss1 : 1.563883, loss2 : 1.781758
train_step : 15971, loss1 : 2.555922, loss2 : 0.947888
train_step : 15972, loss1 : 1.760403, loss2 : 2.043508
train_step : 15973, loss1 : 1.641901, loss2 : 1.782861
train_step : 15974, loss1 : 1.760956, loss2 : 2.221562
train_step : 15975, loss1 : 1.267984, loss2 : 1.703058
train_step : 15976, loss1 : 1.900678, loss2 : 1.257667
train_step : 15977, loss1 : 1.829404, loss2 : 2.044682
train_step : 15978, loss1 : 1.557812, loss2 : 1.481036
train_step : 15979, loss1 : 1.581167, loss2 : 1.401191
train_step : 15980, loss1 : 1.186433, loss2 : 0.712646
train_step : 15981, loss1 : 1.128289, loss2 : 0.890943
train_step : 15982, loss1 : 0.623759, loss2 : 1.171113
train_step : 15983, loss1 : 0.781029, loss2 : 0.702008
train_step : 15984, loss1 : 0.691847, loss2 : 1.229679
train_step : 15985, loss1 : 0.944547, loss2 : 1.915595
train_step : 15986, loss1 : 0.746075, loss2 : 1.133911
train_step : 15987, loss1 : 0.661470, loss2 : 0.774173
train_step : 15988, loss1 : 0.767311, loss2 : 1.892740
train_step : 15989, loss1 : 1.106230, loss2 : 1.811599
train_step : 15990, loss1 : 1.558173, loss2 : 1.945102
train_step : 15991, loss1 : 2.643488, loss2 : 0.970949
train_step : 15992, loss1 : 1.454712, loss2 : 1.164238
train_step : 15993, loss1 : 1.034361, loss2 : 0.581309
train_step : 15994, loss1 : 1.282403, loss2 : 0.876493
train_step : 15995, loss1 : 1.933332, loss2 : 0.869144
train_step : 15996, loss1 : 1.507186, loss2 : 1.070853
train_step : 15997, loss1 : 0.786150, loss2 : 0.833301
train_step : 15998, loss1 : 1.470006, loss2 : 1.591796
train_step : 15999, loss1 : 1.053735, loss2 : 1.803546
train_step : 16000, loss1 : 1.215107, loss2 : 1.101123
train_step : 16001, loss1 : 1.664390, loss2 : 1.603027
train_step : 16002, loss1 : 2.259847, loss2 : 2.209456
train_step : 16003, loss1 : 2.788135, loss2 : 3.224996
train_step : 16004, loss1 : 3.222628, loss2 : 2.860598
train_step : 16005, loss1 : 2.820448, loss2 : 2.150702
train_step : 16006, loss1 : 2.577427, loss2 : 2.677551
train_step : 16007, loss1 : 0.868992, loss2 : 1.219257
train_step : 16008, loss1 : 1.558608, loss2 : 1.438659
train_step : 16009, loss1 : 1.453397, loss2 : 0.537694
train_step : 16010, loss1 : 1.091215, loss2 : 1.289340
train_step : 16011, loss1 : 0.815132, loss2 : 2.216433
train_step : 16012, loss1 : 1.947392, loss2 : 1.493898
train_step : 16013, loss1 : 0.998356, loss2 : 0.981536
train_step : 16014, loss1 : 1.357792, loss2 : 2.030118
train_step : 16015, loss1 : 1.700708, loss2 : 1.461810
train_step : 16016, loss1 : 1.723844, loss2 : 1.290564
train_step : 16017, loss1 : 1.022206, loss2 : 0.892434
train_step : 16018, loss1 : 1.331840, loss2 : 1.149413
train_step : 16019, loss1 : 1.548998, loss2 : 0.955933
train_step : 16020, loss1 : 1.467726, loss2 : 1.859811
train_step : 16021, loss1 : 0.615942, loss2 : 1.645799
train_step : 16022, loss1 : 1.122616, loss2 : 0.805286
train_step : 16023, loss1 : 0.839100, loss2 : 0.764984
train_step : 16024, loss1 : 1.046194, loss2 : 0.924344
train_step : 16025, loss1 : 0.925356, loss2 : 1.297153
train_step : 16026, loss1 : 1.259431, loss2 : 2.066378
train_step : 16027, loss1 : 1.392801, loss2 : 1.996887
train_step : 16028, loss1 : 2.067813, loss2 : 1.762258
train_step : 16029, loss1 : 1.957256, loss2 : 1.369059
train_step : 16030, loss1 : 1.273547, loss2 : 1.579435
train_step : 16031, loss1 : 1.256418, loss2 : 0.751236
train_step : 16032, loss1 : 0.824184, loss2 : 1.367536
train_step : 16033, loss1 : 1.427558, loss2 : 1.087817
train_step : 16034, loss1 : 0.789349, loss2 : 1.841909
train_step : 16035, loss1 : 1.427283, loss2 : 0.761622
train_step : 16036, loss1 : 1.092629, loss2 : 0.889554
train_step : 16037, loss1 : 1.111730, loss2 : 0.537564
train_step : 16038, loss1 : 0.570071, loss2 : 1.053619
train_step : 16039, loss1 : 1.369529, loss2 : 1.005535
train_step : 16040, loss1 : 0.919008, loss2 : 0.966617
train_step : 16041, loss1 : 1.402345, loss2 : 1.204291
train_step : 16042, loss1 : 1.580727, loss2 : 0.740032
train_step : 16043, loss1 : 0.837223, loss2 : 1.350596
train_step : 16044, loss1 : 1.473955, loss2 : 1.130211
train_step : 16045, loss1 : 0.848595, loss2 : 1.483940
train_step : 16046, loss1 : 1.699007, loss2 : 1.683434
train_step : 16047, loss1 : 3.466586, loss2 : 1.086151
train_step : 16048, loss1 : 2.365906, loss2 : 2.262888
train_step : 16049, loss1 : 2.287906, loss2 : 2.653826
train_step : 16050, loss1 : 2.271644, loss2 : 2.756418
train_step : 16051, loss1 : 1.291664, loss2 : 1.050426
train_step : 16052, loss1 : 1.129441, loss2 : 1.015503
train_step : 16053, loss1 : 1.918799, loss2 : 0.617995
train_step : 16054, loss1 : 1.101516, loss2 : 0.892403
train_step : 16055, loss1 : 0.947990, loss2 : 1.061072
train_step : 16056, loss1 : 0.725301, loss2 : 1.124368
train_step : 16057, loss1 : 0.688085, loss2 : 1.788012
train_step : 16058, loss1 : 0.607913, loss2 : 1.151675
train_step : 16059, loss1 : 1.219848, loss2 : 1.250982
train_step : 16060, loss1 : 1.678549, loss2 : 1.501769
train_step : 16061, loss1 : 1.467508, loss2 : 1.167941
train_step : 16062, loss1 : 1.815408, loss2 : 1.224132
train_step : 16063, loss1 : 1.334077, loss2 : 1.535882
train_step : 16064, loss1 : 0.794081, loss2 : 0.635943
train_step : 16065, loss1 : 1.307044, loss2 : 1.420608
train_step : 16066, loss1 : 1.058724, loss2 : 1.172810
train_step : 16067, loss1 : 0.857495, loss2 : 0.968283
train_step : 16068, loss1 : 0.943186, loss2 : 0.985880
train_step : 16069, loss1 : 0.890628, loss2 : 1.737084
train_step : 16070, loss1 : 0.923411, loss2 : 0.758290
train_step : 16071, loss1 : 1.360897, loss2 : 1.924514
train_step : 16072, loss1 : 1.269117, loss2 : 1.397322
train_step : 16073, loss1 : 0.740547, loss2 : 0.926926
train_step : 16074, loss1 : 1.163264, loss2 : 0.925282
train_step : 16075, loss1 : 1.384706, loss2 : 1.096821
train_step : 16076, loss1 : 0.736262, loss2 : 0.780043
train_step : 16077, loss1 : 1.112057, loss2 : 0.415675
train_step : 16078, loss1 : 1.495539, loss2 : 1.282100
train_step : 16079, loss1 : 1.111366, loss2 : 0.992971
train_step : 16080, loss1 : 0.657126, loss2 : 1.259820
train_step : 16081, loss1 : 0.917553, loss2 : 1.332794
train_step : 16082, loss1 : 0.956403, loss2 : 0.824345
train_step : 16083, loss1 : 1.121860, loss2 : 1.425372
train_step : 16084, loss1 : 0.943792, loss2 : 1.098564
train_step : 16085, loss1 : 0.978623, loss2 : 2.113509
train_step : 16086, loss1 : 1.387035, loss2 : 0.629678
train_step : 16087, loss1 : 0.981243, loss2 : 1.208458
train_step : 16088, loss1 : 1.660676, loss2 : 0.882264
train_step : 16089, loss1 : 1.421265, loss2 : 2.147664
train_step : 16090, loss1 : 1.283835, loss2 : 2.087208
train_step : 16091, loss1 : 1.874026, loss2 : 1.608588
train_step : 16092, loss1 : 1.126158, loss2 : 1.401759
train_step : 16093, loss1 : 0.753353, loss2 : 1.584313
train_step : 16094, loss1 : 1.739681, loss2 : 1.096774
train_step : 16095, loss1 : 1.302032, loss2 : 1.699605
train_step : 16096, loss1 : 0.773759, loss2 : 0.805767
train_step : 16097, loss1 : 0.730840, loss2 : 1.230437
train_step : 16098, loss1 : 0.824042, loss2 : 1.200104
train_step : 16099, loss1 : 1.178915, loss2 : 1.890626
train_step : 16100, loss1 : 1.007144, loss2 : 1.132979
train_step : 16101, loss1 : 1.157817, loss2 : 0.788822
train_step : 16102, loss1 : 0.662762, loss2 : 1.426512
train_step : 16103, loss1 : 3.060540, loss2 : 1.901457
train_step : 16104, loss1 : 1.113435, loss2 : 1.443953
train_step : 16105, loss1 : 0.829168, loss2 : 1.239493
train_step : 16106, loss1 : 1.334146, loss2 : 0.880875
train_step : 16107, loss1 : 0.854102, loss2 : 0.969598
train_step : 16108, loss1 : 1.337416, loss2 : 1.594373
train_step : 16109, loss1 : 1.607271, loss2 : 0.951937
train_step : 16110, loss1 : 1.667291, loss2 : 1.853886
train_step : 16111, loss1 : 1.790517, loss2 : 1.468541
train_step : 16112, loss1 : 1.000425, loss2 : 1.349343
train_step : 16113, loss1 : 1.402363, loss2 : 0.663976
train_step : 16114, loss1 : 1.345907, loss2 : 1.443691
train_step : 16115, loss1 : 1.128491, loss2 : 1.130276
train_step : 16116, loss1 : 1.947392, loss2 : 0.681465
train_step : 16117, loss1 : 1.456334, loss2 : 0.997737
train_step : 16118, loss1 : 2.023237, loss2 : 1.585306
train_step : 16119, loss1 : 1.964425, loss2 : 1.803640
train_step : 16120, loss1 : 1.005144, loss2 : 1.886538
train_step : 16121, loss1 : 1.877392, loss2 : 1.514540
train_step : 16122, loss1 : 1.315774, loss2 : 1.135589
train_step : 16123, loss1 : 2.341384, loss2 : 1.649598
train_step : 16124, loss1 : 2.517855, loss2 : 3.011564
train_step : 16125, loss1 : 2.724397, loss2 : 3.597624
train_step : 16126, loss1 : 3.790630, loss2 : 3.508710
train_step : 16127, loss1 : 3.158689, loss2 : 2.752000
train_step : 16128, loss1 : 2.935003, loss2 : 2.629390
train_step : 16129, loss1 : 3.330098, loss2 : 3.560677
train_step : 16130, loss1 : 2.054724, loss2 : 1.882529
train_step : 16131, loss1 : 2.548544, loss2 : 2.407188
train_step : 16132, loss1 : 3.783624, loss2 : 4.381791
train_step : 16133, loss1 : 3.856661, loss2 : 2.338867
train_step : 16134, loss1 : 1.801475, loss2 : 2.309249
train_step : 16135, loss1 : 1.557428, loss2 : 1.461649
train_step : 16136, loss1 : 1.583661, loss2 : 2.415187
train_step : 16137, loss1 : 1.998020, loss2 : 1.511649
train_step : 16138, loss1 : 1.805851, loss2 : 1.875338
train_step : 16139, loss1 : 1.333304, loss2 : 1.522696
train_step : 16140, loss1 : 0.974248, loss2 : 0.624022
train_step : 16141, loss1 : 1.365462, loss2 : 1.725260
train_step : 16142, loss1 : 1.045883, loss2 : 1.203215
train_step : 16143, loss1 : 1.810158, loss2 : 1.724841
train_step : 16144, loss1 : 2.799059, loss2 : 2.637511
train_step : 16145, loss1 : 1.810448, loss2 : 3.118221
train_step : 16146, loss1 : 1.835296, loss2 : 1.683468
train_step : 16147, loss1 : 2.526841, loss2 : 0.986137
train_step : 16148, loss1 : 1.261847, loss2 : 1.291619
train_step : 16149, loss1 : 1.565392, loss2 : 1.453399
train_step : 16150, loss1 : 1.509762, loss2 : 1.782007
train_step : 16151, loss1 : 1.969104, loss2 : 1.508562
train_step : 16152, loss1 : 1.290343, loss2 : 0.976955
train_step : 16153, loss1 : 0.821343, loss2 : 0.481115
train_step : 16154, loss1 : 1.280402, loss2 : 2.637456
train_step : 16155, loss1 : 1.422950, loss2 : 1.680791
train_step : 16156, loss1 : 1.570045, loss2 : 1.639068
train_step : 16157, loss1 : 1.968540, loss2 : 1.023665
train_step : 16158, loss1 : 1.682988, loss2 : 1.974044
train_step : 16159, loss1 : 2.926157, loss2 : 0.727267
train_step : 16160, loss1 : 2.281977, loss2 : 1.425570
train_step : 16161, loss1 : 0.999943, loss2 : 1.722493
train_step : 16162, loss1 : 0.993580, loss2 : 1.800203
train_step : 16163, loss1 : 1.374087, loss2 : 1.884181
train_step : 16164, loss1 : 0.932557, loss2 : 1.163072
train_step : 16165, loss1 : 1.344851, loss2 : 0.606134
train_step : 16166, loss1 : 0.843491, loss2 : 0.923711
train_step : 16167, loss1 : 0.985049, loss2 : 1.203748
train_step : 16168, loss1 : 1.231437, loss2 : 0.854721
train_step : 16169, loss1 : 1.416943, loss2 : 1.519012
train_step : 16170, loss1 : 0.887749, loss2 : 0.976843
train_step : 16171, loss1 : 1.271636, loss2 : 0.832015
train_step : 16172, loss1 : 1.092563, loss2 : 1.024004
train_step : 16173, loss1 : 1.467923, loss2 : 0.515841
train_step : 16174, loss1 : 1.418286, loss2 : 1.033730
train_step : 16175, loss1 : 1.263356, loss2 : 1.406161
train_step : 16176, loss1 : 1.029369, loss2 : 1.360059
train_step : 16177, loss1 : 1.317481, loss2 : 0.912728
train_step : 16178, loss1 : 1.771464, loss2 : 0.858932
train_step : 16179, loss1 : 1.217919, loss2 : 0.944675
train_step : 16180, loss1 : 0.803264, loss2 : 1.775489
train_step : 16181, loss1 : 1.359646, loss2 : 1.540582
train_step : 16182, loss1 : 1.206744, loss2 : 1.265111
train_step : 16183, loss1 : 1.392080, loss2 : 0.782133
train_step : 16184, loss1 : 1.797047, loss2 : 1.238116
train_step : 16185, loss1 : 1.073413, loss2 : 1.438542
train_step : 16186, loss1 : 1.454189, loss2 : 0.633672
train_step : 16187, loss1 : 1.832653, loss2 : 1.829130
train_step : 16188, loss1 : 1.535173, loss2 : 2.061667
train_step : 16189, loss1 : 1.787098, loss2 : 1.771920
train_step : 16190, loss1 : 1.899288, loss2 : 1.523503
train_step : 16191, loss1 : 1.758550, loss2 : 1.409941
train_step : 16192, loss1 : 1.487997, loss2 : 1.751039
train_step : 16193, loss1 : 1.665871, loss2 : 2.226440
train_step : 16194, loss1 : 1.874921, loss2 : 1.067684
train_step : 16195, loss1 : 1.794661, loss2 : 1.301618
train_step : 16196, loss1 : 2.234120, loss2 : 2.376572
train_step : 16197, loss1 : 1.186178, loss2 : 2.089368
train_step : 16198, loss1 : 1.950442, loss2 : 0.781330
train_step : 16199, loss1 : 1.959017, loss2 : 1.757470
train_step : 16200, loss1 : 2.044896, loss2 : 2.173298
train_step : 16201, loss1 : 2.077805, loss2 : 2.163939
train_step : 16202, loss1 : 1.072260, loss2 : 1.103575
train_step : 16203, loss1 : 0.929831, loss2 : 1.643819
train_step : 16204, loss1 : 1.245635, loss2 : 1.049099
train_step : 16205, loss1 : 1.581811, loss2 : 0.747542
train_step : 16206, loss1 : 1.084307, loss2 : 0.969042
train_step : 16207, loss1 : 0.870398, loss2 : 1.450077
train_step : 16208, loss1 : 1.096173, loss2 : 1.037993
train_step : 16209, loss1 : 1.593741, loss2 : 1.404308
train_step : 16210, loss1 : 0.984845, loss2 : 1.300599
train_step : 16211, loss1 : 0.578612, loss2 : 0.816589
train_step : 16212, loss1 : 1.267272, loss2 : 0.590986
train_step : 16213, loss1 : 1.647529, loss2 : 0.757451
train_step : 16214, loss1 : 0.620352, loss2 : 0.671769
train_step : 16215, loss1 : 1.335703, loss2 : 1.118587
train_step : 16216, loss1 : 1.307609, loss2 : 1.087039
train_step : 16217, loss1 : 1.093682, loss2 : 0.894661
train_step : 16218, loss1 : 1.530305, loss2 : 1.016016
train_step : 16219, loss1 : 0.965267, loss2 : 0.596318
train_step : 16220, loss1 : 1.813115, loss2 : 0.955623
train_step : 16221, loss1 : 1.149592, loss2 : 1.234114
train_step : 16222, loss1 : 0.870406, loss2 : 1.394132
train_step : 16223, loss1 : 1.007733, loss2 : 0.981875
train_step : 16224, loss1 : 0.859077, loss2 : 0.820571
train_step : 16225, loss1 : 0.640636, loss2 : 1.215367
train_step : 16226, loss1 : 0.404765, loss2 : 1.001387
train_step : 16227, loss1 : 1.067448, loss2 : 1.051903
train_step : 16228, loss1 : 1.685649, loss2 : 1.201092
train_step : 16229, loss1 : 0.779244, loss2 : 1.412455
train_step : 16230, loss1 : 1.596524, loss2 : 1.611382
train_step : 16231, loss1 : 0.840464, loss2 : 1.368137
train_step : 16232, loss1 : 1.868073, loss2 : 1.047672
train_step : 16233, loss1 : 1.236790, loss2 : 1.918650
train_step : 16234, loss1 : 1.437403, loss2 : 1.340545
train_step : 16235, loss1 : 0.687463, loss2 : 2.336430
train_step : 16236, loss1 : 1.273730, loss2 : 1.086474
train_step : 16237, loss1 : 1.283189, loss2 : 1.399140
train_step : 16238, loss1 : 0.674461, loss2 : 1.252219
train_step : 16239, loss1 : 0.874607, loss2 : 1.633889
train_step : 16240, loss1 : 1.217851, loss2 : 1.532183
train_step : 16241, loss1 : 0.839403, loss2 : 0.814792
train_step : 16242, loss1 : 1.324171, loss2 : 1.795491
train_step : 16243, loss1 : 1.293448, loss2 : 1.712244
train_step : 16244, loss1 : 2.954663, loss2 : 1.446314
train_step : 16245, loss1 : 2.476650, loss2 : 1.618892
train_step : 16246, loss1 : 2.363706, loss2 : 2.029659
train_step : 16247, loss1 : 1.690326, loss2 : 3.321774
train_step : 16248, loss1 : 2.264011, loss2 : 1.511399
train_step : 16249, loss1 : 1.550994, loss2 : 2.563745
train_step : 16250, loss1 : 1.576751, loss2 : 1.187852
train_step : 16251, loss1 : 1.688596, loss2 : 2.877223
train_step : 16252, loss1 : 1.635491, loss2 : 2.318976
train_step : 16253, loss1 : 1.927606, loss2 : 1.678212
train_step : 16254, loss1 : 2.743685, loss2 : 1.081594
train_step : 16255, loss1 : 1.487226, loss2 : 1.763039
train_step : 16256, loss1 : 1.092997, loss2 : 1.730513
train_step : 16257, loss1 : 1.178889, loss2 : 1.586694
train_step : 16258, loss1 : 0.917518, loss2 : 0.921544
train_step : 16259, loss1 : 1.210494, loss2 : 1.782967
train_step : 16260, loss1 : 2.511547, loss2 : 2.279507
train_step : 16261, loss1 : 1.731343, loss2 : 1.885094
train_step : 16262, loss1 : 1.221414, loss2 : 1.064466
train_step : 16263, loss1 : 1.108974, loss2 : 1.207339
train_step : 16264, loss1 : 1.126863, loss2 : 1.373429
train_step : 16265, loss1 : 1.670818, loss2 : 2.431329
train_step : 16266, loss1 : 1.686289, loss2 : 2.797363
train_step : 16267, loss1 : 1.933687, loss2 : 2.172492
train_step : 16268, loss1 : 0.604397, loss2 : 1.528775
train_step : 16269, loss1 : 0.742028, loss2 : 1.071014
train_step : 16270, loss1 : 1.470071, loss2 : 1.201674
train_step : 16271, loss1 : 1.018323, loss2 : 1.045350
train_step : 16272, loss1 : 0.836853, loss2 : 0.514833
train_step : 16273, loss1 : 0.889845, loss2 : 0.624455
train_step : 16274, loss1 : 1.036850, loss2 : 0.721364
train_step : 16275, loss1 : 1.018454, loss2 : 0.919591
train_step : 16276, loss1 : 2.159564, loss2 : 0.717012
train_step : 16277, loss1 : 1.536044, loss2 : 1.088772
train_step : 16278, loss1 : 1.125800, loss2 : 0.811375
train_step : 16279, loss1 : 1.216520, loss2 : 1.551638
train_step : 16280, loss1 : 1.401434, loss2 : 1.413156
train_step : 16281, loss1 : 2.124686, loss2 : 1.460222
train_step : 16282, loss1 : 1.907554, loss2 : 1.783815
train_step : 16283, loss1 : 3.225419, loss2 : 3.136046
train_step : 16284, loss1 : 1.199306, loss2 : 1.773835
train_step : 16285, loss1 : 1.762209, loss2 : 2.353194
train_step : 16286, loss1 : 3.133650, loss2 : 2.134503
train_step : 16287, loss1 : 5.052033, loss2 : 2.233774
train_step : 16288, loss1 : 3.804194, loss2 : 3.975139
train_step : 16289, loss1 : 3.472562, loss2 : 4.910436
train_step : 16290, loss1 : 3.544779, loss2 : 4.425210
train_step : 16291, loss1 : 3.498272, loss2 : 4.878646
train_step : 16292, loss1 : 3.235255, loss2 : 2.140466
train_step : 16293, loss1 : 2.312219, loss2 : 2.866797
train_step : 16294, loss1 : 1.252319, loss2 : 0.974022
train_step : 16295, loss1 : 1.519255, loss2 : 1.716609
train_step : 16296, loss1 : 0.812917, loss2 : 1.035235
train_step : 16297, loss1 : 0.909690, loss2 : 0.795052
train_step : 16298, loss1 : 1.272693, loss2 : 2.164649
train_step : 16299, loss1 : 1.568079, loss2 : 0.921824
train_step : 16300, loss1 : 1.390419, loss2 : 1.268974
train_step : 16301, loss1 : 1.264462, loss2 : 0.647997
train_step : 16302, loss1 : 1.098509, loss2 : 1.142351
train_step : 16303, loss1 : 1.079325, loss2 : 1.019696
train_step : 16304, loss1 : 0.822204, loss2 : 0.980200
train_step : 16305, loss1 : 1.098339, loss2 : 2.221675
train_step : 16306, loss1 : 0.523012, loss2 : 1.007319
train_step : 16307, loss1 : 1.099906, loss2 : 1.266485
train_step : 16308, loss1 : 1.480734, loss2 : 1.070583
train_step : 16309, loss1 : 1.159437, loss2 : 0.603413
train_step : 16310, loss1 : 1.298162, loss2 : 2.284699
train_step : 16311, loss1 : 2.056743, loss2 : 1.654225
train_step : 16312, loss1 : 1.639447, loss2 : 2.403172
train_step : 16313, loss1 : 1.306639, loss2 : 1.757568
train_step : 16314, loss1 : 0.756122, loss2 : 1.665007
train_step : 16315, loss1 : 1.867444, loss2 : 1.117334
train_step : 16316, loss1 : 1.498382, loss2 : 1.779409
train_step : 16317, loss1 : 1.706583, loss2 : 2.183959
train_step : 16318, loss1 : 0.904475, loss2 : 1.425440
train_step : 16319, loss1 : 1.296321, loss2 : 1.469519
train_step : 16320, loss1 : 0.377521, loss2 : 1.007738
train_step : 16321, loss1 : 1.118092, loss2 : 0.691003
train_step : 16322, loss1 : 1.268041, loss2 : 1.105342
train_step : 16323, loss1 : 0.624999, loss2 : 0.836922
train_step : 16324, loss1 : 1.373671, loss2 : 1.014989
train_step : 16325, loss1 : 0.911965, loss2 : 1.823991
train_step : 16326, loss1 : 1.824224, loss2 : 1.661344
train_step : 16327, loss1 : 0.913869, loss2 : 0.611973
train_step : 16328, loss1 : 0.897205, loss2 : 2.281530
train_step : 16329, loss1 : 1.388364, loss2 : 1.009869
train_step : 16330, loss1 : 1.722261, loss2 : 1.107027
train_step : 16331, loss1 : 1.507361, loss2 : 4.818920
train_step : 16332, loss1 : 1.919311, loss2 : 1.901778
train_step : 16333, loss1 : 2.245121, loss2 : 1.310008
train_step : 16334, loss1 : 2.890465, loss2 : 1.926887
train_step : 16335, loss1 : 2.782282, loss2 : 3.879618
train_step : 16336, loss1 : 2.376387, loss2 : 2.944080
train_step : 16337, loss1 : 2.835058, loss2 : 3.188955
train_step : 16338, loss1 : 1.320361, loss2 : 1.520566
train_step : 16339, loss1 : 1.393579, loss2 : 1.922935
train_step : 16340, loss1 : 1.769526, loss2 : 1.146296
train_step : 16341, loss1 : 0.887232, loss2 : 2.393130
train_step : 16342, loss1 : 1.028729, loss2 : 1.559649
train_step : 16343, loss1 : 0.846606, loss2 : 1.033710
train_step : 16344, loss1 : 1.325047, loss2 : 1.299575
train_step : 16345, loss1 : 0.729821, loss2 : 0.920471
train_step : 16346, loss1 : 1.035414, loss2 : 1.607955
train_step : 16347, loss1 : 1.717895, loss2 : 0.943806
train_step : 16348, loss1 : 0.944658, loss2 : 0.857529
train_step : 16349, loss1 : 0.658729, loss2 : 1.188356
train_step : 16350, loss1 : 0.867360, loss2 : 0.900607
train_step : 16351, loss1 : 0.833588, loss2 : 1.241408
train_step : 16352, loss1 : 1.363652, loss2 : 1.966068
train_step : 16353, loss1 : 1.310072, loss2 : 0.707358
train_step : 16354, loss1 : 1.103171, loss2 : 3.647752
train_step : 16355, loss1 : 1.354944, loss2 : 1.616538
train_step : 16356, loss1 : 1.211439, loss2 : 1.295881
train_step : 16357, loss1 : 1.312412, loss2 : 1.189649
train_step : 16358, loss1 : 1.657002, loss2 : 1.706330
train_step : 16359, loss1 : 1.410352, loss2 : 0.958544
train_step : 16360, loss1 : 0.715692, loss2 : 1.220102
train_step : 16361, loss1 : 1.866663, loss2 : 0.972526
train_step : 16362, loss1 : 1.494871, loss2 : 2.121425
train_step : 16363, loss1 : 1.444309, loss2 : 1.528539
train_step : 16364, loss1 : 0.662172, loss2 : 2.163365
train_step : 16365, loss1 : 1.432040, loss2 : 2.094620
train_step : 16366, loss1 : 1.693389, loss2 : 1.934069
train_step : 16367, loss1 : 1.288370, loss2 : 1.839812
train_step : 16368, loss1 : 1.002326, loss2 : 1.257091
train_step : 16369, loss1 : 0.674626, loss2 : 1.145946
train_step : 16370, loss1 : 1.130207, loss2 : 0.928833
train_step : 16371, loss1 : 1.126177, loss2 : 0.724092
train_step : 16372, loss1 : 1.237895, loss2 : 1.146466
train_step : 16373, loss1 : 0.778013, loss2 : 0.856894
train_step : 16374, loss1 : 0.388467, loss2 : 1.904798
train_step : 16375, loss1 : 1.280457, loss2 : 0.609385
train_step : 16376, loss1 : 1.067419, loss2 : 1.469664
train_step : 16377, loss1 : 0.794892, loss2 : 1.852246
train_step : 16378, loss1 : 1.142477, loss2 : 0.573094
train_step : 16379, loss1 : 1.501001, loss2 : 0.902806
train_step : 16380, loss1 : 0.720744, loss2 : 1.361310
train_step : 16381, loss1 : 0.940270, loss2 : 1.482708
train_step : 16382, loss1 : 1.144348, loss2 : 0.970529
train_step : 16383, loss1 : 2.781301, loss2 : 1.535996
train_step : 16384, loss1 : 2.079460, loss2 : 1.028823
train_step : 16385, loss1 : 1.510358, loss2 : 1.379791
train_step : 16386, loss1 : 1.116018, loss2 : 1.151326
train_step : 16387, loss1 : 4.520715, loss2 : 0.940080
train_step : 16388, loss1 : 1.598922, loss2 : 0.952249
train_step : 16389, loss1 : 1.627750, loss2 : 1.136085
train_step : 16390, loss1 : 1.270085, loss2 : 1.240199
train_step : 16391, loss1 : 1.540901, loss2 : 0.949389
train_step : 16392, loss1 : 1.613143, loss2 : 1.861527
train_step : 16393, loss1 : 1.918642, loss2 : 1.045558
train_step : 16394, loss1 : 1.434793, loss2 : 1.248375
train_step : 16395, loss1 : 1.938347, loss2 : 0.785035
train_step : 16396, loss1 : 1.156903, loss2 : 0.986870
train_step : 16397, loss1 : 0.464105, loss2 : 1.467936
train_step : 16398, loss1 : 0.767326, loss2 : 0.721005
train_step : 16399, loss1 : 1.270909, loss2 : 1.684918
train_step : 16400, loss1 : 1.051452, loss2 : 2.169027
train_step : 16401, loss1 : 0.825190, loss2 : 1.599219
train_step : 16402, loss1 : 1.327318, loss2 : 0.842777
train_step : 16403, loss1 : 1.269701, loss2 : 0.879825
train_step : 16404, loss1 : 1.196879, loss2 : 0.936575
train_step : 16405, loss1 : 1.246437, loss2 : 0.832460
train_step : 16406, loss1 : 1.626244, loss2 : 0.924691
train_step : 16407, loss1 : 0.959129, loss2 : 1.388413
train_step : 16408, loss1 : 0.771127, loss2 : 1.394114
train_step : 16409, loss1 : 0.578249, loss2 : 0.874966
train_step : 16410, loss1 : 1.410745, loss2 : 1.945637
train_step : 16411, loss1 : 0.803037, loss2 : 1.134521
train_step : 16412, loss1 : 0.747323, loss2 : 0.624791
train_step : 16413, loss1 : 0.963987, loss2 : 1.803091
train_step : 16414, loss1 : 0.969278, loss2 : 0.908251
train_step : 16415, loss1 : 0.566723, loss2 : 1.475253
train_step : 16416, loss1 : 0.913412, loss2 : 1.370357
train_step : 16417, loss1 : 1.172646, loss2 : 1.032932
train_step : 16418, loss1 : 1.706025, loss2 : 0.687009
train_step : 16419, loss1 : 1.066969, loss2 : 1.498220
train_step : 16420, loss1 : 2.323224, loss2 : 1.800668
train_step : 16421, loss1 : 1.758979, loss2 : 2.175488
train_step : 16422, loss1 : 2.677872, loss2 : 2.178511
train_step : 16423, loss1 : 2.267759, loss2 : 2.670751
train_step : 16424, loss1 : 4.533218, loss2 : 2.626240
train_step : 16425, loss1 : 3.585832, loss2 : 4.311282
train_step : 16426, loss1 : 3.730818, loss2 : 4.430617
train_step : 16427, loss1 : 2.466486, loss2 : 2.511204
train_step : 16428, loss1 : 2.170497, loss2 : 2.203933
train_step : 16429, loss1 : 1.242076, loss2 : 1.901358
train_step : 16430, loss1 : 1.415955, loss2 : 1.625561
train_step : 16431, loss1 : 1.574305, loss2 : 1.516385
train_step : 16432, loss1 : 0.699231, loss2 : 0.729602
train_step : 16433, loss1 : 1.043661, loss2 : 1.377579
train_step : 16434, loss1 : 1.685481, loss2 : 1.760184
train_step : 16435, loss1 : 1.638439, loss2 : 1.417273
train_step : 16436, loss1 : 0.904192, loss2 : 1.499635
train_step : 16437, loss1 : 1.471754, loss2 : 1.189517
train_step : 16438, loss1 : 1.076941, loss2 : 0.956336
train_step : 16439, loss1 : 0.712910, loss2 : 0.703729
train_step : 16440, loss1 : 1.257725, loss2 : 1.298373
train_step : 16441, loss1 : 1.202478, loss2 : 1.885855
train_step : 16442, loss1 : 0.863404, loss2 : 1.612945
train_step : 16443, loss1 : 0.628560, loss2 : 1.007172
train_step : 16444, loss1 : 1.164119, loss2 : 0.605675
train_step : 16445, loss1 : 0.848643, loss2 : 0.631141
train_step : 16446, loss1 : 0.527781, loss2 : 0.759241
train_step : 16447, loss1 : 0.696006, loss2 : 1.484876
train_step : 16448, loss1 : 1.044705, loss2 : 2.330400
train_step : 16449, loss1 : 1.394944, loss2 : 1.704793
train_step : 16450, loss1 : 1.522291, loss2 : 2.137703
train_step : 16451, loss1 : 1.743253, loss2 : 2.465961
train_step : 16452, loss1 : 2.002745, loss2 : 2.041885
train_step : 16453, loss1 : 3.467763, loss2 : 2.314847
train_step : 16454, loss1 : 1.201051, loss2 : 2.576989
train_step : 16455, loss1 : 1.303424, loss2 : 2.345753
train_step : 16456, loss1 : 0.976113, loss2 : 1.216002
train_step : 16457, loss1 : 1.132371, loss2 : 1.070010
train_step : 16458, loss1 : 0.408968, loss2 : 1.271921
train_step : 16459, loss1 : 1.226641, loss2 : 1.748360
train_step : 16460, loss1 : 1.223229, loss2 : 1.359643
train_step : 16461, loss1 : 1.367161, loss2 : 1.225959
train_step : 16462, loss1 : 0.925657, loss2 : 1.289628
train_step : 16463, loss1 : 0.980896, loss2 : 1.200146
train_step : 16464, loss1 : 0.610239, loss2 : 1.226390
train_step : 16465, loss1 : 0.742869, loss2 : 1.249371
train_step : 16466, loss1 : 1.654821, loss2 : 0.772514
train_step : 16467, loss1 : 1.323887, loss2 : 1.579395
train_step : 16468, loss1 : 2.683319, loss2 : 3.140668
train_step : 16469, loss1 : 1.061224, loss2 : 2.651129
train_step : 16470, loss1 : 2.974979, loss2 : 2.221144
train_step : 16471, loss1 : 2.245610, loss2 : 0.556021
train_step : 16472, loss1 : 1.811183, loss2 : 1.494427
train_step : 16473, loss1 : 2.604570, loss2 : 1.698259
train_step : 16474, loss1 : 1.593373, loss2 : 2.270575
train_step : 16475, loss1 : 0.653801, loss2 : 1.292566
train_step : 16476, loss1 : 0.816464, loss2 : 1.693038
train_step : 16477, loss1 : 0.666826, loss2 : 1.649595
train_step : 16478, loss1 : 0.628251, loss2 : 0.984968
train_step : 16479, loss1 : 1.621367, loss2 : 1.703788
train_step : 16480, loss1 : 3.118443, loss2 : 2.397408
train_step : 16481, loss1 : 1.665091, loss2 : 5.512148
train_step : 16482, loss1 : 4.693941, loss2 : 6.280309
train_step : 16483, loss1 : 4.080423, loss2 : 5.862034
train_step : 16484, loss1 : 5.707950, loss2 : 4.012307
train_step : 16485, loss1 : 3.564347, loss2 : 3.170351
train_step : 16486, loss1 : 3.604432, loss2 : 2.537497
train_step : 16487, loss1 : 1.342898, loss2 : 1.964917
train_step : 16488, loss1 : 1.465415, loss2 : 1.310966
train_step : 16489, loss1 : 1.188963, loss2 : 1.292025
train_step : 16490, loss1 : 0.666246, loss2 : 1.055264
train_step : 16491, loss1 : 1.476264, loss2 : 1.065084
train_step : 16492, loss1 : 3.693008, loss2 : 0.931560
train_step : 16493, loss1 : 1.096531, loss2 : 1.529893
train_step : 16494, loss1 : 1.116466, loss2 : 1.645488
train_step : 16495, loss1 : 1.163888, loss2 : 1.989665
train_step : 16496, loss1 : 1.693892, loss2 : 1.009176
train_step : 16497, loss1 : 0.965587, loss2 : 1.919884
train_step : 16498, loss1 : 1.059414, loss2 : 0.445824
train_step : 16499, loss1 : 1.438097, loss2 : 1.169184
train_step : 16500, loss1 : 1.670205, loss2 : 1.935150
train_step : 16501, loss1 : 1.733806, loss2 : 3.558479
train_step : 16502, loss1 : 2.069305, loss2 : 1.671056
train_step : 16503, loss1 : 1.335486, loss2 : 2.461464
train_step : 16504, loss1 : 2.317183, loss2 : 0.946584
train_step : 16505, loss1 : 1.935951, loss2 : 1.543956
train_step : 16506, loss1 : 2.480809, loss2 : 1.602398
train_step : 16507, loss1 : 2.398041, loss2 : 1.792406
train_step : 16508, loss1 : 1.662182, loss2 : 0.999925
train_step : 16509, loss1 : 1.152856, loss2 : 0.864068
train_step : 16510, loss1 : 1.896110, loss2 : 0.977884
train_step : 16511, loss1 : 0.927844, loss2 : 1.015411
train_step : 16512, loss1 : 1.466667, loss2 : 2.370285
train_step : 16513, loss1 : 1.207980, loss2 : 1.743397
train_step : 16514, loss1 : 1.372741, loss2 : 2.873790
train_step : 16515, loss1 : 1.567264, loss2 : 0.511006
train_step : 16516, loss1 : 0.613662, loss2 : 1.209966
train_step : 16517, loss1 : 1.128052, loss2 : 0.816954
train_step : 16518, loss1 : 1.582445, loss2 : 1.579596
train_step : 16519, loss1 : 1.746334, loss2 : 1.568603
train_step : 16520, loss1 : 1.330639, loss2 : 2.216917
train_step : 16521, loss1 : 2.909628, loss2 : 1.685785
train_step : 16522, loss1 : 2.305649, loss2 : 0.834827
train_step : 16523, loss1 : 1.255129, loss2 : 1.068950
train_step : 16524, loss1 : 0.716729, loss2 : 1.098415
train_step : 16525, loss1 : 1.254884, loss2 : 1.721652
train_step : 16526, loss1 : 1.149281, loss2 : 1.819566
train_step : 16527, loss1 : 1.339916, loss2 : 1.235800
train_step : 16528, loss1 : 1.823418, loss2 : 0.773416
train_step : 16529, loss1 : 1.092370, loss2 : 1.132989
train_step : 16530, loss1 : 1.882342, loss2 : 1.317931
train_step : 16531, loss1 : 1.236728, loss2 : 1.524425
train_step : 16532, loss1 : 1.888394, loss2 : 0.907823
train_step : 16533, loss1 : 2.163169, loss2 : 1.121191
train_step : 16534, loss1 : 2.100906, loss2 : 1.305602
train_step : 16535, loss1 : 0.904307, loss2 : 1.029653
train_step : 16536, loss1 : 1.975677, loss2 : 0.890187
train_step : 16537, loss1 : 1.323218, loss2 : 0.884051
train_step : 16538, loss1 : 1.029351, loss2 : 0.948514
train_step : 16539, loss1 : 1.678337, loss2 : 2.057709
train_step : 16540, loss1 : 1.021407, loss2 : 0.939673
train_step : 16541, loss1 : 1.550288, loss2 : 0.892134
train_step : 16542, loss1 : 1.043079, loss2 : 0.561586
train_step : 16543, loss1 : 0.675538, loss2 : 1.102923
train_step : 16544, loss1 : 0.689635, loss2 : 0.875808
train_step : 16545, loss1 : 0.939422, loss2 : 1.412681
train_step : 16546, loss1 : 1.619341, loss2 : 0.976849
train_step : 16547, loss1 : 2.305833, loss2 : 1.046584
train_step : 16548, loss1 : 1.235961, loss2 : 1.811213
train_step : 16549, loss1 : 2.208160, loss2 : 1.914165
train_step : 16550, loss1 : 1.794785, loss2 : 2.202897
train_step : 16551, loss1 : 1.726400, loss2 : 2.307166
train_step : 16552, loss1 : 1.291867, loss2 : 2.029383
train_step : 16553, loss1 : 1.783844, loss2 : 2.175609
train_step : 16554, loss1 : 1.452177, loss2 : 1.876695
train_step : 16555, loss1 : 1.169412, loss2 : 1.760768
train_step : 16556, loss1 : 1.227389, loss2 : 0.992850
train_step : 16557, loss1 : 1.290312, loss2 : 1.278710
train_step : 16558, loss1 : 1.843720, loss2 : 1.557572
train_step : 16559, loss1 : 1.473594, loss2 : 1.025860
train_step : 16560, loss1 : 1.303157, loss2 : 1.493905
train_step : 16561, loss1 : 1.146546, loss2 : 0.806695
train_step : 16562, loss1 : 1.128922, loss2 : 1.535685
train_step : 16563, loss1 : 1.062793, loss2 : 1.486546
train_step : 16564, loss1 : 1.497221, loss2 : 1.851179
train_step : 16565, loss1 : 1.469796, loss2 : 1.231673
train_step : 16566, loss1 : 1.290976, loss2 : 2.170029
train_step : 16567, loss1 : 0.646031, loss2 : 1.514212
train_step : 16568, loss1 : 0.757089, loss2 : 1.191404
train_step : 16569, loss1 : 1.320613, loss2 : 2.373812
train_step : 16570, loss1 : 0.653303, loss2 : 1.268338
train_step : 16571, loss1 : 1.078697, loss2 : 1.477953
train_step : 16572, loss1 : 0.765334, loss2 : 1.016066
train_step : 16573, loss1 : 1.034563, loss2 : 0.896563
train_step : 16574, loss1 : 1.484273, loss2 : 1.121546
train_step : 16575, loss1 : 0.720292, loss2 : 0.537292
train_step : 16576, loss1 : 2.376316, loss2 : 1.188307
train_step : 16577, loss1 : 1.902731, loss2 : 1.810574
train_step : 16578, loss1 : 1.563868, loss2 : 1.992789
train_step : 16579, loss1 : 1.990932, loss2 : 2.179133
train_step : 16580, loss1 : 1.951784, loss2 : 2.137925
train_step : 16581, loss1 : 2.630967, loss2 : 2.456719
train_step : 16582, loss1 : 2.343520, loss2 : 0.953012
train_step : 16583, loss1 : 2.041520, loss2 : 1.453824
train_step : 16584, loss1 : 1.341687, loss2 : 1.176094
train_step : 16585, loss1 : 1.526689, loss2 : 1.469671
train_step : 16586, loss1 : 1.191347, loss2 : 0.718034
train_step : 16587, loss1 : 0.773130, loss2 : 1.155864
train_step : 16588, loss1 : 1.482684, loss2 : 1.113277
train_step : 16589, loss1 : 0.738792, loss2 : 0.860569
train_step : 16590, loss1 : 0.781723, loss2 : 1.152885
train_step : 16591, loss1 : 0.971144, loss2 : 0.592888
train_step : 16592, loss1 : 1.270955, loss2 : 0.737767
train_step : 16593, loss1 : 0.970581, loss2 : 0.857820
train_step : 16594, loss1 : 1.411261, loss2 : 0.711683
train_step : 16595, loss1 : 1.663632, loss2 : 1.020521
train_step : 16596, loss1 : 1.434146, loss2 : 1.296923
train_step : 16597, loss1 : 1.113630, loss2 : 1.366414
train_step : 16598, loss1 : 0.939518, loss2 : 1.442367
train_step : 16599, loss1 : 1.328142, loss2 : 0.742546
train_step : 16600, loss1 : 1.364279, loss2 : 1.761268
train_step : 16601, loss1 : 2.727776, loss2 : 1.455525
train_step : 16602, loss1 : 2.134303, loss2 : 1.744715
train_step : 16603, loss1 : 1.780701, loss2 : 2.116525
train_step : 16604, loss1 : 2.140923, loss2 : 1.644334
train_step : 16605, loss1 : 1.781898, loss2 : 1.416327
train_step : 16606, loss1 : 1.014612, loss2 : 1.119883
train_step : 16607, loss1 : 1.539408, loss2 : 1.713844
train_step : 16608, loss1 : 0.775476, loss2 : 1.346361
train_step : 16609, loss1 : 1.235164, loss2 : 1.142948
train_step : 16610, loss1 : 1.507031, loss2 : 1.398209
train_step : 16611, loss1 : 1.897909, loss2 : 2.339865
train_step : 16612, loss1 : 2.272293, loss2 : 1.080449
train_step : 16613, loss1 : 1.234531, loss2 : 0.731841
train_step : 16614, loss1 : 0.878753, loss2 : 1.085920
train_step : 16615, loss1 : 1.169517, loss2 : 1.639724
train_step : 16616, loss1 : 1.654454, loss2 : 0.680735
train_step : 16617, loss1 : 0.670202, loss2 : 2.447357
train_step : 16618, loss1 : 1.162982, loss2 : 0.692126
train_step : 16619, loss1 : 0.602216, loss2 : 0.991524
train_step : 16620, loss1 : 1.821915, loss2 : 1.307467
train_step : 16621, loss1 : 1.590822, loss2 : 1.589845
train_step : 16622, loss1 : 2.216829, loss2 : 2.008661
train_step : 16623, loss1 : 1.376053, loss2 : 2.262407
train_step : 16624, loss1 : 1.936574, loss2 : 1.826759
train_step : 16625, loss1 : 1.081686, loss2 : 1.579005
train_step : 16626, loss1 : 1.167364, loss2 : 1.322896
train_step : 16627, loss1 : 0.773779, loss2 : 0.968913
train_step : 16628, loss1 : 1.752333, loss2 : 1.064589
train_step : 16629, loss1 : 2.215714, loss2 : 1.305407
train_step : 16630, loss1 : 1.223852, loss2 : 0.752365
train_step : 16631, loss1 : 1.153028, loss2 : 1.004192
train_step : 16632, loss1 : 1.422705, loss2 : 0.962032
train_step : 16633, loss1 : 1.433963, loss2 : 0.895245
train_step : 16634, loss1 : 0.904520, loss2 : 1.496632
train_step : 16635, loss1 : 2.340290, loss2 : 1.283144
train_step : 16636, loss1 : 2.869840, loss2 : 1.197345
train_step : 16637, loss1 : 1.313235, loss2 : 1.597794
train_step : 16638, loss1 : 0.907507, loss2 : 0.901972
train_step : 16639, loss1 : 0.375582, loss2 : 0.641809
train_step : 16640, loss1 : 0.706063, loss2 : 2.023406
train_step : 16641, loss1 : 0.904699, loss2 : 0.894345
train_step : 16642, loss1 : 0.568810, loss2 : 1.037693
train_step : 16643, loss1 : 1.002799, loss2 : 1.680779
train_step : 16644, loss1 : 1.116508, loss2 : 1.297112
train_step : 16645, loss1 : 2.188415, loss2 : 1.455040
train_step : 16646, loss1 : 1.648153, loss2 : 2.644842
train_step : 16647, loss1 : 1.676078, loss2 : 1.976594
train_step : 16648, loss1 : 1.322001, loss2 : 0.903862
train_step : 16649, loss1 : 1.831097, loss2 : 1.808030
train_step : 16650, loss1 : 1.601217, loss2 : 2.240591
train_step : 16651, loss1 : 1.348247, loss2 : 1.730699
train_step : 16652, loss1 : 0.947485, loss2 : 0.979702
train_step : 16653, loss1 : 1.275684, loss2 : 0.880135
train_step : 16654, loss1 : 1.470669, loss2 : 1.351496
train_step : 16655, loss1 : 1.332700, loss2 : 0.890277
train_step : 16656, loss1 : 0.875495, loss2 : 1.116023
train_step : 16657, loss1 : 1.742851, loss2 : 1.079312
train_step : 16658, loss1 : 0.904146, loss2 : 1.392354
train_step : 16659, loss1 : 1.057267, loss2 : 1.580062
train_step : 16660, loss1 : 0.999340, loss2 : 0.854569
train_step : 16661, loss1 : 1.243466, loss2 : 0.739937
train_step : 16662, loss1 : 2.069632, loss2 : 1.432564
train_step : 16663, loss1 : 1.636774, loss2 : 1.111315
train_step : 16664, loss1 : 0.798120, loss2 : 1.675810
train_step : 16665, loss1 : 1.174723, loss2 : 1.309995
train_step : 16666, loss1 : 1.337692, loss2 : 0.830329
train_step : 16667, loss1 : 1.787436, loss2 : 1.378022
train_step : 16668, loss1 : 0.472601, loss2 : 1.160061
train_step : 16669, loss1 : 1.585754, loss2 : 0.903760
train_step : 16670, loss1 : 1.558128, loss2 : 1.046152
train_step : 16671, loss1 : 0.792095, loss2 : 2.352080
train_step : 16672, loss1 : 1.272161, loss2 : 1.995641
train_step : 16673, loss1 : 1.064135, loss2 : 1.334383
train_step : 16674, loss1 : 1.824843, loss2 : 0.946925
train_step : 16675, loss1 : 0.971735, loss2 : 1.540081
train_step : 16676, loss1 : 2.029793, loss2 : 1.278133
train_step : 16677, loss1 : 1.973666, loss2 : 2.470736
train_step : 16678, loss1 : 0.869509, loss2 : 1.123571
train_step : 16679, loss1 : 0.708289, loss2 : 1.162407
train_step : 16680, loss1 : 2.419720, loss2 : 1.276543
train_step : 16681, loss1 : 0.937257, loss2 : 0.956788
train_step : 16682, loss1 : 0.764509, loss2 : 0.846265
train_step : 16683, loss1 : 0.885535, loss2 : 0.924220
train_step : 16684, loss1 : 1.114992, loss2 : 3.299339
train_step : 16685, loss1 : 1.365497, loss2 : 0.733857
train_step : 16686, loss1 : 0.704219, loss2 : 0.564478
train_step : 16687, loss1 : 0.784011, loss2 : 1.874167
train_step : 16688, loss1 : 2.115639, loss2 : 1.282744
train_step : 16689, loss1 : 1.590341, loss2 : 1.201964
train_step : 16690, loss1 : 2.031485, loss2 : 2.018059
train_step : 16691, loss1 : 1.605941, loss2 : 2.149252
train_step : 16692, loss1 : 2.207113, loss2 : 2.209528
train_step : 16693, loss1 : 2.310080, loss2 : 1.198552
train_step : 16694, loss1 : 1.933536, loss2 : 1.589392
train_step : 16695, loss1 : 1.642336, loss2 : 1.827304
train_step : 16696, loss1 : 1.547653, loss2 : 1.461121
train_step : 16697, loss1 : 2.287997, loss2 : 1.390259
train_step : 16698, loss1 : 1.870877, loss2 : 1.539412
train_step : 16699, loss1 : 1.643453, loss2 : 0.942521
train_step : 16700, loss1 : 1.063752, loss2 : 1.271908
train_step : 16701, loss1 : 1.519803, loss2 : 1.527136
train_step : 16702, loss1 : 1.103159, loss2 : 1.204041
train_step : 16703, loss1 : 1.288524, loss2 : 0.858644
train_step : 16704, loss1 : 2.604848, loss2 : 1.289743
train_step : 16705, loss1 : 1.047115, loss2 : 1.370966
train_step : 16706, loss1 : 0.769854, loss2 : 2.036103
train_step : 16707, loss1 : 1.409405, loss2 : 1.390766
train_step : 16708, loss1 : 0.379298, loss2 : 1.465923
train_step : 16709, loss1 : 0.760960, loss2 : 1.926697
train_step : 16710, loss1 : 1.379830, loss2 : 1.583829
train_step : 16711, loss1 : 1.031218, loss2 : 2.197073
train_step : 16712, loss1 : 1.522854, loss2 : 2.014893
train_step : 16713, loss1 : 2.367278, loss2 : 2.730878
train_step : 16714, loss1 : 3.630414, loss2 : 2.487575
train_step : 16715, loss1 : 3.801118, loss2 : 2.666474
train_step : 16716, loss1 : 3.357548, loss2 : 4.279449
train_step : 16717, loss1 : 3.916421, loss2 : 3.730479
train_step : 16718, loss1 : 5.814624, loss2 : 4.135009
train_step : 16719, loss1 : 3.683129, loss2 : 1.886745
train_step : 16720, loss1 : 1.354456, loss2 : 1.418052
train_step : 16721, loss1 : 2.591069, loss2 : 1.434673
train_step : 16722, loss1 : 1.225204, loss2 : 1.035788
train_step : 16723, loss1 : 0.662880, loss2 : 1.256565
train_step : 16724, loss1 : 1.436980, loss2 : 1.146247
train_step : 16725, loss1 : 1.137554, loss2 : 0.536413
train_step : 16726, loss1 : 1.206926, loss2 : 0.957235
train_step : 16727, loss1 : 0.819532, loss2 : 1.236050
train_step : 16728, loss1 : 0.990242, loss2 : 1.464308
train_step : 16729, loss1 : 1.328316, loss2 : 1.562532
train_step : 16730, loss1 : 1.145279, loss2 : 1.328256
train_step : 16731, loss1 : 1.001971, loss2 : 1.552598
train_step : 16732, loss1 : 1.068221, loss2 : 1.046766
train_step : 16733, loss1 : 1.482396, loss2 : 0.987002
train_step : 16734, loss1 : 1.522747, loss2 : 0.680667
train_step : 16735, loss1 : 1.496686, loss2 : 1.730048
train_step : 16736, loss1 : 0.985938, loss2 : 2.658336
train_step : 16737, loss1 : 1.500905, loss2 : 1.581163
train_step : 16738, loss1 : 1.314227, loss2 : 0.792910
train_step : 16739, loss1 : 0.957819, loss2 : 0.621962
train_step : 16740, loss1 : 2.482262, loss2 : 1.580308
train_step : 16741, loss1 : 1.603734, loss2 : 2.076648
train_step : 16742, loss1 : 0.718901, loss2 : 1.399998
train_step : 16743, loss1 : 0.959981, loss2 : 0.852343
train_step : 16744, loss1 : 0.920955, loss2 : 1.137537
train_step : 16745, loss1 : 1.061384, loss2 : 1.203797
train_step : 16746, loss1 : 1.113562, loss2 : 1.032330
train_step : 16747, loss1 : 0.936590, loss2 : 1.487430
train_step : 16748, loss1 : 0.783274, loss2 : 0.673381
train_step : 16749, loss1 : 0.679777, loss2 : 1.381112
train_step : 16750, loss1 : 1.395881, loss2 : 1.490893
train_step : 16751, loss1 : 1.045472, loss2 : 1.184594
train_step : 16752, loss1 : 0.925886, loss2 : 1.247276
train_step : 16753, loss1 : 1.642795, loss2 : 1.711276
train_step : 16754, loss1 : 1.395668, loss2 : 1.262067
train_step : 16755, loss1 : 1.040851, loss2 : 1.348330
train_step : 16756, loss1 : 0.416329, loss2 : 1.318163
train_step : 16757, loss1 : 1.613820, loss2 : 1.208388
train_step : 16758, loss1 : 1.450475, loss2 : 0.913883
train_step : 16759, loss1 : 0.926046, loss2 : 1.155672
train_step : 16760, loss1 : 1.393220, loss2 : 1.524423
train_step : 16761, loss1 : 1.467212, loss2 : 1.203724
train_step : 16762, loss1 : 1.093695, loss2 : 0.848958
train_step : 16763, loss1 : 1.006114, loss2 : 1.388342
train_step : 16764, loss1 : 0.949903, loss2 : 1.068381
train_step : 16765, loss1 : 0.745210, loss2 : 0.953783
train_step : 16766, loss1 : 1.141461, loss2 : 1.904428
train_step : 16767, loss1 : 2.319563, loss2 : 0.872581
train_step : 16768, loss1 : 0.812143, loss2 : 1.670650
train_step : 16769, loss1 : 0.824845, loss2 : 0.998628
train_step : 16770, loss1 : 1.434798, loss2 : 0.560180
train_step : 16771, loss1 : 1.347506, loss2 : 1.444162
train_step : 16772, loss1 : 1.503037, loss2 : 1.250644
train_step : 16773, loss1 : 0.784564, loss2 : 1.271406
train_step : 16774, loss1 : 1.290239, loss2 : 1.697196
train_step : 16775, loss1 : 1.766192, loss2 : 0.707795
train_step : 16776, loss1 : 0.433252, loss2 : 1.084857
train_step : 16777, loss1 : 1.192874, loss2 : 0.897280
train_step : 16778, loss1 : 1.130099, loss2 : 1.468241
train_step : 16779, loss1 : 1.443609, loss2 : 1.219728
train_step : 16780, loss1 : 0.826451, loss2 : 0.632574
train_step : 16781, loss1 : 0.589938, loss2 : 1.139263
train_step : 16782, loss1 : 1.101276, loss2 : 1.064220
train_step : 16783, loss1 : 1.207836, loss2 : 0.931950
train_step : 16784, loss1 : 1.180797, loss2 : 0.767623
train_step : 16785, loss1 : 0.415197, loss2 : 1.087888
train_step : 16786, loss1 : 0.752087, loss2 : 0.977245
train_step : 16787, loss1 : 0.877783, loss2 : 0.731050
train_step : 16788, loss1 : 0.825714, loss2 : 0.744828
train_step : 16789, loss1 : 1.103657, loss2 : 1.369435
train_step : 16790, loss1 : 1.017549, loss2 : 1.809202
train_step : 16791, loss1 : 1.047110, loss2 : 1.840522
train_step : 16792, loss1 : 0.904800, loss2 : 0.955944
train_step : 16793, loss1 : 0.800899, loss2 : 2.805106
train_step : 16794, loss1 : 1.725384, loss2 : 1.932894
train_step : 16795, loss1 : 0.854327, loss2 : 1.568431
train_step : 16796, loss1 : 0.982022, loss2 : 0.791148
train_step : 16797, loss1 : 0.465361, loss2 : 0.604826
train_step : 16798, loss1 : 1.403269, loss2 : 1.231162
train_step : 16799, loss1 : 1.953969, loss2 : 2.132773
train_step : 16800, loss1 : 1.557180, loss2 : 1.592376
train_step : 16801, loss1 : 1.789537, loss2 : 1.619713
train_step : 16802, loss1 : 0.947886, loss2 : 1.321998
train_step : 16803, loss1 : 1.855043, loss2 : 1.622159
train_step : 16804, loss1 : 1.376115, loss2 : 1.179113
train_step : 16805, loss1 : 1.348092, loss2 : 2.507740
train_step : 16806, loss1 : 2.002799, loss2 : 1.539095
train_step : 16807, loss1 : 1.029742, loss2 : 1.760474
train_step : 16808, loss1 : 1.255529, loss2 : 1.247661
train_step : 16809, loss1 : 0.896158, loss2 : 0.782262
train_step : 16810, loss1 : 1.921880, loss2 : 1.066721
train_step : 16811, loss1 : 1.350536, loss2 : 2.021662
train_step : 16812, loss1 : 1.285886, loss2 : 2.540927
train_step : 16813, loss1 : 1.573537, loss2 : 1.659956
train_step : 16814, loss1 : 1.241082, loss2 : 0.952894
train_step : 16815, loss1 : 1.611548, loss2 : 1.159590
train_step : 16816, loss1 : 1.236745, loss2 : 1.724707
train_step : 16817, loss1 : 1.142580, loss2 : 1.523498
train_step : 16818, loss1 : 1.187265, loss2 : 1.466884
train_step : 16819, loss1 : 1.050676, loss2 : 0.823947
train_step : 16820, loss1 : 1.500815, loss2 : 1.935077
train_step : 16821, loss1 : 1.654102, loss2 : 0.877563
train_step : 16822, loss1 : 0.878332, loss2 : 1.765481
train_step : 16823, loss1 : 0.669696, loss2 : 2.006455
train_step : 16824, loss1 : 0.848453, loss2 : 1.626683
train_step : 16825, loss1 : 1.129674, loss2 : 1.193860
train_step : 16826, loss1 : 1.227122, loss2 : 1.119603
train_step : 16827, loss1 : 1.312193, loss2 : 0.816331
train_step : 16828, loss1 : 1.220398, loss2 : 0.927351
train_step : 16829, loss1 : 1.093471, loss2 : 0.769272
train_step : 16830, loss1 : 1.362834, loss2 : 1.403878
train_step : 16831, loss1 : 1.017995, loss2 : 1.782429
train_step : 16832, loss1 : 0.681442, loss2 : 1.390644
train_step : 16833, loss1 : 1.661380, loss2 : 1.943392
train_step : 16834, loss1 : 1.287034, loss2 : 1.622642
train_step : 16835, loss1 : 1.818509, loss2 : 0.729612
train_step : 16836, loss1 : 1.266044, loss2 : 1.301302
train_step : 16837, loss1 : 0.807024, loss2 : 1.054306
train_step : 16838, loss1 : 0.876971, loss2 : 0.591106
train_step : 16839, loss1 : 1.418805, loss2 : 0.795691
train_step : 16840, loss1 : 0.610618, loss2 : 1.249378
train_step : 16841, loss1 : 1.257299, loss2 : 0.989635
train_step : 16842, loss1 : 1.211835, loss2 : 1.894896
train_step : 16843, loss1 : 1.245267, loss2 : 2.009424
train_step : 16844, loss1 : 2.178928, loss2 : 2.342558
train_step : 16845, loss1 : 0.996613, loss2 : 2.265494
train_step : 16846, loss1 : 1.019194, loss2 : 1.657074
train_step : 16847, loss1 : 1.849862, loss2 : 1.804168
train_step : 16848, loss1 : 1.197413, loss2 : 2.350636
train_step : 16849, loss1 : 1.988226, loss2 : 1.179681
train_step : 16850, loss1 : 1.180556, loss2 : 1.381028
train_step : 16851, loss1 : 0.693736, loss2 : 0.753783
train_step : 16852, loss1 : 0.871641, loss2 : 1.443091
train_step : 16853, loss1 : 0.914459, loss2 : 1.623437
train_step : 16854, loss1 : 1.038089, loss2 : 1.103554
train_step : 16855, loss1 : 1.342850, loss2 : 1.143949
train_step : 16856, loss1 : 3.248840, loss2 : 1.617555
train_step : 16857, loss1 : 2.754045, loss2 : 3.598119
train_step : 16858, loss1 : 2.956944, loss2 : 2.770963
train_step : 16859, loss1 : 3.104258, loss2 : 1.636636
train_step : 16860, loss1 : 2.926942, loss2 : 2.150227
train_step : 16861, loss1 : 2.163019, loss2 : 2.125526
train_step : 16862, loss1 : 0.804057, loss2 : 1.897074
train_step : 16863, loss1 : 1.917222, loss2 : 1.158397
train_step : 16864, loss1 : 0.862885, loss2 : 1.051728
train_step : 16865, loss1 : 1.249902, loss2 : 1.064329
train_step : 16866, loss1 : 1.121793, loss2 : 1.491812
train_step : 16867, loss1 : 2.380050, loss2 : 1.240134
train_step : 16868, loss1 : 0.997123, loss2 : 3.001083
train_step : 16869, loss1 : 1.381820, loss2 : 2.374696
train_step : 16870, loss1 : 1.434685, loss2 : 0.759155
train_step : 16871, loss1 : 1.460466, loss2 : 1.629994
train_step : 16872, loss1 : 1.857285, loss2 : 1.852495
train_step : 16873, loss1 : 0.793733, loss2 : 0.541865
train_step : 16874, loss1 : 1.180221, loss2 : 1.666486
train_step : 16875, loss1 : 1.536560, loss2 : 0.603236
train_step : 16876, loss1 : 1.306578, loss2 : 0.816691
train_step : 16877, loss1 : 0.997935, loss2 : 0.525959
train_step : 16878, loss1 : 0.801334, loss2 : 1.217744
train_step : 16879, loss1 : 0.895289, loss2 : 1.210513
train_step : 16880, loss1 : 1.156919, loss2 : 1.041901
train_step : 16881, loss1 : 0.779850, loss2 : 1.485827
train_step : 16882, loss1 : 1.845156, loss2 : 0.853326
train_step : 16883, loss1 : 1.742968, loss2 : 1.554262
train_step : 16884, loss1 : 1.187347, loss2 : 1.106349
train_step : 16885, loss1 : 0.973591, loss2 : 1.940363
train_step : 16886, loss1 : 1.427121, loss2 : 1.557197
train_step : 16887, loss1 : 1.655471, loss2 : 1.501135
train_step : 16888, loss1 : 1.587627, loss2 : 1.829385
train_step : 16889, loss1 : 1.370178, loss2 : 1.302042
train_step : 16890, loss1 : 1.451227, loss2 : 0.986638
train_step : 16891, loss1 : 1.524935, loss2 : 1.128435
train_step : 16892, loss1 : 1.787376, loss2 : 1.181321
train_step : 16893, loss1 : 1.346029, loss2 : 0.943721
train_step : 16894, loss1 : 1.636275, loss2 : 0.500049
train_step : 16895, loss1 : 1.116063, loss2 : 1.642754
train_step : 16896, loss1 : 1.501581, loss2 : 0.956795
train_step : 16897, loss1 : 0.606630, loss2 : 1.465690
train_step : 16898, loss1 : 1.239355, loss2 : 2.051123
train_step : 16899, loss1 : 1.042567, loss2 : 1.870835
train_step : 16900, loss1 : 1.363683, loss2 : 1.514476
train_step : 16901, loss1 : 1.022760, loss2 : 1.834906
train_step : 16902, loss1 : 0.863517, loss2 : 1.663945
train_step : 16903, loss1 : 1.348680, loss2 : 1.089619
train_step : 16904, loss1 : 0.997068, loss2 : 1.158597
train_step : 16905, loss1 : 0.867969, loss2 : 0.771347
train_step : 16906, loss1 : 1.348996, loss2 : 1.464351
train_step : 16907, loss1 : 0.998795, loss2 : 1.333667
train_step : 16908, loss1 : 0.959184, loss2 : 1.874724
train_step : 16909, loss1 : 0.956012, loss2 : 2.134476
train_step : 16910, loss1 : 1.321185, loss2 : 1.935446
train_step : 16911, loss1 : 0.905478, loss2 : 2.304903
train_step : 16912, loss1 : 0.680507, loss2 : 1.483362
train_step : 16913, loss1 : 1.104689, loss2 : 1.144370
train_step : 16914, loss1 : 1.705227, loss2 : 0.972501
train_step : 16915, loss1 : 1.027017, loss2 : 1.437456
train_step : 16916, loss1 : 0.694069, loss2 : 1.128730
train_step : 16917, loss1 : 0.883255, loss2 : 0.930410
train_step : 16918, loss1 : 1.155711, loss2 : 0.576341
train_step : 16919, loss1 : 1.340207, loss2 : 1.162308
train_step : 16920, loss1 : 1.050051, loss2 : 1.118565
train_step : 16921, loss1 : 1.488633, loss2 : 1.140625
train_step : 16922, loss1 : 1.242257, loss2 : 1.245270
train_step : 16923, loss1 : 1.205842, loss2 : 1.210526
train_step : 16924, loss1 : 2.151293, loss2 : 1.122132
train_step : 16925, loss1 : 1.097395, loss2 : 0.934389
train_step : 16926, loss1 : 1.087276, loss2 : 1.234461
train_step : 16927, loss1 : 1.626336, loss2 : 0.628685
train_step : 16928, loss1 : 1.267701, loss2 : 1.309847
train_step : 16929, loss1 : 1.150662, loss2 : 0.488585
train_step : 16930, loss1 : 1.463444, loss2 : 1.440469
train_step : 16931, loss1 : 1.035685, loss2 : 1.164550
train_step : 16932, loss1 : 0.738115, loss2 : 1.716916
train_step : 16933, loss1 : 1.047498, loss2 : 1.698090
train_step : 16934, loss1 : 0.790509, loss2 : 0.887226
train_step : 16935, loss1 : 0.965792, loss2 : 1.282565
train_step : 16936, loss1 : 0.835899, loss2 : 1.684042
train_step : 16937, loss1 : 0.696240, loss2 : 1.258445
train_step : 16938, loss1 : 0.862967, loss2 : 1.893156
train_step : 16939, loss1 : 1.140739, loss2 : 0.965867
train_step : 16940, loss1 : 1.926562, loss2 : 0.891665
train_step : 16941, loss1 : 2.154857, loss2 : 1.338440
train_step : 16942, loss1 : 0.546968, loss2 : 1.072447
train_step : 16943, loss1 : 1.779559, loss2 : 2.046114
train_step : 16944, loss1 : 0.824747, loss2 : 0.877248
train_step : 16945, loss1 : 1.521003, loss2 : 0.911715
train_step : 16946, loss1 : 2.975283, loss2 : 2.366940
train_step : 16947, loss1 : 4.397249, loss2 : 2.639998
train_step : 16948, loss1 : 4.505169, loss2 : 4.138277
train_step : 16949, loss1 : 1.565982, loss2 : 2.141798
train_step : 16950, loss1 : 1.275607, loss2 : 0.924139
train_step : 16951, loss1 : 1.198311, loss2 : 1.690389
train_step : 16952, loss1 : 1.392535, loss2 : 1.876602
train_step : 16953, loss1 : 1.807700, loss2 : 1.333102
train_step : 16954, loss1 : 3.089273, loss2 : 1.211938
train_step : 16955, loss1 : 1.815524, loss2 : 2.102416
train_step : 16956, loss1 : 0.547725, loss2 : 1.200446
train_step : 16957, loss1 : 1.082769, loss2 : 0.678884
train_step : 16958, loss1 : 0.878937, loss2 : 2.185687
train_step : 16959, loss1 : 0.884709, loss2 : 1.713167
train_step : 16960, loss1 : 1.111108, loss2 : 1.292809
train_step : 16961, loss1 : 1.654436, loss2 : 1.391711
train_step : 16962, loss1 : 1.813353, loss2 : 0.727483
train_step : 16963, loss1 : 1.399371, loss2 : 1.196240
train_step : 16964, loss1 : 1.432945, loss2 : 1.789187
train_step : 16965, loss1 : 3.480132, loss2 : 1.549536
train_step : 16966, loss1 : 1.454634, loss2 : 0.997341
train_step : 16967, loss1 : 1.123378, loss2 : 1.176687
train_step : 16968, loss1 : 1.610195, loss2 : 1.115972
train_step : 16969, loss1 : 0.899637, loss2 : 2.645869
train_step : 16970, loss1 : 1.599063, loss2 : 1.263102
train_step : 16971, loss1 : 1.070289, loss2 : 1.129448
train_step : 16972, loss1 : 1.273727, loss2 : 0.759724
train_step : 16973, loss1 : 1.403490, loss2 : 0.642897
train_step : 16974, loss1 : 1.972354, loss2 : 0.857798
train_step : 16975, loss1 : 0.974671, loss2 : 1.011017
train_step : 16976, loss1 : 0.989989, loss2 : 2.352868
train_step : 16977, loss1 : 0.958046, loss2 : 1.776851
train_step : 16978, loss1 : 0.818776, loss2 : 1.009330
train_step : 16979, loss1 : 1.318796, loss2 : 1.159479
train_step : 16980, loss1 : 1.129649, loss2 : 1.594959
train_step : 16981, loss1 : 1.373303, loss2 : 0.978022
train_step : 16982, loss1 : 1.701786, loss2 : 1.312654
train_step : 16983, loss1 : 1.406712, loss2 : 2.525067
train_step : 16984, loss1 : 2.594304, loss2 : 1.904213
train_step : 16985, loss1 : 2.027502, loss2 : 2.922987
train_step : 16986, loss1 : 2.217091, loss2 : 1.408239
train_step : 16987, loss1 : 1.628905, loss2 : 1.917141
train_step : 16988, loss1 : 0.878139, loss2 : 1.143813
train_step : 16989, loss1 : 1.287586, loss2 : 1.087759
train_step : 16990, loss1 : 1.283904, loss2 : 1.454151
train_step : 16991, loss1 : 0.964062, loss2 : 1.131137
train_step : 16992, loss1 : 0.781229, loss2 : 1.397893
train_step : 16993, loss1 : 1.124150, loss2 : 0.994447
train_step : 16994, loss1 : 0.954881, loss2 : 0.259066
train_step : 16995, loss1 : 1.565930, loss2 : 1.079339
train_step : 16996, loss1 : 1.370816, loss2 : 0.533532
train_step : 16997, loss1 : 1.264675, loss2 : 1.203108
train_step : 16998, loss1 : 0.828048, loss2 : 1.714824
train_step : 16999, loss1 : 0.890492, loss2 : 1.216533
train_step : 17000, loss1 : 1.441335, loss2 : 1.333927
train_step : 17001, loss1 : 1.253511, loss2 : 0.578609
train_step : 17002, loss1 : 1.765706, loss2 : 1.054880
train_step : 17003, loss1 : 0.712497, loss2 : 0.792548
train_step : 17004, loss1 : 1.449114, loss2 : 1.251925
train_step : 17005, loss1 : 2.262757, loss2 : 1.157038
train_step : 17006, loss1 : 1.063638, loss2 : 0.742665
train_step : 17007, loss1 : 0.543337, loss2 : 1.180434
train_step : 17008, loss1 : 0.922888, loss2 : 1.080204
train_step : 17009, loss1 : 1.112436, loss2 : 0.671840
train_step : 17010, loss1 : 2.139320, loss2 : 1.047526
train_step : 17011, loss1 : 2.213049, loss2 : 1.500359
train_step : 17012, loss1 : 2.031728, loss2 : 1.597289
train_step : 17013, loss1 : 2.868442, loss2 : 1.749650
train_step : 17014, loss1 : 2.404341, loss2 : 3.039235
train_step : 17015, loss1 : 4.220896, loss2 : 2.426037
train_step : 17016, loss1 : 2.828978, loss2 : 2.383581
train_step : 17017, loss1 : 2.136861, loss2 : 1.900017
train_step : 17018, loss1 : 2.771204, loss2 : 1.948643
train_step : 17019, loss1 : 1.741886, loss2 : 1.863343
train_step : 17020, loss1 : 1.800477, loss2 : 1.687929
train_step : 17021, loss1 : 0.940682, loss2 : 1.990599
train_step : 17022, loss1 : 2.024211, loss2 : 1.217053
train_step : 17023, loss1 : 1.726321, loss2 : 2.613853
train_step : 17024, loss1 : 3.490900, loss2 : 2.367601
train_step : 17025, loss1 : 2.715111, loss2 : 2.662595
train_step : 17026, loss1 : 3.899694, loss2 : 3.687013
train_step : 17027, loss1 : 2.055160, loss2 : 3.331808
train_step : 17028, loss1 : 2.151668, loss2 : 3.282830
train_step : 17029, loss1 : 0.778917, loss2 : 2.022208
train_step : 17030, loss1 : 1.910421, loss2 : 1.546283
train_step : 17031, loss1 : 2.666569, loss2 : 1.356205
train_step : 17032, loss1 : 1.545583, loss2 : 1.721688
train_step : 17033, loss1 : 0.852741, loss2 : 0.919140
train_step : 17034, loss1 : 1.930040, loss2 : 1.317793
train_step : 17035, loss1 : 1.016941, loss2 : 1.889642
train_step : 17036, loss1 : 1.605298, loss2 : 1.855838
train_step : 17037, loss1 : 0.897976, loss2 : 2.333579
train_step : 17038, loss1 : 1.776030, loss2 : 2.584993
train_step : 17039, loss1 : 2.585570, loss2 : 2.566068
train_step : 17040, loss1 : 3.921627, loss2 : 4.273241
train_step : 17041, loss1 : 4.530622, loss2 : 5.030111
train_step : 17042, loss1 : 6.067960, loss2 : 5.997184
train_step : 17043, loss1 : 4.837052, loss2 : 6.036505
train_step : 17044, loss1 : 5.261480, loss2 : 7.470671
train_step : 17045, loss1 : 2.080943, loss2 : 2.771646
train_step : 17046, loss1 : 2.600365, loss2 : 1.804096
train_step : 17047, loss1 : 1.976168, loss2 : 1.783960
train_step : 17048, loss1 : 4.127834, loss2 : 1.392215
train_step : 17049, loss1 : 0.862784, loss2 : 1.014495
train_step : 17050, loss1 : 1.057695, loss2 : 0.828153
train_step : 17051, loss1 : 1.412199, loss2 : 3.992614
train_step : 17052, loss1 : 2.069552, loss2 : 1.733038
train_step : 17053, loss1 : 1.372908, loss2 : 1.644522
train_step : 17054, loss1 : 2.075196, loss2 : 1.424914
train_step : 17055, loss1 : 2.404329, loss2 : 2.245161
train_step : 17056, loss1 : 2.832910, loss2 : 2.241656
train_step : 17057, loss1 : 1.701859, loss2 : 1.228396
train_step : 17058, loss1 : 1.613926, loss2 : 0.888269
train_step : 17059, loss1 : 1.482012, loss2 : 1.416702
train_step : 17060, loss1 : 1.680324, loss2 : 1.515095
train_step : 17061, loss1 : 1.083738, loss2 : 0.964890
train_step : 17062, loss1 : 0.778465, loss2 : 1.044235
train_step : 17063, loss1 : 1.332376, loss2 : 1.108731
train_step : 17064, loss1 : 1.069982, loss2 : 0.921259
train_step : 17065, loss1 : 1.314028, loss2 : 0.978948
train_step : 17066, loss1 : 2.000237, loss2 : 0.928203
train_step : 17067, loss1 : 1.420816, loss2 : 1.417249
train_step : 17068, loss1 : 0.845130, loss2 : 0.970321
train_step : 17069, loss1 : 0.894042, loss2 : 0.734072
train_step : 17070, loss1 : 1.136837, loss2 : 1.419586
train_step : 17071, loss1 : 0.662315, loss2 : 1.593419
train_step : 17072, loss1 : 0.758029, loss2 : 1.083915
train_step : 17073, loss1 : 1.072203, loss2 : 0.625050
train_step : 17074, loss1 : 0.895396, loss2 : 0.975437
train_step : 17075, loss1 : 1.268584, loss2 : 1.600686
train_step : 17076, loss1 : 0.808817, loss2 : 1.158002
train_step : 17077, loss1 : 1.645879, loss2 : 0.884019
train_step : 17078, loss1 : 0.707539, loss2 : 1.227947
train_step : 17079, loss1 : 0.938704, loss2 : 1.456421
train_step : 17080, loss1 : 1.058134, loss2 : 0.801222
train_step : 17081, loss1 : 1.344206, loss2 : 0.473161
train_step : 17082, loss1 : 0.689120, loss2 : 1.081836
train_step : 17083, loss1 : 1.403005, loss2 : 1.352112
train_step : 17084, loss1 : 1.157925, loss2 : 1.426060
train_step : 17085, loss1 : 0.620171, loss2 : 1.751312
train_step : 17086, loss1 : 0.976775, loss2 : 1.718517
train_step : 17087, loss1 : 1.569248, loss2 : 1.285423
train_step : 17088, loss1 : 1.737943, loss2 : 1.712359
train_step : 17089, loss1 : 1.068025, loss2 : 1.226540
train_step : 17090, loss1 : 0.991314, loss2 : 1.206200
train_step : 17091, loss1 : 1.524696, loss2 : 1.013935
train_step : 17092, loss1 : 1.041510, loss2 : 1.357010
train_step : 17093, loss1 : 0.989141, loss2 : 0.776899
train_step : 17094, loss1 : 0.983855, loss2 : 0.940823
train_step : 17095, loss1 : 1.668317, loss2 : 0.553751
train_step : 17096, loss1 : 1.545614, loss2 : 0.623493
train_step : 17097, loss1 : 1.091360, loss2 : 1.167195
train_step : 17098, loss1 : 1.586473, loss2 : 1.758605
train_step : 17099, loss1 : 1.129100, loss2 : 1.464112
train_step : 17100, loss1 : 1.134828, loss2 : 2.220483
train_step : 17101, loss1 : 1.750317, loss2 : 2.670576
train_step : 17102, loss1 : 1.592124, loss2 : 1.009264
train_step : 17103, loss1 : 1.087563, loss2 : 2.146208
train_step : 17104, loss1 : 1.138744, loss2 : 1.403484
train_step : 17105, loss1 : 1.743742, loss2 : 1.347094
train_step : 17106, loss1 : 0.556076, loss2 : 0.630475
train_step : 17107, loss1 : 1.104871, loss2 : 0.953277
train_step : 17108, loss1 : 1.678408, loss2 : 0.888325
train_step : 17109, loss1 : 1.213457, loss2 : 0.596100
train_step : 17110, loss1 : 1.448491, loss2 : 0.861733
train_step : 17111, loss1 : 0.901977, loss2 : 1.829584
train_step : 17112, loss1 : 1.914015, loss2 : 1.596735
train_step : 17113, loss1 : 1.859465, loss2 : 1.440106
train_step : 17114, loss1 : 1.033592, loss2 : 1.079041
train_step : 17115, loss1 : 1.200763, loss2 : 0.764530
train_step : 17116, loss1 : 1.443106, loss2 : 1.608674
train_step : 17117, loss1 : 1.625924, loss2 : 1.557925
train_step : 17118, loss1 : 1.070158, loss2 : 1.534345
train_step : 17119, loss1 : 2.010962, loss2 : 2.622493
train_step : 17120, loss1 : 1.999149, loss2 : 1.438701
train_step : 17121, loss1 : 2.051838, loss2 : 2.626090
train_step : 17122, loss1 : 1.681910, loss2 : 3.813319
train_step : 17123, loss1 : 3.065213, loss2 : 2.721972
train_step : 17124, loss1 : 1.752114, loss2 : 2.398357
train_step : 17125, loss1 : 2.863325, loss2 : 3.498686
train_step : 17126, loss1 : 3.720868, loss2 : 3.595289
train_step : 17127, loss1 : 4.171291, loss2 : 3.737817
train_step : 17128, loss1 : 1.557036, loss2 : 1.778275
train_step : 17129, loss1 : 2.303205, loss2 : 2.028167
train_step : 17130, loss1 : 1.344693, loss2 : 2.462733
train_step : 17131, loss1 : 1.385942, loss2 : 1.215607
train_step : 17132, loss1 : 1.378722, loss2 : 1.678854
train_step : 17133, loss1 : 2.763316, loss2 : 2.162819
train_step : 17134, loss1 : 1.755368, loss2 : 0.967415
train_step : 17135, loss1 : 0.733515, loss2 : 1.344335
train_step : 17136, loss1 : 0.491837, loss2 : 3.259106
train_step : 17137, loss1 : 0.824760, loss2 : 1.410325
train_step : 17138, loss1 : 1.007086, loss2 : 2.325173
train_step : 17139, loss1 : 0.696318, loss2 : 1.050754
train_step : 17140, loss1 : 1.285953, loss2 : 1.033006
train_step : 17141, loss1 : 1.305596, loss2 : 1.268952
train_step : 17142, loss1 : 1.148635, loss2 : 0.748953
train_step : 17143, loss1 : 0.836604, loss2 : 1.003524
train_step : 17144, loss1 : 1.078150, loss2 : 0.866079
train_step : 17145, loss1 : 1.409009, loss2 : 1.520200
train_step : 17146, loss1 : 1.954609, loss2 : 2.108856
train_step : 17147, loss1 : 2.201265, loss2 : 1.541217
train_step : 17148, loss1 : 1.486727, loss2 : 1.852441
train_step : 17149, loss1 : 1.822639, loss2 : 1.710694
train_step : 17150, loss1 : 2.185910, loss2 : 1.799511
train_step : 17151, loss1 : 2.115051, loss2 : 2.698359
train_step : 17152, loss1 : 2.010748, loss2 : 2.796685
train_step : 17153, loss1 : 1.586018, loss2 : 1.272342
train_step : 17154, loss1 : 2.255481, loss2 : 1.909090
train_step : 17155, loss1 : 0.883193, loss2 : 1.614623
train_step : 17156, loss1 : 1.899019, loss2 : 1.083602
train_step : 17157, loss1 : 0.971416, loss2 : 1.053756
train_step : 17158, loss1 : 1.534253, loss2 : 1.174465
train_step : 17159, loss1 : 1.063040, loss2 : 1.403374
train_step : 17160, loss1 : 0.908145, loss2 : 0.956255
train_step : 17161, loss1 : 1.506325, loss2 : 1.403105
train_step : 17162, loss1 : 1.109494, loss2 : 0.981726
train_step : 17163, loss1 : 0.837906, loss2 : 1.407848
train_step : 17164, loss1 : 1.013240, loss2 : 1.314493
train_step : 17165, loss1 : 2.139671, loss2 : 1.729984
train_step : 17166, loss1 : 2.603395, loss2 : 2.412466
train_step : 17167, loss1 : 1.738967, loss2 : 1.990728
train_step : 17168, loss1 : 2.518240, loss2 : 1.951305
train_step : 17169, loss1 : 2.525738, loss2 : 3.605834
train_step : 17170, loss1 : 4.554678, loss2 : 2.817742
train_step : 17171, loss1 : 2.342923, loss2 : 2.570489
train_step : 17172, loss1 : 1.938399, loss2 : 1.929148
train_step : 17173, loss1 : 1.155836, loss2 : 0.884450
train_step : 17174, loss1 : 0.628100, loss2 : 1.324702
train_step : 17175, loss1 : 1.538416, loss2 : 1.386325
train_step : 17176, loss1 : 1.683772, loss2 : 1.056488
train_step : 17177, loss1 : 0.530060, loss2 : 1.126483
train_step : 17178, loss1 : 0.728011, loss2 : 1.252198
train_step : 17179, loss1 : 0.600524, loss2 : 0.508622
train_step : 17180, loss1 : 1.657831, loss2 : 1.027959
train_step : 17181, loss1 : 0.954310, loss2 : 0.917276
train_step : 17182, loss1 : 0.740794, loss2 : 1.161400
train_step : 17183, loss1 : 1.503139, loss2 : 1.172838
train_step : 17184, loss1 : 0.910665, loss2 : 1.118814
train_step : 17185, loss1 : 2.161004, loss2 : 1.502723
train_step : 17186, loss1 : 0.757982, loss2 : 1.305951
train_step : 17187, loss1 : 1.420847, loss2 : 0.992745
train_step : 17188, loss1 : 0.953120, loss2 : 1.431452
train_step : 17189, loss1 : 1.222880, loss2 : 1.201655
train_step : 17190, loss1 : 0.611732, loss2 : 1.061244
train_step : 17191, loss1 : 0.863275, loss2 : 0.903155
train_step : 17192, loss1 : 1.156782, loss2 : 0.866539
train_step : 17193, loss1 : 1.041746, loss2 : 0.949947
train_step : 17194, loss1 : 0.974845, loss2 : 1.292061
train_step : 17195, loss1 : 0.955854, loss2 : 1.551728
train_step : 17196, loss1 : 1.817302, loss2 : 1.133870
train_step : 17197, loss1 : 1.226058, loss2 : 0.986858
train_step : 17198, loss1 : 0.383681, loss2 : 1.662639
train_step : 17199, loss1 : 0.918814, loss2 : 0.704792
train_step : 17200, loss1 : 0.794012, loss2 : 0.865036
train_step : 17201, loss1 : 0.583383, loss2 : 1.094942
train_step : 17202, loss1 : 2.116457, loss2 : 1.461834
train_step : 17203, loss1 : 2.393176, loss2 : 1.414841
train_step : 17204, loss1 : 1.102945, loss2 : 1.356331
train_step : 17205, loss1 : 0.959431, loss2 : 0.446838
train_step : 17206, loss1 : 0.874887, loss2 : 0.390538
train_step : 17207, loss1 : 0.934423, loss2 : 1.285499
train_step : 17208, loss1 : 0.795002, loss2 : 0.795893
train_step : 17209, loss1 : 0.651424, loss2 : 1.158157
train_step : 17210, loss1 : 1.119591, loss2 : 0.928568
train_step : 17211, loss1 : 1.018937, loss2 : 1.026716
train_step : 17212, loss1 : 1.288285, loss2 : 0.989130
train_step : 17213, loss1 : 1.471406, loss2 : 0.891845
train_step : 17214, loss1 : 0.844684, loss2 : 1.158349
train_step : 17215, loss1 : 2.138950, loss2 : 1.492024
train_step : 17216, loss1 : 1.630242, loss2 : 1.808447
train_step : 17217, loss1 : 1.373449, loss2 : 1.660948
train_step : 17218, loss1 : 1.419885, loss2 : 1.488328
train_step : 17219, loss1 : 2.493608, loss2 : 1.895807
train_step : 17220, loss1 : 0.905192, loss2 : 1.085223
train_step : 17221, loss1 : 0.864967, loss2 : 1.608416
train_step : 17222, loss1 : 1.379329, loss2 : 1.506380
train_step : 17223, loss1 : 1.181260, loss2 : 1.454145
train_step : 17224, loss1 : 1.003942, loss2 : 0.993697
train_step : 17225, loss1 : 0.936798, loss2 : 1.080090
train_step : 17226, loss1 : 1.416893, loss2 : 1.046132
train_step : 17227, loss1 : 1.208276, loss2 : 1.357235
train_step : 17228, loss1 : 1.000018, loss2 : 0.510092
train_step : 17229, loss1 : 1.008528, loss2 : 0.833432
train_step : 17230, loss1 : 1.431947, loss2 : 1.178380
train_step : 17231, loss1 : 1.558544, loss2 : 0.606037
train_step : 17232, loss1 : 1.327746, loss2 : 1.719187
train_step : 17233, loss1 : 1.746113, loss2 : 0.924201
train_step : 17234, loss1 : 1.501214, loss2 : 0.855484
train_step : 17235, loss1 : 2.034435, loss2 : 1.623700
train_step : 17236, loss1 : 1.591990, loss2 : 1.398673
train_step : 17237, loss1 : 2.351686, loss2 : 1.405883
train_step : 17238, loss1 : 0.953878, loss2 : 1.134851
train_step : 17239, loss1 : 1.223185, loss2 : 0.981494
train_step : 17240, loss1 : 1.718651, loss2 : 1.438727
train_step : 17241, loss1 : 1.991788, loss2 : 1.397538
train_step : 17242, loss1 : 1.758594, loss2 : 2.150454
train_step : 17243, loss1 : 2.477655, loss2 : 1.423111
train_step : 17244, loss1 : 2.723567, loss2 : 2.123546
train_step : 17245, loss1 : 2.368207, loss2 : 1.077637
train_step : 17246, loss1 : 2.325307, loss2 : 1.972583
train_step : 17247, loss1 : 1.713807, loss2 : 2.729710
train_step : 17248, loss1 : 1.503007, loss2 : 2.132026
train_step : 17249, loss1 : 1.502053, loss2 : 1.086446
train_step : 17250, loss1 : 1.284813, loss2 : 1.119755
train_step : 17251, loss1 : 1.659388, loss2 : 1.069795
train_step : 17252, loss1 : 1.204537, loss2 : 1.192121
train_step : 17253, loss1 : 1.257083, loss2 : 0.684906
train_step : 17254, loss1 : 1.678801, loss2 : 1.547014
train_step : 17255, loss1 : 0.971414, loss2 : 1.557485
train_step : 17256, loss1 : 1.838821, loss2 : 1.659709
train_step : 17257, loss1 : 0.522458, loss2 : 0.798710
train_step : 17258, loss1 : 1.209784, loss2 : 1.967792
train_step : 17259, loss1 : 1.155520, loss2 : 1.213372
train_step : 17260, loss1 : 1.630030, loss2 : 1.106457
train_step : 17261, loss1 : 0.999184, loss2 : 1.095094
train_step : 17262, loss1 : 1.970836, loss2 : 1.478638
train_step : 17263, loss1 : 1.574961, loss2 : 1.924724
train_step : 17264, loss1 : 1.221743, loss2 : 1.180931
train_step : 17265, loss1 : 1.009306, loss2 : 0.639895
train_step : 17266, loss1 : 0.916413, loss2 : 1.135965
train_step : 17267, loss1 : 0.922853, loss2 : 1.012557
train_step : 17268, loss1 : 0.466474, loss2 : 0.936706
train_step : 17269, loss1 : 1.107219, loss2 : 1.067105
train_step : 17270, loss1 : 2.139322, loss2 : 2.257774
train_step : 17271, loss1 : 1.301941, loss2 : 1.188135
train_step : 17272, loss1 : 2.250850, loss2 : 1.332460
train_step : 17273, loss1 : 1.406389, loss2 : 1.942963
train_step : 17274, loss1 : 1.508201, loss2 : 0.964959
train_step : 17275, loss1 : 1.898571, loss2 : 0.749310
train_step : 17276, loss1 : 0.566262, loss2 : 0.906390
train_step : 17277, loss1 : 0.801160, loss2 : 0.910668
train_step : 17278, loss1 : 1.083997, loss2 : 1.486545
train_step : 17279, loss1 : 0.906089, loss2 : 1.587282
train_step : 17280, loss1 : 0.617396, loss2 : 2.535976
train_step : 17281, loss1 : 1.192833, loss2 : 1.397877
train_step : 17282, loss1 : 0.995601, loss2 : 0.933789
train_step : 17283, loss1 : 0.988582, loss2 : 0.550876
train_step : 17284, loss1 : 1.057468, loss2 : 0.790379
train_step : 17285, loss1 : 1.245258, loss2 : 2.153469
train_step : 17286, loss1 : 1.995458, loss2 : 0.925440
train_step : 17287, loss1 : 1.187631, loss2 : 1.382526
train_step : 17288, loss1 : 0.842224, loss2 : 1.422110
train_step : 17289, loss1 : 1.617389, loss2 : 1.567429
train_step : 17290, loss1 : 1.118752, loss2 : 1.563216
train_step : 17291, loss1 : 1.378770, loss2 : 1.299369
train_step : 17292, loss1 : 2.533409, loss2 : 1.484997
train_step : 17293, loss1 : 2.108225, loss2 : 1.872241
train_step : 17294, loss1 : 1.444577, loss2 : 2.627491
train_step : 17295, loss1 : 2.003810, loss2 : 3.548749
train_step : 17296, loss1 : 3.147898, loss2 : 1.959355
train_step : 17297, loss1 : 2.435705, loss2 : 3.786387
train_step : 17298, loss1 : 1.607957, loss2 : 2.188673
train_step : 17299, loss1 : 1.253831, loss2 : 1.579402
train_step : 17300, loss1 : 1.577673, loss2 : 1.248156
train_step : 17301, loss1 : 1.630233, loss2 : 1.416202
train_step : 17302, loss1 : 1.485600, loss2 : 3.223499
train_step : 17303, loss1 : 1.598232, loss2 : 1.395171
train_step : 17304, loss1 : 1.250783, loss2 : 1.506988
train_step : 17305, loss1 : 1.346035, loss2 : 1.866870
train_step : 17306, loss1 : 2.320492, loss2 : 2.326028
train_step : 17307, loss1 : 3.067480, loss2 : 0.936890
train_step : 17308, loss1 : 2.019476, loss2 : 1.540348
train_step : 17309, loss1 : 1.398376, loss2 : 1.713497
train_step : 17310, loss1 : 1.121336, loss2 : 0.928162
train_step : 17311, loss1 : 1.196924, loss2 : 0.847647
train_step : 17312, loss1 : 1.444819, loss2 : 0.922834
train_step : 17313, loss1 : 1.258761, loss2 : 1.279205
train_step : 17314, loss1 : 1.818351, loss2 : 1.080475
train_step : 17315, loss1 : 0.864692, loss2 : 1.285099
train_step : 17316, loss1 : 1.180824, loss2 : 1.313819
train_step : 17317, loss1 : 1.429052, loss2 : 1.012586
train_step : 17318, loss1 : 0.934685, loss2 : 1.385141
train_step : 17319, loss1 : 1.189735, loss2 : 1.595216
train_step : 17320, loss1 : 0.940439, loss2 : 0.878048
train_step : 17321, loss1 : 1.147812, loss2 : 1.290773
train_step : 17322, loss1 : 1.638457, loss2 : 0.897115
train_step : 17323, loss1 : 0.860722, loss2 : 1.113131
train_step : 17324, loss1 : 1.225956, loss2 : 0.962574
train_step : 17325, loss1 : 1.061111, loss2 : 0.948138
train_step : 17326, loss1 : 1.313605, loss2 : 1.355225
train_step : 17327, loss1 : 1.193645, loss2 : 2.480220
train_step : 17328, loss1 : 1.679210, loss2 : 0.781244
train_step : 17329, loss1 : 1.203398, loss2 : 1.597403
train_step : 17330, loss1 : 0.825672, loss2 : 0.620723
train_step : 17331, loss1 : 0.898049, loss2 : 1.122398
train_step : 17332, loss1 : 0.616063, loss2 : 0.695686
train_step : 17333, loss1 : 1.575822, loss2 : 1.139688
train_step : 17334, loss1 : 1.513494, loss2 : 1.368710
train_step : 17335, loss1 : 1.424814, loss2 : 0.815316
train_step : 17336, loss1 : 0.743709, loss2 : 0.819357
train_step : 17337, loss1 : 0.613221, loss2 : 1.266831
train_step : 17338, loss1 : 0.782914, loss2 : 0.716657
train_step : 17339, loss1 : 1.425167, loss2 : 1.721228
train_step : 17340, loss1 : 0.992987, loss2 : 1.183124
train_step : 17341, loss1 : 1.168732, loss2 : 0.940157
train_step : 17342, loss1 : 1.517513, loss2 : 1.316179
train_step : 17343, loss1 : 0.924087, loss2 : 1.172257
train_step : 17344, loss1 : 0.669424, loss2 : 2.016894
train_step : 17345, loss1 : 0.785375, loss2 : 1.117850
train_step : 17346, loss1 : 0.508125, loss2 : 1.140235
train_step : 17347, loss1 : 0.960801, loss2 : 1.970566
train_step : 17348, loss1 : 0.988592, loss2 : 1.760224
train_step : 17349, loss1 : 1.166159, loss2 : 1.147421
train_step : 17350, loss1 : 0.843049, loss2 : 1.095821
train_step : 17351, loss1 : 1.013422, loss2 : 1.043627
train_step : 17352, loss1 : 1.524814, loss2 : 1.379453
train_step : 17353, loss1 : 2.199089, loss2 : 1.333205
train_step : 17354, loss1 : 1.442768, loss2 : 1.677904
train_step : 17355, loss1 : 2.407265, loss2 : 2.302718
train_step : 17356, loss1 : 3.457173, loss2 : 3.529376
train_step : 17357, loss1 : 3.389665, loss2 : 2.976607
train_step : 17358, loss1 : 1.275912, loss2 : 1.545885
train_step : 17359, loss1 : 2.186658, loss2 : 1.243912
train_step : 17360, loss1 : 1.365003, loss2 : 1.274627
train_step : 17361, loss1 : 1.270479, loss2 : 1.600526
train_step : 17362, loss1 : 0.813789, loss2 : 1.051707
train_step : 17363, loss1 : 0.513295, loss2 : 2.116439
train_step : 17364, loss1 : 0.795902, loss2 : 0.890698
train_step : 17365, loss1 : 1.054174, loss2 : 1.228123
train_step : 17366, loss1 : 1.300200, loss2 : 1.996511
train_step : 17367, loss1 : 1.480524, loss2 : 1.529364
train_step : 17368, loss1 : 1.899088, loss2 : 1.518563
train_step : 17369, loss1 : 0.950573, loss2 : 0.947210
train_step : 17370, loss1 : 0.766438, loss2 : 0.988655
train_step : 17371, loss1 : 1.923750, loss2 : 1.601101
train_step : 17372, loss1 : 1.075774, loss2 : 1.492287
train_step : 17373, loss1 : 0.665655, loss2 : 1.023469
train_step : 17374, loss1 : 1.397262, loss2 : 1.475557
train_step : 17375, loss1 : 1.809246, loss2 : 1.620288
train_step : 17376, loss1 : 1.992408, loss2 : 2.133738
train_step : 17377, loss1 : 3.042428, loss2 : 2.975505
train_step : 17378, loss1 : 3.819719, loss2 : 4.147693
train_step : 17379, loss1 : 4.162086, loss2 : 4.610376
train_step : 17380, loss1 : 1.405966, loss2 : 1.743747
train_step : 17381, loss1 : 1.107799, loss2 : 1.128954
train_step : 17382, loss1 : 1.145880, loss2 : 0.717532
train_step : 17383, loss1 : 0.988543, loss2 : 1.083601
train_step : 17384, loss1 : 1.568203, loss2 : 1.499844
train_step : 17385, loss1 : 1.995809, loss2 : 1.678875
train_step : 17386, loss1 : 1.381546, loss2 : 1.568483
train_step : 17387, loss1 : 1.716398, loss2 : 1.318505
train_step : 17388, loss1 : 1.482593, loss2 : 1.149159
train_step : 17389, loss1 : 1.755441, loss2 : 1.131842
train_step : 17390, loss1 : 1.029656, loss2 : 0.989218
train_step : 17391, loss1 : 1.114244, loss2 : 1.204961
train_step : 17392, loss1 : 1.375714, loss2 : 0.885786
train_step : 17393, loss1 : 2.025643, loss2 : 1.269500
train_step : 17394, loss1 : 1.391427, loss2 : 1.248953
train_step : 17395, loss1 : 0.808177, loss2 : 0.880335
train_step : 17396, loss1 : 1.425354, loss2 : 1.698128
train_step : 17397, loss1 : 1.768501, loss2 : 1.650968
train_step : 17398, loss1 : 1.407358, loss2 : 2.197792
train_step : 17399, loss1 : 2.976850, loss2 : 1.733568
train_step : 17400, loss1 : 1.389897, loss2 : 1.282547
train_step : 17401, loss1 : 1.832474, loss2 : 1.505422
train_step : 17402, loss1 : 0.993962, loss2 : 1.023783
train_step : 17403, loss1 : 1.311800, loss2 : 1.468478
train_step : 17404, loss1 : 2.084858, loss2 : 1.704557
train_step : 17405, loss1 : 1.396791, loss2 : 1.922047
train_step : 17406, loss1 : 1.989110, loss2 : 1.051046
train_step : 17407, loss1 : 0.524895, loss2 : 3.927411
train_step : 17408, loss1 : 0.934242, loss2 : 1.101994
train_step : 17409, loss1 : 0.878865, loss2 : 1.667627
train_step : 17410, loss1 : 1.194273, loss2 : 1.181148
train_step : 17411, loss1 : 1.606724, loss2 : 1.270724
train_step : 17412, loss1 : 2.073441, loss2 : 1.265821
train_step : 17413, loss1 : 0.962375, loss2 : 0.794379
train_step : 17414, loss1 : 1.234690, loss2 : 2.192055
train_step : 17415, loss1 : 2.420283, loss2 : 2.057990
train_step : 17416, loss1 : 2.710302, loss2 : 3.373660
train_step : 17417, loss1 : 4.692538, loss2 : 2.619275
train_step : 17418, loss1 : 3.279400, loss2 : 3.363742
train_step : 17419, loss1 : 3.791821, loss2 : 2.381880
train_step : 17420, loss1 : 1.638728, loss2 : 1.740801
train_step : 17421, loss1 : 3.057775, loss2 : 1.903343
train_step : 17422, loss1 : 1.673423, loss2 : 1.651268
train_step : 17423, loss1 : 1.922751, loss2 : 2.014992
train_step : 17424, loss1 : 0.765408, loss2 : 1.659771
train_step : 17425, loss1 : 1.602680, loss2 : 3.108775
train_step : 17426, loss1 : 2.296207, loss2 : 0.904230
train_step : 17427, loss1 : 1.245744, loss2 : 1.772437
train_step : 17428, loss1 : 0.978746, loss2 : 1.905951
train_step : 17429, loss1 : 1.237115, loss2 : 1.668445
train_step : 17430, loss1 : 1.932224, loss2 : 1.406506
train_step : 17431, loss1 : 0.969992, loss2 : 2.396386
train_step : 17432, loss1 : 0.653862, loss2 : 1.253617
train_step : 17433, loss1 : 1.097394, loss2 : 1.688396
train_step : 17434, loss1 : 1.248910, loss2 : 0.588190
train_step : 17435, loss1 : 1.056821, loss2 : 1.278980
train_step : 17436, loss1 : 1.179797, loss2 : 1.056981
train_step : 17437, loss1 : 0.723253, loss2 : 0.992291
train_step : 17438, loss1 : 0.955375, loss2 : 0.770201
train_step : 17439, loss1 : 1.350317, loss2 : 1.255841
train_step : 17440, loss1 : 2.058155, loss2 : 2.654402
train_step : 17441, loss1 : 3.626411, loss2 : 2.668354
train_step : 17442, loss1 : 3.253002, loss2 : 2.566708
train_step : 17443, loss1 : 3.087732, loss2 : 4.349106
train_step : 17444, loss1 : 1.760698, loss2 : 2.073638
train_step : 17445, loss1 : 1.641118, loss2 : 1.331919
train_step : 17446, loss1 : 0.940568, loss2 : 1.154672
train_step : 17447, loss1 : 1.551354, loss2 : 1.062023
train_step : 17448, loss1 : 1.415504, loss2 : 1.438500
train_step : 17449, loss1 : 0.779273, loss2 : 0.695547
train_step : 17450, loss1 : 0.872421, loss2 : 0.783941
train_step : 17451, loss1 : 1.253613, loss2 : 1.136960
train_step : 17452, loss1 : 1.189717, loss2 : 1.801125
train_step : 17453, loss1 : 1.124179, loss2 : 1.565385
train_step : 17454, loss1 : 0.982486, loss2 : 1.022984
train_step : 17455, loss1 : 0.644816, loss2 : 1.051033
train_step : 17456, loss1 : 0.918914, loss2 : 1.347519
train_step : 17457, loss1 : 1.814826, loss2 : 1.554715
train_step : 17458, loss1 : 1.782122, loss2 : 1.390654
train_step : 17459, loss1 : 1.600136, loss2 : 0.826851
train_step : 17460, loss1 : 0.931568, loss2 : 1.761903
train_step : 17461, loss1 : 0.982585, loss2 : 1.241860
train_step : 17462, loss1 : 2.245015, loss2 : 2.310100
train_step : 17463, loss1 : 2.530038, loss2 : 2.834692
train_step : 17464, loss1 : 3.171455, loss2 : 4.695013
train_step : 17465, loss1 : 2.296006, loss2 : 3.469424
train_step : 17466, loss1 : 3.432069, loss2 : 4.375014
train_step : 17467, loss1 : 3.600361, loss2 : 3.623414
train_step : 17468, loss1 : 4.817164, loss2 : 4.452789
train_step : 17469, loss1 : 2.732524, loss2 : 4.249258
train_step : 17470, loss1 : 5.694939, loss2 : 4.614728
train_step : 17471, loss1 : 5.277912, loss2 : 4.449221
train_step : 17472, loss1 : 4.892423, loss2 : 5.782155
train_step : 17473, loss1 : 2.758931, loss2 : 3.317966
train_step : 17474, loss1 : 1.328583, loss2 : 1.454571
train_step : 17475, loss1 : 1.224192, loss2 : 2.929020
train_step : 17476, loss1 : 2.848470, loss2 : 2.260548
train_step : 17477, loss1 : 3.554536, loss2 : 2.094750
train_step : 17478, loss1 : 3.960705, loss2 : 2.160261
train_step : 17479, loss1 : 1.720454, loss2 : 0.582457
train_step : 17480, loss1 : 0.957456, loss2 : 0.739264
train_step : 17481, loss1 : 1.312969, loss2 : 0.939169
train_step : 17482, loss1 : 2.443785, loss2 : 1.016884
train_step : 17483, loss1 : 1.341801, loss2 : 1.353873
train_step : 17484, loss1 : 2.439249, loss2 : 1.617551
train_step : 17485, loss1 : 1.425288, loss2 : 1.037282
train_step : 17486, loss1 : 1.205809, loss2 : 1.137698
train_step : 17487, loss1 : 1.122373, loss2 : 1.146859
train_step : 17488, loss1 : 0.861498, loss2 : 0.835695
train_step : 17489, loss1 : 1.651893, loss2 : 0.583047
train_step : 17490, loss1 : 0.579290, loss2 : 1.249753
train_step : 17491, loss1 : 2.253558, loss2 : 0.904189
train_step : 17492, loss1 : 1.606753, loss2 : 1.411922
train_step : 17493, loss1 : 1.853291, loss2 : 1.256802
train_step : 17494, loss1 : 2.428492, loss2 : 1.373483
train_step : 17495, loss1 : 3.275564, loss2 : 1.656862
train_step : 17496, loss1 : 2.579703, loss2 : 0.894892
train_step : 17497, loss1 : 1.299694, loss2 : 1.204484
train_step : 17498, loss1 : 1.571752, loss2 : 1.469444
train_step : 17499, loss1 : 0.765098, loss2 : 0.776830
train_step : 17500, loss1 : 1.252049, loss2 : 1.338475
train_step : 17501, loss1 : 2.442124, loss2 : 0.973815
train_step : 17502, loss1 : 1.914106, loss2 : 1.445823
train_step : 17503, loss1 : 2.230787, loss2 : 1.468179
train_step : 17504, loss1 : 1.448570, loss2 : 1.873988
train_step : 17505, loss1 : 2.107686, loss2 : 1.560522
train_step : 17506, loss1 : 1.638476, loss2 : 1.044592
train_step : 17507, loss1 : 1.767696, loss2 : 1.422743
train_step : 17508, loss1 : 0.949427, loss2 : 1.108209
train_step : 17509, loss1 : 1.327230, loss2 : 1.481875
train_step : 17510, loss1 : 0.633586, loss2 : 1.424620
train_step : 17511, loss1 : 1.001426, loss2 : 1.223486
train_step : 17512, loss1 : 1.195796, loss2 : 0.748250
train_step : 17513, loss1 : 0.819048, loss2 : 1.290398
train_step : 17514, loss1 : 1.176415, loss2 : 0.795159
train_step : 17515, loss1 : 0.804617, loss2 : 0.854664
train_step : 17516, loss1 : 1.063558, loss2 : 1.397386
train_step : 17517, loss1 : 1.814823, loss2 : 1.289357
train_step : 17518, loss1 : 1.527541, loss2 : 1.764070
train_step : 17519, loss1 : 1.321984, loss2 : 0.957967
train_step : 17520, loss1 : 1.019449, loss2 : 1.319795
train_step : 17521, loss1 : 1.383106, loss2 : 1.302451
train_step : 17522, loss1 : 0.569676, loss2 : 0.799892
train_step : 17523, loss1 : 1.048456, loss2 : 1.588943
train_step : 17524, loss1 : 0.984544, loss2 : 1.328400
train_step : 17525, loss1 : 0.971941, loss2 : 0.785552
train_step : 17526, loss1 : 2.805876, loss2 : 0.976303
train_step : 17527, loss1 : 0.914923, loss2 : 1.271923
train_step : 17528, loss1 : 1.024670, loss2 : 0.911699
train_step : 17529, loss1 : 1.965505, loss2 : 1.070815
train_step : 17530, loss1 : 2.220304, loss2 : 2.202127
train_step : 17531, loss1 : 2.027153, loss2 : 2.232616
train_step : 17532, loss1 : 2.301716, loss2 : 2.126541
train_step : 17533, loss1 : 1.213085, loss2 : 0.742324
train_step : 17534, loss1 : 1.004288, loss2 : 1.170318
train_step : 17535, loss1 : 1.262895, loss2 : 1.291268
train_step : 17536, loss1 : 1.474657, loss2 : 1.057293
train_step : 17537, loss1 : 1.194450, loss2 : 0.989638
train_step : 17538, loss1 : 0.696704, loss2 : 1.027488
train_step : 17539, loss1 : 1.445779, loss2 : 0.958079
train_step : 17540, loss1 : 0.721897, loss2 : 0.717994
train_step : 17541, loss1 : 1.945957, loss2 : 0.998530
train_step : 17542, loss1 : 1.156973, loss2 : 1.239863
train_step : 17543, loss1 : 0.710277, loss2 : 1.203432
train_step : 17544, loss1 : 0.944207, loss2 : 1.188996
train_step : 17545, loss1 : 1.197608, loss2 : 0.792381
train_step : 17546, loss1 : 1.407277, loss2 : 1.005250
train_step : 17547, loss1 : 0.899343, loss2 : 0.835004
train_step : 17548, loss1 : 1.039419, loss2 : 1.799027
train_step : 17549, loss1 : 1.452259, loss2 : 1.968794
train_step : 17550, loss1 : 1.257007, loss2 : 2.124255
train_step : 17551, loss1 : 1.337597, loss2 : 1.120398
train_step : 17552, loss1 : 0.493249, loss2 : 1.067908
train_step : 17553, loss1 : 1.451490, loss2 : 1.016759
train_step : 17554, loss1 : 1.498522, loss2 : 2.290385
train_step : 17555, loss1 : 1.309813, loss2 : 0.947513
train_step : 17556, loss1 : 0.562254, loss2 : 1.705432
train_step : 17557, loss1 : 1.872692, loss2 : 1.484302
train_step : 17558, loss1 : 0.826906, loss2 : 1.837873
train_step : 17559, loss1 : 1.378271, loss2 : 1.716277
train_step : 17560, loss1 : 0.642677, loss2 : 1.853069
train_step : 17561, loss1 : 2.057275, loss2 : 1.150464
train_step : 17562, loss1 : 1.268067, loss2 : 0.595875
train_step : 17563, loss1 : 0.550492, loss2 : 1.167395
train_step : 17564, loss1 : 1.284820, loss2 : 0.666967
train_step : 17565, loss1 : 1.300469, loss2 : 1.575664
train_step : 17566, loss1 : 1.117229, loss2 : 2.644197
train_step : 17567, loss1 : 2.471587, loss2 : 1.284121
train_step : 17568, loss1 : 1.363848, loss2 : 1.744796
train_step : 17569, loss1 : 1.603081, loss2 : 0.830047
train_step : 17570, loss1 : 1.097884, loss2 : 1.970334
train_step : 17571, loss1 : 1.593251, loss2 : 1.488839
train_step : 17572, loss1 : 1.618559, loss2 : 1.861631
train_step : 17573, loss1 : 2.712558, loss2 : 1.995552
train_step : 17574, loss1 : 1.778069, loss2 : 1.129974
train_step : 17575, loss1 : 1.538186, loss2 : 3.743748
train_step : 17576, loss1 : 1.610947, loss2 : 1.172099
train_step : 17577, loss1 : 1.303442, loss2 : 1.094702
train_step : 17578, loss1 : 0.750902, loss2 : 0.683432
train_step : 17579, loss1 : 0.776799, loss2 : 1.496036
train_step : 17580, loss1 : 1.260460, loss2 : 1.308760
train_step : 17581, loss1 : 1.090771, loss2 : 0.600823
train_step : 17582, loss1 : 1.048315, loss2 : 0.925073
train_step : 17583, loss1 : 1.002633, loss2 : 1.402820
train_step : 17584, loss1 : 1.111358, loss2 : 0.801105
train_step : 17585, loss1 : 1.116699, loss2 : 2.244526
train_step : 17586, loss1 : 1.091835, loss2 : 2.109355
train_step : 17587, loss1 : 2.322559, loss2 : 1.854219
train_step : 17588, loss1 : 1.489858, loss2 : 2.922534
train_step : 17589, loss1 : 1.462624, loss2 : 1.888422
train_step : 17590, loss1 : 1.105343, loss2 : 0.709962
train_step : 17591, loss1 : 1.563269, loss2 : 0.897410
train_step : 17592, loss1 : 1.838102, loss2 : 1.246415
train_step : 17593, loss1 : 1.943860, loss2 : 1.741911
train_step : 17594, loss1 : 0.831084, loss2 : 1.435154
train_step : 17595, loss1 : 1.963679, loss2 : 0.853636
train_step : 17596, loss1 : 1.118961, loss2 : 1.667080
train_step : 17597, loss1 : 1.388416, loss2 : 1.990388
train_step : 17598, loss1 : 2.013964, loss2 : 2.317385
train_step : 17599, loss1 : 1.639681, loss2 : 1.732169
train_step : 17600, loss1 : 1.364283, loss2 : 1.716165
train_step : 17601, loss1 : 1.875460, loss2 : 1.139806
train_step : 17602, loss1 : 0.754177, loss2 : 1.958353
train_step : 17603, loss1 : 1.268353, loss2 : 1.644539
train_step : 17604, loss1 : 1.805195, loss2 : 1.744296
train_step : 17605, loss1 : 1.725991, loss2 : 2.248313
train_step : 17606, loss1 : 0.998688, loss2 : 1.534428
train_step : 17607, loss1 : 2.286742, loss2 : 0.995139
train_step : 17608, loss1 : 1.461906, loss2 : 1.581317
train_step : 17609, loss1 : 1.017082, loss2 : 1.326708
train_step : 17610, loss1 : 1.912966, loss2 : 1.256358
train_step : 17611, loss1 : 1.013963, loss2 : 0.978393
train_step : 17612, loss1 : 0.391853, loss2 : 1.022019
train_step : 17613, loss1 : 0.684670, loss2 : 1.603132
train_step : 17614, loss1 : 1.139040, loss2 : 0.844809
train_step : 17615, loss1 : 1.048669, loss2 : 1.306121
train_step : 17616, loss1 : 0.928783, loss2 : 0.738080
train_step : 17617, loss1 : 1.132965, loss2 : 0.876026
train_step : 17618, loss1 : 1.978865, loss2 : 1.810790
train_step : 17619, loss1 : 2.798158, loss2 : 2.018618
train_step : 17620, loss1 : 2.753005, loss2 : 2.565079
train_step : 17621, loss1 : 2.332030, loss2 : 3.146348
train_step : 17622, loss1 : 2.432653, loss2 : 2.089804
train_step : 17623, loss1 : 3.225049, loss2 : 2.400906
train_step : 17624, loss1 : 2.526935, loss2 : 1.407613
train_step : 17625, loss1 : 1.433005, loss2 : 1.326600
train_step : 17626, loss1 : 0.898103, loss2 : 1.459705
train_step : 17627, loss1 : 0.487107, loss2 : 1.211366
train_step : 17628, loss1 : 0.943655, loss2 : 0.921076
train_step : 17629, loss1 : 0.839399, loss2 : 0.662120
train_step : 17630, loss1 : 1.323294, loss2 : 0.816594
train_step : 17631, loss1 : 1.038280, loss2 : 2.370397
train_step : 17632, loss1 : 0.956189, loss2 : 0.933346
train_step : 17633, loss1 : 1.781693, loss2 : 1.496510
train_step : 17634, loss1 : 1.217664, loss2 : 1.967800
train_step : 17635, loss1 : 1.704069, loss2 : 2.472863
train_step : 17636, loss1 : 2.150841, loss2 : 2.108630
train_step : 17637, loss1 : 2.304311, loss2 : 1.481680
train_step : 17638, loss1 : 1.153772, loss2 : 1.555514
train_step : 17639, loss1 : 1.203620, loss2 : 0.974256
train_step : 17640, loss1 : 1.119694, loss2 : 1.080968
train_step : 17641, loss1 : 0.678123, loss2 : 1.634526
train_step : 17642, loss1 : 0.795274, loss2 : 0.830639
train_step : 17643, loss1 : 1.653095, loss2 : 0.721580
train_step : 17644, loss1 : 0.384067, loss2 : 1.138984
train_step : 17645, loss1 : 1.798760, loss2 : 1.320132
train_step : 17646, loss1 : 3.170921, loss2 : 1.736255
train_step : 17647, loss1 : 2.399774, loss2 : 2.030188
train_step : 17648, loss1 : 1.608156, loss2 : 2.640682
train_step : 17649, loss1 : 1.622537, loss2 : 2.040363
train_step : 17650, loss1 : 2.118145, loss2 : 1.732000
train_step : 17651, loss1 : 1.299338, loss2 : 1.372764
train_step : 17652, loss1 : 1.176574, loss2 : 0.884374
train_step : 17653, loss1 : 1.316848, loss2 : 1.038423
train_step : 17654, loss1 : 1.563205, loss2 : 1.235968
train_step : 17655, loss1 : 1.224771, loss2 : 1.659471
train_step : 17656, loss1 : 1.758515, loss2 : 1.054357
train_step : 17657, loss1 : 2.011438, loss2 : 2.192009
train_step : 17658, loss1 : 0.684369, loss2 : 1.702160
train_step : 17659, loss1 : 0.907853, loss2 : 1.411592
train_step : 17660, loss1 : 1.072661, loss2 : 1.684760
train_step : 17661, loss1 : 1.782120, loss2 : 1.379884
train_step : 17662, loss1 : 1.133151, loss2 : 0.942667
train_step : 17663, loss1 : 0.856849, loss2 : 1.136601
train_step : 17664, loss1 : 0.586279, loss2 : 0.937216
train_step : 17665, loss1 : 1.126055, loss2 : 1.074100
train_step : 17666, loss1 : 1.014817, loss2 : 3.767869
train_step : 17667, loss1 : 0.732066, loss2 : 1.355746
train_step : 17668, loss1 : 1.876725, loss2 : 0.492773
train_step : 17669, loss1 : 0.867814, loss2 : 0.615602
train_step : 17670, loss1 : 1.575341, loss2 : 0.989932
train_step : 17671, loss1 : 0.933768, loss2 : 0.745897
train_step : 17672, loss1 : 1.323883, loss2 : 1.012062
train_step : 17673, loss1 : 0.856636, loss2 : 1.656910
train_step : 17674, loss1 : 1.073760, loss2 : 0.452048
train_step : 17675, loss1 : 1.625956, loss2 : 1.834190
train_step : 17676, loss1 : 2.198689, loss2 : 1.592348
train_step : 17677, loss1 : 1.235708, loss2 : 1.302388
train_step : 17678, loss1 : 0.833590, loss2 : 0.761611
train_step : 17679, loss1 : 0.689216, loss2 : 1.391985
train_step : 17680, loss1 : 1.505421, loss2 : 0.765406
train_step : 17681, loss1 : 1.218651, loss2 : 1.058053
train_step : 17682, loss1 : 1.144298, loss2 : 1.203910
train_step : 17683, loss1 : 1.116270, loss2 : 0.718345
train_step : 17684, loss1 : 0.789406, loss2 : 1.284183
train_step : 17685, loss1 : 1.332513, loss2 : 0.555077
train_step : 17686, loss1 : 0.485359, loss2 : 1.867722
train_step : 17687, loss1 : 1.567197, loss2 : 1.251666
train_step : 17688, loss1 : 1.284730, loss2 : 1.518825
train_step : 17689, loss1 : 1.409006, loss2 : 0.906925
train_step : 17690, loss1 : 2.444089, loss2 : 0.920909
train_step : 17691, loss1 : 0.935245, loss2 : 1.240669
train_step : 17692, loss1 : 0.809693, loss2 : 0.732528
train_step : 17693, loss1 : 1.279490, loss2 : 0.981734
train_step : 17694, loss1 : 1.394723, loss2 : 1.265677
train_step : 17695, loss1 : 1.236729, loss2 : 0.991697
train_step : 17696, loss1 : 0.668024, loss2 : 1.189996
train_step : 17697, loss1 : 2.097978, loss2 : 1.691096
train_step : 17698, loss1 : 0.988673, loss2 : 1.020902
train_step : 17699, loss1 : 1.439221, loss2 : 1.186246
train_step : 17700, loss1 : 1.158293, loss2 : 1.105718
train_step : 17701, loss1 : 1.402881, loss2 : 1.003998
train_step : 17702, loss1 : 0.987402, loss2 : 1.136151
train_step : 17703, loss1 : 1.391209, loss2 : 1.138916
train_step : 17704, loss1 : 0.977418, loss2 : 1.338780
train_step : 17705, loss1 : 0.838393, loss2 : 1.305551
train_step : 17706, loss1 : 1.956985, loss2 : 1.375908
train_step : 17707, loss1 : 0.681396, loss2 : 1.024161
train_step : 17708, loss1 : 1.292506, loss2 : 1.479896
train_step : 17709, loss1 : 2.337045, loss2 : 1.343451
train_step : 17710, loss1 : 0.986996, loss2 : 1.606705
train_step : 17711, loss1 : 1.618209, loss2 : 0.925932
train_step : 17712, loss1 : 0.998156, loss2 : 1.617766
train_step : 17713, loss1 : 1.165696, loss2 : 0.921616
train_step : 17714, loss1 : 0.607244, loss2 : 0.617842
train_step : 17715, loss1 : 0.776335, loss2 : 1.324522
train_step : 17716, loss1 : 0.897201, loss2 : 1.045964
train_step : 17717, loss1 : 1.249503, loss2 : 2.500405
train_step : 17718, loss1 : 1.809970, loss2 : 3.003362
train_step : 17719, loss1 : 2.356379, loss2 : 1.673414
train_step : 17720, loss1 : 1.270019, loss2 : 1.117830
train_step : 17721, loss1 : 2.221169, loss2 : 0.765084
train_step : 17722, loss1 : 1.139310, loss2 : 2.151873
train_step : 17723, loss1 : 2.325008, loss2 : 1.441579
train_step : 17724, loss1 : 1.274689, loss2 : 2.751977
train_step : 17725, loss1 : 1.809718, loss2 : 1.889376
train_step : 17726, loss1 : 1.496755, loss2 : 1.178762
train_step : 17727, loss1 : 0.870748, loss2 : 0.730997
train_step : 17728, loss1 : 0.876706, loss2 : 0.599637
train_step : 17729, loss1 : 1.300626, loss2 : 0.930993
train_step : 17730, loss1 : 1.045350, loss2 : 0.773849
train_step : 17731, loss1 : 0.990826, loss2 : 0.481416
train_step : 17732, loss1 : 1.432874, loss2 : 1.315400
train_step : 17733, loss1 : 1.109209, loss2 : 0.558607
train_step : 17734, loss1 : 1.282843, loss2 : 0.624717
train_step : 17735, loss1 : 1.046664, loss2 : 0.880559
train_step : 17736, loss1 : 1.058017, loss2 : 0.558976
train_step : 17737, loss1 : 0.617553, loss2 : 1.690969
train_step : 17738, loss1 : 0.877327, loss2 : 1.611221
train_step : 17739, loss1 : 1.312989, loss2 : 0.779636
train_step : 17740, loss1 : 1.260746, loss2 : 1.069626
train_step : 17741, loss1 : 0.892249, loss2 : 1.195034
train_step : 17742, loss1 : 0.933425, loss2 : 0.814757
train_step : 17743, loss1 : 0.798166, loss2 : 0.929103
train_step : 17744, loss1 : 0.603739, loss2 : 0.849456
train_step : 17745, loss1 : 1.109820, loss2 : 1.521312
train_step : 17746, loss1 : 0.730073, loss2 : 0.860197
train_step : 17747, loss1 : 1.101550, loss2 : 0.902498
train_step : 17748, loss1 : 0.836478, loss2 : 1.036085
train_step : 17749, loss1 : 0.877643, loss2 : 1.189445
train_step : 17750, loss1 : 1.161828, loss2 : 1.910052
train_step : 17751, loss1 : 0.982439, loss2 : 0.831411
train_step : 17752, loss1 : 1.217239, loss2 : 1.554271
train_step : 17753, loss1 : 1.360701, loss2 : 1.090054
train_step : 17754, loss1 : 1.051937, loss2 : 0.981456
train_step : 17755, loss1 : 1.777167, loss2 : 2.906278
train_step : 17756, loss1 : 1.387404, loss2 : 2.213765
train_step : 17757, loss1 : 1.161810, loss2 : 1.951067
train_step : 17758, loss1 : 1.256493, loss2 : 1.444461
train_step : 17759, loss1 : 1.271697, loss2 : 1.197549
train_step : 17760, loss1 : 1.242693, loss2 : 1.351570
train_step : 17761, loss1 : 1.614818, loss2 : 1.215559
train_step : 17762, loss1 : 1.580403, loss2 : 1.583229
train_step : 17763, loss1 : 1.765291, loss2 : 2.449824
train_step : 17764, loss1 : 2.048906, loss2 : 1.059688
train_step : 17765, loss1 : 1.708253, loss2 : 1.075874
train_step : 17766, loss1 : 0.758886, loss2 : 0.917031
train_step : 17767, loss1 : 1.220218, loss2 : 1.076924
train_step : 17768, loss1 : 1.888726, loss2 : 1.206402
train_step : 17769, loss1 : 2.143878, loss2 : 1.949483
train_step : 17770, loss1 : 1.472053, loss2 : 1.674510
train_step : 17771, loss1 : 1.257648, loss2 : 0.808411
train_step : 17772, loss1 : 0.982666, loss2 : 1.946493
train_step : 17773, loss1 : 1.139048, loss2 : 1.291895
train_step : 17774, loss1 : 0.907643, loss2 : 0.883766
train_step : 17775, loss1 : 1.673777, loss2 : 0.693463
train_step : 17776, loss1 : 0.919066, loss2 : 0.715016
train_step : 17777, loss1 : 0.947855, loss2 : 1.188147
train_step : 17778, loss1 : 1.431064, loss2 : 1.170774
train_step : 17779, loss1 : 0.963763, loss2 : 1.959102
train_step : 17780, loss1 : 0.652427, loss2 : 0.786022
train_step : 17781, loss1 : 0.687308, loss2 : 0.348917
train_step : 17782, loss1 : 0.836033, loss2 : 0.717141
train_step : 17783, loss1 : 1.203719, loss2 : 0.935351
train_step : 17784, loss1 : 0.596125, loss2 : 1.024597
train_step : 17785, loss1 : 1.193515, loss2 : 1.643502
train_step : 17786, loss1 : 0.488472, loss2 : 0.737062
train_step : 17787, loss1 : 0.573326, loss2 : 1.568894
train_step : 17788, loss1 : 1.589074, loss2 : 1.131050
train_step : 17789, loss1 : 1.328278, loss2 : 1.658828
train_step : 17790, loss1 : 1.052803, loss2 : 1.373111
train_step : 17791, loss1 : 1.181109, loss2 : 1.715307
train_step : 17792, loss1 : 1.833685, loss2 : 0.860942
train_step : 17793, loss1 : 0.982698, loss2 : 0.829473
train_step : 17794, loss1 : 0.721315, loss2 : 0.806478
train_step : 17795, loss1 : 1.219893, loss2 : 1.633847
train_step : 17796, loss1 : 1.328261, loss2 : 1.589390
train_step : 17797, loss1 : 1.684356, loss2 : 1.010763
train_step : 17798, loss1 : 1.979079, loss2 : 1.610266
train_step : 17799, loss1 : 1.146346, loss2 : 1.780275
train_step : 17800, loss1 : 1.824562, loss2 : 1.554360
train_step : 17801, loss1 : 2.015544, loss2 : 1.692628
train_step : 17802, loss1 : 3.421644, loss2 : 1.407519
train_step : 17803, loss1 : 1.691834, loss2 : 2.098281
train_step : 17804, loss1 : 1.179114, loss2 : 2.144566
train_step : 17805, loss1 : 2.020069, loss2 : 2.697856
train_step : 17806, loss1 : 2.094815, loss2 : 1.403241
train_step : 17807, loss1 : 2.503704, loss2 : 1.307727
train_step : 17808, loss1 : 2.619880, loss2 : 1.745202
train_step : 17809, loss1 : 1.121911, loss2 : 2.336922
train_step : 17810, loss1 : 1.415849, loss2 : 1.985752
train_step : 17811, loss1 : 2.207659, loss2 : 1.618081
train_step : 17812, loss1 : 1.959618, loss2 : 1.659685
train_step : 17813, loss1 : 1.768566, loss2 : 0.708516
train_step : 17814, loss1 : 0.958296, loss2 : 1.012405
train_step : 17815, loss1 : 1.523025, loss2 : 1.338572
train_step : 17816, loss1 : 0.840517, loss2 : 0.732744
train_step : 17817, loss1 : 1.613850, loss2 : 0.699520
train_step : 17818, loss1 : 1.138662, loss2 : 1.115449
train_step : 17819, loss1 : 1.232337, loss2 : 1.438092
train_step : 17820, loss1 : 1.016475, loss2 : 1.229315
train_step : 17821, loss1 : 1.450098, loss2 : 1.083210
train_step : 17822, loss1 : 0.988500, loss2 : 1.047115
train_step : 17823, loss1 : 0.651793, loss2 : 0.929157
train_step : 17824, loss1 : 0.770027, loss2 : 0.799235
train_step : 17825, loss1 : 0.811479, loss2 : 1.693889
train_step : 17826, loss1 : 1.242667, loss2 : 1.206305
train_step : 17827, loss1 : 0.941142, loss2 : 1.070652
train_step : 17828, loss1 : 1.582504, loss2 : 1.420655
train_step : 17829, loss1 : 0.621543, loss2 : 1.674477
train_step : 17830, loss1 : 0.642422, loss2 : 0.932847
train_step : 17831, loss1 : 0.528276, loss2 : 1.526098
train_step : 17832, loss1 : 1.592708, loss2 : 0.799305
train_step : 17833, loss1 : 2.316956, loss2 : 2.039083
train_step : 17834, loss1 : 1.251032, loss2 : 1.924748
train_step : 17835, loss1 : 1.883878, loss2 : 1.438168
train_step : 17836, loss1 : 1.666831, loss2 : 1.593142
train_step : 17837, loss1 : 0.799084, loss2 : 1.049575
train_step : 17838, loss1 : 2.396004, loss2 : 1.908613
train_step : 17839, loss1 : 1.768346, loss2 : 2.365745
train_step : 17840, loss1 : 2.377561, loss2 : 1.736823
train_step : 17841, loss1 : 1.827034, loss2 : 1.361941
train_step : 17842, loss1 : 1.526106, loss2 : 1.008108
train_step : 17843, loss1 : 1.243675, loss2 : 1.376712
train_step : 17844, loss1 : 1.178761, loss2 : 1.251736
train_step : 17845, loss1 : 0.715678, loss2 : 2.005852
train_step : 17846, loss1 : 1.612102, loss2 : 1.220418
train_step : 17847, loss1 : 1.196031, loss2 : 1.724430
train_step : 17848, loss1 : 1.730384, loss2 : 1.297149
train_step : 17849, loss1 : 2.455683, loss2 : 1.884741
train_step : 17850, loss1 : 2.076332, loss2 : 1.858041
train_step : 17851, loss1 : 2.986265, loss2 : 1.864961
train_step : 17852, loss1 : 3.044829, loss2 : 1.849259
train_step : 17853, loss1 : 2.386919, loss2 : 2.645114
train_step : 17854, loss1 : 0.710614, loss2 : 1.841363
train_step : 17855, loss1 : 0.890019, loss2 : 1.355140
train_step : 17856, loss1 : 1.046193, loss2 : 1.489456
train_step : 17857, loss1 : 1.152198, loss2 : 1.385158
train_step : 17858, loss1 : 1.239339, loss2 : 1.214156
train_step : 17859, loss1 : 0.401415, loss2 : 1.397171
train_step : 17860, loss1 : 1.087759, loss2 : 1.069540
train_step : 17861, loss1 : 0.758466, loss2 : 1.179222
train_step : 17862, loss1 : 1.298859, loss2 : 1.185420
train_step : 17863, loss1 : 1.072799, loss2 : 1.279924
train_step : 17864, loss1 : 1.827010, loss2 : 1.198317
train_step : 17865, loss1 : 1.787669, loss2 : 1.513208
train_step : 17866, loss1 : 2.451585, loss2 : 2.414591
train_step : 17867, loss1 : 1.964693, loss2 : 1.136492
train_step : 17868, loss1 : 2.091132, loss2 : 1.533899
train_step : 17869, loss1 : 1.372696, loss2 : 1.023146
train_step : 17870, loss1 : 0.810978, loss2 : 1.151551
train_step : 17871, loss1 : 1.643845, loss2 : 1.176478
train_step : 17872, loss1 : 1.082906, loss2 : 0.845342
train_step : 17873, loss1 : 0.786685, loss2 : 1.170054
train_step : 17874, loss1 : 0.888038, loss2 : 0.830316
train_step : 17875, loss1 : 1.006286, loss2 : 1.275793
train_step : 17876, loss1 : 1.014341, loss2 : 0.769201
train_step : 17877, loss1 : 1.215576, loss2 : 0.830205
train_step : 17878, loss1 : 1.583041, loss2 : 1.641882
train_step : 17879, loss1 : 1.114625, loss2 : 0.828880
train_step : 17880, loss1 : 1.101070, loss2 : 1.157756
train_step : 17881, loss1 : 1.612255, loss2 : 1.973300
train_step : 17882, loss1 : 1.988710, loss2 : 1.722960
train_step : 17883, loss1 : 2.620983, loss2 : 1.061787
train_step : 17884, loss1 : 1.514795, loss2 : 2.231238
train_step : 17885, loss1 : 1.026540, loss2 : 2.671679
train_step : 17886, loss1 : 1.270668, loss2 : 1.744823
train_step : 17887, loss1 : 1.262805, loss2 : 3.546443
train_step : 17888, loss1 : 2.432860, loss2 : 2.204074
train_step : 17889, loss1 : 1.944090, loss2 : 1.775166
train_step : 17890, loss1 : 2.827706, loss2 : 1.513961
train_step : 17891, loss1 : 1.752824, loss2 : 1.357821
train_step : 17892, loss1 : 2.156981, loss2 : 2.029380
train_step : 17893, loss1 : 2.042490, loss2 : 3.065205
train_step : 17894, loss1 : 3.149933, loss2 : 2.260550
train_step : 17895, loss1 : 1.318330, loss2 : 1.884303
train_step : 17896, loss1 : 2.142906, loss2 : 1.236940
train_step : 17897, loss1 : 5.193457, loss2 : 1.434896
train_step : 17898, loss1 : 0.584646, loss2 : 2.172238
train_step : 17899, loss1 : 2.291399, loss2 : 1.266456
train_step : 17900, loss1 : 1.344985, loss2 : 1.789025
train_step : 17901, loss1 : 0.551422, loss2 : 1.172970
train_step : 17902, loss1 : 0.895329, loss2 : 1.271534
train_step : 17903, loss1 : 1.075917, loss2 : 0.865860
train_step : 17904, loss1 : 0.832784, loss2 : 1.342713
train_step : 17905, loss1 : 0.761445, loss2 : 0.383971
train_step : 17906, loss1 : 0.842932, loss2 : 2.669546
train_step : 17907, loss1 : 0.776945, loss2 : 1.247184
train_step : 17908, loss1 : 1.072091, loss2 : 0.751014
train_step : 17909, loss1 : 1.659656, loss2 : 1.344147
train_step : 17910, loss1 : 1.041323, loss2 : 1.777846
train_step : 17911, loss1 : 1.352213, loss2 : 1.565158
train_step : 17912, loss1 : 2.000103, loss2 : 1.796885
train_step : 17913, loss1 : 2.242049, loss2 : 1.123549
train_step : 17914, loss1 : 1.090253, loss2 : 1.744045
train_step : 17915, loss1 : 1.153701, loss2 : 2.246928
train_step : 17916, loss1 : 2.365602, loss2 : 3.195695
train_step : 17917, loss1 : 2.289984, loss2 : 2.336885
train_step : 17918, loss1 : 2.095225, loss2 : 1.452031
train_step : 17919, loss1 : 1.604354, loss2 : 1.677696
train_step : 17920, loss1 : 1.115589, loss2 : 1.124929
train_step : 17921, loss1 : 1.213147, loss2 : 1.675566
train_step : 17922, loss1 : 0.956434, loss2 : 0.508172
train_step : 17923, loss1 : 2.885497, loss2 : 0.736043
train_step : 17924, loss1 : 0.556144, loss2 : 1.794862
train_step : 17925, loss1 : 2.215854, loss2 : 1.424922
train_step : 17926, loss1 : 2.352653, loss2 : 1.148993
train_step : 17927, loss1 : 1.671336, loss2 : 1.440382
train_step : 17928, loss1 : 0.877178, loss2 : 0.971361
train_step : 17929, loss1 : 0.746822, loss2 : 0.700975
train_step : 17930, loss1 : 1.621042, loss2 : 1.244095
train_step : 17931, loss1 : 1.880138, loss2 : 1.248246
train_step : 17932, loss1 : 2.016975, loss2 : 0.904423
train_step : 17933, loss1 : 0.624424, loss2 : 1.240507
train_step : 17934, loss1 : 0.649988, loss2 : 1.536682
train_step : 17935, loss1 : 1.053003, loss2 : 1.277645
train_step : 17936, loss1 : 1.888319, loss2 : 1.744140
train_step : 17937, loss1 : 2.156415, loss2 : 1.928068
train_step : 17938, loss1 : 2.582181, loss2 : 1.172925
train_step : 17939, loss1 : 0.904697, loss2 : 1.137587
train_step : 17940, loss1 : 0.792769, loss2 : 0.677571
train_step : 17941, loss1 : 1.016414, loss2 : 1.421251
train_step : 17942, loss1 : 1.052542, loss2 : 1.188057
train_step : 17943, loss1 : 0.475938, loss2 : 0.701190
train_step : 17944, loss1 : 1.388531, loss2 : 0.542891
train_step : 17945, loss1 : 2.066404, loss2 : 1.105443
train_step : 17946, loss1 : 1.867802, loss2 : 1.917729
train_step : 17947, loss1 : 2.240284, loss2 : 3.071141
train_step : 17948, loss1 : 3.647007, loss2 : 5.233009
train_step : 17949, loss1 : 1.632560, loss2 : 4.009151
train_step : 17950, loss1 : 3.355729, loss2 : 4.523039
train_step : 17951, loss1 : 3.378107, loss2 : 4.835837
train_step : 17952, loss1 : 4.413497, loss2 : 5.016229
train_step : 17953, loss1 : 2.292015, loss2 : 3.522729
train_step : 17954, loss1 : 1.825732, loss2 : 3.152686
train_step : 17955, loss1 : 1.875537, loss2 : 1.468757
train_step : 17956, loss1 : 1.853105, loss2 : 1.291590
train_step : 17957, loss1 : 2.356241, loss2 : 2.636258
train_step : 17958, loss1 : 2.863505, loss2 : 2.312696
train_step : 17959, loss1 : 1.767747, loss2 : 2.013599
train_step : 17960, loss1 : 3.691805, loss2 : 1.050950
train_step : 17961, loss1 : 1.734853, loss2 : 2.258520
train_step : 17962, loss1 : 1.659688, loss2 : 2.362083
train_step : 17963, loss1 : 1.166066, loss2 : 1.359873
train_step : 17964, loss1 : 2.331141, loss2 : 1.325861
train_step : 17965, loss1 : 1.619446, loss2 : 1.189371
train_step : 17966, loss1 : 0.903372, loss2 : 0.963105
train_step : 17967, loss1 : 1.502655, loss2 : 1.612509
train_step : 17968, loss1 : 0.580273, loss2 : 1.189482
train_step : 17969, loss1 : 0.947724, loss2 : 1.264673
train_step : 17970, loss1 : 1.415962, loss2 : 1.092313
train_step : 17971, loss1 : 1.390898, loss2 : 1.214063
train_step : 17972, loss1 : 1.744413, loss2 : 1.822040
train_step : 17973, loss1 : 1.023821, loss2 : 1.680040
train_step : 17974, loss1 : 1.606009, loss2 : 1.734027
train_step : 17975, loss1 : 0.774934, loss2 : 0.812637
train_step : 17976, loss1 : 0.966252, loss2 : 1.781445
train_step : 17977, loss1 : 0.975232, loss2 : 1.031066
train_step : 17978, loss1 : 1.161984, loss2 : 0.629538
train_step : 17979, loss1 : 1.011331, loss2 : 0.655361
train_step : 17980, loss1 : 1.088951, loss2 : 0.867476
train_step : 17981, loss1 : 1.261615, loss2 : 1.115767
train_step : 17982, loss1 : 1.428957, loss2 : 0.945896
train_step : 17983, loss1 : 1.366906, loss2 : 1.251086
train_step : 17984, loss1 : 0.785090, loss2 : 1.202435
train_step : 17985, loss1 : 0.782617, loss2 : 1.001775
train_step : 17986, loss1 : 1.543239, loss2 : 0.567674
train_step : 17987, loss1 : 1.341481, loss2 : 1.332515
train_step : 17988, loss1 : 0.891497, loss2 : 1.112036
train_step : 17989, loss1 : 0.754145, loss2 : 1.282903
train_step : 17990, loss1 : 0.948088, loss2 : 0.889023
train_step : 17991, loss1 : 1.568574, loss2 : 1.314782
train_step : 17992, loss1 : 1.107393, loss2 : 0.769093
train_step : 17993, loss1 : 0.959390, loss2 : 1.786109
train_step : 17994, loss1 : 0.958939, loss2 : 1.067728
train_step : 17995, loss1 : 1.543477, loss2 : 1.380952
train_step : 17996, loss1 : 1.562406, loss2 : 1.017033
train_step : 17997, loss1 : 0.838458, loss2 : 2.105746
train_step : 17998, loss1 : 3.024493, loss2 : 3.405882
train_step : 17999, loss1 : 1.722340, loss2 : 2.326372
train_step : 18000, loss1 : 3.026143, loss2 : 1.401044
train_step : 18001, loss1 : 1.065885, loss2 : 0.928631
train_step : 18002, loss1 : 0.850561, loss2 : 1.058368
train_step : 18003, loss1 : 1.072956, loss2 : 0.699623
train_step : 18004, loss1 : 1.785241, loss2 : 1.053080
train_step : 18005, loss1 : 0.991281, loss2 : 1.243408
train_step : 18006, loss1 : 1.163382, loss2 : 1.356518
train_step : 18007, loss1 : 0.997670, loss2 : 0.936661
train_step : 18008, loss1 : 1.274210, loss2 : 2.697284
train_step : 18009, loss1 : 2.256693, loss2 : 1.578927
train_step : 18010, loss1 : 1.417828, loss2 : 1.077000
train_step : 18011, loss1 : 1.630604, loss2 : 1.484371
train_step : 18012, loss1 : 1.284280, loss2 : 0.643085
train_step : 18013, loss1 : 1.069774, loss2 : 1.463032
train_step : 18014, loss1 : 0.688674, loss2 : 2.270778
train_step : 18015, loss1 : 1.689444, loss2 : 1.045350
train_step : 18016, loss1 : 1.751218, loss2 : 1.022102
train_step : 18017, loss1 : 0.698847, loss2 : 1.108443
train_step : 18018, loss1 : 0.907376, loss2 : 0.640625
train_step : 18019, loss1 : 1.578151, loss2 : 1.359148
train_step : 18020, loss1 : 0.998694, loss2 : 1.901061
train_step : 18021, loss1 : 1.152241, loss2 : 2.247470
train_step : 18022, loss1 : 0.882726, loss2 : 1.089435
train_step : 18023, loss1 : 1.138847, loss2 : 1.327477
train_step : 18024, loss1 : 2.515660, loss2 : 1.437369
train_step : 18025, loss1 : 1.979666, loss2 : 0.690086
train_step : 18026, loss1 : 1.562397, loss2 : 2.400957
train_step : 18027, loss1 : 1.996536, loss2 : 1.621836
train_step : 18028, loss1 : 2.176356, loss2 : 0.917990
train_step : 18029, loss1 : 1.269027, loss2 : 1.170558
train_step : 18030, loss1 : 1.641317, loss2 : 1.707124
train_step : 18031, loss1 : 2.482520, loss2 : 2.661496
train_step : 18032, loss1 : 4.666416, loss2 : 2.159702
train_step : 18033, loss1 : 2.160080, loss2 : 2.939216
train_step : 18034, loss1 : 3.027704, loss2 : 2.859368
train_step : 18035, loss1 : 2.582302, loss2 : 1.838223
train_step : 18036, loss1 : 2.558619, loss2 : 2.536194
train_step : 18037, loss1 : 1.448021, loss2 : 1.304981
train_step : 18038, loss1 : 1.161565, loss2 : 0.879338
train_step : 18039, loss1 : 0.978864, loss2 : 0.844617
train_step : 18040, loss1 : 1.971982, loss2 : 1.436057
train_step : 18041, loss1 : 1.540620, loss2 : 1.162071
train_step : 18042, loss1 : 0.980213, loss2 : 1.946976
train_step : 18043, loss1 : 1.641182, loss2 : 1.157106
train_step : 18044, loss1 : 1.145119, loss2 : 0.817545
train_step : 18045, loss1 : 1.542604, loss2 : 0.604184
train_step : 18046, loss1 : 0.861766, loss2 : 1.152381
train_step : 18047, loss1 : 1.305480, loss2 : 1.518706
train_step : 18048, loss1 : 0.653431, loss2 : 0.850532
train_step : 18049, loss1 : 1.438253, loss2 : 1.835233
train_step : 18050, loss1 : 0.921937, loss2 : 1.543053
train_step : 18051, loss1 : 1.048276, loss2 : 1.101914
train_step : 18052, loss1 : 1.242622, loss2 : 1.095333
train_step : 18053, loss1 : 1.267522, loss2 : 1.439069
train_step : 18054, loss1 : 0.809196, loss2 : 1.766067
train_step : 18055, loss1 : 0.782694, loss2 : 1.279839
train_step : 18056, loss1 : 0.972437, loss2 : 0.984883
train_step : 18057, loss1 : 1.319244, loss2 : 1.067354
train_step : 18058, loss1 : 1.477150, loss2 : 1.019514
train_step : 18059, loss1 : 1.141917, loss2 : 2.495751
train_step : 18060, loss1 : 1.907105, loss2 : 1.507492
train_step : 18061, loss1 : 1.668723, loss2 : 1.424992
train_step : 18062, loss1 : 2.265810, loss2 : 1.694595
train_step : 18063, loss1 : 1.912669, loss2 : 3.124551
train_step : 18064, loss1 : 3.300653, loss2 : 3.172115
train_step : 18065, loss1 : 2.816137, loss2 : 3.085399
train_step : 18066, loss1 : 2.661765, loss2 : 3.600368
train_step : 18067, loss1 : 3.272363, loss2 : 1.670354
train_step : 18068, loss1 : 1.614142, loss2 : 1.605279
train_step : 18069, loss1 : 1.031350, loss2 : 1.558251
train_step : 18070, loss1 : 1.784023, loss2 : 1.463049
train_step : 18071, loss1 : 1.378165, loss2 : 1.017839
train_step : 18072, loss1 : 0.987208, loss2 : 1.086485
train_step : 18073, loss1 : 1.641737, loss2 : 1.163267
train_step : 18074, loss1 : 1.786042, loss2 : 1.080068
train_step : 18075, loss1 : 1.968793, loss2 : 0.918073
train_step : 18076, loss1 : 1.178552, loss2 : 0.946366
train_step : 18077, loss1 : 1.447606, loss2 : 1.900821
train_step : 18078, loss1 : 2.017049, loss2 : 2.830929
train_step : 18079, loss1 : 1.139810, loss2 : 1.933148
train_step : 18080, loss1 : 0.862822, loss2 : 1.272621
train_step : 18081, loss1 : 0.640123, loss2 : 0.642267
train_step : 18082, loss1 : 0.742042, loss2 : 0.883699
train_step : 18083, loss1 : 1.823815, loss2 : 1.713433
train_step : 18084, loss1 : 1.055110, loss2 : 1.402596
train_step : 18085, loss1 : 1.075574, loss2 : 0.650018
train_step : 18086, loss1 : 1.385261, loss2 : 1.036627
train_step : 18087, loss1 : 0.798672, loss2 : 1.166182
train_step : 18088, loss1 : 1.014167, loss2 : 0.933468
train_step : 18089, loss1 : 2.203926, loss2 : 0.855780
train_step : 18090, loss1 : 1.539838, loss2 : 1.738120
train_step : 18091, loss1 : 1.714979, loss2 : 1.266900
train_step : 18092, loss1 : 0.519332, loss2 : 1.129307
train_step : 18093, loss1 : 1.571036, loss2 : 1.232990
train_step : 18094, loss1 : 1.166711, loss2 : 0.901480
train_step : 18095, loss1 : 1.419350, loss2 : 1.781172
train_step : 18096, loss1 : 2.992193, loss2 : 2.003623
train_step : 18097, loss1 : 2.102581, loss2 : 2.626885
train_step : 18098, loss1 : 1.563342, loss2 : 1.304663
train_step : 18099, loss1 : 1.691696, loss2 : 1.736145
train_step : 18100, loss1 : 1.194751, loss2 : 1.505069
train_step : 18101, loss1 : 0.944295, loss2 : 0.793926
train_step : 18102, loss1 : 0.701616, loss2 : 1.348593
train_step : 18103, loss1 : 1.548841, loss2 : 0.956423
train_step : 18104, loss1 : 2.519392, loss2 : 2.576591
train_step : 18105, loss1 : 2.041203, loss2 : 1.822972
train_step : 18106, loss1 : 1.290556, loss2 : 2.602381
train_step : 18107, loss1 : 1.526320, loss2 : 1.804085
train_step : 18108, loss1 : 2.120888, loss2 : 1.378932
train_step : 18109, loss1 : 2.205915, loss2 : 1.523543
train_step : 18110, loss1 : 2.688020, loss2 : 2.428531
train_step : 18111, loss1 : 2.541477, loss2 : 1.650533
train_step : 18112, loss1 : 2.292868, loss2 : 2.122699
train_step : 18113, loss1 : 1.873706, loss2 : 2.787448
train_step : 18114, loss1 : 1.733274, loss2 : 2.434393
train_step : 18115, loss1 : 1.663678, loss2 : 2.560547
train_step : 18116, loss1 : 0.836521, loss2 : 1.291218
train_step : 18117, loss1 : 1.575381, loss2 : 1.001427
train_step : 18118, loss1 : 1.280675, loss2 : 1.572842
train_step : 18119, loss1 : 1.686691, loss2 : 1.762122
train_step : 18120, loss1 : 2.521218, loss2 : 2.337175
train_step : 18121, loss1 : 2.537318, loss2 : 2.054703
train_step : 18122, loss1 : 1.029072, loss2 : 0.986918
train_step : 18123, loss1 : 0.791345, loss2 : 1.249007
train_step : 18124, loss1 : 1.636263, loss2 : 1.983744
train_step : 18125, loss1 : 0.970186, loss2 : 2.315347
train_step : 18126, loss1 : 1.772513, loss2 : 1.811551
train_step : 18127, loss1 : 1.831991, loss2 : 2.566374
train_step : 18128, loss1 : 2.082966, loss2 : 2.243311
train_step : 18129, loss1 : 2.083392, loss2 : 1.097411
train_step : 18130, loss1 : 1.692338, loss2 : 1.263365
train_step : 18131, loss1 : 1.259461, loss2 : 1.643545
train_step : 18132, loss1 : 1.119344, loss2 : 1.283706
train_step : 18133, loss1 : 0.684740, loss2 : 1.166059
train_step : 18134, loss1 : 1.045355, loss2 : 2.425625
train_step : 18135, loss1 : 1.119373, loss2 : 3.012581
train_step : 18136, loss1 : 1.270265, loss2 : 1.318402
train_step : 18137, loss1 : 1.323197, loss2 : 1.417880
train_step : 18138, loss1 : 1.115442, loss2 : 0.909132
train_step : 18139, loss1 : 2.557694, loss2 : 1.168380
train_step : 18140, loss1 : 0.565779, loss2 : 1.306081
train_step : 18141, loss1 : 0.868778, loss2 : 0.948595
train_step : 18142, loss1 : 0.903159, loss2 : 1.082076
train_step : 18143, loss1 : 1.370848, loss2 : 1.376875
train_step : 18144, loss1 : 2.009459, loss2 : 1.238974
train_step : 18145, loss1 : 2.031743, loss2 : 1.535208
train_step : 18146, loss1 : 0.823485, loss2 : 1.874733
train_step : 18147, loss1 : 0.639072, loss2 : 1.650753
train_step : 18148, loss1 : 1.579141, loss2 : 1.055918
train_step : 18149, loss1 : 1.103267, loss2 : 1.069582
train_step : 18150, loss1 : 1.083998, loss2 : 0.752573
train_step : 18151, loss1 : 0.829089, loss2 : 1.174307
train_step : 18152, loss1 : 0.756422, loss2 : 1.078566
train_step : 18153, loss1 : 1.112844, loss2 : 0.595623
train_step : 18154, loss1 : 0.997141, loss2 : 0.871165
train_step : 18155, loss1 : 1.074196, loss2 : 0.790214
train_step : 18156, loss1 : 0.572859, loss2 : 1.372472
train_step : 18157, loss1 : 0.840309, loss2 : 1.144993
train_step : 18158, loss1 : 1.322032, loss2 : 1.697341
train_step : 18159, loss1 : 1.317605, loss2 : 2.002437
train_step : 18160, loss1 : 0.730038, loss2 : 2.095152
train_step : 18161, loss1 : 1.278486, loss2 : 1.145621
train_step : 18162, loss1 : 1.213225, loss2 : 1.462919
train_step : 18163, loss1 : 1.314904, loss2 : 0.919535
train_step : 18164, loss1 : 1.033705, loss2 : 1.138827
train_step : 18165, loss1 : 1.295083, loss2 : 0.542753
train_step : 18166, loss1 : 0.724983, loss2 : 0.974178
train_step : 18167, loss1 : 1.293321, loss2 : 1.247297
train_step : 18168, loss1 : 2.126532, loss2 : 1.701419
train_step : 18169, loss1 : 0.995293, loss2 : 0.840448
train_step : 18170, loss1 : 1.127832, loss2 : 1.333169
train_step : 18171, loss1 : 0.991333, loss2 : 1.559447
train_step : 18172, loss1 : 1.638165, loss2 : 1.754206
train_step : 18173, loss1 : 1.816617, loss2 : 0.983651
train_step : 18174, loss1 : 1.575839, loss2 : 1.500772
train_step : 18175, loss1 : 1.874903, loss2 : 1.919726
train_step : 18176, loss1 : 1.871672, loss2 : 1.444454
train_step : 18177, loss1 : 1.401905, loss2 : 2.127004
train_step : 18178, loss1 : 1.480646, loss2 : 1.836953
train_step : 18179, loss1 : 1.202343, loss2 : 1.304989
train_step : 18180, loss1 : 1.003182, loss2 : 0.963362
train_step : 18181, loss1 : 1.002827, loss2 : 1.478154
train_step : 18182, loss1 : 1.184597, loss2 : 1.809094
train_step : 18183, loss1 : 1.373247, loss2 : 0.806281
train_step : 18184, loss1 : 1.114292, loss2 : 1.306144
train_step : 18185, loss1 : 1.026301, loss2 : 0.871002
train_step : 18186, loss1 : 1.488118, loss2 : 1.608299
train_step : 18187, loss1 : 0.684696, loss2 : 1.496909
train_step : 18188, loss1 : 0.633455, loss2 : 1.301647
train_step : 18189, loss1 : 1.546462, loss2 : 1.171625
train_step : 18190, loss1 : 1.279314, loss2 : 5.470497
train_step : 18191, loss1 : 1.096799, loss2 : 2.235474
train_step : 18192, loss1 : 2.556396, loss2 : 1.644198
train_step : 18193, loss1 : 1.971416, loss2 : 2.321564
train_step : 18194, loss1 : 1.439746, loss2 : 1.450630
train_step : 18195, loss1 : 1.908514, loss2 : 1.396858
train_step : 18196, loss1 : 1.176718, loss2 : 1.308882
train_step : 18197, loss1 : 1.770926, loss2 : 1.526909
train_step : 18198, loss1 : 1.455862, loss2 : 0.862901
train_step : 18199, loss1 : 0.651453, loss2 : 2.105133
train_step : 18200, loss1 : 2.400944, loss2 : 3.083917
train_step : 18201, loss1 : 1.902712, loss2 : 1.709730
train_step : 18202, loss1 : 3.196669, loss2 : 2.364143
train_step : 18203, loss1 : 2.489160, loss2 : 2.558570
train_step : 18204, loss1 : 1.200014, loss2 : 1.352012
train_step : 18205, loss1 : 0.767642, loss2 : 2.230418
train_step : 18206, loss1 : 2.480417, loss2 : 1.765389
train_step : 18207, loss1 : 1.331257, loss2 : 1.652494
train_step : 18208, loss1 : 1.592506, loss2 : 1.653746
train_step : 18209, loss1 : 2.742250, loss2 : 2.738179
train_step : 18210, loss1 : 3.849258, loss2 : 3.050627
train_step : 18211, loss1 : 5.567998, loss2 : 3.851476
train_step : 18212, loss1 : 4.215452, loss2 : 4.011874
train_step : 18213, loss1 : 2.785135, loss2 : 3.826805
train_step : 18214, loss1 : 2.691336, loss2 : 0.868783
train_step : 18215, loss1 : 2.039008, loss2 : 1.901186
train_step : 18216, loss1 : 1.516557, loss2 : 3.075414
train_step : 18217, loss1 : 2.380194, loss2 : 0.858879
train_step : 18218, loss1 : 1.695461, loss2 : 1.415141
train_step : 18219, loss1 : 0.806241, loss2 : 1.079932
train_step : 18220, loss1 : 0.932198, loss2 : 1.684501
train_step : 18221, loss1 : 0.674033, loss2 : 1.261758
train_step : 18222, loss1 : 0.664735, loss2 : 2.437977
train_step : 18223, loss1 : 1.033877, loss2 : 1.681674
train_step : 18224, loss1 : 1.317772, loss2 : 1.507594
train_step : 18225, loss1 : 1.426404, loss2 : 1.121439
train_step : 18226, loss1 : 1.142220, loss2 : 0.789869
train_step : 18227, loss1 : 1.570494, loss2 : 1.320691
train_step : 18228, loss1 : 0.748328, loss2 : 0.965977
train_step : 18229, loss1 : 1.079989, loss2 : 1.343480
train_step : 18230, loss1 : 1.528507, loss2 : 1.491474
train_step : 18231, loss1 : 1.464964, loss2 : 0.468847
train_step : 18232, loss1 : 0.853522, loss2 : 0.983010
train_step : 18233, loss1 : 0.780893, loss2 : 0.692205
train_step : 18234, loss1 : 0.799713, loss2 : 1.595400
train_step : 18235, loss1 : 1.581340, loss2 : 1.028826
train_step : 18236, loss1 : 1.063995, loss2 : 1.344533
train_step : 18237, loss1 : 0.830517, loss2 : 1.286981
train_step : 18238, loss1 : 1.145963, loss2 : 0.921219
train_step : 18239, loss1 : 1.863408, loss2 : 2.331927
train_step : 18240, loss1 : 0.572189, loss2 : 1.585588
train_step : 18241, loss1 : 1.029294, loss2 : 0.821753
train_step : 18242, loss1 : 0.489856, loss2 : 2.096653
train_step : 18243, loss1 : 3.246242, loss2 : 1.014959
train_step : 18244, loss1 : 1.133261, loss2 : 1.384949
train_step : 18245, loss1 : 1.322110, loss2 : 1.559391
train_step : 18246, loss1 : 1.101809, loss2 : 1.468183
train_step : 18247, loss1 : 1.252973, loss2 : 1.191229
train_step : 18248, loss1 : 0.790649, loss2 : 0.936339
train_step : 18249, loss1 : 0.818820, loss2 : 1.576798
train_step : 18250, loss1 : 1.707158, loss2 : 1.633953
train_step : 18251, loss1 : 1.106210, loss2 : 2.305738
train_step : 18252, loss1 : 1.934379, loss2 : 2.961900
train_step : 18253, loss1 : 2.463252, loss2 : 2.619074
train_step : 18254, loss1 : 0.988243, loss2 : 2.209281
train_step : 18255, loss1 : 1.626819, loss2 : 1.557190
train_step : 18256, loss1 : 0.529036, loss2 : 1.714957
train_step : 18257, loss1 : 1.762345, loss2 : 1.037632
train_step : 18258, loss1 : 1.050076, loss2 : 0.909729
train_step : 18259, loss1 : 1.263039, loss2 : 0.978481
train_step : 18260, loss1 : 0.895560, loss2 : 0.773738
train_step : 18261, loss1 : 0.940270, loss2 : 0.412965
train_step : 18262, loss1 : 0.805715, loss2 : 1.415725
train_step : 18263, loss1 : 0.845204, loss2 : 1.046769
train_step : 18264, loss1 : 1.472034, loss2 : 0.576304
train_step : 18265, loss1 : 1.105337, loss2 : 1.053617
train_step : 18266, loss1 : 0.763313, loss2 : 1.214317
train_step : 18267, loss1 : 2.242748, loss2 : 0.513365
train_step : 18268, loss1 : 1.290695, loss2 : 0.952754
train_step : 18269, loss1 : 1.012870, loss2 : 1.052775
train_step : 18270, loss1 : 0.767765, loss2 : 1.050772
train_step : 18271, loss1 : 0.946533, loss2 : 0.935623
train_step : 18272, loss1 : 0.937382, loss2 : 1.307485
train_step : 18273, loss1 : 0.685612, loss2 : 1.850982
train_step : 18274, loss1 : 1.570320, loss2 : 1.692695
train_step : 18275, loss1 : 1.161521, loss2 : 1.858871
train_step : 18276, loss1 : 1.106856, loss2 : 1.375907
train_step : 18277, loss1 : 1.042241, loss2 : 0.771772
train_step : 18278, loss1 : 1.047055, loss2 : 1.280200
train_step : 18279, loss1 : 0.948122, loss2 : 1.197989
train_step : 18280, loss1 : 1.342408, loss2 : 1.244949
train_step : 18281, loss1 : 1.042671, loss2 : 1.572889
train_step : 18282, loss1 : 1.400379, loss2 : 1.227265
train_step : 18283, loss1 : 1.536999, loss2 : 1.154530
train_step : 18284, loss1 : 0.958753, loss2 : 1.284328
train_step : 18285, loss1 : 1.666478, loss2 : 0.670497
train_step : 18286, loss1 : 0.968018, loss2 : 0.880457
train_step : 18287, loss1 : 0.867544, loss2 : 1.415747
train_step : 18288, loss1 : 0.932177, loss2 : 0.973491
train_step : 18289, loss1 : 1.579319, loss2 : 0.666932
train_step : 18290, loss1 : 0.738967, loss2 : 1.457536
train_step : 18291, loss1 : 1.951202, loss2 : 0.854535
train_step : 18292, loss1 : 2.268815, loss2 : 2.140514
train_step : 18293, loss1 : 1.905459, loss2 : 1.763177
train_step : 18294, loss1 : 1.032174, loss2 : 1.462120
train_step : 18295, loss1 : 2.492876, loss2 : 2.345696
train_step : 18296, loss1 : 1.842354, loss2 : 2.583635
train_step : 18297, loss1 : 0.949783, loss2 : 2.705107
train_step : 18298, loss1 : 1.456399, loss2 : 1.621652
train_step : 18299, loss1 : 3.105117, loss2 : 1.558034
train_step : 18300, loss1 : 1.787309, loss2 : 3.779971
train_step : 18301, loss1 : 1.953593, loss2 : 1.470084
train_step : 18302, loss1 : 1.106776, loss2 : 2.173728
train_step : 18303, loss1 : 0.937773, loss2 : 1.201597
train_step : 18304, loss1 : 1.189036, loss2 : 0.951602
train_step : 18305, loss1 : 1.194673, loss2 : 1.867477
train_step : 18306, loss1 : 0.774415, loss2 : 0.686698
train_step : 18307, loss1 : 1.463096, loss2 : 0.862981
train_step : 18308, loss1 : 0.680402, loss2 : 1.646096
train_step : 18309, loss1 : 2.262325, loss2 : 1.958570
train_step : 18310, loss1 : 1.458919, loss2 : 1.829258
train_step : 18311, loss1 : 1.095112, loss2 : 0.946586
train_step : 18312, loss1 : 1.857879, loss2 : 2.830991
train_step : 18313, loss1 : 3.034725, loss2 : 1.083687
train_step : 18314, loss1 : 3.422233, loss2 : 1.629780
train_step : 18315, loss1 : 3.109436, loss2 : 2.579508
train_step : 18316, loss1 : 4.925464, loss2 : 3.615698
train_step : 18317, loss1 : 4.664548, loss2 : 4.209979
train_step : 18318, loss1 : 2.250503, loss2 : 2.940008
train_step : 18319, loss1 : 3.427681, loss2 : 1.905710
train_step : 18320, loss1 : 1.804349, loss2 : 3.708200
train_step : 18321, loss1 : 1.701374, loss2 : 2.098025
train_step : 18322, loss1 : 1.205785, loss2 : 1.520808
train_step : 18323, loss1 : 1.098141, loss2 : 1.381763
train_step : 18324, loss1 : 1.341290, loss2 : 1.234099
train_step : 18325, loss1 : 2.113816, loss2 : 2.331073
train_step : 18326, loss1 : 0.950454, loss2 : 1.618810
train_step : 18327, loss1 : 1.055506, loss2 : 2.379340
train_step : 18328, loss1 : 2.407745, loss2 : 1.036808
train_step : 18329, loss1 : 1.522002, loss2 : 1.285216
train_step : 18330, loss1 : 1.854218, loss2 : 1.025331
train_step : 18331, loss1 : 1.238276, loss2 : 1.287501
train_step : 18332, loss1 : 1.265024, loss2 : 0.799597
train_step : 18333, loss1 : 1.589743, loss2 : 1.586206
train_step : 18334, loss1 : 2.256510, loss2 : 1.949455
train_step : 18335, loss1 : 1.679371, loss2 : 2.493455
train_step : 18336, loss1 : 3.051101, loss2 : 2.589561
train_step : 18337, loss1 : 4.109434, loss2 : 4.168108
train_step : 18338, loss1 : 2.782349, loss2 : 3.021176
train_step : 18339, loss1 : 3.268322, loss2 : 3.133889
train_step : 18340, loss1 : 2.987185, loss2 : 4.060411
train_step : 18341, loss1 : 3.141204, loss2 : 3.370288
train_step : 18342, loss1 : 2.851240, loss2 : 1.418515
train_step : 18343, loss1 : 1.172922, loss2 : 1.402522
train_step : 18344, loss1 : 0.676221, loss2 : 1.128136
train_step : 18345, loss1 : 0.751286, loss2 : 0.940021
train_step : 18346, loss1 : 1.919173, loss2 : 1.386971
train_step : 18347, loss1 : 1.282490, loss2 : 0.631050
train_step : 18348, loss1 : 1.609122, loss2 : 1.214877
train_step : 18349, loss1 : 1.352900, loss2 : 1.136177
train_step : 18350, loss1 : 0.810196, loss2 : 1.273121
train_step : 18351, loss1 : 0.759295, loss2 : 1.014221
train_step : 18352, loss1 : 0.689800, loss2 : 1.766140
train_step : 18353, loss1 : 0.559167, loss2 : 1.057359
train_step : 18354, loss1 : 1.534254, loss2 : 1.143746
train_step : 18355, loss1 : 0.564822, loss2 : 0.671600
train_step : 18356, loss1 : 1.471600, loss2 : 1.437393
train_step : 18357, loss1 : 0.599271, loss2 : 1.191388
train_step : 18358, loss1 : 0.696168, loss2 : 1.191953
train_step : 18359, loss1 : 1.023039, loss2 : 1.358720
train_step : 18360, loss1 : 0.651195, loss2 : 1.218328
train_step : 18361, loss1 : 1.151903, loss2 : 1.082226
train_step : 18362, loss1 : 1.923683, loss2 : 1.501458
train_step : 18363, loss1 : 0.989691, loss2 : 1.072443
train_step : 18364, loss1 : 1.195502, loss2 : 1.512533
train_step : 18365, loss1 : 1.405854, loss2 : 1.798753
train_step : 18366, loss1 : 1.707904, loss2 : 2.241197
train_step : 18367, loss1 : 1.563002, loss2 : 1.868241
train_step : 18368, loss1 : 1.274480, loss2 : 0.941757
train_step : 18369, loss1 : 0.999401, loss2 : 1.144108
train_step : 18370, loss1 : 1.034456, loss2 : 0.655733
train_step : 18371, loss1 : 0.419133, loss2 : 0.574908
train_step : 18372, loss1 : 1.327723, loss2 : 1.638173
train_step : 18373, loss1 : 1.114719, loss2 : 0.966955
train_step : 18374, loss1 : 0.845359, loss2 : 1.246628
train_step : 18375, loss1 : 0.820800, loss2 : 0.977399
train_step : 18376, loss1 : 1.411139, loss2 : 0.685288
train_step : 18377, loss1 : 0.819816, loss2 : 1.354795
train_step : 18378, loss1 : 0.716449, loss2 : 0.911872
train_step : 18379, loss1 : 0.658875, loss2 : 1.573906
train_step : 18380, loss1 : 1.303176, loss2 : 0.874404
train_step : 18381, loss1 : 0.591275, loss2 : 0.677064
train_step : 18382, loss1 : 0.490157, loss2 : 1.278818
train_step : 18383, loss1 : 0.414791, loss2 : 0.961905
train_step : 18384, loss1 : 1.074336, loss2 : 1.559606
train_step : 18385, loss1 : 1.385900, loss2 : 1.450698
train_step : 18386, loss1 : 2.135495, loss2 : 1.154057
train_step : 18387, loss1 : 1.013680, loss2 : 1.473415
train_step : 18388, loss1 : 1.422444, loss2 : 0.897935
train_step : 18389, loss1 : 2.155394, loss2 : 1.136731
train_step : 18390, loss1 : 0.721367, loss2 : 1.538435
train_step : 18391, loss1 : 0.769278, loss2 : 1.609665
train_step : 18392, loss1 : 1.255421, loss2 : 1.652189
train_step : 18393, loss1 : 1.174033, loss2 : 1.426386
train_step : 18394, loss1 : 1.392842, loss2 : 0.913265
train_step : 18395, loss1 : 1.163733, loss2 : 1.052448
train_step : 18396, loss1 : 1.255058, loss2 : 1.716286
train_step : 18397, loss1 : 0.894604, loss2 : 1.150116
train_step : 18398, loss1 : 1.003990, loss2 : 1.159149
train_step : 18399, loss1 : 1.806336, loss2 : 1.466860
train_step : 18400, loss1 : 1.106309, loss2 : 0.776888
train_step : 18401, loss1 : 0.921191, loss2 : 1.230294
train_step : 18402, loss1 : 1.263558, loss2 : 1.236565
train_step : 18403, loss1 : 1.256423, loss2 : 0.924657
train_step : 18404, loss1 : 1.438947, loss2 : 0.810160
train_step : 18405, loss1 : 0.981987, loss2 : 0.788820
train_step : 18406, loss1 : 1.067017, loss2 : 0.578958
train_step : 18407, loss1 : 1.543980, loss2 : 1.000748
train_step : 18408, loss1 : 0.998785, loss2 : 1.336365
train_step : 18409, loss1 : 1.843974, loss2 : 0.900101
train_step : 18410, loss1 : 0.941416, loss2 : 1.207117
train_step : 18411, loss1 : 1.540649, loss2 : 0.889163
train_step : 18412, loss1 : 1.920704, loss2 : 1.143351
train_step : 18413, loss1 : 2.008102, loss2 : 1.872844
train_step : 18414, loss1 : 2.829210, loss2 : 2.726455
train_step : 18415, loss1 : 1.070315, loss2 : 3.665806
train_step : 18416, loss1 : 2.445653, loss2 : 2.589926
train_step : 18417, loss1 : 1.205947, loss2 : 1.961445
train_step : 18418, loss1 : 1.204639, loss2 : 0.762017
train_step : 18419, loss1 : 1.245391, loss2 : 1.281308
train_step : 18420, loss1 : 1.258727, loss2 : 1.481924
train_step : 18421, loss1 : 0.921195, loss2 : 0.666751
train_step : 18422, loss1 : 1.477953, loss2 : 1.147642
train_step : 18423, loss1 : 0.629874, loss2 : 1.134118
train_step : 18424, loss1 : 1.322344, loss2 : 1.155824
train_step : 18425, loss1 : 1.167585, loss2 : 1.031984
train_step : 18426, loss1 : 1.162113, loss2 : 0.951319
train_step : 18427, loss1 : 0.537450, loss2 : 0.848055
train_step : 18428, loss1 : 0.985573, loss2 : 0.995948
train_step : 18429, loss1 : 0.906098, loss2 : 1.260922
train_step : 18430, loss1 : 0.952950, loss2 : 1.373778
train_step : 18431, loss1 : 2.196750, loss2 : 0.826515
train_step : 18432, loss1 : 2.330771, loss2 : 1.282691
train_step : 18433, loss1 : 1.502450, loss2 : 1.466111
train_step : 18434, loss1 : 1.465413, loss2 : 1.361236
train_step : 18435, loss1 : 1.241881, loss2 : 1.763933
train_step : 18436, loss1 : 1.418927, loss2 : 1.491200
train_step : 18437, loss1 : 1.264309, loss2 : 1.324091
train_step : 18438, loss1 : 1.042983, loss2 : 1.421732
train_step : 18439, loss1 : 1.774960, loss2 : 0.818184
train_step : 18440, loss1 : 0.988956, loss2 : 1.613081
train_step : 18441, loss1 : 0.828577, loss2 : 0.841545
train_step : 18442, loss1 : 1.035735, loss2 : 1.107753
train_step : 18443, loss1 : 1.102715, loss2 : 1.060182
train_step : 18444, loss1 : 1.382171, loss2 : 0.585908
train_step : 18445, loss1 : 1.201834, loss2 : 0.932062
train_step : 18446, loss1 : 1.724623, loss2 : 1.009427
train_step : 18447, loss1 : 1.211973, loss2 : 0.815591
train_step : 18448, loss1 : 1.576122, loss2 : 1.100682
train_step : 18449, loss1 : 1.035006, loss2 : 0.872545
train_step : 18450, loss1 : 1.334738, loss2 : 1.179947
train_step : 18451, loss1 : 0.776354, loss2 : 1.098422
train_step : 18452, loss1 : 0.623000, loss2 : 0.758146
train_step : 18453, loss1 : 1.177752, loss2 : 1.059018
train_step : 18454, loss1 : 0.798961, loss2 : 0.786538
train_step : 18455, loss1 : 0.918031, loss2 : 1.034994
train_step : 18456, loss1 : 1.258470, loss2 : 1.433418
train_step : 18457, loss1 : 1.290259, loss2 : 1.668423
train_step : 18458, loss1 : 1.908185, loss2 : 1.056608
train_step : 18459, loss1 : 0.641598, loss2 : 1.321337
train_step : 18460, loss1 : 2.353066, loss2 : 1.032624
train_step : 18461, loss1 : 2.192797, loss2 : 2.096360
train_step : 18462, loss1 : 1.917559, loss2 : 1.824809
train_step : 18463, loss1 : 1.632966, loss2 : 2.087189
train_step : 18464, loss1 : 0.540521, loss2 : 1.188837
train_step : 18465, loss1 : 1.252351, loss2 : 2.003766
train_step : 18466, loss1 : 1.285945, loss2 : 1.778757
train_step : 18467, loss1 : 0.768759, loss2 : 1.474675
train_step : 18468, loss1 : 0.977554, loss2 : 0.859659
train_step : 18469, loss1 : 1.165606, loss2 : 1.839674
train_step : 18470, loss1 : 1.740615, loss2 : 1.374437
train_step : 18471, loss1 : 1.221107, loss2 : 0.664577
train_step : 18472, loss1 : 0.740390, loss2 : 1.457610
train_step : 18473, loss1 : 1.331029, loss2 : 0.893502
train_step : 18474, loss1 : 1.076367, loss2 : 1.540314
train_step : 18475, loss1 : 0.822475, loss2 : 1.101756
train_step : 18476, loss1 : 1.215829, loss2 : 2.447701
train_step : 18477, loss1 : 2.628848, loss2 : 2.434167
train_step : 18478, loss1 : 2.842214, loss2 : 3.533984
train_step : 18479, loss1 : 2.166782, loss2 : 2.519419
train_step : 18480, loss1 : 1.909207, loss2 : 2.656292
train_step : 18481, loss1 : 1.790469, loss2 : 1.302279
train_step : 18482, loss1 : 1.400439, loss2 : 2.376557
train_step : 18483, loss1 : 0.653604, loss2 : 0.938626
train_step : 18484, loss1 : 0.929827, loss2 : 0.987557
train_step : 18485, loss1 : 1.518636, loss2 : 0.834495
train_step : 18486, loss1 : 1.175866, loss2 : 0.975420
train_step : 18487, loss1 : 1.316748, loss2 : 1.170456
train_step : 18488, loss1 : 0.570527, loss2 : 1.583786
train_step : 18489, loss1 : 0.925978, loss2 : 1.027639
train_step : 18490, loss1 : 0.686011, loss2 : 1.728748
train_step : 18491, loss1 : 1.196831, loss2 : 1.206386
train_step : 18492, loss1 : 0.731577, loss2 : 1.370864
train_step : 18493, loss1 : 1.235828, loss2 : 0.888701
train_step : 18494, loss1 : 1.105178, loss2 : 1.929161
train_step : 18495, loss1 : 0.936353, loss2 : 1.473073
train_step : 18496, loss1 : 1.180763, loss2 : 1.370446
train_step : 18497, loss1 : 1.999856, loss2 : 1.194822
train_step : 18498, loss1 : 1.015965, loss2 : 1.040942
train_step : 18499, loss1 : 0.932333, loss2 : 1.473301
train_step : 18500, loss1 : 1.867373, loss2 : 0.951472
train_step : 18501, loss1 : 1.503757, loss2 : 2.077079
train_step : 18502, loss1 : 1.147070, loss2 : 1.200034
train_step : 18503, loss1 : 0.752265, loss2 : 1.338024
train_step : 18504, loss1 : 0.684926, loss2 : 0.903401
train_step : 18505, loss1 : 0.354052, loss2 : 1.103022
train_step : 18506, loss1 : 0.891339, loss2 : 1.099859
train_step : 18507, loss1 : 1.545674, loss2 : 1.145284
train_step : 18508, loss1 : 1.194207, loss2 : 1.346937
train_step : 18509, loss1 : 0.985361, loss2 : 1.252934
train_step : 18510, loss1 : 0.835778, loss2 : 0.610876
train_step : 18511, loss1 : 0.771100, loss2 : 1.295087
train_step : 18512, loss1 : 0.829251, loss2 : 1.078762
train_step : 18513, loss1 : 0.991397, loss2 : 0.960457
train_step : 18514, loss1 : 0.823457, loss2 : 1.198623
train_step : 18515, loss1 : 1.155133, loss2 : 1.051607
train_step : 18516, loss1 : 1.215964, loss2 : 0.782342
train_step : 18517, loss1 : 1.477971, loss2 : 1.780728
train_step : 18518, loss1 : 1.113327, loss2 : 1.071114
train_step : 18519, loss1 : 1.810005, loss2 : 1.084815
train_step : 18520, loss1 : 0.876591, loss2 : 1.468546
train_step : 18521, loss1 : 0.740867, loss2 : 1.279192
train_step : 18522, loss1 : 1.336591, loss2 : 2.703989
train_step : 18523, loss1 : 1.244720, loss2 : 2.799279
train_step : 18524, loss1 : 1.194139, loss2 : 1.139204
train_step : 18525, loss1 : 1.391055, loss2 : 1.422721
train_step : 18526, loss1 : 4.273083, loss2 : 1.164379
train_step : 18527, loss1 : 1.539160, loss2 : 1.229493
train_step : 18528, loss1 : 1.693862, loss2 : 1.681583
train_step : 18529, loss1 : 1.951357, loss2 : 0.896894
train_step : 18530, loss1 : 1.462618, loss2 : 0.916636
train_step : 18531, loss1 : 0.938248, loss2 : 1.093220
train_step : 18532, loss1 : 1.229595, loss2 : 0.889393
train_step : 18533, loss1 : 1.846220, loss2 : 0.892428
train_step : 18534, loss1 : 1.697550, loss2 : 0.989477
train_step : 18535, loss1 : 0.932400, loss2 : 1.367115
train_step : 18536, loss1 : 0.889367, loss2 : 1.777469
train_step : 18537, loss1 : 1.063048, loss2 : 0.784009
train_step : 18538, loss1 : 1.199376, loss2 : 0.887042
train_step : 18539, loss1 : 0.838398, loss2 : 0.977433
train_step : 18540, loss1 : 1.317516, loss2 : 1.431247
train_step : 18541, loss1 : 1.638212, loss2 : 2.378411
train_step : 18542, loss1 : 1.670693, loss2 : 1.610929
train_step : 18543, loss1 : 1.103712, loss2 : 1.992501
train_step : 18544, loss1 : 1.592384, loss2 : 1.017567
train_step : 18545, loss1 : 0.977880, loss2 : 1.750952
train_step : 18546, loss1 : 1.986440, loss2 : 0.818921
train_step : 18547, loss1 : 1.297476, loss2 : 1.484177
train_step : 18548, loss1 : 1.426638, loss2 : 1.531911
train_step : 18549, loss1 : 1.623707, loss2 : 1.394345
train_step : 18550, loss1 : 1.801173, loss2 : 2.320298
train_step : 18551, loss1 : 2.317657, loss2 : 2.629173
train_step : 18552, loss1 : 1.794962, loss2 : 1.843525
train_step : 18553, loss1 : 0.823131, loss2 : 2.221098
train_step : 18554, loss1 : 2.511406, loss2 : 1.784976
train_step : 18555, loss1 : 2.847228, loss2 : 2.985669
train_step : 18556, loss1 : 3.663084, loss2 : 2.318127
train_step : 18557, loss1 : 4.217390, loss2 : 2.097462
train_step : 18558, loss1 : 3.063776, loss2 : 3.151699
train_step : 18559, loss1 : 2.077187, loss2 : 1.996241
train_step : 18560, loss1 : 1.806917, loss2 : 0.903989
train_step : 18561, loss1 : 2.052680, loss2 : 0.852764
train_step : 18562, loss1 : 1.660880, loss2 : 0.663473
train_step : 18563, loss1 : 1.546251, loss2 : 1.708268
train_step : 18564, loss1 : 1.178888, loss2 : 1.608695
train_step : 18565, loss1 : 1.183099, loss2 : 2.079160
train_step : 18566, loss1 : 2.345229, loss2 : 1.297073
train_step : 18567, loss1 : 1.986208, loss2 : 1.454163
train_step : 18568, loss1 : 1.072414, loss2 : 2.543864
train_step : 18569, loss1 : 1.467667, loss2 : 2.134674
train_step : 18570, loss1 : 1.086706, loss2 : 1.900146
train_step : 18571, loss1 : 1.203936, loss2 : 1.240573
train_step : 18572, loss1 : 0.705468, loss2 : 1.683121
train_step : 18573, loss1 : 1.399649, loss2 : 1.072261
train_step : 18574, loss1 : 0.888621, loss2 : 1.434743
train_step : 18575, loss1 : 1.366817, loss2 : 1.110232
train_step : 18576, loss1 : 0.568852, loss2 : 0.908039
train_step : 18577, loss1 : 0.835647, loss2 : 1.099283
train_step : 18578, loss1 : 0.890649, loss2 : 1.914517
train_step : 18579, loss1 : 1.083423, loss2 : 1.257697
train_step : 18580, loss1 : 1.496793, loss2 : 0.772026
train_step : 18581, loss1 : 2.056811, loss2 : 1.126575
train_step : 18582, loss1 : 2.144097, loss2 : 3.641059
train_step : 18583, loss1 : 2.181669, loss2 : 2.336172
train_step : 18584, loss1 : 2.176025, loss2 : 1.790937
train_step : 18585, loss1 : 1.391767, loss2 : 1.304208
train_step : 18586, loss1 : 1.185694, loss2 : 0.734967
train_step : 18587, loss1 : 1.149164, loss2 : 2.210966
train_step : 18588, loss1 : 1.609201, loss2 : 1.655961
train_step : 18589, loss1 : 1.715173, loss2 : 2.963960
train_step : 18590, loss1 : 2.286778, loss2 : 1.942899
train_step : 18591, loss1 : 1.244319, loss2 : 0.828195
train_step : 18592, loss1 : 1.215605, loss2 : 1.223771
train_step : 18593, loss1 : 1.303246, loss2 : 1.802439
train_step : 18594, loss1 : 1.308690, loss2 : 0.974854
train_step : 18595, loss1 : 1.778339, loss2 : 1.229301
train_step : 18596, loss1 : 1.484193, loss2 : 1.954984
train_step : 18597, loss1 : 2.617057, loss2 : 1.952299
train_step : 18598, loss1 : 2.818550, loss2 : 2.551185
train_step : 18599, loss1 : 2.864288, loss2 : 2.294298
train_step : 18600, loss1 : 2.194943, loss2 : 2.736974
train_step : 18601, loss1 : 1.050463, loss2 : 2.187192
train_step : 18602, loss1 : 1.119225, loss2 : 1.225780
train_step : 18603, loss1 : 1.346962, loss2 : 1.747952
train_step : 18604, loss1 : 1.949764, loss2 : 1.080191
train_step : 18605, loss1 : 1.693100, loss2 : 2.509986
train_step : 18606, loss1 : 2.507481, loss2 : 3.317214
train_step : 18607, loss1 : 3.286901, loss2 : 1.527698
train_step : 18608, loss1 : 2.554339, loss2 : 1.858031
train_step : 18609, loss1 : 1.744734, loss2 : 1.083306
train_step : 18610, loss1 : 0.774386, loss2 : 2.085632
train_step : 18611, loss1 : 1.194446, loss2 : 1.416865
train_step : 18612, loss1 : 1.782297, loss2 : 1.351604
train_step : 18613, loss1 : 1.228338, loss2 : 0.879895
train_step : 18614, loss1 : 1.164347, loss2 : 1.020014
train_step : 18615, loss1 : 1.699594, loss2 : 0.896821
train_step : 18616, loss1 : 0.867183, loss2 : 1.038038
train_step : 18617, loss1 : 1.880687, loss2 : 0.823418
train_step : 18618, loss1 : 1.004604, loss2 : 1.545771
train_step : 18619, loss1 : 0.791095, loss2 : 1.450260
train_step : 18620, loss1 : 1.949141, loss2 : 0.591666
train_step : 18621, loss1 : 1.718889, loss2 : 1.101195
train_step : 18622, loss1 : 0.936644, loss2 : 0.714644
train_step : 18623, loss1 : 0.786805, loss2 : 0.556860
train_step : 18624, loss1 : 0.829244, loss2 : 1.253778
train_step : 18625, loss1 : 2.849409, loss2 : 0.931739
train_step : 18626, loss1 : 0.905140, loss2 : 0.749022
train_step : 18627, loss1 : 0.962877, loss2 : 1.852984
train_step : 18628, loss1 : 0.650473, loss2 : 1.534003
train_step : 18629, loss1 : 1.373497, loss2 : 0.956142
train_step : 18630, loss1 : 2.940192, loss2 : 2.547873
train_step : 18631, loss1 : 2.993848, loss2 : 3.778622
train_step : 18632, loss1 : 2.687588, loss2 : 3.933528
train_step : 18633, loss1 : 1.348033, loss2 : 1.942087
train_step : 18634, loss1 : 0.682733, loss2 : 0.833130
train_step : 18635, loss1 : 1.190546, loss2 : 0.793755
train_step : 18636, loss1 : 1.179841, loss2 : 1.880731
train_step : 18637, loss1 : 2.222641, loss2 : 0.895352
train_step : 18638, loss1 : 2.049466, loss2 : 0.983463
train_step : 18639, loss1 : 1.608806, loss2 : 2.371761
train_step : 18640, loss1 : 1.431238, loss2 : 2.484735
train_step : 18641, loss1 : 1.337895, loss2 : 0.992394
train_step : 18642, loss1 : 1.208530, loss2 : 0.619660
train_step : 18643, loss1 : 0.979294, loss2 : 0.693694
train_step : 18644, loss1 : 1.207221, loss2 : 0.723159
train_step : 18645, loss1 : 0.874851, loss2 : 1.047027
train_step : 18646, loss1 : 1.449575, loss2 : 1.274486
train_step : 18647, loss1 : 1.299168, loss2 : 1.274357
train_step : 18648, loss1 : 1.286612, loss2 : 0.568269
train_step : 18649, loss1 : 0.982763, loss2 : 1.570320
train_step : 18650, loss1 : 0.753609, loss2 : 1.091026
train_step : 18651, loss1 : 0.817660, loss2 : 1.228288
train_step : 18652, loss1 : 0.941417, loss2 : 1.153002
train_step : 18653, loss1 : 0.614290, loss2 : 1.007918
train_step : 18654, loss1 : 1.121730, loss2 : 2.157410
train_step : 18655, loss1 : 1.431232, loss2 : 1.418635
train_step : 18656, loss1 : 0.665540, loss2 : 1.839950
train_step : 18657, loss1 : 1.318505, loss2 : 0.833849
train_step : 18658, loss1 : 1.137209, loss2 : 1.570812
train_step : 18659, loss1 : 1.072141, loss2 : 1.067494
train_step : 18660, loss1 : 1.682154, loss2 : 2.304406
train_step : 18661, loss1 : 1.690742, loss2 : 2.059968
train_step : 18662, loss1 : 1.419916, loss2 : 1.368665
train_step : 18663, loss1 : 1.023748, loss2 : 1.087592
train_step : 18664, loss1 : 1.036449, loss2 : 2.540812
train_step : 18665, loss1 : 1.659626, loss2 : 1.035778
train_step : 18666, loss1 : 1.294159, loss2 : 1.577172
train_step : 18667, loss1 : 0.596996, loss2 : 2.436841
train_step : 18668, loss1 : 1.407425, loss2 : 1.781348
train_step : 18669, loss1 : 1.703279, loss2 : 2.043720
train_step : 18670, loss1 : 1.953534, loss2 : 2.527545
train_step : 18671, loss1 : 2.597771, loss2 : 2.344129
train_step : 18672, loss1 : 2.446509, loss2 : 2.456226
train_step : 18673, loss1 : 2.239473, loss2 : 1.640527
train_step : 18674, loss1 : 1.032824, loss2 : 1.613836
train_step : 18675, loss1 : 1.676462, loss2 : 1.212072
train_step : 18676, loss1 : 1.297836, loss2 : 1.054640
train_step : 18677, loss1 : 1.055277, loss2 : 1.273148
train_step : 18678, loss1 : 0.830645, loss2 : 1.091694
train_step : 18679, loss1 : 1.655102, loss2 : 1.547198
train_step : 18680, loss1 : 1.476602, loss2 : 0.779432
train_step : 18681, loss1 : 1.578471, loss2 : 1.241407
train_step : 18682, loss1 : 0.771142, loss2 : 1.036160
train_step : 18683, loss1 : 1.475291, loss2 : 1.442613
train_step : 18684, loss1 : 1.133626, loss2 : 0.782636
train_step : 18685, loss1 : 1.136093, loss2 : 0.692461
train_step : 18686, loss1 : 0.870646, loss2 : 1.183846
train_step : 18687, loss1 : 1.015341, loss2 : 1.015708
train_step : 18688, loss1 : 3.625408, loss2 : 1.137107
train_step : 18689, loss1 : 1.383736, loss2 : 1.480295
train_step : 18690, loss1 : 1.456611, loss2 : 1.829797
train_step : 18691, loss1 : 1.577797, loss2 : 1.470285
train_step : 18692, loss1 : 0.918812, loss2 : 1.436046
train_step : 18693, loss1 : 0.694596, loss2 : 1.090266
train_step : 18694, loss1 : 1.171365, loss2 : 0.783557
train_step : 18695, loss1 : 1.737190, loss2 : 1.076445
train_step : 18696, loss1 : 0.654915, loss2 : 1.041301
train_step : 18697, loss1 : 0.523206, loss2 : 1.147393
train_step : 18698, loss1 : 0.750096, loss2 : 0.673804
train_step : 18699, loss1 : 1.221325, loss2 : 0.850085
train_step : 18700, loss1 : 0.477721, loss2 : 1.357000
train_step : 18701, loss1 : 1.434689, loss2 : 1.207690
train_step : 18702, loss1 : 1.918623, loss2 : 1.187923
train_step : 18703, loss1 : 2.703281, loss2 : 1.283879
train_step : 18704, loss1 : 1.996024, loss2 : 2.330752
train_step : 18705, loss1 : 2.852339, loss2 : 3.948841
train_step : 18706, loss1 : 3.045546, loss2 : 3.113318
train_step : 18707, loss1 : 3.805950, loss2 : 3.809499
train_step : 18708, loss1 : 2.216110, loss2 : 2.950146
train_step : 18709, loss1 : 2.267901, loss2 : 3.364492
train_step : 18710, loss1 : 1.341309, loss2 : 1.200845
train_step : 18711, loss1 : 0.655646, loss2 : 0.837248
train_step : 18712, loss1 : 1.678454, loss2 : 2.164238
train_step : 18713, loss1 : 1.153535, loss2 : 1.106480
train_step : 18714, loss1 : 1.101559, loss2 : 1.163040
train_step : 18715, loss1 : 1.197864, loss2 : 1.513928
train_step : 18716, loss1 : 1.122906, loss2 : 1.384178
train_step : 18717, loss1 : 2.350768, loss2 : 1.311283
train_step : 18718, loss1 : 1.460266, loss2 : 1.727937
train_step : 18719, loss1 : 0.728873, loss2 : 0.786401
train_step : 18720, loss1 : 1.480699, loss2 : 1.352816
train_step : 18721, loss1 : 1.403282, loss2 : 1.356914
train_step : 18722, loss1 : 1.112869, loss2 : 0.666772
train_step : 18723, loss1 : 1.284115, loss2 : 0.791532
train_step : 18724, loss1 : 0.587009, loss2 : 0.487640
train_step : 18725, loss1 : 0.839016, loss2 : 1.394611
train_step : 18726, loss1 : 1.168659, loss2 : 1.418634
train_step : 18727, loss1 : 1.817441, loss2 : 1.396399
train_step : 18728, loss1 : 0.982767, loss2 : 0.737007
train_step : 18729, loss1 : 1.105625, loss2 : 0.760335
train_step : 18730, loss1 : 1.578032, loss2 : 0.787176
train_step : 18731, loss1 : 1.152663, loss2 : 1.104389
train_step : 18732, loss1 : 0.797296, loss2 : 0.677162
train_step : 18733, loss1 : 1.322260, loss2 : 1.490197
train_step : 18734, loss1 : 1.872931, loss2 : 0.787275
train_step : 18735, loss1 : 1.300031, loss2 : 1.293557
train_step : 18736, loss1 : 0.912508, loss2 : 1.103522
train_step : 18737, loss1 : 0.689950, loss2 : 1.070626
train_step : 18738, loss1 : 0.952671, loss2 : 1.103697
train_step : 18739, loss1 : 0.715664, loss2 : 0.949624
train_step : 18740, loss1 : 1.757838, loss2 : 1.169617
train_step : 18741, loss1 : 1.229048, loss2 : 2.483732
train_step : 18742, loss1 : 1.657734, loss2 : 0.850033
train_step : 18743, loss1 : 0.827345, loss2 : 1.178359
train_step : 18744, loss1 : 1.707002, loss2 : 1.117314
train_step : 18745, loss1 : 0.675266, loss2 : 1.667188
train_step : 18746, loss1 : 1.528254, loss2 : 0.614715
train_step : 18747, loss1 : 0.802680, loss2 : 1.457281
train_step : 18748, loss1 : 0.862055, loss2 : 1.282494
train_step : 18749, loss1 : 0.802876, loss2 : 0.602424
train_step : 18750, loss1 : 1.373235, loss2 : 1.405049
train_step : 18751, loss1 : 1.346279, loss2 : 1.678306
train_step : 18752, loss1 : 1.433843, loss2 : 0.623817
train_step : 18753, loss1 : 2.390070, loss2 : 2.359986
train_step : 18754, loss1 : 1.920787, loss2 : 2.009567
train_step : 18755, loss1 : 2.067261, loss2 : 1.567927
train_step : 18756, loss1 : 1.648382, loss2 : 1.221643
train_step : 18757, loss1 : 2.223411, loss2 : 1.807289
train_step : 18758, loss1 : 2.379257, loss2 : 1.952491
train_step : 18759, loss1 : 0.233451, loss2 : 1.597640
train_step : 18760, loss1 : 0.647741, loss2 : 0.639880
train_step : 18761, loss1 : 0.748809, loss2 : 0.926219
train_step : 18762, loss1 : 1.493973, loss2 : 1.505772
train_step : 18763, loss1 : 2.380229, loss2 : 2.566432
train_step : 18764, loss1 : 2.224568, loss2 : 3.218009
train_step : 18765, loss1 : 2.001454, loss2 : 2.497171
train_step : 18766, loss1 : 1.489149, loss2 : 2.017149
train_step : 18767, loss1 : 1.361279, loss2 : 1.553187
train_step : 18768, loss1 : 0.794876, loss2 : 1.012396
train_step : 18769, loss1 : 1.310677, loss2 : 1.136478
train_step : 18770, loss1 : 1.217335, loss2 : 1.185315
train_step : 18771, loss1 : 0.382157, loss2 : 1.302111
train_step : 18772, loss1 : 0.984311, loss2 : 1.308375
train_step : 18773, loss1 : 0.782970, loss2 : 1.305248
train_step : 18774, loss1 : 0.976719, loss2 : 1.228268
train_step : 18775, loss1 : 0.778941, loss2 : 1.329452
train_step : 18776, loss1 : 0.794291, loss2 : 0.700538
train_step : 18777, loss1 : 1.344231, loss2 : 2.093830
train_step : 18778, loss1 : 1.657235, loss2 : 0.892320
train_step : 18779, loss1 : 1.596726, loss2 : 1.754583
train_step : 18780, loss1 : 2.361117, loss2 : 1.606444
train_step : 18781, loss1 : 2.619530, loss2 : 2.889850
train_step : 18782, loss1 : 3.234983, loss2 : 2.512021
train_step : 18783, loss1 : 2.140664, loss2 : 2.623613
train_step : 18784, loss1 : 1.704165, loss2 : 1.524051
train_step : 18785, loss1 : 1.392788, loss2 : 1.501586
train_step : 18786, loss1 : 2.050845, loss2 : 1.619979
train_step : 18787, loss1 : 2.141612, loss2 : 2.183141
train_step : 18788, loss1 : 2.715327, loss2 : 1.670324
train_step : 18789, loss1 : 2.702538, loss2 : 2.984749
train_step : 18790, loss1 : 2.155886, loss2 : 2.169372
train_step : 18791, loss1 : 1.171507, loss2 : 1.383733
train_step : 18792, loss1 : 1.143743, loss2 : 0.887839
train_step : 18793, loss1 : 0.907839, loss2 : 1.935426
train_step : 18794, loss1 : 1.580513, loss2 : 0.437014
train_step : 18795, loss1 : 1.231230, loss2 : 1.125283
train_step : 18796, loss1 : 1.260237, loss2 : 0.933810
train_step : 18797, loss1 : 1.322199, loss2 : 0.596820
train_step : 18798, loss1 : 1.177902, loss2 : 1.036208
train_step : 18799, loss1 : 0.962130, loss2 : 1.081849
train_step : 18800, loss1 : 1.116024, loss2 : 0.872777
train_step : 18801, loss1 : 0.847091, loss2 : 1.129764
train_step : 18802, loss1 : 0.952821, loss2 : 1.840281
train_step : 18803, loss1 : 0.969764, loss2 : 2.252028
train_step : 18804, loss1 : 1.600971, loss2 : 0.795226
train_step : 18805, loss1 : 1.489894, loss2 : 1.587287
train_step : 18806, loss1 : 1.582864, loss2 : 2.026179
train_step : 18807, loss1 : 1.735026, loss2 : 1.356878
train_step : 18808, loss1 : 0.790404, loss2 : 1.332826
train_step : 18809, loss1 : 1.196147, loss2 : 0.805734
train_step : 18810, loss1 : 0.916779, loss2 : 0.751924
train_step : 18811, loss1 : 1.008679, loss2 : 0.873955
train_step : 18812, loss1 : 0.511277, loss2 : 1.162376
train_step : 18813, loss1 : 0.901118, loss2 : 1.157238
train_step : 18814, loss1 : 0.718252, loss2 : 0.837161
train_step : 18815, loss1 : 0.800553, loss2 : 2.010923
train_step : 18816, loss1 : 1.575474, loss2 : 1.132032
train_step : 18817, loss1 : 1.784127, loss2 : 0.835037
train_step : 18818, loss1 : 1.249415, loss2 : 1.090240
train_step : 18819, loss1 : 1.680067, loss2 : 0.819468
train_step : 18820, loss1 : 1.024608, loss2 : 1.053358
train_step : 18821, loss1 : 1.220422, loss2 : 1.166622
train_step : 18822, loss1 : 0.706093, loss2 : 1.211179
train_step : 18823, loss1 : 0.925893, loss2 : 1.029115
train_step : 18824, loss1 : 1.345938, loss2 : 1.466481
train_step : 18825, loss1 : 1.674777, loss2 : 1.356800
train_step : 18826, loss1 : 0.975601, loss2 : 1.316606
train_step : 18827, loss1 : 0.821445, loss2 : 0.515311
train_step : 18828, loss1 : 0.991075, loss2 : 1.168373
train_step : 18829, loss1 : 1.188425, loss2 : 0.767394
train_step : 18830, loss1 : 0.511775, loss2 : 1.461087
train_step : 18831, loss1 : 1.434097, loss2 : 0.683134
train_step : 18832, loss1 : 1.422090, loss2 : 0.670809
train_step : 18833, loss1 : 0.853031, loss2 : 0.733842
train_step : 18834, loss1 : 1.631274, loss2 : 0.579817
train_step : 18835, loss1 : 0.489296, loss2 : 1.124354
train_step : 18836, loss1 : 1.605208, loss2 : 0.834432
train_step : 18837, loss1 : 1.026375, loss2 : 1.013264
train_step : 18838, loss1 : 0.961228, loss2 : 1.898733
train_step : 18839, loss1 : 1.465543, loss2 : 1.467760
train_step : 18840, loss1 : 1.145315, loss2 : 1.686945
train_step : 18841, loss1 : 1.011617, loss2 : 1.072481
train_step : 18842, loss1 : 1.105242, loss2 : 1.263852
train_step : 18843, loss1 : 1.154153, loss2 : 1.246581
train_step : 18844, loss1 : 1.476621, loss2 : 0.984581
train_step : 18845, loss1 : 1.299333, loss2 : 0.906080
train_step : 18846, loss1 : 0.982483, loss2 : 0.978652
train_step : 18847, loss1 : 1.542886, loss2 : 0.438509
train_step : 18848, loss1 : 1.423525, loss2 : 0.991433
train_step : 18849, loss1 : 0.800187, loss2 : 1.033161
train_step : 18850, loss1 : 1.338234, loss2 : 1.277720
train_step : 18851, loss1 : 1.080862, loss2 : 1.324270
train_step : 18852, loss1 : 1.800093, loss2 : 1.028947
train_step : 18853, loss1 : 0.783891, loss2 : 1.127981
train_step : 18854, loss1 : 2.174049, loss2 : 3.524216
train_step : 18855, loss1 : 1.155925, loss2 : 1.666925
train_step : 18856, loss1 : 1.328907, loss2 : 1.397735
train_step : 18857, loss1 : 1.191750, loss2 : 0.913231
train_step : 18858, loss1 : 1.425695, loss2 : 0.824397
train_step : 18859, loss1 : 1.726169, loss2 : 0.663474
train_step : 18860, loss1 : 0.898459, loss2 : 1.399056
train_step : 18861, loss1 : 2.249691, loss2 : 0.679143
train_step : 18862, loss1 : 1.870093, loss2 : 2.316699
train_step : 18863, loss1 : 3.050079, loss2 : 2.115106
train_step : 18864, loss1 : 2.862178, loss2 : 2.327530
train_step : 18865, loss1 : 1.700189, loss2 : 0.799227
train_step : 18866, loss1 : 1.008584, loss2 : 1.350438
train_step : 18867, loss1 : 1.145112, loss2 : 0.654876
train_step : 18868, loss1 : 1.453422, loss2 : 2.031535
train_step : 18869, loss1 : 1.103029, loss2 : 1.618603
train_step : 18870, loss1 : 1.527718, loss2 : 1.331896
train_step : 18871, loss1 : 1.344563, loss2 : 1.099778
train_step : 18872, loss1 : 1.205180, loss2 : 0.678129
train_step : 18873, loss1 : 0.536053, loss2 : 1.129743
train_step : 18874, loss1 : 1.466115, loss2 : 1.459276
train_step : 18875, loss1 : 1.324096, loss2 : 3.506100
train_step : 18876, loss1 : 1.142962, loss2 : 1.533278
train_step : 18877, loss1 : 1.401447, loss2 : 1.312805
train_step : 18878, loss1 : 1.220506, loss2 : 2.595401
train_step : 18879, loss1 : 1.254260, loss2 : 1.695226
train_step : 18880, loss1 : 1.812995, loss2 : 1.295720
train_step : 18881, loss1 : 1.199916, loss2 : 2.263201
train_step : 18882, loss1 : 1.343947, loss2 : 1.865317
train_step : 18883, loss1 : 0.761190, loss2 : 2.037261
train_step : 18884, loss1 : 0.520068, loss2 : 0.911800
train_step : 18885, loss1 : 0.888443, loss2 : 1.430361
train_step : 18886, loss1 : 1.752617, loss2 : 1.984025
train_step : 18887, loss1 : 2.142950, loss2 : 1.422647
train_step : 18888, loss1 : 2.232543, loss2 : 1.713560
train_step : 18889, loss1 : 2.352462, loss2 : 1.067976
train_step : 18890, loss1 : 2.646891, loss2 : 3.209401
train_step : 18891, loss1 : 4.085005, loss2 : 3.610631
train_step : 18892, loss1 : 3.727533, loss2 : 3.732842
train_step : 18893, loss1 : 2.513382, loss2 : 2.658365
train_step : 18894, loss1 : 1.769239, loss2 : 1.888931
train_step : 18895, loss1 : 1.757200, loss2 : 2.027503
train_step : 18896, loss1 : 2.167575, loss2 : 1.993122
train_step : 18897, loss1 : 2.119750, loss2 : 2.108248
train_step : 18898, loss1 : 2.301725, loss2 : 2.226246
train_step : 18899, loss1 : 1.880360, loss2 : 1.796584
train_step : 18900, loss1 : 1.647384, loss2 : 1.444067
train_step : 18901, loss1 : 1.303572, loss2 : 0.800000
train_step : 18902, loss1 : 0.738632, loss2 : 0.716177
train_step : 18903, loss1 : 0.813997, loss2 : 1.009123
train_step : 18904, loss1 : 0.631328, loss2 : 0.818783
train_step : 18905, loss1 : 1.143782, loss2 : 0.815791
train_step : 18906, loss1 : 0.537930, loss2 : 0.534193
train_step : 18907, loss1 : 0.700705, loss2 : 1.204862
train_step : 18908, loss1 : 1.122207, loss2 : 1.084694
train_step : 18909, loss1 : 1.492621, loss2 : 1.128175
train_step : 18910, loss1 : 1.371192, loss2 : 1.427094
train_step : 18911, loss1 : 1.735411, loss2 : 1.350429
train_step : 18912, loss1 : 1.614502, loss2 : 2.161406
train_step : 18913, loss1 : 1.201442, loss2 : 1.560634
train_step : 18914, loss1 : 0.887628, loss2 : 0.947935
train_step : 18915, loss1 : 1.699504, loss2 : 1.544561
train_step : 18916, loss1 : 0.992840, loss2 : 0.953730
train_step : 18917, loss1 : 1.386016, loss2 : 1.975423
train_step : 18918, loss1 : 2.120457, loss2 : 2.185695
train_step : 18919, loss1 : 2.358552, loss2 : 2.862495
train_step : 18920, loss1 : 2.583985, loss2 : 3.988555
train_step : 18921, loss1 : 5.406147, loss2 : 3.331933
train_step : 18922, loss1 : 4.472249, loss2 : 2.350314
train_step : 18923, loss1 : 3.261589, loss2 : 2.408128
train_step : 18924, loss1 : 1.793125, loss2 : 1.794611
train_step : 18925, loss1 : 1.583015, loss2 : 1.377331
train_step : 18926, loss1 : 0.949202, loss2 : 1.484724
train_step : 18927, loss1 : 0.950325, loss2 : 1.127864
train_step : 18928, loss1 : 0.879211, loss2 : 1.203028
train_step : 18929, loss1 : 1.260294, loss2 : 1.175963
train_step : 18930, loss1 : 0.770922, loss2 : 0.841789
train_step : 18931, loss1 : 1.192026, loss2 : 2.136242
train_step : 18932, loss1 : 3.113731, loss2 : 1.490881
train_step : 18933, loss1 : 2.550835, loss2 : 2.062017
train_step : 18934, loss1 : 1.211942, loss2 : 2.155067
train_step : 18935, loss1 : 2.802959, loss2 : 2.499595
train_step : 18936, loss1 : 1.031687, loss2 : 1.162070
train_step : 18937, loss1 : 1.752268, loss2 : 1.586292
train_step : 18938, loss1 : 1.141283, loss2 : 1.095503
train_step : 18939, loss1 : 0.613170, loss2 : 0.487709
train_step : 18940, loss1 : 0.967193, loss2 : 0.807808
train_step : 18941, loss1 : 0.688617, loss2 : 1.116360
train_step : 18942, loss1 : 1.489715, loss2 : 1.326380
train_step : 18943, loss1 : 1.825969, loss2 : 1.107751
train_step : 18944, loss1 : 0.813111, loss2 : 2.041024
train_step : 18945, loss1 : 2.215911, loss2 : 0.937835
train_step : 18946, loss1 : 1.012542, loss2 : 1.260480
train_step : 18947, loss1 : 1.227369, loss2 : 1.813178
train_step : 18948, loss1 : 1.175364, loss2 : 1.456309
train_step : 18949, loss1 : 1.703886, loss2 : 0.994083
train_step : 18950, loss1 : 1.556702, loss2 : 0.991954
train_step : 18951, loss1 : 1.316587, loss2 : 1.795488
train_step : 18952, loss1 : 1.442283, loss2 : 1.062181
train_step : 18953, loss1 : 1.283220, loss2 : 1.450420
train_step : 18954, loss1 : 0.887030, loss2 : 1.724776
train_step : 18955, loss1 : 1.004872, loss2 : 2.051842
train_step : 18956, loss1 : 1.605229, loss2 : 1.061970
train_step : 18957, loss1 : 2.679273, loss2 : 1.841421
train_step : 18958, loss1 : 2.724740, loss2 : 3.024096
train_step : 18959, loss1 : 2.087434, loss2 : 2.907797
train_step : 18960, loss1 : 2.196239, loss2 : 3.127417
train_step : 18961, loss1 : 1.578167, loss2 : 3.538333
train_step : 18962, loss1 : 3.392782, loss2 : 1.855563
train_step : 18963, loss1 : 1.113291, loss2 : 1.258942
train_step : 18964, loss1 : 1.012796, loss2 : 2.007479
train_step : 18965, loss1 : 1.128247, loss2 : 0.722924
train_step : 18966, loss1 : 1.404880, loss2 : 0.632276
train_step : 18967, loss1 : 1.246820, loss2 : 1.689262
train_step : 18968, loss1 : 1.020360, loss2 : 0.651330
train_step : 18969, loss1 : 1.205986, loss2 : 0.564460
train_step : 18970, loss1 : 1.705605, loss2 : 0.957452
train_step : 18971, loss1 : 1.177604, loss2 : 0.817234
train_step : 18972, loss1 : 2.323676, loss2 : 1.711526
train_step : 18973, loss1 : 2.145395, loss2 : 2.413342
train_step : 18974, loss1 : 1.649111, loss2 : 2.465631
train_step : 18975, loss1 : 1.252387, loss2 : 1.578342
train_step : 18976, loss1 : 1.164904, loss2 : 1.429017
train_step : 18977, loss1 : 0.593132, loss2 : 1.354654
train_step : 18978, loss1 : 1.315370, loss2 : 1.931337
train_step : 18979, loss1 : 1.033227, loss2 : 1.126272
train_step : 18980, loss1 : 1.136940, loss2 : 0.847763
train_step : 18981, loss1 : 1.154469, loss2 : 0.710225
train_step : 18982, loss1 : 1.364157, loss2 : 0.929112
train_step : 18983, loss1 : 1.055271, loss2 : 0.931816
train_step : 18984, loss1 : 1.625402, loss2 : 1.384380
train_step : 18985, loss1 : 0.907445, loss2 : 0.884649
train_step : 18986, loss1 : 1.271401, loss2 : 1.696931
train_step : 18987, loss1 : 1.079929, loss2 : 1.208998
train_step : 18988, loss1 : 2.128079, loss2 : 0.948892
train_step : 18989, loss1 : 1.926971, loss2 : 1.767125
train_step : 18990, loss1 : 1.126923, loss2 : 1.351528
train_step : 18991, loss1 : 1.076563, loss2 : 1.301947
train_step : 18992, loss1 : 1.604650, loss2 : 1.005903
train_step : 18993, loss1 : 1.010168, loss2 : 1.122977
train_step : 18994, loss1 : 1.329545, loss2 : 1.305115
train_step : 18995, loss1 : 1.687147, loss2 : 0.880326
train_step : 18996, loss1 : 1.063298, loss2 : 1.160648
train_step : 18997, loss1 : 0.858736, loss2 : 1.135451
train_step : 18998, loss1 : 1.750913, loss2 : 1.347277
train_step : 18999, loss1 : 0.864673, loss2 : 0.760152
train_step : 19000, loss1 : 1.688491, loss2 : 1.193618
train_step : 19001, loss1 : 0.976263, loss2 : 1.656906
train_step : 19002, loss1 : 1.231007, loss2 : 0.880845
train_step : 19003, loss1 : 1.085782, loss2 : 0.862952
train_step : 19004, loss1 : 1.171095, loss2 : 0.563773
train_step : 19005, loss1 : 1.178028, loss2 : 0.946360
train_step : 19006, loss1 : 0.986571, loss2 : 0.601822
train_step : 19007, loss1 : 0.806904, loss2 : 1.162773
train_step : 19008, loss1 : 0.911176, loss2 : 0.934096
train_step : 19009, loss1 : 1.732296, loss2 : 0.632941
train_step : 19010, loss1 : 1.080473, loss2 : 0.986871
train_step : 19011, loss1 : 1.096385, loss2 : 1.272986
train_step : 19012, loss1 : 0.448236, loss2 : 1.552881
train_step : 19013, loss1 : 0.908303, loss2 : 0.806407
train_step : 19014, loss1 : 1.035812, loss2 : 1.761227
train_step : 19015, loss1 : 1.286188, loss2 : 1.138145
train_step : 19016, loss1 : 1.672463, loss2 : 1.098825
train_step : 19017, loss1 : 1.487875, loss2 : 1.729091
train_step : 19018, loss1 : 3.995823, loss2 : 1.624980
train_step : 19019, loss1 : 2.802997, loss2 : 2.381260
train_step : 19020, loss1 : 2.991672, loss2 : 2.887441
train_step : 19021, loss1 : 2.386390, loss2 : 3.133695
train_step : 19022, loss1 : 2.018253, loss2 : 2.268375
train_step : 19023, loss1 : 1.594704, loss2 : 0.876894
train_step : 19024, loss1 : 1.409574, loss2 : 0.702142
train_step : 19025, loss1 : 0.853734, loss2 : 0.896491
train_step : 19026, loss1 : 1.538559, loss2 : 0.799634
train_step : 19027, loss1 : 1.660663, loss2 : 1.710282
train_step : 19028, loss1 : 0.823723, loss2 : 1.431292
train_step : 19029, loss1 : 1.403291, loss2 : 1.070768
train_step : 19030, loss1 : 1.345412, loss2 : 1.219101
train_step : 19031, loss1 : 1.275816, loss2 : 1.999793
train_step : 19032, loss1 : 1.284820, loss2 : 1.607268
train_step : 19033, loss1 : 1.056817, loss2 : 2.171109
train_step : 19034, loss1 : 1.187596, loss2 : 1.519696
train_step : 19035, loss1 : 1.536850, loss2 : 1.320085
train_step : 19036, loss1 : 1.009786, loss2 : 1.515338
train_step : 19037, loss1 : 1.846556, loss2 : 1.268201
train_step : 19038, loss1 : 1.429677, loss2 : 1.785707
train_step : 19039, loss1 : 0.825500, loss2 : 1.341935
train_step : 19040, loss1 : 1.613398, loss2 : 0.637513
train_step : 19041, loss1 : 1.336038, loss2 : 0.685300
train_step : 19042, loss1 : 0.809291, loss2 : 0.894200
train_step : 19043, loss1 : 1.572796, loss2 : 0.984212
train_step : 19044, loss1 : 0.699624, loss2 : 0.825637
train_step : 19045, loss1 : 1.065531, loss2 : 0.618965
train_step : 19046, loss1 : 0.907285, loss2 : 1.706080
train_step : 19047, loss1 : 1.732622, loss2 : 1.128426
train_step : 19048, loss1 : 1.553572, loss2 : 0.735075
train_step : 19049, loss1 : 1.354917, loss2 : 1.348489
train_step : 19050, loss1 : 1.641670, loss2 : 2.302768
train_step : 19051, loss1 : 1.032826, loss2 : 0.692329
train_step : 19052, loss1 : 0.696770, loss2 : 1.776907
train_step : 19053, loss1 : 1.117766, loss2 : 1.133604
train_step : 19054, loss1 : 1.937016, loss2 : 1.925721
train_step : 19055, loss1 : 1.759418, loss2 : 1.457040
train_step : 19056, loss1 : 1.230302, loss2 : 1.216427
train_step : 19057, loss1 : 1.327853, loss2 : 1.477852
train_step : 19058, loss1 : 2.140471, loss2 : 1.070682
train_step : 19059, loss1 : 1.846773, loss2 : 1.301246
train_step : 19060, loss1 : 1.720436, loss2 : 1.572144
train_step : 19061, loss1 : 1.515996, loss2 : 1.591822
train_step : 19062, loss1 : 2.836480, loss2 : 1.683501
train_step : 19063, loss1 : 3.274016, loss2 : 2.543314
train_step : 19064, loss1 : 2.632565, loss2 : 1.232502
train_step : 19065, loss1 : 1.138347, loss2 : 1.304456
train_step : 19066, loss1 : 1.802097, loss2 : 1.677473
train_step : 19067, loss1 : 1.587409, loss2 : 1.738812
train_step : 19068, loss1 : 1.534495, loss2 : 1.841371
train_step : 19069, loss1 : 0.703254, loss2 : 1.592601
train_step : 19070, loss1 : 2.195217, loss2 : 1.154735
train_step : 19071, loss1 : 2.422711, loss2 : 1.330879
train_step : 19072, loss1 : 1.797037, loss2 : 1.827611
train_step : 19073, loss1 : 0.892100, loss2 : 1.170038
train_step : 19074, loss1 : 1.567922, loss2 : 1.682600
train_step : 19075, loss1 : 1.342872, loss2 : 1.674402
train_step : 19076, loss1 : 2.176102, loss2 : 1.867558
train_step : 19077, loss1 : 2.808471, loss2 : 2.890371
train_step : 19078, loss1 : 1.387856, loss2 : 2.165891
train_step : 19079, loss1 : 0.866195, loss2 : 1.744050
train_step : 19080, loss1 : 1.333445, loss2 : 1.732425
train_step : 19081, loss1 : 3.708656, loss2 : 0.923066
train_step : 19082, loss1 : 0.633773, loss2 : 1.203006
train_step : 19083, loss1 : 0.803729, loss2 : 0.790929
train_step : 19084, loss1 : 1.033138, loss2 : 0.498861
train_step : 19085, loss1 : 0.704845, loss2 : 1.399230
train_step : 19086, loss1 : 1.588194, loss2 : 2.794794
train_step : 19087, loss1 : 1.731308, loss2 : 1.210268
train_step : 19088, loss1 : 1.653185, loss2 : 1.272702
train_step : 19089, loss1 : 1.028818, loss2 : 1.580225
train_step : 19090, loss1 : 1.254762, loss2 : 1.510809
train_step : 19091, loss1 : 1.198040, loss2 : 0.792795
train_step : 19092, loss1 : 1.546296, loss2 : 1.215905
train_step : 19093, loss1 : 0.674928, loss2 : 1.312759
train_step : 19094, loss1 : 0.956075, loss2 : 1.024013
train_step : 19095, loss1 : 1.312808, loss2 : 1.604000
train_step : 19096, loss1 : 1.114395, loss2 : 0.806922
train_step : 19097, loss1 : 0.979014, loss2 : 1.639132
train_step : 19098, loss1 : 1.752222, loss2 : 0.748350
train_step : 19099, loss1 : 0.719726, loss2 : 0.955954
train_step : 19100, loss1 : 1.137218, loss2 : 1.426006
train_step : 19101, loss1 : 1.308508, loss2 : 1.170530
train_step : 19102, loss1 : 0.766909, loss2 : 0.788132
train_step : 19103, loss1 : 1.108895, loss2 : 0.976984
train_step : 19104, loss1 : 1.597285, loss2 : 1.501379
train_step : 19105, loss1 : 1.227978, loss2 : 0.697132
train_step : 19106, loss1 : 1.145976, loss2 : 1.345485
train_step : 19107, loss1 : 0.678553, loss2 : 2.313650
train_step : 19108, loss1 : 0.844272, loss2 : 1.065731
train_step : 19109, loss1 : 1.128047, loss2 : 1.286445
train_step : 19110, loss1 : 1.467691, loss2 : 1.626456
train_step : 19111, loss1 : 1.499220, loss2 : 1.054356
train_step : 19112, loss1 : 0.607059, loss2 : 0.510619
train_step : 19113, loss1 : 0.917854, loss2 : 0.658645
train_step : 19114, loss1 : 1.110430, loss2 : 0.769089
train_step : 19115, loss1 : 0.975085, loss2 : 1.046587
train_step : 19116, loss1 : 0.766610, loss2 : 0.553622
train_step : 19117, loss1 : 0.838587, loss2 : 0.962500
train_step : 19118, loss1 : 1.031359, loss2 : 0.693495
train_step : 19119, loss1 : 0.876236, loss2 : 1.461485
train_step : 19120, loss1 : 0.858478, loss2 : 0.824403
train_step : 19121, loss1 : 0.370818, loss2 : 1.425759
train_step : 19122, loss1 : 0.707734, loss2 : 1.303043
train_step : 19123, loss1 : 1.437701, loss2 : 0.752413
train_step : 19124, loss1 : 1.102758, loss2 : 1.092271
train_step : 19125, loss1 : 1.292935, loss2 : 0.789219
train_step : 19126, loss1 : 2.522340, loss2 : 0.803590
train_step : 19127, loss1 : 1.032429, loss2 : 1.272159
train_step : 19128, loss1 : 1.373167, loss2 : 0.849417
train_step : 19129, loss1 : 1.287560, loss2 : 1.358407
train_step : 19130, loss1 : 2.092576, loss2 : 1.850085
train_step : 19131, loss1 : 0.868648, loss2 : 1.605328
train_step : 19132, loss1 : 1.431208, loss2 : 1.147942
train_step : 19133, loss1 : 1.731103, loss2 : 0.967136
train_step : 19134, loss1 : 1.123764, loss2 : 1.655331
train_step : 19135, loss1 : 1.146088, loss2 : 1.917823
train_step : 19136, loss1 : 1.976490, loss2 : 1.229852
train_step : 19137, loss1 : 0.996499, loss2 : 2.259802
train_step : 19138, loss1 : 2.159841, loss2 : 1.794896
train_step : 19139, loss1 : 1.693887, loss2 : 2.353286
train_step : 19140, loss1 : 2.617553, loss2 : 2.149753
train_step : 19141, loss1 : 2.946151, loss2 : 2.187453
train_step : 19142, loss1 : 3.059352, loss2 : 3.113395
train_step : 19143, loss1 : 3.227769, loss2 : 2.068546
train_step : 19144, loss1 : 2.679649, loss2 : 1.776731
train_step : 19145, loss1 : 1.516581, loss2 : 1.429745
train_step : 19146, loss1 : 0.861452, loss2 : 1.063603
train_step : 19147, loss1 : 1.596823, loss2 : 0.958674
train_step : 19148, loss1 : 0.963467, loss2 : 0.759521
train_step : 19149, loss1 : 1.378177, loss2 : 0.754193
train_step : 19150, loss1 : 0.824213, loss2 : 1.218078
train_step : 19151, loss1 : 0.769881, loss2 : 0.525138
train_step : 19152, loss1 : 0.907044, loss2 : 1.211531
train_step : 19153, loss1 : 1.425346, loss2 : 0.707087
train_step : 19154, loss1 : 1.161679, loss2 : 0.958536
train_step : 19155, loss1 : 1.035993, loss2 : 0.953707
train_step : 19156, loss1 : 1.616888, loss2 : 1.776986
train_step : 19157, loss1 : 1.598950, loss2 : 0.913800
train_step : 19158, loss1 : 1.109920, loss2 : 0.774678
train_step : 19159, loss1 : 0.956505, loss2 : 1.409720
train_step : 19160, loss1 : 1.452811, loss2 : 1.554528
train_step : 19161, loss1 : 2.277606, loss2 : 2.362087
train_step : 19162, loss1 : 1.939105, loss2 : 1.126143
train_step : 19163, loss1 : 1.150237, loss2 : 1.138779
train_step : 19164, loss1 : 1.307620, loss2 : 0.767704
train_step : 19165, loss1 : 0.939458, loss2 : 2.005996
train_step : 19166, loss1 : 1.398011, loss2 : 1.657881
train_step : 19167, loss1 : 0.662178, loss2 : 1.463231
train_step : 19168, loss1 : 0.902592, loss2 : 1.024473
train_step : 19169, loss1 : 1.118732, loss2 : 1.553942
train_step : 19170, loss1 : 0.820458, loss2 : 1.655375
train_step : 19171, loss1 : 1.725810, loss2 : 0.976220
train_step : 19172, loss1 : 0.938314, loss2 : 1.005145
train_step : 19173, loss1 : 2.084458, loss2 : 1.313292
train_step : 19174, loss1 : 2.831160, loss2 : 1.753677
train_step : 19175, loss1 : 1.230039, loss2 : 1.651979
train_step : 19176, loss1 : 1.320517, loss2 : 1.029286
train_step : 19177, loss1 : 1.783169, loss2 : 1.565357
train_step : 19178, loss1 : 1.133410, loss2 : 1.024432
train_step : 19179, loss1 : 0.854865, loss2 : 1.268013
train_step : 19180, loss1 : 0.685687, loss2 : 1.118160
train_step : 19181, loss1 : 1.142424, loss2 : 2.176581
train_step : 19182, loss1 : 0.956593, loss2 : 0.586230
train_step : 19183, loss1 : 1.068257, loss2 : 1.158685
train_step : 19184, loss1 : 1.157358, loss2 : 1.927933
train_step : 19185, loss1 : 0.509658, loss2 : 2.067799
train_step : 19186, loss1 : 1.918164, loss2 : 0.896414
train_step : 19187, loss1 : 3.263577, loss2 : 0.878288
train_step : 19188, loss1 : 1.674906, loss2 : 0.706214
train_step : 19189, loss1 : 0.836094, loss2 : 1.295904
train_step : 19190, loss1 : 1.349136, loss2 : 0.590873
train_step : 19191, loss1 : 1.608366, loss2 : 1.134743
train_step : 19192, loss1 : 1.687847, loss2 : 1.387912
train_step : 19193, loss1 : 2.207867, loss2 : 1.354076
train_step : 19194, loss1 : 2.859831, loss2 : 2.593137
train_step : 19195, loss1 : 2.250210, loss2 : 3.729520
train_step : 19196, loss1 : 3.790864, loss2 : 4.230675
train_step : 19197, loss1 : 2.309996, loss2 : 4.103920
train_step : 19198, loss1 : 3.673447, loss2 : 4.894702
train_step : 19199, loss1 : 2.367950, loss2 : 3.253393
train_step : 19200, loss1 : 4.924042, loss2 : 3.059438
train_step : 19201, loss1 : 2.654917, loss2 : 3.570009
train_step : 19202, loss1 : 3.253001, loss2 : 4.544749
train_step : 19203, loss1 : 4.542090, loss2 : 3.577573
train_step : 19204, loss1 : 5.582214, loss2 : 5.004297
train_step : 19205, loss1 : 3.926572, loss2 : 4.646331
train_step : 19206, loss1 : 5.788842, loss2 : 5.123604
train_step : 19207, loss1 : 2.524335, loss2 : 1.842182
train_step : 19208, loss1 : 1.140722, loss2 : 1.745323
train_step : 19209, loss1 : 0.702543, loss2 : 1.003760
train_step : 19210, loss1 : 1.314275, loss2 : 0.949706
train_step : 19211, loss1 : 0.539547, loss2 : 1.083844
train_step : 19212, loss1 : 1.069310, loss2 : 0.818305
train_step : 19213, loss1 : 1.224787, loss2 : 1.267568
train_step : 19214, loss1 : 1.437802, loss2 : 0.855573
train_step : 19215, loss1 : 0.838724, loss2 : 1.199436
train_step : 19216, loss1 : 1.986647, loss2 : 1.109071
train_step : 19217, loss1 : 0.568728, loss2 : 0.858675
train_step : 19218, loss1 : 0.661300, loss2 : 1.248652
train_step : 19219, loss1 : 1.768584, loss2 : 1.613925
train_step : 19220, loss1 : 1.642559, loss2 : 1.214775
train_step : 19221, loss1 : 2.230600, loss2 : 1.933106
train_step : 19222, loss1 : 1.697502, loss2 : 3.733456
train_step : 19223, loss1 : 1.385275, loss2 : 1.809448
train_step : 19224, loss1 : 1.028648, loss2 : 1.681481
train_step : 19225, loss1 : 1.204554, loss2 : 0.849623
train_step : 19226, loss1 : 0.959168, loss2 : 1.069369
train_step : 19227, loss1 : 1.087607, loss2 : 0.910630
train_step : 19228, loss1 : 1.333066, loss2 : 1.115479
train_step : 19229, loss1 : 1.798896, loss2 : 2.024810
train_step : 19230, loss1 : 1.408099, loss2 : 0.849689
train_step : 19231, loss1 : 1.959422, loss2 : 1.127765
train_step : 19232, loss1 : 1.585028, loss2 : 2.361784
train_step : 19233, loss1 : 2.537355, loss2 : 1.394307
train_step : 19234, loss1 : 1.583221, loss2 : 1.649984
train_step : 19235, loss1 : 1.992286, loss2 : 0.841742
train_step : 19236, loss1 : 1.418571, loss2 : 1.546885
train_step : 19237, loss1 : 0.891043, loss2 : 0.526330
train_step : 19238, loss1 : 1.082282, loss2 : 1.191224
train_step : 19239, loss1 : 0.873257, loss2 : 1.056396
train_step : 19240, loss1 : 1.284402, loss2 : 0.556241
train_step : 19241, loss1 : 1.078552, loss2 : 1.370715
train_step : 19242, loss1 : 1.039263, loss2 : 1.163957
train_step : 19243, loss1 : 1.253056, loss2 : 0.905899
train_step : 19244, loss1 : 0.845214, loss2 : 1.375223
train_step : 19245, loss1 : 1.258789, loss2 : 0.716980
train_step : 19246, loss1 : 2.032359, loss2 : 1.038847
train_step : 19247, loss1 : 1.269483, loss2 : 1.633320
train_step : 19248, loss1 : 1.009293, loss2 : 1.897280
train_step : 19249, loss1 : 1.041507, loss2 : 1.361824
train_step : 19250, loss1 : 1.000338, loss2 : 1.977731
train_step : 19251, loss1 : 1.215333, loss2 : 2.413466
train_step : 19252, loss1 : 1.736386, loss2 : 2.414832
train_step : 19253, loss1 : 1.138330, loss2 : 1.767211
train_step : 19254, loss1 : 1.173620, loss2 : 0.899565
train_step : 19255, loss1 : 1.075529, loss2 : 1.363141
train_step : 19256, loss1 : 1.154188, loss2 : 1.504029
train_step : 19257, loss1 : 1.314683, loss2 : 1.000923
train_step : 19258, loss1 : 1.111445, loss2 : 1.769988
train_step : 19259, loss1 : 0.785470, loss2 : 1.812487
train_step : 19260, loss1 : 1.789433, loss2 : 1.171628
train_step : 19261, loss1 : 1.815303, loss2 : 0.467897
train_step : 19262, loss1 : 1.869478, loss2 : 1.154739
train_step : 19263, loss1 : 1.008387, loss2 : 0.942209
train_step : 19264, loss1 : 0.654324, loss2 : 0.922384
train_step : 19265, loss1 : 0.818526, loss2 : 1.260540
train_step : 19266, loss1 : 0.809686, loss2 : 1.380776
train_step : 19267, loss1 : 0.907219, loss2 : 1.076970
train_step : 19268, loss1 : 0.922902, loss2 : 0.696787
train_step : 19269, loss1 : 2.042250, loss2 : 2.430704
train_step : 19270, loss1 : 1.371939, loss2 : 0.590135
train_step : 19271, loss1 : 2.045949, loss2 : 0.928723
train_step : 19272, loss1 : 0.786016, loss2 : 0.715944
train_step : 19273, loss1 : 2.575849, loss2 : 0.643411
train_step : 19274, loss1 : 1.664052, loss2 : 1.149728
train_step : 19275, loss1 : 1.048190, loss2 : 0.992514
train_step : 19276, loss1 : 0.917586, loss2 : 0.926125
train_step : 19277, loss1 : 0.699464, loss2 : 1.044687
train_step : 19278, loss1 : 0.889319, loss2 : 0.802947
train_step : 19279, loss1 : 0.773376, loss2 : 0.643841
train_step : 19280, loss1 : 1.445608, loss2 : 1.537885
train_step : 19281, loss1 : 0.882522, loss2 : 1.715168
train_step : 19282, loss1 : 1.174968, loss2 : 1.029897
train_step : 19283, loss1 : 1.115618, loss2 : 0.917658
train_step : 19284, loss1 : 1.210137, loss2 : 1.415816
train_step : 19285, loss1 : 1.295350, loss2 : 0.640212
train_step : 19286, loss1 : 0.499173, loss2 : 2.230662
train_step : 19287, loss1 : 0.855426, loss2 : 1.074395
train_step : 19288, loss1 : 1.880003, loss2 : 0.690656
train_step : 19289, loss1 : 1.313433, loss2 : 0.994973
train_step : 19290, loss1 : 1.013328, loss2 : 2.546635
train_step : 19291, loss1 : 0.724194, loss2 : 2.633452
train_step : 19292, loss1 : 2.234438, loss2 : 1.854125
train_step : 19293, loss1 : 1.433456, loss2 : 1.509735
train_step : 19294, loss1 : 1.262995, loss2 : 1.389943
train_step : 19295, loss1 : 1.926184, loss2 : 2.395631
train_step : 19296, loss1 : 2.340658, loss2 : 1.569244
train_step : 19297, loss1 : 1.817606, loss2 : 0.967580
train_step : 19298, loss1 : 1.347222, loss2 : 0.987846
train_step : 19299, loss1 : 1.306587, loss2 : 1.075039
train_step : 19300, loss1 : 0.520806, loss2 : 1.177743
train_step : 19301, loss1 : 2.141010, loss2 : 0.896900
train_step : 19302, loss1 : 2.031573, loss2 : 1.193152
train_step : 19303, loss1 : 0.636267, loss2 : 1.134852
train_step : 19304, loss1 : 0.571830, loss2 : 1.225870
train_step : 19305, loss1 : 0.686387, loss2 : 0.694985
train_step : 19306, loss1 : 1.467471, loss2 : 0.886059
train_step : 19307, loss1 : 0.978629, loss2 : 1.101807
train_step : 19308, loss1 : 1.072045, loss2 : 4.922498
train_step : 19309, loss1 : 1.064665, loss2 : 1.403223
train_step : 19310, loss1 : 1.239420, loss2 : 1.582290
train_step : 19311, loss1 : 0.855836, loss2 : 0.828662
train_step : 19312, loss1 : 1.137771, loss2 : 1.377035
train_step : 19313, loss1 : 1.635820, loss2 : 2.045408
train_step : 19314, loss1 : 1.302213, loss2 : 1.981808
train_step : 19315, loss1 : 2.574552, loss2 : 1.180057
train_step : 19316, loss1 : 1.087525, loss2 : 1.464808
train_step : 19317, loss1 : 1.688430, loss2 : 1.502557
train_step : 19318, loss1 : 2.248028, loss2 : 1.501868
train_step : 19319, loss1 : 1.151427, loss2 : 1.925533
train_step : 19320, loss1 : 1.579056, loss2 : 1.282932
train_step : 19321, loss1 : 1.714870, loss2 : 0.613767
train_step : 19322, loss1 : 1.118106, loss2 : 1.126664
train_step : 19323, loss1 : 1.139017, loss2 : 1.391935
train_step : 19324, loss1 : 0.804685, loss2 : 1.480170
train_step : 19325, loss1 : 1.514776, loss2 : 0.927869
train_step : 19326, loss1 : 1.424069, loss2 : 0.458352
train_step : 19327, loss1 : 1.200746, loss2 : 1.513538
train_step : 19328, loss1 : 0.924412, loss2 : 1.213791
train_step : 19329, loss1 : 0.927328, loss2 : 1.053295
train_step : 19330, loss1 : 0.743404, loss2 : 0.723594
train_step : 19331, loss1 : 0.822241, loss2 : 0.928654
train_step : 19332, loss1 : 0.598998, loss2 : 0.965797
train_step : 19333, loss1 : 0.728986, loss2 : 1.175081
train_step : 19334, loss1 : 1.383748, loss2 : 1.025091
train_step : 19335, loss1 : 0.821488, loss2 : 0.881376
train_step : 19336, loss1 : 0.772237, loss2 : 0.851686
train_step : 19337, loss1 : 0.811887, loss2 : 1.250713
train_step : 19338, loss1 : 1.094596, loss2 : 1.160953
train_step : 19339, loss1 : 1.104596, loss2 : 1.068548
train_step : 19340, loss1 : 2.479973, loss2 : 2.467976
train_step : 19341, loss1 : 3.076846, loss2 : 4.152097
train_step : 19342, loss1 : 3.456671, loss2 : 3.572013
train_step : 19343, loss1 : 3.115698, loss2 : 1.727333
train_step : 19344, loss1 : 1.957256, loss2 : 0.860427
train_step : 19345, loss1 : 1.003596, loss2 : 0.755467
train_step : 19346, loss1 : 1.738435, loss2 : 1.004497
train_step : 19347, loss1 : 0.638100, loss2 : 1.016612
train_step : 19348, loss1 : 0.640688, loss2 : 1.044982
train_step : 19349, loss1 : 1.257805, loss2 : 1.443340
train_step : 19350, loss1 : 0.901853, loss2 : 1.084871
train_step : 19351, loss1 : 1.226587, loss2 : 1.206180
train_step : 19352, loss1 : 2.190691, loss2 : 1.403283
train_step : 19353, loss1 : 1.009496, loss2 : 1.620282
train_step : 19354, loss1 : 0.734738, loss2 : 1.407102
train_step : 19355, loss1 : 0.556614, loss2 : 0.927013
train_step : 19356, loss1 : 1.276581, loss2 : 1.118819
train_step : 19357, loss1 : 1.004860, loss2 : 1.140312
train_step : 19358, loss1 : 2.194931, loss2 : 1.393888
train_step : 19359, loss1 : 1.040663, loss2 : 1.489212
train_step : 19360, loss1 : 1.096075, loss2 : 0.579618
train_step : 19361, loss1 : 0.611159, loss2 : 1.056787
train_step : 19362, loss1 : 1.408748, loss2 : 0.566178
train_step : 19363, loss1 : 0.854564, loss2 : 1.927867
train_step : 19364, loss1 : 1.155530, loss2 : 1.510298
train_step : 19365, loss1 : 0.901541, loss2 : 1.942259
train_step : 19366, loss1 : 0.642626, loss2 : 1.540227
train_step : 19367, loss1 : 0.692970, loss2 : 1.489990
train_step : 19368, loss1 : 0.644323, loss2 : 0.672379
train_step : 19369, loss1 : 0.741642, loss2 : 1.080433
train_step : 19370, loss1 : 0.810076, loss2 : 0.969499
train_step : 19371, loss1 : 1.445176, loss2 : 1.278007
train_step : 19372, loss1 : 1.839779, loss2 : 1.139723
train_step : 19373, loss1 : 0.981543, loss2 : 0.982487
train_step : 19374, loss1 : 0.871370, loss2 : 1.152945
train_step : 19375, loss1 : 0.945309, loss2 : 0.845166
train_step : 19376, loss1 : 0.496018, loss2 : 0.475513
train_step : 19377, loss1 : 0.727366, loss2 : 1.108269
train_step : 19378, loss1 : 1.756909, loss2 : 0.508594
train_step : 19379, loss1 : 2.455549, loss2 : 1.965956
train_step : 19380, loss1 : 3.204873, loss2 : 2.445399
train_step : 19381, loss1 : 1.666459, loss2 : 2.117245
train_step : 19382, loss1 : 1.872481, loss2 : 1.491236
train_step : 19383, loss1 : 1.705407, loss2 : 0.643058
train_step : 19384, loss1 : 2.282677, loss2 : 1.239892
train_step : 19385, loss1 : 1.151760, loss2 : 0.956987
train_step : 19386, loss1 : 1.062999, loss2 : 0.755988
train_step : 19387, loss1 : 1.184090, loss2 : 0.960630
train_step : 19388, loss1 : 0.673831, loss2 : 0.881260
train_step : 19389, loss1 : 0.878752, loss2 : 0.840788
train_step : 19390, loss1 : 1.142527, loss2 : 0.952619
train_step : 19391, loss1 : 1.178132, loss2 : 2.298942
train_step : 19392, loss1 : 1.902440, loss2 : 1.382625
train_step : 19393, loss1 : 1.214682, loss2 : 1.731186
train_step : 19394, loss1 : 1.661249, loss2 : 1.982590
train_step : 19395, loss1 : 1.433138, loss2 : 0.651420
train_step : 19396, loss1 : 1.891930, loss2 : 0.970872
train_step : 19397, loss1 : 0.971190, loss2 : 1.448638
train_step : 19398, loss1 : 3.545991, loss2 : 1.043559
train_step : 19399, loss1 : 0.941562, loss2 : 2.464790
train_step : 19400, loss1 : 3.972600, loss2 : 1.668599
train_step : 19401, loss1 : 1.161757, loss2 : 1.418831
train_step : 19402, loss1 : 1.239585, loss2 : 0.797332
train_step : 19403, loss1 : 0.814037, loss2 : 1.386636
train_step : 19404, loss1 : 1.265325, loss2 : 1.073447
train_step : 19405, loss1 : 0.971116, loss2 : 1.520319
train_step : 19406, loss1 : 1.274081, loss2 : 2.008222
train_step : 19407, loss1 : 1.254324, loss2 : 2.460780
train_step : 19408, loss1 : 2.670856, loss2 : 3.237046
train_step : 19409, loss1 : 2.005985, loss2 : 3.136506
train_step : 19410, loss1 : 1.886446, loss2 : 3.025398
train_step : 19411, loss1 : 1.245250, loss2 : 0.786825
train_step : 19412, loss1 : 1.303244, loss2 : 1.656634
train_step : 19413, loss1 : 0.798998, loss2 : 1.946645
train_step : 19414, loss1 : 1.277845, loss2 : 1.293949
train_step : 19415, loss1 : 1.414696, loss2 : 0.827783
train_step : 19416, loss1 : 0.710795, loss2 : 0.798702
train_step : 19417, loss1 : 1.404961, loss2 : 1.312552
train_step : 19418, loss1 : 1.569081, loss2 : 1.612432
train_step : 19419, loss1 : 2.320796, loss2 : 1.388587
train_step : 19420, loss1 : 1.355840, loss2 : 1.776741
train_step : 19421, loss1 : 1.281422, loss2 : 1.721583
train_step : 19422, loss1 : 1.217781, loss2 : 1.101499
train_step : 19423, loss1 : 1.661506, loss2 : 1.006129
train_step : 19424, loss1 : 1.244800, loss2 : 0.870492
train_step : 19425, loss1 : 0.863724, loss2 : 1.119930
train_step : 19426, loss1 : 1.869954, loss2 : 2.957324
train_step : 19427, loss1 : 3.160804, loss2 : 1.077004
train_step : 19428, loss1 : 1.949481, loss2 : 1.869820
train_step : 19429, loss1 : 1.509357, loss2 : 1.990727
train_step : 19430, loss1 : 1.592923, loss2 : 1.057573
train_step : 19431, loss1 : 1.697739, loss2 : 0.951980
train_step : 19432, loss1 : 0.879270, loss2 : 0.950513
train_step : 19433, loss1 : 1.286411, loss2 : 1.466382
train_step : 19434, loss1 : 0.979887, loss2 : 1.509937
train_step : 19435, loss1 : 1.961080, loss2 : 2.849322
train_step : 19436, loss1 : 1.595591, loss2 : 1.765816
train_step : 19437, loss1 : 1.847211, loss2 : 1.255685
train_step : 19438, loss1 : 1.784329, loss2 : 0.822468
train_step : 19439, loss1 : 1.052055, loss2 : 1.794131
train_step : 19440, loss1 : 1.430854, loss2 : 1.107961
train_step : 19441, loss1 : 1.503467, loss2 : 0.591684
train_step : 19442, loss1 : 1.727438, loss2 : 1.749907
train_step : 19443, loss1 : 1.004609, loss2 : 1.881666
train_step : 19444, loss1 : 0.821276, loss2 : 1.739771
train_step : 19445, loss1 : 1.051489, loss2 : 0.846769
train_step : 19446, loss1 : 2.476290, loss2 : 0.941363
train_step : 19447, loss1 : 1.522105, loss2 : 1.091732
train_step : 19448, loss1 : 1.333839, loss2 : 1.497452
train_step : 19449, loss1 : 1.200348, loss2 : 1.278607
train_step : 19450, loss1 : 1.129775, loss2 : 1.206241
train_step : 19451, loss1 : 1.268987, loss2 : 0.608298
train_step : 19452, loss1 : 0.586813, loss2 : 1.730552
train_step : 19453, loss1 : 1.042948, loss2 : 0.665788
train_step : 19454, loss1 : 1.400867, loss2 : 1.026969
train_step : 19455, loss1 : 0.859705, loss2 : 1.120368
train_step : 19456, loss1 : 1.092800, loss2 : 0.837157
train_step : 19457, loss1 : 0.734644, loss2 : 0.971100
train_step : 19458, loss1 : 0.938014, loss2 : 0.684174
train_step : 19459, loss1 : 1.827848, loss2 : 1.210326
train_step : 19460, loss1 : 1.636397, loss2 : 1.941396
train_step : 19461, loss1 : 1.054923, loss2 : 0.843927
train_step : 19462, loss1 : 1.022253, loss2 : 0.982702
train_step : 19463, loss1 : 0.624987, loss2 : 0.780369
train_step : 19464, loss1 : 1.115096, loss2 : 1.358616
train_step : 19465, loss1 : 1.294967, loss2 : 0.785924
train_step : 19466, loss1 : 1.436435, loss2 : 1.652599
train_step : 19467, loss1 : 0.537823, loss2 : 1.180606
train_step : 19468, loss1 : 0.987515, loss2 : 0.954947
train_step : 19469, loss1 : 0.788679, loss2 : 0.714131
train_step : 19470, loss1 : 0.622123, loss2 : 1.361915
train_step : 19471, loss1 : 0.676352, loss2 : 0.624266
train_step : 19472, loss1 : 0.820817, loss2 : 1.033413
train_step : 19473, loss1 : 1.862562, loss2 : 1.302691
train_step : 19474, loss1 : 1.325304, loss2 : 2.742383
train_step : 19475, loss1 : 2.130633, loss2 : 2.570000
train_step : 19476, loss1 : 2.443808, loss2 : 1.252875
train_step : 19477, loss1 : 1.477805, loss2 : 1.132179
train_step : 19478, loss1 : 0.755247, loss2 : 1.694176
train_step : 19479, loss1 : 0.919505, loss2 : 1.884764
train_step : 19480, loss1 : 1.665684, loss2 : 1.818589
train_step : 19481, loss1 : 1.832744, loss2 : 1.993696
train_step : 19482, loss1 : 2.125484, loss2 : 2.381474
train_step : 19483, loss1 : 1.207885, loss2 : 0.989260
train_step : 19484, loss1 : 1.075322, loss2 : 2.707944
train_step : 19485, loss1 : 0.914100, loss2 : 1.760635
train_step : 19486, loss1 : 0.999123, loss2 : 1.461160
train_step : 19487, loss1 : 0.533667, loss2 : 1.357350
train_step : 19488, loss1 : 1.208313, loss2 : 1.923600
train_step : 19489, loss1 : 1.534800, loss2 : 0.971272
train_step : 19490, loss1 : 1.090023, loss2 : 1.308861
train_step : 19491, loss1 : 1.006049, loss2 : 0.745083
train_step : 19492, loss1 : 1.481661, loss2 : 1.367268
train_step : 19493, loss1 : 1.044266, loss2 : 0.998625
train_step : 19494, loss1 : 0.739689, loss2 : 0.966507
train_step : 19495, loss1 : 1.309675, loss2 : 0.995432
train_step : 19496, loss1 : 0.957884, loss2 : 1.080140
train_step : 19497, loss1 : 1.397112, loss2 : 0.914971
train_step : 19498, loss1 : 0.905468, loss2 : 1.325693
train_step : 19499, loss1 : 1.718158, loss2 : 1.584568
train_step : 19500, loss1 : 1.081402, loss2 : 1.295399
train_step : 19501, loss1 : 1.061584, loss2 : 1.399904
train_step : 19502, loss1 : 1.616063, loss2 : 0.998217
train_step : 19503, loss1 : 1.710106, loss2 : 1.326621
train_step : 19504, loss1 : 0.643986, loss2 : 0.965487
train_step : 19505, loss1 : 1.297245, loss2 : 0.894693
train_step : 19506, loss1 : 1.083717, loss2 : 0.959891
train_step : 19507, loss1 : 0.499308, loss2 : 0.975831
train_step : 19508, loss1 : 1.160333, loss2 : 0.772456
train_step : 19509, loss1 : 0.696157, loss2 : 1.126474
train_step : 19510, loss1 : 1.750573, loss2 : 0.861108
train_step : 19511, loss1 : 2.917425, loss2 : 1.530601
train_step : 19512, loss1 : 1.393115, loss2 : 1.170924
train_step : 19513, loss1 : 1.367234, loss2 : 1.383821
train_step : 19514, loss1 : 1.257459, loss2 : 1.173783
train_step : 19515, loss1 : 0.921741, loss2 : 1.220598
train_step : 19516, loss1 : 1.514556, loss2 : 0.476600
train_step : 19517, loss1 : 1.073242, loss2 : 0.883875
train_step : 19518, loss1 : 2.088754, loss2 : 1.906511
train_step : 19519, loss1 : 2.845348, loss2 : 1.582227
train_step : 19520, loss1 : 1.545750, loss2 : 1.830669
train_step : 19521, loss1 : 2.495916, loss2 : 1.777237
train_step : 19522, loss1 : 0.937222, loss2 : 2.717999
train_step : 19523, loss1 : 1.795485, loss2 : 1.658713
train_step : 19524, loss1 : 1.563954, loss2 : 1.305151
train_step : 19525, loss1 : 1.609790, loss2 : 1.150620
train_step : 19526, loss1 : 2.916740, loss2 : 2.401247
train_step : 19527, loss1 : 2.987135, loss2 : 2.697632
train_step : 19528, loss1 : 2.702663, loss2 : 1.765496
train_step : 19529, loss1 : 1.847865, loss2 : 2.093246
train_step : 19530, loss1 : 0.958392, loss2 : 1.692747
train_step : 19531, loss1 : 1.625117, loss2 : 1.164105
train_step : 19532, loss1 : 0.769024, loss2 : 1.003889
train_step : 19533, loss1 : 0.813828, loss2 : 0.697411
train_step : 19534, loss1 : 0.811853, loss2 : 1.347611
train_step : 19535, loss1 : 0.925279, loss2 : 1.088618
train_step : 19536, loss1 : 0.810584, loss2 : 1.251727
train_step : 19537, loss1 : 0.690996, loss2 : 0.591476
train_step : 19538, loss1 : 0.581114, loss2 : 1.328225
train_step : 19539, loss1 : 1.579476, loss2 : 1.227834
train_step : 19540, loss1 : 1.271359, loss2 : 1.703121
train_step : 19541, loss1 : 2.414164, loss2 : 1.159546
train_step : 19542, loss1 : 0.696982, loss2 : 0.944348
train_step : 19543, loss1 : 1.157633, loss2 : 1.575181
train_step : 19544, loss1 : 1.918648, loss2 : 1.503012
train_step : 19545, loss1 : 1.975038, loss2 : 1.353497
train_step : 19546, loss1 : 1.656441, loss2 : 0.714330
train_step : 19547, loss1 : 0.956427, loss2 : 1.497631
train_step : 19548, loss1 : 1.185545, loss2 : 0.853125
train_step : 19549, loss1 : 1.115482, loss2 : 1.556950
train_step : 19550, loss1 : 1.337835, loss2 : 1.330088
train_step : 19551, loss1 : 4.786535, loss2 : 1.223271
train_step : 19552, loss1 : 1.370809, loss2 : 1.889821
train_step : 19553, loss1 : 2.112597, loss2 : 1.036306
train_step : 19554, loss1 : 1.337709, loss2 : 0.993943
train_step : 19555, loss1 : 1.729618, loss2 : 1.049139
train_step : 19556, loss1 : 1.962710, loss2 : 1.489151
train_step : 19557, loss1 : 1.146718, loss2 : 0.873428
train_step : 19558, loss1 : 1.259530, loss2 : 1.351525
train_step : 19559, loss1 : 1.421298, loss2 : 0.788830
train_step : 19560, loss1 : 0.941481, loss2 : 0.515646
train_step : 19561, loss1 : 0.920714, loss2 : 0.816945
train_step : 19562, loss1 : 1.388745, loss2 : 1.467234
train_step : 19563, loss1 : 1.346763, loss2 : 0.958937
train_step : 19564, loss1 : 1.873494, loss2 : 1.761765
train_step : 19565, loss1 : 2.433431, loss2 : 0.972592
train_step : 19566, loss1 : 3.140054, loss2 : 1.298290
train_step : 19567, loss1 : 1.603020, loss2 : 1.018718
train_step : 19568, loss1 : 1.556370, loss2 : 1.317495
train_step : 19569, loss1 : 0.996135, loss2 : 1.398691
train_step : 19570, loss1 : 2.080752, loss2 : 1.273786
train_step : 19571, loss1 : 0.652872, loss2 : 1.662395
train_step : 19572, loss1 : 0.859398, loss2 : 1.062532
train_step : 19573, loss1 : 1.581368, loss2 : 1.235643
train_step : 19574, loss1 : 1.147185, loss2 : 1.347670
train_step : 19575, loss1 : 1.020715, loss2 : 0.971882
train_step : 19576, loss1 : 2.376158, loss2 : 0.987374
train_step : 19577, loss1 : 1.615730, loss2 : 1.243619
train_step : 19578, loss1 : 1.921538, loss2 : 1.360059
train_step : 19579, loss1 : 0.594946, loss2 : 1.108878
train_step : 19580, loss1 : 0.986255, loss2 : 1.581086
train_step : 19581, loss1 : 2.084153, loss2 : 0.702817
train_step : 19582, loss1 : 0.967781, loss2 : 0.887620
train_step : 19583, loss1 : 0.793503, loss2 : 1.123581
train_step : 19584, loss1 : 1.146432, loss2 : 1.251269
train_step : 19585, loss1 : 1.550404, loss2 : 1.659412
train_step : 19586, loss1 : 1.198957, loss2 : 1.207678
train_step : 19587, loss1 : 0.811404, loss2 : 1.547108
train_step : 19588, loss1 : 1.578348, loss2 : 0.677889
train_step : 19589, loss1 : 1.089587, loss2 : 1.883969
train_step : 19590, loss1 : 0.873096, loss2 : 0.626599
train_step : 19591, loss1 : 1.463831, loss2 : 0.800787
train_step : 19592, loss1 : 1.073569, loss2 : 1.616192
train_step : 19593, loss1 : 0.705092, loss2 : 0.702648
train_step : 19594, loss1 : 1.029217, loss2 : 1.148593
train_step : 19595, loss1 : 0.721447, loss2 : 1.189142
train_step : 19596, loss1 : 1.081698, loss2 : 1.236924
train_step : 19597, loss1 : 1.160830, loss2 : 1.012483
train_step : 19598, loss1 : 0.921616, loss2 : 1.350437
train_step : 19599, loss1 : 1.489205, loss2 : 1.638271
train_step : 19600, loss1 : 0.872644, loss2 : 0.933292
train_step : 19601, loss1 : 0.712123, loss2 : 1.022521
train_step : 19602, loss1 : 1.944612, loss2 : 1.164723
train_step : 19603, loss1 : 1.676567, loss2 : 1.465652
train_step : 19604, loss1 : 1.147485, loss2 : 0.960085
train_step : 19605, loss1 : 1.210030, loss2 : 1.080180
train_step : 19606, loss1 : 1.252826, loss2 : 1.730327
train_step : 19607, loss1 : 1.360118, loss2 : 2.112120
train_step : 19608, loss1 : 1.213894, loss2 : 1.140169
train_step : 19609, loss1 : 2.664311, loss2 : 1.673820
train_step : 19610, loss1 : 1.573664, loss2 : 1.124261
train_step : 19611, loss1 : 0.831373, loss2 : 0.833670
train_step : 19612, loss1 : 2.168394, loss2 : 0.571447
train_step : 19613, loss1 : 1.473642, loss2 : 0.726697
train_step : 19614, loss1 : 0.672204, loss2 : 0.816778
train_step : 19615, loss1 : 1.269171, loss2 : 1.449278
train_step : 19616, loss1 : 2.183217, loss2 : 1.193284
train_step : 19617, loss1 : 2.314709, loss2 : 4.535300
train_step : 19618, loss1 : 5.044366, loss2 : 4.415261
train_step : 19619, loss1 : 4.838731, loss2 : 7.393002
train_step : 19620, loss1 : 3.532401, loss2 : 4.237990
train_step : 19621, loss1 : 4.250336, loss2 : 4.641849
train_step : 19622, loss1 : 6.172942, loss2 : 3.304849
train_step : 19623, loss1 : 6.023397, loss2 : 5.675549
train_step : 19624, loss1 : 3.137267, loss2 : 2.917838
train_step : 19625, loss1 : 1.502624, loss2 : 1.272775
train_step : 19626, loss1 : 1.139899, loss2 : 1.035624
train_step : 19627, loss1 : 3.207200, loss2 : 0.931320
train_step : 19628, loss1 : 1.133203, loss2 : 1.847172
train_step : 19629, loss1 : 0.757241, loss2 : 0.908777
train_step : 19630, loss1 : 1.517555, loss2 : 1.698629
train_step : 19631, loss1 : 1.648407, loss2 : 3.061488
train_step : 19632, loss1 : 2.615782, loss2 : 1.492566
train_step : 19633, loss1 : 1.001698, loss2 : 1.670435
train_step : 19634, loss1 : 0.900735, loss2 : 0.842342
train_step : 19635, loss1 : 0.808302, loss2 : 0.984471
train_step : 19636, loss1 : 1.823754, loss2 : 0.622165
train_step : 19637, loss1 : 1.755667, loss2 : 0.566903
train_step : 19638, loss1 : 1.306965, loss2 : 1.373520
train_step : 19639, loss1 : 1.143590, loss2 : 2.107268
train_step : 19640, loss1 : 0.680457, loss2 : 2.249778
train_step : 19641, loss1 : 2.414939, loss2 : 1.764824
train_step : 19642, loss1 : 0.998116, loss2 : 1.603165
train_step : 19643, loss1 : 0.889714, loss2 : 1.264559
train_step : 19644, loss1 : 0.790452, loss2 : 1.475435
train_step : 19645, loss1 : 0.947195, loss2 : 0.511378
train_step : 19646, loss1 : 0.962791, loss2 : 1.360533
train_step : 19647, loss1 : 1.790340, loss2 : 0.767179
train_step : 19648, loss1 : 2.039190, loss2 : 1.052540
train_step : 19649, loss1 : 1.003122, loss2 : 1.672642
train_step : 19650, loss1 : 1.250957, loss2 : 0.987317
train_step : 19651, loss1 : 1.319463, loss2 : 0.939677
train_step : 19652, loss1 : 1.099812, loss2 : 1.384777
train_step : 19653, loss1 : 0.687116, loss2 : 1.058520
train_step : 19654, loss1 : 1.454605, loss2 : 0.699750
train_step : 19655, loss1 : 1.184430, loss2 : 0.699021
train_step : 19656, loss1 : 1.033367, loss2 : 1.490911
train_step : 19657, loss1 : 1.912869, loss2 : 2.197093
train_step : 19658, loss1 : 1.613197, loss2 : 1.057562
train_step : 19659, loss1 : 1.153048, loss2 : 1.211972
train_step : 19660, loss1 : 0.771461, loss2 : 1.257812
train_step : 19661, loss1 : 1.065956, loss2 : 1.388777
train_step : 19662, loss1 : 1.371153, loss2 : 0.665791
train_step : 19663, loss1 : 0.875970, loss2 : 1.105907
train_step : 19664, loss1 : 1.007705, loss2 : 1.281306
train_step : 19665, loss1 : 1.595998, loss2 : 1.309683
train_step : 19666, loss1 : 0.920640, loss2 : 1.447111
train_step : 19667, loss1 : 1.149416, loss2 : 1.676804
train_step : 19668, loss1 : 1.215016, loss2 : 1.443388
train_step : 19669, loss1 : 1.215449, loss2 : 0.659181
train_step : 19670, loss1 : 0.704890, loss2 : 0.465485
train_step : 19671, loss1 : 0.818728, loss2 : 0.955985
train_step : 19672, loss1 : 1.112369, loss2 : 1.268237
train_step : 19673, loss1 : 0.665119, loss2 : 1.144242
train_step : 19674, loss1 : 1.517887, loss2 : 0.870392
train_step : 19675, loss1 : 0.855843, loss2 : 1.090737
train_step : 19676, loss1 : 1.108763, loss2 : 1.048492
train_step : 19677, loss1 : 1.194966, loss2 : 1.919643
train_step : 19678, loss1 : 1.182202, loss2 : 1.594884
train_step : 19679, loss1 : 1.388918, loss2 : 1.330819
train_step : 19680, loss1 : 1.002704, loss2 : 1.106675
train_step : 19681, loss1 : 1.378078, loss2 : 1.384341
train_step : 19682, loss1 : 1.700974, loss2 : 1.718170
train_step : 19683, loss1 : 1.237445, loss2 : 0.807202
train_step : 19684, loss1 : 0.845409, loss2 : 0.645920
train_step : 19685, loss1 : 0.816457, loss2 : 1.157855
train_step : 19686, loss1 : 1.371106, loss2 : 1.856503
train_step : 19687, loss1 : 1.055924, loss2 : 0.883317
train_step : 19688, loss1 : 2.131799, loss2 : 1.292457
train_step : 19689, loss1 : 1.411599, loss2 : 1.413975
train_step : 19690, loss1 : 2.191945, loss2 : 1.908151
train_step : 19691, loss1 : 2.394492, loss2 : 2.754471
train_step : 19692, loss1 : 1.644054, loss2 : 2.351278
train_step : 19693, loss1 : 1.808847, loss2 : 2.029552
train_step : 19694, loss1 : 1.056592, loss2 : 1.891411
train_step : 19695, loss1 : 0.900746, loss2 : 0.669183
train_step : 19696, loss1 : 0.945834, loss2 : 0.789737
train_step : 19697, loss1 : 1.477397, loss2 : 1.247760
train_step : 19698, loss1 : 1.966310, loss2 : 1.135538
train_step : 19699, loss1 : 1.129767, loss2 : 0.610950
train_step : 19700, loss1 : 1.098548, loss2 : 0.837227
train_step : 19701, loss1 : 0.981863, loss2 : 1.678172
train_step : 19702, loss1 : 0.947191, loss2 : 1.539892
train_step : 19703, loss1 : 0.782312, loss2 : 1.329349
train_step : 19704, loss1 : 0.698446, loss2 : 1.054080
train_step : 19705, loss1 : 0.988276, loss2 : 0.791151
train_step : 19706, loss1 : 0.520141, loss2 : 0.994194
train_step : 19707, loss1 : 1.244305, loss2 : 1.268900
train_step : 19708, loss1 : 0.857097, loss2 : 1.310545
train_step : 19709, loss1 : 1.277407, loss2 : 1.399368
train_step : 19710, loss1 : 1.885496, loss2 : 0.931064
train_step : 19711, loss1 : 1.819410, loss2 : 1.262841
train_step : 19712, loss1 : 1.134074, loss2 : 2.430937
train_step : 19713, loss1 : 2.255495, loss2 : 2.663402
train_step : 19714, loss1 : 2.415005, loss2 : 0.811142
train_step : 19715, loss1 : 1.880565, loss2 : 1.504178
train_step : 19716, loss1 : 1.289160, loss2 : 1.940932
train_step : 19717, loss1 : 0.783175, loss2 : 0.836827
train_step : 19718, loss1 : 1.290994, loss2 : 1.624329
train_step : 19719, loss1 : 1.145828, loss2 : 0.898555
train_step : 19720, loss1 : 1.233463, loss2 : 0.814378
train_step : 19721, loss1 : 0.762456, loss2 : 0.748494
train_step : 19722, loss1 : 1.375243, loss2 : 1.276611
train_step : 19723, loss1 : 1.503834, loss2 : 1.100480
train_step : 19724, loss1 : 1.026473, loss2 : 0.928724
train_step : 19725, loss1 : 0.943123, loss2 : 1.483324
train_step : 19726, loss1 : 0.963075, loss2 : 1.559336
train_step : 19727, loss1 : 1.031053, loss2 : 0.979538
train_step : 19728, loss1 : 1.120620, loss2 : 1.185439
train_step : 19729, loss1 : 1.224643, loss2 : 0.536102
train_step : 19730, loss1 : 0.871748, loss2 : 0.936367
train_step : 19731, loss1 : 1.237854, loss2 : 1.365522
train_step : 19732, loss1 : 0.862349, loss2 : 1.285241
train_step : 19733, loss1 : 1.440266, loss2 : 1.247661
train_step : 19734, loss1 : 1.530939, loss2 : 1.448376
train_step : 19735, loss1 : 0.530046, loss2 : 1.327149
train_step : 19736, loss1 : 0.818003, loss2 : 1.189427
train_step : 19737, loss1 : 1.134221, loss2 : 1.422061
train_step : 19738, loss1 : 1.204804, loss2 : 1.338402
train_step : 19739, loss1 : 0.915694, loss2 : 1.260982
train_step : 19740, loss1 : 1.249608, loss2 : 1.815572
train_step : 19741, loss1 : 1.418355, loss2 : 0.928895
train_step : 19742, loss1 : 1.517453, loss2 : 1.152664
train_step : 19743, loss1 : 0.509856, loss2 : 1.513112
train_step : 19744, loss1 : 1.247555, loss2 : 0.969366
train_step : 19745, loss1 : 1.275545, loss2 : 0.924555
train_step : 19746, loss1 : 1.750611, loss2 : 1.174032
train_step : 19747, loss1 : 1.937182, loss2 : 0.737827
train_step : 19748, loss1 : 1.077691, loss2 : 0.870746
train_step : 19749, loss1 : 1.936059, loss2 : 0.963300
train_step : 19750, loss1 : 1.127470, loss2 : 0.865241
train_step : 19751, loss1 : 1.310928, loss2 : 1.191267
train_step : 19752, loss1 : 0.714304, loss2 : 1.138343
train_step : 19753, loss1 : 1.870672, loss2 : 1.789162
train_step : 19754, loss1 : 1.273235, loss2 : 0.889093
train_step : 19755, loss1 : 0.800205, loss2 : 2.547174
train_step : 19756, loss1 : 1.026921, loss2 : 1.225533
train_step : 19757, loss1 : 0.998970, loss2 : 0.959934
train_step : 19758, loss1 : 0.920119, loss2 : 0.778828
train_step : 19759, loss1 : 0.933131, loss2 : 1.525507
train_step : 19760, loss1 : 1.234565, loss2 : 1.321845
train_step : 19761, loss1 : 1.356958, loss2 : 0.966073
train_step : 19762, loss1 : 1.635229, loss2 : 0.759708
train_step : 19763, loss1 : 0.552790, loss2 : 0.727258
train_step : 19764, loss1 : 1.402939, loss2 : 1.065026
train_step : 19765, loss1 : 1.038551, loss2 : 1.815939
train_step : 19766, loss1 : 0.881628, loss2 : 1.186594
train_step : 19767, loss1 : 1.261940, loss2 : 1.503406
train_step : 19768, loss1 : 0.843059, loss2 : 0.968492
train_step : 19769, loss1 : 1.443217, loss2 : 1.897415
train_step : 19770, loss1 : 1.852444, loss2 : 2.119308
train_step : 19771, loss1 : 2.746543, loss2 : 1.688046
train_step : 19772, loss1 : 2.535971, loss2 : 2.338233
train_step : 19773, loss1 : 2.215595, loss2 : 2.184404
train_step : 19774, loss1 : 2.905598, loss2 : 2.678563
train_step : 19775, loss1 : 3.068572, loss2 : 3.329200
train_step : 19776, loss1 : 1.878891, loss2 : 2.268898
train_step : 19777, loss1 : 2.782709, loss2 : 3.058249
train_step : 19778, loss1 : 4.024278, loss2 : 1.892940
train_step : 19779, loss1 : 0.840440, loss2 : 1.508119
train_step : 19780, loss1 : 2.013172, loss2 : 1.331349
train_step : 19781, loss1 : 1.322980, loss2 : 1.895925
train_step : 19782, loss1 : 1.997856, loss2 : 1.209108
train_step : 19783, loss1 : 1.612382, loss2 : 1.438179
train_step : 19784, loss1 : 2.282094, loss2 : 2.491542
train_step : 19785, loss1 : 1.330626, loss2 : 1.960231
train_step : 19786, loss1 : 1.555606, loss2 : 1.599149
train_step : 19787, loss1 : 1.618341, loss2 : 1.230793
train_step : 19788, loss1 : 2.094374, loss2 : 1.177269
train_step : 19789, loss1 : 8.548416, loss2 : 1.256433
train_step : 19790, loss1 : 0.967935, loss2 : 10.646709
train_step : 19791, loss1 : 1.948484, loss2 : 2.437275
train_step : 19792, loss1 : 2.380645, loss2 : 1.499769
train_step : 19793, loss1 : 1.332581, loss2 : 2.226287
train_step : 19794, loss1 : 1.329871, loss2 : 1.901800
train_step : 19795, loss1 : 0.419674, loss2 : 0.816264
train_step : 19796, loss1 : 1.042791, loss2 : 1.069545
train_step : 19797, loss1 : 1.498671, loss2 : 0.921918
train_step : 19798, loss1 : 1.184288, loss2 : 0.915757
train_step : 19799, loss1 : 1.038661, loss2 : 0.863069
train_step : 19800, loss1 : 1.119512, loss2 : 2.196111
train_step : 19801, loss1 : 1.669520, loss2 : 1.616325
train_step : 19802, loss1 : 2.051055, loss2 : 1.694852
train_step : 19803, loss1 : 2.238864, loss2 : 1.675068
train_step : 19804, loss1 : 3.110034, loss2 : 2.086779
train_step : 19805, loss1 : 3.617895, loss2 : 3.307054
train_step : 19806, loss1 : 2.741502, loss2 : 2.201087
train_step : 19807, loss1 : 5.409270, loss2 : 3.544939
train_step : 19808, loss1 : 4.658650, loss2 : 4.398678
train_step : 19809, loss1 : 5.983939, loss2 : 3.522884
train_step : 19810, loss1 : 4.038714, loss2 : 4.764248
train_step : 19811, loss1 : 7.135967, loss2 : 6.614415
train_step : 19812, loss1 : 2.809058, loss2 : 7.900959
train_step : 19813, loss1 : 3.045741, loss2 : 3.730398
train_step : 19814, loss1 : 2.055143, loss2 : 1.980546
train_step : 19815, loss1 : 2.502124, loss2 : 1.761979
train_step : 19816, loss1 : 2.176152, loss2 : 2.366116
train_step : 19817, loss1 : 3.213398, loss2 : 2.564835
train_step : 19818, loss1 : 2.038834, loss2 : 4.042037
train_step : 19819, loss1 : 3.238379, loss2 : 2.564702
train_step : 19820, loss1 : 1.993046, loss2 : 2.247990
train_step : 19821, loss1 : 2.040112, loss2 : 1.181295
train_step : 19822, loss1 : 1.660272, loss2 : 1.010179
train_step : 19823, loss1 : 1.126971, loss2 : 1.072850
train_step : 19824, loss1 : 1.346804, loss2 : 1.142258
train_step : 19825, loss1 : 0.861710, loss2 : 1.703046
train_step : 19826, loss1 : 0.721953, loss2 : 1.019409
train_step : 19827, loss1 : 1.073343, loss2 : 1.013199
train_step : 19828, loss1 : 2.466031, loss2 : 1.391957
train_step : 19829, loss1 : 2.943307, loss2 : 1.569026
train_step : 19830, loss1 : 1.337211, loss2 : 1.638049
train_step : 19831, loss1 : 1.433748, loss2 : 1.289519
train_step : 19832, loss1 : 1.701139, loss2 : 1.910329
train_step : 19833, loss1 : 1.766945, loss2 : 2.285421
train_step : 19834, loss1 : 1.422529, loss2 : 1.801903
train_step : 19835, loss1 : 1.367605, loss2 : 2.566051
train_step : 19836, loss1 : 1.139018, loss2 : 1.295450
train_step : 19837, loss1 : 1.796279, loss2 : 1.028381
train_step : 19838, loss1 : 1.836886, loss2 : 1.876656
train_step : 19839, loss1 : 2.680655, loss2 : 1.700446
train_step : 19840, loss1 : 1.994325, loss2 : 1.558984
train_step : 19841, loss1 : 1.441802, loss2 : 2.351713
train_step : 19842, loss1 : 1.508604, loss2 : 1.849891
train_step : 19843, loss1 : 1.998805, loss2 : 0.973411
train_step : 19844, loss1 : 1.245611, loss2 : 1.624530
train_step : 19845, loss1 : 1.232494, loss2 : 1.130018
train_step : 19846, loss1 : 1.108425, loss2 : 1.483028
train_step : 19847, loss1 : 0.672427, loss2 : 1.281202
train_step : 19848, loss1 : 1.170177, loss2 : 0.563574
train_step : 19849, loss1 : 1.384643, loss2 : 1.124522
train_step : 19850, loss1 : 1.349413, loss2 : 0.896103
train_step : 19851, loss1 : 1.635833, loss2 : 1.286334
train_step : 19852, loss1 : 1.650082, loss2 : 0.817864
train_step : 19853, loss1 : 1.412626, loss2 : 1.178450
train_step : 19854, loss1 : 0.615313, loss2 : 1.056231
train_step : 19855, loss1 : 0.690099, loss2 : 1.133555
train_step : 19856, loss1 : 1.134291, loss2 : 1.114529
train_step : 19857, loss1 : 0.809583, loss2 : 1.082858
train_step : 19858, loss1 : 1.514992, loss2 : 0.759244
train_step : 19859, loss1 : 1.069260, loss2 : 0.893453
train_step : 19860, loss1 : 1.364837, loss2 : 1.609541
train_step : 19861, loss1 : 0.791387, loss2 : 1.503457
train_step : 19862, loss1 : 1.225068, loss2 : 1.037416
train_step : 19863, loss1 : 1.092724, loss2 : 1.229465
train_step : 19864, loss1 : 0.713085, loss2 : 0.859496
train_step : 19865, loss1 : 0.667930, loss2 : 0.754639
train_step : 19866, loss1 : 0.786200, loss2 : 0.614377
train_step : 19867, loss1 : 0.948931, loss2 : 1.443838
train_step : 19868, loss1 : 0.526499, loss2 : 1.522701
train_step : 19869, loss1 : 0.551327, loss2 : 2.534994
train_step : 19870, loss1 : 1.409422, loss2 : 1.099450
train_step : 19871, loss1 : 0.799314, loss2 : 1.127736
train_step : 19872, loss1 : 1.940337, loss2 : 1.131096
train_step : 19873, loss1 : 0.805509, loss2 : 0.712313
train_step : 19874, loss1 : 1.374156, loss2 : 0.782239
train_step : 19875, loss1 : 0.878804, loss2 : 1.752059
train_step : 19876, loss1 : 1.169042, loss2 : 0.758046
train_step : 19877, loss1 : 0.877837, loss2 : 0.956457
train_step : 19878, loss1 : 1.430884, loss2 : 1.170644
train_step : 19879, loss1 : 1.021791, loss2 : 1.306674
train_step : 19880, loss1 : 0.613938, loss2 : 0.638583
train_step : 19881, loss1 : 1.202876, loss2 : 1.344599
train_step : 19882, loss1 : 1.120088, loss2 : 0.916881
train_step : 19883, loss1 : 1.146826, loss2 : 1.233438
train_step : 19884, loss1 : 2.244679, loss2 : 1.397427
train_step : 19885, loss1 : 1.179186, loss2 : 1.516396
train_step : 19886, loss1 : 1.005518, loss2 : 1.030118
train_step : 19887, loss1 : 0.872616, loss2 : 1.234491
train_step : 19888, loss1 : 0.721871, loss2 : 1.099919
train_step : 19889, loss1 : 1.294356, loss2 : 1.096902
train_step : 19890, loss1 : 1.325812, loss2 : 1.976738
train_step : 19891, loss1 : 1.406185, loss2 : 0.806104
train_step : 19892, loss1 : 0.627618, loss2 : 0.912238
train_step : 19893, loss1 : 1.121935, loss2 : 1.473559
train_step : 19894, loss1 : 1.422867, loss2 : 0.993758
train_step : 19895, loss1 : 0.904032, loss2 : 0.356879
train_step : 19896, loss1 : 1.071699, loss2 : 1.353674
train_step : 19897, loss1 : 0.934088, loss2 : 0.663988
train_step : 19898, loss1 : 1.482489, loss2 : 1.228111
train_step : 19899, loss1 : 1.133118, loss2 : 1.094128
train_step : 19900, loss1 : 0.717816, loss2 : 1.223332
train_step : 19901, loss1 : 0.739899, loss2 : 1.348753
train_step : 19902, loss1 : 0.666055, loss2 : 1.492894
train_step : 19903, loss1 : 1.538453, loss2 : 0.918839
train_step : 19904, loss1 : 2.220333, loss2 : 1.598695
train_step : 19905, loss1 : 0.848139, loss2 : 1.494598
train_step : 19906, loss1 : 1.703943, loss2 : 1.187197
train_step : 19907, loss1 : 1.368281, loss2 : 0.804821
train_step : 19908, loss1 : 1.413850, loss2 : 1.005521
train_step : 19909, loss1 : 0.729514, loss2 : 0.839048
train_step : 19910, loss1 : 0.547391, loss2 : 1.487699
train_step : 19911, loss1 : 1.268483, loss2 : 1.398681
train_step : 19912, loss1 : 0.870021, loss2 : 1.811400
train_step : 19913, loss1 : 1.372013, loss2 : 1.325267
train_step : 19914, loss1 : 1.672137, loss2 : 1.152233
train_step : 19915, loss1 : 1.489780, loss2 : 1.860219
train_step : 19916, loss1 : 2.293097, loss2 : 2.490872
train_step : 19917, loss1 : 3.045495, loss2 : 3.435165
train_step : 19918, loss1 : 1.991714, loss2 : 2.715310
train_step : 19919, loss1 : 1.173573, loss2 : 1.732441
train_step : 19920, loss1 : 1.357381, loss2 : 2.401904
train_step : 19921, loss1 : 1.056644, loss2 : 1.646977
train_step : 19922, loss1 : 0.907166, loss2 : 2.089230
train_step : 19923, loss1 : 0.732945, loss2 : 1.251836
train_step : 19924, loss1 : 1.081585, loss2 : 0.702860
train_step : 19925, loss1 : 1.141577, loss2 : 0.953822
train_step : 19926, loss1 : 0.657331, loss2 : 1.083882
train_step : 19927, loss1 : 0.670217, loss2 : 0.778262
train_step : 19928, loss1 : 1.448868, loss2 : 1.376409
train_step : 19929, loss1 : 2.618006, loss2 : 1.021939
train_step : 19930, loss1 : 0.652718, loss2 : 2.381358
train_step : 19931, loss1 : 0.873634, loss2 : 1.014918
train_step : 19932, loss1 : 0.999782, loss2 : 1.439233
train_step : 19933, loss1 : 1.626706, loss2 : 1.341200
train_step : 19934, loss1 : 1.485097, loss2 : 2.218942
train_step : 19935, loss1 : 1.210633, loss2 : 3.116292
train_step : 19936, loss1 : 3.907947, loss2 : 1.303281
train_step : 19937, loss1 : 1.520495, loss2 : 3.307058
train_step : 19938, loss1 : 2.733565, loss2 : 2.371156
train_step : 19939, loss1 : 2.262133, loss2 : 2.167704
train_step : 19940, loss1 : 2.264319, loss2 : 2.341523
train_step : 19941, loss1 : 2.930792, loss2 : 2.208955
train_step : 19942, loss1 : 2.387230, loss2 : 2.144915
train_step : 19943, loss1 : 1.588190, loss2 : 0.882564
train_step : 19944, loss1 : 2.206076, loss2 : 2.990636
train_step : 19945, loss1 : 2.021517, loss2 : 2.337766
train_step : 19946, loss1 : 2.851476, loss2 : 1.927911
train_step : 19947, loss1 : 2.593369, loss2 : 3.190320
train_step : 19948, loss1 : 2.591831, loss2 : 4.169259
train_step : 19949, loss1 : 2.786968, loss2 : 3.319813
train_step : 19950, loss1 : 1.389538, loss2 : 1.946732
train_step : 19951, loss1 : 1.523396, loss2 : 0.987254
train_step : 19952, loss1 : 1.307167, loss2 : 0.711216
train_step : 19953, loss1 : 0.678517, loss2 : 1.492254
train_step : 19954, loss1 : 1.011018, loss2 : 1.184803
train_step : 19955, loss1 : 0.989481, loss2 : 1.158135
train_step : 19956, loss1 : 1.168039, loss2 : 1.139283
train_step : 19957, loss1 : 2.033495, loss2 : 1.359680
train_step : 19958, loss1 : 0.421277, loss2 : 0.609206
train_step : 19959, loss1 : 1.170387, loss2 : 0.965405
train_step : 19960, loss1 : 0.651745, loss2 : 1.246057
train_step : 19961, loss1 : 1.191876, loss2 : 1.416100
train_step : 19962, loss1 : 1.944806, loss2 : 1.870685
train_step : 19963, loss1 : 1.918598, loss2 : 1.474610
train_step : 19964, loss1 : 1.059885, loss2 : 1.534318
train_step : 19965, loss1 : 1.414283, loss2 : 1.752827
train_step : 19966, loss1 : 0.582237, loss2 : 0.698898
train_step : 19967, loss1 : 1.310701, loss2 : 1.234370
train_step : 19968, loss1 : 1.229213, loss2 : 0.734087
train_step : 19969, loss1 : 0.870090, loss2 : 0.818106
train_step : 19970, loss1 : 1.106710, loss2 : 1.329725
train_step : 19971, loss1 : 1.014201, loss2 : 2.537145
train_step : 19972, loss1 : 1.476934, loss2 : 1.087139
train_step : 19973, loss1 : 0.984646, loss2 : 1.183335
train_step : 19974, loss1 : 0.873040, loss2 : 1.611688
train_step : 19975, loss1 : 1.703921, loss2 : 1.255870
train_step : 19976, loss1 : 1.804909, loss2 : 1.589402
train_step : 19977, loss1 : 1.957888, loss2 : 1.776455
train_step : 19978, loss1 : 1.360456, loss2 : 0.857842
train_step : 19979, loss1 : 1.187778, loss2 : 1.532288
train_step : 19980, loss1 : 0.832182, loss2 : 1.023885
train_step : 19981, loss1 : 1.392787, loss2 : 1.422028
train_step : 19982, loss1 : 1.320022, loss2 : 0.893105
train_step : 19983, loss1 : 1.159517, loss2 : 1.135143
train_step : 19984, loss1 : 0.957743, loss2 : 0.955300
train_step : 19985, loss1 : 1.756909, loss2 : 1.768065
train_step : 19986, loss1 : 1.228851, loss2 : 2.092853
train_step : 19987, loss1 : 1.466498, loss2 : 0.918504
train_step : 19988, loss1 : 1.461706, loss2 : 1.546982
train_step : 19989, loss1 : 1.786481, loss2 : 1.924402
train_step : 19990, loss1 : 0.940252, loss2 : 0.914876
train_step : 19991, loss1 : 0.960729, loss2 : 1.269622
train_step : 19992, loss1 : 1.004541, loss2 : 1.278282
train_step : 19993, loss1 : 0.535879, loss2 : 0.760396
train_step : 19994, loss1 : 0.616466, loss2 : 0.733888
train_step : 19995, loss1 : 1.698673, loss2 : 1.209524
train_step : 19996, loss1 : 1.207186, loss2 : 2.484900
train_step : 19997, loss1 : 1.048624, loss2 : 1.743978
train_step : 19998, loss1 : 1.268392, loss2 : 1.492758
train_step : 19999, loss1 : 1.325902, loss2 : 1.422932
train_step : 20000, loss1 : 1.803916, loss2 : 3.213858
train_step : 20001, loss1 : 3.235940, loss2 : 4.274895
train_step : 20002, loss1 : 3.826175, loss2 : 2.747174
train_step : 20003, loss1 : 1.393227, loss2 : 3.210872
train_step : 20004, loss1 : 2.058216, loss2 : 1.496443
train_step : 20005, loss1 : 1.416757, loss2 : 2.060331
train_step : 20006, loss1 : 2.098969, loss2 : 1.884311
train_step : 20007, loss1 : 1.906558, loss2 : 1.452579
train_step : 20008, loss1 : 1.019922, loss2 : 1.928098
train_step : 20009, loss1 : 1.340785, loss2 : 1.188847
train_step : 20010, loss1 : 1.015994, loss2 : 1.892175
train_step : 20011, loss1 : 3.186574, loss2 : 0.986602
train_step : 20012, loss1 : 5.930645, loss2 : 1.430668
train_step : 20013, loss1 : 2.332724, loss2 : 1.636244
train_step : 20014, loss1 : 1.909389, loss2 : 1.945125
train_step : 20015, loss1 : 1.631421, loss2 : 1.138863
train_step : 20016, loss1 : 2.306180, loss2 : 1.174802
train_step : 20017, loss1 : 1.818661, loss2 : 0.981731
train_step : 20018, loss1 : 0.759145, loss2 : 1.948170
train_step : 20019, loss1 : 0.930729, loss2 : 0.820304
train_step : 20020, loss1 : 1.118022, loss2 : 1.122207
train_step : 20021, loss1 : 1.170064, loss2 : 0.907080
train_step : 20022, loss1 : 0.671115, loss2 : 1.511445
train_step : 20023, loss1 : 0.630423, loss2 : 0.622796
train_step : 20024, loss1 : 0.594629, loss2 : 1.418792
train_step : 20025, loss1 : 1.053919, loss2 : 0.591267
train_step : 20026, loss1 : 1.438434, loss2 : 1.209161
train_step : 20027, loss1 : 0.971748, loss2 : 1.274501
train_step : 20028, loss1 : 0.829730, loss2 : 1.420199
train_step : 20029, loss1 : 1.202360, loss2 : 2.031220
train_step : 20030, loss1 : 0.998860, loss2 : 0.689188
train_step : 20031, loss1 : 0.940735, loss2 : 1.083807
train_step : 20032, loss1 : 1.760243, loss2 : 0.519389
train_step : 20033, loss1 : 1.157055, loss2 : 1.100198
train_step : 20034, loss1 : 1.923480, loss2 : 0.792077
train_step : 20035, loss1 : 1.186009, loss2 : 0.733155
train_step : 20036, loss1 : 1.165962, loss2 : 1.164461
train_step : 20037, loss1 : 1.786001, loss2 : 1.257519
train_step : 20038, loss1 : 1.319000, loss2 : 0.968246
train_step : 20039, loss1 : 1.143152, loss2 : 0.469751
train_step : 20040, loss1 : 1.198506, loss2 : 1.611344
train_step : 20041, loss1 : 2.650234, loss2 : 0.879864
train_step : 20042, loss1 : 1.910265, loss2 : 1.518562
train_step : 20043, loss1 : 1.797422, loss2 : 0.801249
train_step : 20044, loss1 : 1.510589, loss2 : 0.741898
train_step : 20045, loss1 : 1.144455, loss2 : 1.593553
train_step : 20046, loss1 : 1.919332, loss2 : 2.397387
train_step : 20047, loss1 : 1.350211, loss2 : 2.020693
train_step : 20048, loss1 : 1.681360, loss2 : 2.775962
train_step : 20049, loss1 : 1.919097, loss2 : 2.273454
train_step : 20050, loss1 : 1.840203, loss2 : 2.042590
train_step : 20051, loss1 : 5.021670, loss2 : 3.237633
train_step : 20052, loss1 : 4.956604, loss2 : 5.098605
train_step : 20053, loss1 : 6.590637, loss2 : 4.161016
train_step : 20054, loss1 : 1.480917, loss2 : 1.299045
train_step : 20055, loss1 : 0.913944, loss2 : 1.380861
train_step : 20056, loss1 : 1.525655, loss2 : 1.042116
train_step : 20057, loss1 : 1.485858, loss2 : 1.222437
train_step : 20058, loss1 : 1.054706, loss2 : 1.006468
train_step : 20059, loss1 : 1.274111, loss2 : 1.276547
train_step : 20060, loss1 : 1.528246, loss2 : 0.930891
train_step : 20061, loss1 : 0.695676, loss2 : 0.915111
train_step : 20062, loss1 : 1.372056, loss2 : 1.140766
train_step : 20063, loss1 : 1.237947, loss2 : 1.019586
train_step : 20064, loss1 : 1.843010, loss2 : 1.573046
train_step : 20065, loss1 : 0.425624, loss2 : 1.138311
train_step : 20066, loss1 : 1.008779, loss2 : 1.005381
train_step : 20067, loss1 : 0.755452, loss2 : 1.457005
train_step : 20068, loss1 : 0.732195, loss2 : 1.565424
train_step : 20069, loss1 : 2.191267, loss2 : 2.156731
train_step : 20070, loss1 : 1.887827, loss2 : 2.009492
train_step : 20071, loss1 : 1.583848, loss2 : 1.365499
train_step : 20072, loss1 : 1.236431, loss2 : 0.962630
train_step : 20073, loss1 : 1.346168, loss2 : 1.694139
train_step : 20074, loss1 : 1.753234, loss2 : 1.675076
train_step : 20075, loss1 : 1.019481, loss2 : 1.232943
train_step : 20076, loss1 : 0.753918, loss2 : 0.917920
train_step : 20077, loss1 : 0.677558, loss2 : 1.916967
train_step : 20078, loss1 : 0.868440, loss2 : 1.055478
train_step : 20079, loss1 : 0.888977, loss2 : 0.928590
train_step : 20080, loss1 : 0.898116, loss2 : 1.156340
train_step : 20081, loss1 : 0.851130, loss2 : 0.736509
train_step : 20082, loss1 : 1.156062, loss2 : 0.858170
train_step : 20083, loss1 : 0.788177, loss2 : 0.794515
train_step : 20084, loss1 : 0.903312, loss2 : 1.942051
train_step : 20085, loss1 : 0.902978, loss2 : 1.666580
train_step : 20086, loss1 : 1.326947, loss2 : 1.729305
train_step : 20087, loss1 : 1.131463, loss2 : 1.861592
train_step : 20088, loss1 : 1.802590, loss2 : 1.844677
train_step : 20089, loss1 : 2.581376, loss2 : 1.961381
train_step : 20090, loss1 : 1.590375, loss2 : 2.113171
train_step : 20091, loss1 : 2.581358, loss2 : 2.010670
train_step : 20092, loss1 : 1.766530, loss2 : 1.180560
train_step : 20093, loss1 : 1.090496, loss2 : 1.333139
train_step : 20094, loss1 : 0.781517, loss2 : 0.975275
train_step : 20095, loss1 : 1.224406, loss2 : 1.762736
train_step : 20096, loss1 : 0.670293, loss2 : 1.452260
train_step : 20097, loss1 : 0.877517, loss2 : 1.295032
train_step : 20098, loss1 : 1.771225, loss2 : 1.409683
train_step : 20099, loss1 : 1.715944, loss2 : 1.920820
train_step : 20100, loss1 : 1.920935, loss2 : 1.012294
train_step : 20101, loss1 : 0.425902, loss2 : 1.555320
train_step : 20102, loss1 : 3.224422, loss2 : 1.770386
train_step : 20103, loss1 : 1.523038, loss2 : 2.009199
train_step : 20104, loss1 : 2.705114, loss2 : 1.586900
train_step : 20105, loss1 : 3.407711, loss2 : 3.329924
train_step : 20106, loss1 : 2.717278, loss2 : 2.512451
train_step : 20107, loss1 : 2.783404, loss2 : 2.268162
train_step : 20108, loss1 : 1.953079, loss2 : 3.249042
train_step : 20109, loss1 : 3.301505, loss2 : 3.307406
train_step : 20110, loss1 : 2.536240, loss2 : 3.036724
train_step : 20111, loss1 : 2.115096, loss2 : 3.315243
train_step : 20112, loss1 : 1.560099, loss2 : 3.436911
train_step : 20113, loss1 : 1.411283, loss2 : 1.386661
train_step : 20114, loss1 : 0.791525, loss2 : 0.744997
train_step : 20115, loss1 : 1.836646, loss2 : 1.542178
train_step : 20116, loss1 : 1.379673, loss2 : 2.643726
train_step : 20117, loss1 : 1.405735, loss2 : 0.800459
train_step : 20118, loss1 : 0.911327, loss2 : 0.945753
train_step : 20119, loss1 : 2.156205, loss2 : 1.000869
train_step : 20120, loss1 : 0.821562, loss2 : 1.142048
train_step : 20121, loss1 : 1.031953, loss2 : 2.091191
train_step : 20122, loss1 : 0.604668, loss2 : 0.957165
train_step : 20123, loss1 : 0.958175, loss2 : 0.831160
train_step : 20124, loss1 : 0.650705, loss2 : 1.387521
train_step : 20125, loss1 : 1.144885, loss2 : 0.815530
train_step : 20126, loss1 : 0.726619, loss2 : 1.048603
train_step : 20127, loss1 : 0.407026, loss2 : 0.996214
train_step : 20128, loss1 : 0.986118, loss2 : 1.393375
train_step : 20129, loss1 : 2.125546, loss2 : 0.969112
train_step : 20130, loss1 : 1.191549, loss2 : 1.375776
train_step : 20131, loss1 : 2.502489, loss2 : 1.366457
train_step : 20132, loss1 : 0.852909, loss2 : 1.659686
train_step : 20133, loss1 : 1.059584, loss2 : 1.477445
train_step : 20134, loss1 : 0.799275, loss2 : 1.109484
train_step : 20135, loss1 : 1.376987, loss2 : 0.909869
train_step : 20136, loss1 : 1.662462, loss2 : 1.749472
train_step : 20137, loss1 : 1.750045, loss2 : 0.804713
train_step : 20138, loss1 : 1.408428, loss2 : 0.872228
train_step : 20139, loss1 : 1.437511, loss2 : 0.954445
train_step : 20140, loss1 : 1.730104, loss2 : 0.834227
train_step : 20141, loss1 : 1.262816, loss2 : 0.836905
train_step : 20142, loss1 : 1.232635, loss2 : 0.720558
train_step : 20143, loss1 : 1.204643, loss2 : 2.146352
train_step : 20144, loss1 : 0.898367, loss2 : 0.830855
train_step : 20145, loss1 : 1.167384, loss2 : 0.810602
train_step : 20146, loss1 : 0.732047, loss2 : 0.777902
train_step : 20147, loss1 : 2.146288, loss2 : 1.374481
train_step : 20148, loss1 : 1.372973, loss2 : 1.540441
train_step : 20149, loss1 : 1.332974, loss2 : 1.610999
train_step : 20150, loss1 : 1.338348, loss2 : 0.897417
train_step : 20151, loss1 : 1.983935, loss2 : 1.668096
train_step : 20152, loss1 : 0.677903, loss2 : 1.555426
train_step : 20153, loss1 : 1.021673, loss2 : 1.025950
train_step : 20154, loss1 : 1.657052, loss2 : 1.676816
train_step : 20155, loss1 : 1.495823, loss2 : 1.860456
train_step : 20156, loss1 : 1.524126, loss2 : 1.909818
train_step : 20157, loss1 : 2.294533, loss2 : 1.674891
train_step : 20158, loss1 : 2.649595, loss2 : 2.204899
train_step : 20159, loss1 : 1.081606, loss2 : 1.508229
train_step : 20160, loss1 : 1.144745, loss2 : 1.363754
train_step : 20161, loss1 : 1.659729, loss2 : 1.572295
train_step : 20162, loss1 : 1.310222, loss2 : 2.732580
train_step : 20163, loss1 : 2.549523, loss2 : 2.002989
train_step : 20164, loss1 : 2.342716, loss2 : 2.730029
train_step : 20165, loss1 : 2.825055, loss2 : 2.386211
train_step : 20166, loss1 : 1.664308, loss2 : 2.031939
train_step : 20167, loss1 : 2.166907, loss2 : 2.003129
train_step : 20168, loss1 : 0.834492, loss2 : 0.803028
train_step : 20169, loss1 : 1.361804, loss2 : 1.415865
train_step : 20170, loss1 : 0.582487, loss2 : 1.065709
train_step : 20171, loss1 : 1.365779, loss2 : 1.029024
train_step : 20172, loss1 : 0.932407, loss2 : 1.033451
train_step : 20173, loss1 : 1.401720, loss2 : 1.004884
train_step : 20174, loss1 : 1.473231, loss2 : 1.039218
train_step : 20175, loss1 : 1.381426, loss2 : 1.320596
train_step : 20176, loss1 : 0.893466, loss2 : 1.117206
train_step : 20177, loss1 : 0.915895, loss2 : 1.568739
train_step : 20178, loss1 : 1.091864, loss2 : 1.077390
train_step : 20179, loss1 : 1.371116, loss2 : 0.835978
train_step : 20180, loss1 : 0.753973, loss2 : 0.895911
train_step : 20181, loss1 : 0.986491, loss2 : 1.218397
train_step : 20182, loss1 : 1.780385, loss2 : 1.515139
train_step : 20183, loss1 : 2.546609, loss2 : 1.095692
train_step : 20184, loss1 : 0.868472, loss2 : 1.163355
train_step : 20185, loss1 : 1.172863, loss2 : 0.859013
train_step : 20186, loss1 : 1.853493, loss2 : 0.832796
train_step : 20187, loss1 : 0.710795, loss2 : 0.717466
train_step : 20188, loss1 : 1.258452, loss2 : 1.120889
train_step : 20189, loss1 : 2.584670, loss2 : 2.664609
train_step : 20190, loss1 : 2.065964, loss2 : 1.164867
train_step : 20191, loss1 : 1.686912, loss2 : 2.113661
train_step : 20192, loss1 : 0.919415, loss2 : 1.237281
train_step : 20193, loss1 : 0.852273, loss2 : 0.970275
train_step : 20194, loss1 : 1.478623, loss2 : 0.614725
train_step : 20195, loss1 : 1.122927, loss2 : 1.493974
train_step : 20196, loss1 : 1.177704, loss2 : 1.051089
train_step : 20197, loss1 : 1.161369, loss2 : 0.790433
train_step : 20198, loss1 : 0.534375, loss2 : 1.364567
train_step : 20199, loss1 : 0.812287, loss2 : 0.852392
train_step : 20200, loss1 : 0.635428, loss2 : 1.621413
train_step : 20201, loss1 : 2.140991, loss2 : 0.874645
train_step : 20202, loss1 : 1.130343, loss2 : 1.368289
train_step : 20203, loss1 : 1.314198, loss2 : 1.073011
train_step : 20204, loss1 : 0.629171, loss2 : 0.894051
train_step : 20205, loss1 : 1.774759, loss2 : 1.309562
train_step : 20206, loss1 : 0.663249, loss2 : 0.911564
train_step : 20207, loss1 : 0.686772, loss2 : 1.158570
train_step : 20208, loss1 : 1.727396, loss2 : 1.219428
train_step : 20209, loss1 : 0.905141, loss2 : 1.034069
train_step : 20210, loss1 : 1.610322, loss2 : 0.881580
train_step : 20211, loss1 : 1.441229, loss2 : 1.218558
train_step : 20212, loss1 : 3.973646, loss2 : 1.419949
train_step : 20213, loss1 : 1.502939, loss2 : 1.537418
train_step : 20214, loss1 : 1.172288, loss2 : 1.405479
train_step : 20215, loss1 : 1.173770, loss2 : 0.684400
train_step : 20216, loss1 : 1.150242, loss2 : 1.123238
train_step : 20217, loss1 : 0.816212, loss2 : 0.797538
train_step : 20218, loss1 : 1.827815, loss2 : 1.369208
train_step : 20219, loss1 : 1.663553, loss2 : 2.773801
train_step : 20220, loss1 : 2.801819, loss2 : 2.064205
train_step : 20221, loss1 : 1.749152, loss2 : 1.395483
train_step : 20222, loss1 : 1.050678, loss2 : 0.726067
train_step : 20223, loss1 : 0.956920, loss2 : 0.951704
train_step : 20224, loss1 : 0.775496, loss2 : 1.393386
train_step : 20225, loss1 : 1.157687, loss2 : 1.151191
train_step : 20226, loss1 : 0.877842, loss2 : 2.104469
train_step : 20227, loss1 : 0.909363, loss2 : 0.641714
train_step : 20228, loss1 : 1.003668, loss2 : 1.199283
train_step : 20229, loss1 : 0.817033, loss2 : 1.621597
train_step : 20230, loss1 : 1.371890, loss2 : 1.558374
train_step : 20231, loss1 : 1.177172, loss2 : 1.509952
train_step : 20232, loss1 : 1.688069, loss2 : 1.097537
train_step : 20233, loss1 : 1.844097, loss2 : 1.593890
train_step : 20234, loss1 : 1.090793, loss2 : 1.743404
train_step : 20235, loss1 : 1.040960, loss2 : 0.954046
train_step : 20236, loss1 : 1.296272, loss2 : 1.109179
train_step : 20237, loss1 : 0.750158, loss2 : 1.502696
train_step : 20238, loss1 : 1.112332, loss2 : 0.584904
train_step : 20239, loss1 : 0.835814, loss2 : 0.868525
train_step : 20240, loss1 : 1.025591, loss2 : 0.734146
train_step : 20241, loss1 : 2.249965, loss2 : 1.131125
train_step : 20242, loss1 : 0.756542, loss2 : 0.987573
train_step : 20243, loss1 : 1.217951, loss2 : 1.310847
train_step : 20244, loss1 : 0.333306, loss2 : 1.308715
train_step : 20245, loss1 : 0.812743, loss2 : 1.418603
train_step : 20246, loss1 : 1.116274, loss2 : 1.424537
train_step : 20247, loss1 : 1.437016, loss2 : 0.844564
train_step : 20248, loss1 : 1.760323, loss2 : 1.145018
train_step : 20249, loss1 : 0.912005, loss2 : 1.342668
train_step : 20250, loss1 : 1.900723, loss2 : 0.869335
train_step : 20251, loss1 : 1.139938, loss2 : 1.345001
train_step : 20252, loss1 : 1.474359, loss2 : 1.728582
train_step : 20253, loss1 : 1.777292, loss2 : 0.720674
train_step : 20254, loss1 : 0.808653, loss2 : 1.361831
train_step : 20255, loss1 : 1.146430, loss2 : 1.341413
train_step : 20256, loss1 : 1.961622, loss2 : 1.278419
train_step : 20257, loss1 : 1.264428, loss2 : 1.449871
train_step : 20258, loss1 : 1.826480, loss2 : 1.284164
train_step : 20259, loss1 : 1.722051, loss2 : 1.349460
train_step : 20260, loss1 : 1.190197, loss2 : 2.351400
train_step : 20261, loss1 : 1.435388, loss2 : 1.344423
train_step : 20262, loss1 : 2.102111, loss2 : 1.564401
train_step : 20263, loss1 : 0.929314, loss2 : 1.444254
train_step : 20264, loss1 : 1.740249, loss2 : 1.927477
train_step : 20265, loss1 : 1.348993, loss2 : 1.901804
train_step : 20266, loss1 : 1.856900, loss2 : 1.599081
train_step : 20267, loss1 : 1.427385, loss2 : 1.783226
train_step : 20268, loss1 : 0.958035, loss2 : 1.060317
train_step : 20269, loss1 : 0.599339, loss2 : 1.234386
train_step : 20270, loss1 : 0.917453, loss2 : 1.155405
train_step : 20271, loss1 : 1.086662, loss2 : 1.190301
train_step : 20272, loss1 : 1.560759, loss2 : 1.053858
train_step : 20273, loss1 : 0.996888, loss2 : 2.321458
train_step : 20274, loss1 : 1.407916, loss2 : 1.369705
train_step : 20275, loss1 : 0.806354, loss2 : 1.466890
train_step : 20276, loss1 : 0.996818, loss2 : 1.088027
train_step : 20277, loss1 : 1.175681, loss2 : 1.351852
train_step : 20278, loss1 : 1.625444, loss2 : 0.873786
train_step : 20279, loss1 : 1.410499, loss2 : 1.503560
train_step : 20280, loss1 : 0.943702, loss2 : 1.650210
train_step : 20281, loss1 : 2.043188, loss2 : 0.512668
train_step : 20282, loss1 : 1.606840, loss2 : 0.801765
train_step : 20283, loss1 : 1.239384, loss2 : 1.488758
train_step : 20284, loss1 : 1.240161, loss2 : 1.510031
train_step : 20285, loss1 : 1.237785, loss2 : 0.784180
train_step : 20286, loss1 : 1.773750, loss2 : 0.892018
train_step : 20287, loss1 : 0.501118, loss2 : 1.082835
train_step : 20288, loss1 : 1.303169, loss2 : 1.518440
train_step : 20289, loss1 : 1.605986, loss2 : 1.666169
train_step : 20290, loss1 : 1.408910, loss2 : 1.055831
train_step : 20291, loss1 : 1.298383, loss2 : 1.513335
train_step : 20292, loss1 : 1.611959, loss2 : 1.040938
train_step : 20293, loss1 : 1.301032, loss2 : 1.366308
train_step : 20294, loss1 : 1.032416, loss2 : 0.746475
train_step : 20295, loss1 : 1.086203, loss2 : 1.192141
train_step : 20296, loss1 : 0.757773, loss2 : 0.993929
train_step : 20297, loss1 : 1.706547, loss2 : 1.268270
train_step : 20298, loss1 : 0.689051, loss2 : 3.099265
train_step : 20299, loss1 : 0.521222, loss2 : 1.477078
train_step : 20300, loss1 : 1.220846, loss2 : 0.691860
train_step : 20301, loss1 : 0.967351, loss2 : 1.207147
train_step : 20302, loss1 : 1.283624, loss2 : 0.875388
train_step : 20303, loss1 : 1.295058, loss2 : 1.306805
train_step : 20304, loss1 : 1.388347, loss2 : 0.935001
train_step : 20305, loss1 : 0.627387, loss2 : 0.827349
train_step : 20306, loss1 : 1.267540, loss2 : 0.573268
train_step : 20307, loss1 : 1.376669, loss2 : 1.055222
train_step : 20308, loss1 : 1.165134, loss2 : 0.717052
train_step : 20309, loss1 : 2.089909, loss2 : 1.492358
train_step : 20310, loss1 : 1.138810, loss2 : 2.658203
train_step : 20311, loss1 : 0.929207, loss2 : 1.601949
train_step : 20312, loss1 : 1.935025, loss2 : 0.801072
train_step : 20313, loss1 : 1.216884, loss2 : 1.301224
train_step : 20314, loss1 : 1.104255, loss2 : 0.909986
train_step : 20315, loss1 : 0.846118, loss2 : 1.470041
train_step : 20316, loss1 : 1.359604, loss2 : 1.413663
train_step : 20317, loss1 : 1.343644, loss2 : 1.167453
train_step : 20318, loss1 : 1.235655, loss2 : 1.225755
train_step : 20319, loss1 : 1.454132, loss2 : 1.799488
train_step : 20320, loss1 : 1.353065, loss2 : 1.542797
train_step : 20321, loss1 : 1.558272, loss2 : 1.760331
train_step : 20322, loss1 : 1.308402, loss2 : 1.683439
train_step : 20323, loss1 : 2.071503, loss2 : 1.956796
train_step : 20324, loss1 : 1.026039, loss2 : 1.113802
train_step : 20325, loss1 : 0.531781, loss2 : 2.155777
train_step : 20326, loss1 : 1.229302, loss2 : 0.806695
train_step : 20327, loss1 : 1.084155, loss2 : 0.947681
train_step : 20328, loss1 : 1.767766, loss2 : 0.786201
train_step : 20329, loss1 : 1.216668, loss2 : 0.574603
train_step : 20330, loss1 : 1.546785, loss2 : 0.851556
train_step : 20331, loss1 : 0.551297, loss2 : 1.287040
train_step : 20332, loss1 : 1.510059, loss2 : 0.814065
train_step : 20333, loss1 : 0.708036, loss2 : 1.295096
train_step : 20334, loss1 : 0.919154, loss2 : 1.054836
train_step : 20335, loss1 : 0.711980, loss2 : 0.709287
train_step : 20336, loss1 : 1.149367, loss2 : 0.560729
train_step : 20337, loss1 : 0.783890, loss2 : 0.806061
train_step : 20338, loss1 : 1.049135, loss2 : 0.978358
train_step : 20339, loss1 : 1.528859, loss2 : 1.133692
train_step : 20340, loss1 : 2.422762, loss2 : 1.200084
train_step : 20341, loss1 : 2.081056, loss2 : 2.504738
train_step : 20342, loss1 : 1.407802, loss2 : 2.707925
train_step : 20343, loss1 : 1.875543, loss2 : 2.003042
train_step : 20344, loss1 : 3.099817, loss2 : 2.703228
train_step : 20345, loss1 : 2.280079, loss2 : 2.432055
train_step : 20346, loss1 : 1.656688, loss2 : 1.573522
train_step : 20347, loss1 : 2.103023, loss2 : 2.503520
train_step : 20348, loss1 : 2.105192, loss2 : 2.704549
train_step : 20349, loss1 : 2.691413, loss2 : 3.858646
train_step : 20350, loss1 : 2.714987, loss2 : 2.552541
train_step : 20351, loss1 : 3.537640, loss2 : 2.057771
train_step : 20352, loss1 : 1.410728, loss2 : 1.719605
train_step : 20353, loss1 : 1.550172, loss2 : 0.747841
train_step : 20354, loss1 : 1.476903, loss2 : 2.009260
train_step : 20355, loss1 : 2.328022, loss2 : 2.817092
train_step : 20356, loss1 : 2.832759, loss2 : 1.896715
train_step : 20357, loss1 : 2.913624, loss2 : 3.963383
train_step : 20358, loss1 : 2.808238, loss2 : 4.088730
train_step : 20359, loss1 : 2.767481, loss2 : 3.450841
train_step : 20360, loss1 : 1.734748, loss2 : 1.784322
train_step : 20361, loss1 : 1.525789, loss2 : 2.295231
train_step : 20362, loss1 : 2.676229, loss2 : 1.834605
train_step : 20363, loss1 : 2.303270, loss2 : 2.202563
train_step : 20364, loss1 : 2.591418, loss2 : 1.397495
train_step : 20365, loss1 : 3.328286, loss2 : 2.241865
train_step : 20366, loss1 : 2.969097, loss2 : 2.358683
train_step : 20367, loss1 : 3.721317, loss2 : 2.278265
train_step : 20368, loss1 : 4.006195, loss2 : 2.610840
train_step : 20369, loss1 : 2.487694, loss2 : 2.700582
train_step : 20370, loss1 : 1.991578, loss2 : 0.484029
train_step : 20371, loss1 : 1.282468, loss2 : 0.849353
train_step : 20372, loss1 : 1.554677, loss2 : 1.134397
train_step : 20373, loss1 : 1.298305, loss2 : 1.042871
train_step : 20374, loss1 : 1.602175, loss2 : 1.927774
train_step : 20375, loss1 : 2.494706, loss2 : 1.650954
train_step : 20376, loss1 : 1.335158, loss2 : 1.823275
train_step : 20377, loss1 : 1.427466, loss2 : 1.939068
train_step : 20378, loss1 : 1.038163, loss2 : 0.747845
train_step : 20379, loss1 : 0.643195, loss2 : 0.814695
train_step : 20380, loss1 : 1.090176, loss2 : 1.532145
train_step : 20381, loss1 : 1.303566, loss2 : 1.484040
train_step : 20382, loss1 : 0.812837, loss2 : 1.281911
train_step : 20383, loss1 : 1.165950, loss2 : 1.282794
train_step : 20384, loss1 : 1.323550, loss2 : 0.472107
train_step : 20385, loss1 : 1.984580, loss2 : 1.540091
train_step : 20386, loss1 : 1.928917, loss2 : 2.529783
train_step : 20387, loss1 : 1.350026, loss2 : 0.925728
train_step : 20388, loss1 : 1.243187, loss2 : 0.759116
train_step : 20389, loss1 : 0.963903, loss2 : 0.572436
train_step : 20390, loss1 : 1.157609, loss2 : 1.680002
train_step : 20391, loss1 : 2.333944, loss2 : 1.024874
train_step : 20392, loss1 : 1.878316, loss2 : 1.753884
train_step : 20393, loss1 : 1.110104, loss2 : 2.163303
train_step : 20394, loss1 : 0.824262, loss2 : 0.941013
train_step : 20395, loss1 : 1.007835, loss2 : 0.998486
train_step : 20396, loss1 : 1.472126, loss2 : 0.535629
train_step : 20397, loss1 : 2.107496, loss2 : 1.196610
train_step : 20398, loss1 : 1.381368, loss2 : 1.126433
train_step : 20399, loss1 : 1.785779, loss2 : 1.564875
train_step : 20400, loss1 : 1.973626, loss2 : 3.283549
train_step : 20401, loss1 : 0.944503, loss2 : 1.006468
train_step : 20402, loss1 : 1.026289, loss2 : 0.979669
train_step : 20403, loss1 : 0.613941, loss2 : 1.474706
train_step : 20404, loss1 : 1.789914, loss2 : 0.982817
train_step : 20405, loss1 : 1.526253, loss2 : 1.565051
train_step : 20406, loss1 : 1.110622, loss2 : 2.193590
train_step : 20407, loss1 : 1.693293, loss2 : 1.443549
train_step : 20408, loss1 : 1.210913, loss2 : 1.501937
train_step : 20409, loss1 : 1.588210, loss2 : 1.373034
train_step : 20410, loss1 : 0.673202, loss2 : 1.211476
train_step : 20411, loss1 : 1.424654, loss2 : 1.458750
train_step : 20412, loss1 : 1.034246, loss2 : 1.108688
train_step : 20413, loss1 : 1.286754, loss2 : 1.086986
train_step : 20414, loss1 : 0.811944, loss2 : 1.521393
train_step : 20415, loss1 : 1.152500, loss2 : 1.231388
train_step : 20416, loss1 : 0.782710, loss2 : 1.074504
train_step : 20417, loss1 : 2.025768, loss2 : 1.194220
train_step : 20418, loss1 : 0.891419, loss2 : 1.363291
train_step : 20419, loss1 : 0.873753, loss2 : 0.739156
train_step : 20420, loss1 : 1.814070, loss2 : 1.979169
train_step : 20421, loss1 : 0.996630, loss2 : 1.482289
train_step : 20422, loss1 : 2.075975, loss2 : 1.076704
train_step : 20423, loss1 : 1.823700, loss2 : 1.233659
train_step : 20424, loss1 : 0.929622, loss2 : 1.416753
train_step : 20425, loss1 : 0.511173, loss2 : 0.775371
train_step : 20426, loss1 : 1.556888, loss2 : 0.843294
train_step : 20427, loss1 : 1.090789, loss2 : 2.074800
train_step : 20428, loss1 : 0.927434, loss2 : 2.461356
train_step : 20429, loss1 : 1.678434, loss2 : 1.860250
train_step : 20430, loss1 : 2.785351, loss2 : 1.623656
train_step : 20431, loss1 : 1.696427, loss2 : 2.543454
train_step : 20432, loss1 : 2.402166, loss2 : 2.410602
train_step : 20433, loss1 : 1.822785, loss2 : 1.853277
train_step : 20434, loss1 : 2.284367, loss2 : 3.072797
train_step : 20435, loss1 : 2.319322, loss2 : 3.213356
train_step : 20436, loss1 : 3.671733, loss2 : 2.737729
train_step : 20437, loss1 : 3.282155, loss2 : 3.679207
train_step : 20438, loss1 : 3.166720, loss2 : 3.706022
train_step : 20439, loss1 : 2.859756, loss2 : 1.121655
train_step : 20440, loss1 : 1.804337, loss2 : 1.388962
train_step : 20441, loss1 : 1.796312, loss2 : 1.411691
train_step : 20442, loss1 : 2.850414, loss2 : 2.265219
train_step : 20443, loss1 : 4.936872, loss2 : 3.490247
train_step : 20444, loss1 : 5.644166, loss2 : 5.837455
train_step : 20445, loss1 : 5.137163, loss2 : 4.573461
train_step : 20446, loss1 : 6.747448, loss2 : 8.656981
train_step : 20447, loss1 : 5.712202, loss2 : 4.056465
train_step : 20448, loss1 : 2.670342, loss2 : 4.222659
train_step : 20449, loss1 : 1.170999, loss2 : 2.919819
train_step : 20450, loss1 : 1.691257, loss2 : 2.201412
train_step : 20451, loss1 : 1.578779, loss2 : 2.865796
train_step : 20452, loss1 : 1.302795, loss2 : 1.563162
train_step : 20453, loss1 : 0.783872, loss2 : 1.226343
train_step : 20454, loss1 : 0.867462, loss2 : 0.920747
train_step : 20455, loss1 : 0.937572, loss2 : 1.043219
train_step : 20456, loss1 : 0.970489, loss2 : 1.422810
train_step : 20457, loss1 : 0.915637, loss2 : 1.257941
train_step : 20458, loss1 : 0.988202, loss2 : 1.699709
train_step : 20459, loss1 : 1.055249, loss2 : 1.148636
train_step : 20460, loss1 : 0.641030, loss2 : 0.614699
train_step : 20461, loss1 : 1.156717, loss2 : 1.162778
train_step : 20462, loss1 : 2.762877, loss2 : 1.166300
train_step : 20463, loss1 : 1.334472, loss2 : 0.968331
train_step : 20464, loss1 : 2.158510, loss2 : 1.231970
train_step : 20465, loss1 : 0.955492, loss2 : 2.086061
train_step : 20466, loss1 : 0.661850, loss2 : 0.921527
train_step : 20467, loss1 : 1.914496, loss2 : 0.911769
train_step : 20468, loss1 : 0.765525, loss2 : 1.231012
train_step : 20469, loss1 : 1.949570, loss2 : 0.791631
train_step : 20470, loss1 : 0.916318, loss2 : 1.148832
train_step : 20471, loss1 : 1.103385, loss2 : 1.450092
train_step : 20472, loss1 : 1.242574, loss2 : 1.388894
train_step : 20473, loss1 : 0.915286, loss2 : 1.174883
train_step : 20474, loss1 : 1.762045, loss2 : 1.783332
train_step : 20475, loss1 : 2.662137, loss2 : 1.985397
train_step : 20476, loss1 : 2.389917, loss2 : 1.380191
train_step : 20477, loss1 : 1.109889, loss2 : 1.805259
train_step : 20478, loss1 : 1.480358, loss2 : 1.971376
train_step : 20479, loss1 : 0.730623, loss2 : 1.070685
train_step : 20480, loss1 : 0.903617, loss2 : 0.715906
train_step : 20481, loss1 : 1.268667, loss2 : 1.521423
train_step : 20482, loss1 : 1.192642, loss2 : 1.492228
train_step : 20483, loss1 : 0.923481, loss2 : 1.502577
train_step : 20484, loss1 : 2.086217, loss2 : 1.050343
train_step : 20485, loss1 : 3.126974, loss2 : 1.480716
train_step : 20486, loss1 : 1.106061, loss2 : 1.964704
train_step : 20487, loss1 : 1.449685, loss2 : 1.592691
train_step : 20488, loss1 : 1.371341, loss2 : 0.928233
train_step : 20489, loss1 : 1.180701, loss2 : 0.991892
train_step : 20490, loss1 : 0.739378, loss2 : 0.807637
train_step : 20491, loss1 : 1.351702, loss2 : 0.925929
train_step : 20492, loss1 : 1.092048, loss2 : 1.331457
train_step : 20493, loss1 : 1.606377, loss2 : 0.505116
train_step : 20494, loss1 : 0.576386, loss2 : 1.900343
train_step : 20495, loss1 : 1.135443, loss2 : 1.548733
train_step : 20496, loss1 : 0.838168, loss2 : 1.661206
train_step : 20497, loss1 : 1.422782, loss2 : 0.993941
train_step : 20498, loss1 : 0.950364, loss2 : 1.507681
train_step : 20499, loss1 : 0.791488, loss2 : 0.689490
train_step : 20500, loss1 : 0.808453, loss2 : 0.920494
train_step : 20501, loss1 : 1.587522, loss2 : 0.623314
train_step : 20502, loss1 : 1.228616, loss2 : 1.152174
train_step : 20503, loss1 : 1.960916, loss2 : 0.949214
train_step : 20504, loss1 : 0.715448, loss2 : 1.445874
train_step : 20505, loss1 : 0.590749, loss2 : 1.341357
train_step : 20506, loss1 : 0.995777, loss2 : 0.895320
train_step : 20507, loss1 : 0.960563, loss2 : 2.133068
train_step : 20508, loss1 : 1.111471, loss2 : 0.501746
train_step : 20509, loss1 : 1.616801, loss2 : 0.767163
train_step : 20510, loss1 : 0.623017, loss2 : 1.873477
train_step : 20511, loss1 : 1.189093, loss2 : 1.610376
train_step : 20512, loss1 : 1.077969, loss2 : 1.316238
train_step : 20513, loss1 : 0.909983, loss2 : 1.282637
train_step : 20514, loss1 : 0.625531, loss2 : 1.180867
train_step : 20515, loss1 : 1.851120, loss2 : 1.589590
train_step : 20516, loss1 : 1.074758, loss2 : 1.202647
train_step : 20517, loss1 : 1.268857, loss2 : 0.495692
train_step : 20518, loss1 : 1.686387, loss2 : 1.009183
train_step : 20519, loss1 : 0.523155, loss2 : 1.610218
train_step : 20520, loss1 : 1.597000, loss2 : 1.317792
train_step : 20521, loss1 : 1.284768, loss2 : 0.961823
train_step : 20522, loss1 : 0.608800, loss2 : 0.519453
train_step : 20523, loss1 : 0.934739, loss2 : 0.576630
train_step : 20524, loss1 : 1.891221, loss2 : 2.823700
train_step : 20525, loss1 : 1.175097, loss2 : 1.293473
train_step : 20526, loss1 : 0.980198, loss2 : 1.421291
train_step : 20527, loss1 : 1.876352, loss2 : 4.047031
train_step : 20528, loss1 : 1.869770, loss2 : 1.213411
train_step : 20529, loss1 : 1.831593, loss2 : 1.608168
train_step : 20530, loss1 : 0.956954, loss2 : 0.834035
train_step : 20531, loss1 : 1.087219, loss2 : 1.517894
train_step : 20532, loss1 : 1.494546, loss2 : 0.774300
train_step : 20533, loss1 : 0.721836, loss2 : 0.971119
train_step : 20534, loss1 : 1.083962, loss2 : 0.785288
train_step : 20535, loss1 : 0.997879, loss2 : 1.720426
train_step : 20536, loss1 : 0.840746, loss2 : 0.625250
train_step : 20537, loss1 : 1.245177, loss2 : 1.337870
train_step : 20538, loss1 : 1.058196, loss2 : 1.465955
train_step : 20539, loss1 : 1.560877, loss2 : 0.844333
train_step : 20540, loss1 : 1.032849, loss2 : 0.777339
train_step : 20541, loss1 : 0.981739, loss2 : 0.961264
train_step : 20542, loss1 : 2.118111, loss2 : 1.289236
train_step : 20543, loss1 : 1.570437, loss2 : 1.380932
train_step : 20544, loss1 : 1.109170, loss2 : 1.389261
train_step : 20545, loss1 : 1.469640, loss2 : 1.098885
train_step : 20546, loss1 : 1.428988, loss2 : 1.127477
train_step : 20547, loss1 : 2.092807, loss2 : 0.804278
train_step : 20548, loss1 : 0.862968, loss2 : 1.462947
train_step : 20549, loss1 : 1.266545, loss2 : 0.786453
train_step : 20550, loss1 : 1.751741, loss2 : 1.564599
train_step : 20551, loss1 : 0.858921, loss2 : 0.929739
train_step : 20552, loss1 : 1.901571, loss2 : 1.595596
train_step : 20553, loss1 : 1.843764, loss2 : 1.004622
train_step : 20554, loss1 : 0.984715, loss2 : 1.405817
train_step : 20555, loss1 : 2.365615, loss2 : 1.192764
train_step : 20556, loss1 : 1.828757, loss2 : 2.015285
train_step : 20557, loss1 : 1.635821, loss2 : 0.785617
train_step : 20558, loss1 : 0.668783, loss2 : 1.282681
train_step : 20559, loss1 : 1.068915, loss2 : 0.406136
train_step : 20560, loss1 : 1.579248, loss2 : 3.967025
train_step : 20561, loss1 : 1.215086, loss2 : 1.444210
train_step : 20562, loss1 : 1.174856, loss2 : 2.686649
train_step : 20563, loss1 : 2.277544, loss2 : 2.235889
train_step : 20564, loss1 : 2.366442, loss2 : 1.486612
train_step : 20565, loss1 : 2.017457, loss2 : 1.436557
train_step : 20566, loss1 : 2.377557, loss2 : 1.746262
train_step : 20567, loss1 : 2.132057, loss2 : 2.273539
train_step : 20568, loss1 : 1.352499, loss2 : 2.711397
train_step : 20569, loss1 : 2.659276, loss2 : 1.365595
train_step : 20570, loss1 : 1.378672, loss2 : 0.919839
train_step : 20571, loss1 : 1.224921, loss2 : 1.347107
train_step : 20572, loss1 : 1.957716, loss2 : 1.365640
train_step : 20573, loss1 : 1.193432, loss2 : 1.219657
train_step : 20574, loss1 : 1.116055, loss2 : 0.562575
train_step : 20575, loss1 : 1.491556, loss2 : 0.812220
train_step : 20576, loss1 : 1.558679, loss2 : 1.250673
train_step : 20577, loss1 : 1.569715, loss2 : 0.995652
train_step : 20578, loss1 : 0.943999, loss2 : 0.764750
train_step : 20579, loss1 : 1.344106, loss2 : 1.041819
train_step : 20580, loss1 : 0.912519, loss2 : 1.957039
train_step : 20581, loss1 : 1.101532, loss2 : 1.263053
train_step : 20582, loss1 : 2.246700, loss2 : 1.384122
train_step : 20583, loss1 : 1.772977, loss2 : 1.767555
train_step : 20584, loss1 : 1.844748, loss2 : 1.431187
train_step : 20585, loss1 : 2.111562, loss2 : 2.990741
train_step : 20586, loss1 : 1.756971, loss2 : 2.161931
train_step : 20587, loss1 : 1.765974, loss2 : 1.242030
train_step : 20588, loss1 : 1.739842, loss2 : 2.783895
train_step : 20589, loss1 : 2.652772, loss2 : 1.665215
train_step : 20590, loss1 : 3.418103, loss2 : 1.764139
train_step : 20591, loss1 : 3.003644, loss2 : 2.924552
train_step : 20592, loss1 : 3.512294, loss2 : 4.163613
train_step : 20593, loss1 : 4.993896, loss2 : 5.614357
train_step : 20594, loss1 : 3.049368, loss2 : 3.221067
train_step : 20595, loss1 : 4.958903, loss2 : 2.882715
train_step : 20596, loss1 : 2.118148, loss2 : 2.854467
train_step : 20597, loss1 : 2.394326, loss2 : 2.959669
train_step : 20598, loss1 : 2.464316, loss2 : 2.764198
train_step : 20599, loss1 : 2.302552, loss2 : 2.841292
train_step : 20600, loss1 : 2.489286, loss2 : 1.391051
train_step : 20601, loss1 : 1.785128, loss2 : 1.710583
train_step : 20602, loss1 : 2.293548, loss2 : 0.723523
train_step : 20603, loss1 : 1.956335, loss2 : 1.392996
train_step : 20604, loss1 : 2.170965, loss2 : 1.174653
train_step : 20605, loss1 : 1.600844, loss2 : 1.998744
train_step : 20606, loss1 : 1.334612, loss2 : 0.763771
train_step : 20607, loss1 : 1.776437, loss2 : 1.391457
train_step : 20608, loss1 : 2.483407, loss2 : 1.058710
train_step : 20609, loss1 : 1.247151, loss2 : 1.203473
train_step : 20610, loss1 : 1.131970, loss2 : 1.371778
train_step : 20611, loss1 : 2.682603, loss2 : 2.913111
train_step : 20612, loss1 : 2.890171, loss2 : 3.281081
train_step : 20613, loss1 : 1.656085, loss2 : 1.808199
train_step : 20614, loss1 : 1.270603, loss2 : 3.048363
train_step : 20615, loss1 : 3.067107, loss2 : 1.250742
train_step : 20616, loss1 : 1.766278, loss2 : 1.440074
train_step : 20617, loss1 : 0.683411, loss2 : 1.145844
train_step : 20618, loss1 : 0.813993, loss2 : 1.613287
train_step : 20619, loss1 : 1.176380, loss2 : 1.960042
train_step : 20620, loss1 : 1.964374, loss2 : 1.503779
train_step : 20621, loss1 : 2.232255, loss2 : 2.501942
train_step : 20622, loss1 : 2.799068, loss2 : 1.731230
train_step : 20623, loss1 : 1.331600, loss2 : 4.094963
train_step : 20624, loss1 : 1.357385, loss2 : 1.840496
train_step : 20625, loss1 : 1.102257, loss2 : 1.156491
train_step : 20626, loss1 : 1.743928, loss2 : 1.137276
train_step : 20627, loss1 : 1.647984, loss2 : 1.364137
train_step : 20628, loss1 : 1.299060, loss2 : 1.713098
train_step : 20629, loss1 : 2.222760, loss2 : 1.288251
train_step : 20630, loss1 : 1.799546, loss2 : 1.358245
train_step : 20631, loss1 : 1.216239, loss2 : 1.487410
train_step : 20632, loss1 : 1.116708, loss2 : 0.960774
train_step : 20633, loss1 : 0.975629, loss2 : 1.090068
train_step : 20634, loss1 : 0.694220, loss2 : 1.321673
train_step : 20635, loss1 : 1.136352, loss2 : 1.474255
train_step : 20636, loss1 : 1.499624, loss2 : 1.077174
train_step : 20637, loss1 : 1.205213, loss2 : 1.523868
train_step : 20638, loss1 : 2.239074, loss2 : 1.749695
train_step : 20639, loss1 : 2.356678, loss2 : 1.565326
train_step : 20640, loss1 : 2.597537, loss2 : 1.885399
train_step : 20641, loss1 : 1.662043, loss2 : 1.904483
train_step : 20642, loss1 : 1.476219, loss2 : 1.310086
train_step : 20643, loss1 : 0.943330, loss2 : 1.083491
train_step : 20644, loss1 : 0.908498, loss2 : 1.409344
train_step : 20645, loss1 : 0.712363, loss2 : 0.935606
train_step : 20646, loss1 : 1.479954, loss2 : 0.710325
train_step : 20647, loss1 : 0.733841, loss2 : 2.231451
train_step : 20648, loss1 : 1.037947, loss2 : 1.322625
train_step : 20649, loss1 : 0.658673, loss2 : 0.842801
train_step : 20650, loss1 : 0.637971, loss2 : 1.132709
train_step : 20651, loss1 : 0.696756, loss2 : 1.255119
train_step : 20652, loss1 : 0.858744, loss2 : 1.184679
train_step : 20653, loss1 : 1.240395, loss2 : 0.716795
train_step : 20654, loss1 : 1.413174, loss2 : 1.277039
train_step : 20655, loss1 : 1.161696, loss2 : 1.449073
train_step : 20656, loss1 : 1.471375, loss2 : 1.687077
train_step : 20657, loss1 : 1.344105, loss2 : 0.673744
train_step : 20658, loss1 : 1.465738, loss2 : 2.038753
train_step : 20659, loss1 : 0.916941, loss2 : 1.473241
train_step : 20660, loss1 : 1.012437, loss2 : 0.535442
train_step : 20661, loss1 : 0.672696, loss2 : 1.458150
train_step : 20662, loss1 : 1.375472, loss2 : 1.423315
train_step : 20663, loss1 : 1.048266, loss2 : 1.698573
train_step : 20664, loss1 : 1.820792, loss2 : 0.438204
train_step : 20665, loss1 : 1.313636, loss2 : 1.048333
train_step : 20666, loss1 : 1.355468, loss2 : 1.033508
train_step : 20667, loss1 : 0.838551, loss2 : 1.072772
train_step : 20668, loss1 : 0.950793, loss2 : 0.718619
train_step : 20669, loss1 : 1.242366, loss2 : 1.055804
train_step : 20670, loss1 : 1.432623, loss2 : 1.070197
train_step : 20671, loss1 : 0.825066, loss2 : 0.794000
train_step : 20672, loss1 : 0.826500, loss2 : 0.850897
train_step : 20673, loss1 : 1.103421, loss2 : 0.842809
train_step : 20674, loss1 : 1.140404, loss2 : 1.035158
train_step : 20675, loss1 : 1.144609, loss2 : 1.001021
train_step : 20676, loss1 : 1.201417, loss2 : 0.698710
train_step : 20677, loss1 : 1.022509, loss2 : 0.877425
train_step : 20678, loss1 : 1.115130, loss2 : 1.502356
train_step : 20679, loss1 : 1.479998, loss2 : 1.648137
train_step : 20680, loss1 : 1.162907, loss2 : 1.381429
train_step : 20681, loss1 : 1.448399, loss2 : 1.167371
train_step : 20682, loss1 : 1.321227, loss2 : 1.213863
train_step : 20683, loss1 : 1.582760, loss2 : 1.679853
train_step : 20684, loss1 : 1.823983, loss2 : 0.827925
train_step : 20685, loss1 : 0.923023, loss2 : 1.262538
train_step : 20686, loss1 : 2.448948, loss2 : 0.937285
train_step : 20687, loss1 : 1.172425, loss2 : 1.512375
train_step : 20688, loss1 : 1.304882, loss2 : 0.736738
train_step : 20689, loss1 : 1.149325, loss2 : 0.784979
train_step : 20690, loss1 : 1.099366, loss2 : 1.147338
train_step : 20691, loss1 : 1.269567, loss2 : 1.578918
train_step : 20692, loss1 : 0.663773, loss2 : 0.566246
train_step : 20693, loss1 : 1.636660, loss2 : 0.649445
train_step : 20694, loss1 : 0.480360, loss2 : 0.829797
train_step : 20695, loss1 : 1.016503, loss2 : 0.891892
train_step : 20696, loss1 : 3.906034, loss2 : 1.663784
train_step : 20697, loss1 : 1.535595, loss2 : 0.774337
train_step : 20698, loss1 : 1.621055, loss2 : 1.445058
train_step : 20699, loss1 : 1.196192, loss2 : 0.974102
train_step : 20700, loss1 : 3.395403, loss2 : 1.494031
train_step : 20701, loss1 : 1.059639, loss2 : 1.081155
train_step : 20702, loss1 : 1.086570, loss2 : 1.012899
train_step : 20703, loss1 : 2.374250, loss2 : 1.240016
train_step : 20704, loss1 : 1.395244, loss2 : 2.173625
train_step : 20705, loss1 : 1.931952, loss2 : 1.211768
train_step : 20706, loss1 : 1.163490, loss2 : 1.853546
train_step : 20707, loss1 : 1.794579, loss2 : 0.668482
train_step : 20708, loss1 : 0.805127, loss2 : 1.132937
train_step : 20709, loss1 : 0.805659, loss2 : 1.291517
train_step : 20710, loss1 : 2.759466, loss2 : 0.789297
train_step : 20711, loss1 : 1.358678, loss2 : 0.915018
train_step : 20712, loss1 : 1.717763, loss2 : 1.582141
train_step : 20713, loss1 : 1.351678, loss2 : 1.907084
train_step : 20714, loss1 : 0.820458, loss2 : 1.866130
train_step : 20715, loss1 : 1.224303, loss2 : 1.337437
train_step : 20716, loss1 : 1.134812, loss2 : 1.194834
train_step : 20717, loss1 : 1.714103, loss2 : 0.847000
train_step : 20718, loss1 : 1.214936, loss2 : 0.827700
train_step : 20719, loss1 : 0.934537, loss2 : 1.404313
train_step : 20720, loss1 : 1.115538, loss2 : 1.911303
train_step : 20721, loss1 : 0.720528, loss2 : 1.562858
train_step : 20722, loss1 : 0.650708, loss2 : 1.499599
train_step : 20723, loss1 : 0.756801, loss2 : 0.954532
train_step : 20724, loss1 : 1.537418, loss2 : 2.098148
train_step : 20725, loss1 : 1.848367, loss2 : 0.629217
train_step : 20726, loss1 : 0.841660, loss2 : 1.444106
train_step : 20727, loss1 : 1.246179, loss2 : 1.534971
train_step : 20728, loss1 : 1.280410, loss2 : 0.877431
train_step : 20729, loss1 : 1.207599, loss2 : 1.929261
train_step : 20730, loss1 : 2.888355, loss2 : 0.934188
train_step : 20731, loss1 : 0.830147, loss2 : 0.689261
train_step : 20732, loss1 : 1.220642, loss2 : 1.297248
train_step : 20733, loss1 : 1.613615, loss2 : 1.084360
train_step : 20734, loss1 : 1.643167, loss2 : 0.582604
train_step : 20735, loss1 : 1.517348, loss2 : 1.442101
train_step : 20736, loss1 : 0.909407, loss2 : 1.937637
train_step : 20737, loss1 : 1.979867, loss2 : 1.347303
train_step : 20738, loss1 : 1.637818, loss2 : 1.852157
train_step : 20739, loss1 : 1.736914, loss2 : 2.518082
train_step : 20740, loss1 : 3.430161, loss2 : 2.201494
train_step : 20741, loss1 : 2.038236, loss2 : 2.674389
train_step : 20742, loss1 : 0.737783, loss2 : 1.903838
train_step : 20743, loss1 : 0.840694, loss2 : 2.372464
train_step : 20744, loss1 : 1.480093, loss2 : 1.682463
train_step : 20745, loss1 : 2.472944, loss2 : 1.564749
train_step : 20746, loss1 : 1.669792, loss2 : 2.066994
train_step : 20747, loss1 : 3.297150, loss2 : 1.785646
train_step : 20748, loss1 : 3.551893, loss2 : 2.966560
train_step : 20749, loss1 : 2.534406, loss2 : 3.305039
train_step : 20750, loss1 : 3.500917, loss2 : 2.944973
train_step : 20751, loss1 : 2.043466, loss2 : 3.173544
train_step : 20752, loss1 : 2.927866, loss2 : 2.055245
train_step : 20753, loss1 : 2.584322, loss2 : 2.563096
train_step : 20754, loss1 : 2.466051, loss2 : 3.986722
train_step : 20755, loss1 : 3.647548, loss2 : 4.546527
train_step : 20756, loss1 : 4.656309, loss2 : 2.542408
train_step : 20757, loss1 : 2.415203, loss2 : 4.142461
train_step : 20758, loss1 : 3.894675, loss2 : 3.353961
train_step : 20759, loss1 : 2.253884, loss2 : 2.791851
train_step : 20760, loss1 : 1.572874, loss2 : 1.625963
train_step : 20761, loss1 : 1.861651, loss2 : 1.895026
train_step : 20762, loss1 : 1.992200, loss2 : 1.475319
train_step : 20763, loss1 : 1.742079, loss2 : 1.423709
train_step : 20764, loss1 : 0.904909, loss2 : 0.895849
train_step : 20765, loss1 : 1.817821, loss2 : 0.275821
train_step : 20766, loss1 : 1.008425, loss2 : 1.363189
train_step : 20767, loss1 : 1.664038, loss2 : 1.499558
train_step : 20768, loss1 : 1.167140, loss2 : 2.599469
train_step : 20769, loss1 : 0.594533, loss2 : 1.879862
train_step : 20770, loss1 : 1.817372, loss2 : 2.125214
train_step : 20771, loss1 : 1.373426, loss2 : 0.767743
train_step : 20772, loss1 : 0.702008, loss2 : 0.927207
train_step : 20773, loss1 : 1.130947, loss2 : 0.866239
train_step : 20774, loss1 : 1.169166, loss2 : 0.998748
train_step : 20775, loss1 : 1.300116, loss2 : 0.451719
train_step : 20776, loss1 : 0.984024, loss2 : 0.599895
train_step : 20777, loss1 : 0.783591, loss2 : 1.236499
train_step : 20778, loss1 : 2.336551, loss2 : 1.760221
train_step : 20779, loss1 : 1.740070, loss2 : 1.420767
train_step : 20780, loss1 : 1.544264, loss2 : 1.172182
train_step : 20781, loss1 : 1.180519, loss2 : 1.181501
train_step : 20782, loss1 : 1.250970, loss2 : 1.259501
train_step : 20783, loss1 : 1.605056, loss2 : 1.359787
train_step : 20784, loss1 : 1.991577, loss2 : 1.684615
train_step : 20785, loss1 : 1.937650, loss2 : 1.016613
train_step : 20786, loss1 : 0.829505, loss2 : 2.039760
train_step : 20787, loss1 : 0.825767, loss2 : 1.205332
train_step : 20788, loss1 : 1.006180, loss2 : 1.392390
train_step : 20789, loss1 : 1.082012, loss2 : 0.625705
train_step : 20790, loss1 : 0.758833, loss2 : 0.789638
train_step : 20791, loss1 : 1.425232, loss2 : 1.017743
train_step : 20792, loss1 : 1.569789, loss2 : 1.447692
train_step : 20793, loss1 : 1.791084, loss2 : 1.814355
train_step : 20794, loss1 : 1.052863, loss2 : 1.509395
train_step : 20795, loss1 : 1.606744, loss2 : 1.123441
train_step : 20796, loss1 : 1.678999, loss2 : 2.572893
train_step : 20797, loss1 : 1.827429, loss2 : 1.328850
train_step : 20798, loss1 : 1.680597, loss2 : 1.897442
train_step : 20799, loss1 : 1.838504, loss2 : 1.950255
train_step : 20800, loss1 : 0.732603, loss2 : 0.866971
train_step : 20801, loss1 : 1.084134, loss2 : 0.822028
train_step : 20802, loss1 : 1.057409, loss2 : 0.996379
train_step : 20803, loss1 : 0.823907, loss2 : 1.208645
train_step : 20804, loss1 : 1.233123, loss2 : 1.260203
train_step : 20805, loss1 : 1.095435, loss2 : 1.620188
train_step : 20806, loss1 : 1.207848, loss2 : 1.228551
train_step : 20807, loss1 : 0.929762, loss2 : 1.078900
train_step : 20808, loss1 : 0.623165, loss2 : 1.086644
train_step : 20809, loss1 : 1.122125, loss2 : 1.100806
train_step : 20810, loss1 : 0.635013, loss2 : 0.913069
train_step : 20811, loss1 : 0.749791, loss2 : 0.768143
train_step : 20812, loss1 : 0.710790, loss2 : 1.081909
train_step : 20813, loss1 : 1.288401, loss2 : 1.159045
train_step : 20814, loss1 : 1.543320, loss2 : 0.570262
train_step : 20815, loss1 : 0.872777, loss2 : 1.292016
train_step : 20816, loss1 : 1.200740, loss2 : 2.452384
train_step : 20817, loss1 : 1.644839, loss2 : 2.278150
train_step : 20818, loss1 : 2.508087, loss2 : 2.550151
train_step : 20819, loss1 : 4.183953, loss2 : 2.420177
train_step : 20820, loss1 : 2.875590, loss2 : 2.017828
train_step : 20821, loss1 : 1.456424, loss2 : 0.995069
train_step : 20822, loss1 : 1.243799, loss2 : 1.813985
train_step : 20823, loss1 : 2.071724, loss2 : 3.852412
train_step : 20824, loss1 : 3.489748, loss2 : 2.144412
train_step : 20825, loss1 : 2.868208, loss2 : 1.659816
train_step : 20826, loss1 : 0.883634, loss2 : 2.736374
train_step : 20827, loss1 : 1.409891, loss2 : 3.246203
train_step : 20828, loss1 : 1.643422, loss2 : 1.271512
train_step : 20829, loss1 : 0.889444, loss2 : 1.662696
train_step : 20830, loss1 : 1.143375, loss2 : 1.561010
train_step : 20831, loss1 : 1.126756, loss2 : 0.972173
train_step : 20832, loss1 : 1.196610, loss2 : 1.692807
train_step : 20833, loss1 : 0.889741, loss2 : 1.269536
train_step : 20834, loss1 : 1.657144, loss2 : 1.392479
train_step : 20835, loss1 : 1.352813, loss2 : 1.993136
train_step : 20836, loss1 : 1.784501, loss2 : 1.298367
train_step : 20837, loss1 : 1.037241, loss2 : 1.316018
train_step : 20838, loss1 : 1.171813, loss2 : 1.342268
train_step : 20839, loss1 : 1.040382, loss2 : 1.332551
train_step : 20840, loss1 : 1.513394, loss2 : 1.664807
train_step : 20841, loss1 : 1.684369, loss2 : 3.163181
train_step : 20842, loss1 : 3.092092, loss2 : 1.685837
train_step : 20843, loss1 : 1.368070, loss2 : 2.264825
train_step : 20844, loss1 : 2.685087, loss2 : 0.972199
train_step : 20845, loss1 : 3.950533, loss2 : 2.220753
train_step : 20846, loss1 : 1.874431, loss2 : 2.890453
train_step : 20847, loss1 : 1.355914, loss2 : 1.449035
train_step : 20848, loss1 : 1.199633, loss2 : 1.971354
train_step : 20849, loss1 : 1.517678, loss2 : 0.995912
train_step : 20850, loss1 : 1.325330, loss2 : 1.156165
train_step : 20851, loss1 : 1.793905, loss2 : 1.251140
train_step : 20852, loss1 : 0.637099, loss2 : 1.915559
train_step : 20853, loss1 : 1.277154, loss2 : 1.172204
train_step : 20854, loss1 : 1.051244, loss2 : 1.329142
train_step : 20855, loss1 : 1.443234, loss2 : 0.730953
train_step : 20856, loss1 : 0.952226, loss2 : 1.602540
train_step : 20857, loss1 : 1.486443, loss2 : 1.641349
train_step : 20858, loss1 : 1.430567, loss2 : 1.737350
train_step : 20859, loss1 : 1.322184, loss2 : 0.643259
train_step : 20860, loss1 : 1.330075, loss2 : 1.243082
train_step : 20861, loss1 : 1.599587, loss2 : 1.833025
train_step : 20862, loss1 : 2.194843, loss2 : 2.221923
train_step : 20863, loss1 : 2.513274, loss2 : 1.134356
train_step : 20864, loss1 : 1.454577, loss2 : 1.010580
train_step : 20865, loss1 : 1.786632, loss2 : 0.995528
train_step : 20866, loss1 : 1.160635, loss2 : 2.043654
train_step : 20867, loss1 : 2.423167, loss2 : 1.857400
train_step : 20868, loss1 : 1.634821, loss2 : 1.219223
train_step : 20869, loss1 : 1.114668, loss2 : 1.786548
train_step : 20870, loss1 : 1.613450, loss2 : 1.422280
train_step : 20871, loss1 : 1.851967, loss2 : 1.572560
train_step : 20872, loss1 : 1.100674, loss2 : 0.924539
train_step : 20873, loss1 : 0.995386, loss2 : 1.059703
train_step : 20874, loss1 : 1.637342, loss2 : 1.675606
train_step : 20875, loss1 : 1.340625, loss2 : 1.329806
train_step : 20876, loss1 : 3.074197, loss2 : 1.142990
train_step : 20877, loss1 : 1.096514, loss2 : 0.957206
train_step : 20878, loss1 : 1.235849, loss2 : 0.967530
train_step : 20879, loss1 : 0.572688, loss2 : 0.627275
train_step : 20880, loss1 : 0.680383, loss2 : 0.997900
train_step : 20881, loss1 : 1.498256, loss2 : 1.481903
train_step : 20882, loss1 : 2.508430, loss2 : 2.091812
train_step : 20883, loss1 : 1.752073, loss2 : 2.276327
train_step : 20884, loss1 : 2.588249, loss2 : 2.142312
train_step : 20885, loss1 : 2.805723, loss2 : 2.514288
train_step : 20886, loss1 : 2.377069, loss2 : 1.961812
train_step : 20887, loss1 : 1.685515, loss2 : 2.181606
train_step : 20888, loss1 : 2.201167, loss2 : 0.896796
train_step : 20889, loss1 : 1.784555, loss2 : 1.094126
train_step : 20890, loss1 : 1.257327, loss2 : 1.022363
train_step : 20891, loss1 : 1.438018, loss2 : 2.267516
train_step : 20892, loss1 : 1.475675, loss2 : 1.116025
train_step : 20893, loss1 : 1.209729, loss2 : 1.539880
train_step : 20894, loss1 : 1.312667, loss2 : 1.667961
train_step : 20895, loss1 : 1.218760, loss2 : 1.875230
train_step : 20896, loss1 : 1.634254, loss2 : 1.257452
train_step : 20897, loss1 : 0.854324, loss2 : 4.797887
train_step : 20898, loss1 : 1.018982, loss2 : 1.541181
train_step : 20899, loss1 : 1.267530, loss2 : 1.304729
train_step : 20900, loss1 : 0.976363, loss2 : 0.675510
train_step : 20901, loss1 : 1.309170, loss2 : 1.725363
train_step : 20902, loss1 : 2.722538, loss2 : 2.225976
train_step : 20903, loss1 : 1.604239, loss2 : 4.622999
train_step : 20904, loss1 : 3.718387, loss2 : 2.762179
train_step : 20905, loss1 : 2.566875, loss2 : 2.329418
train_step : 20906, loss1 : 2.181903, loss2 : 3.013623
train_step : 20907, loss1 : 2.751057, loss2 : 2.378004
train_step : 20908, loss1 : 6.428027, loss2 : 2.931288
train_step : 20909, loss1 : 4.993917, loss2 : 7.252104
train_step : 20910, loss1 : 6.504947, loss2 : 10.103025
train_step : 20911, loss1 : 3.767982, loss2 : 3.421829
train_step : 20912, loss1 : 3.325173, loss2 : 3.652165
train_step : 20913, loss1 : 3.354478, loss2 : 2.514259
train_step : 20914, loss1 : 2.414481, loss2 : 2.980629
train_step : 20915, loss1 : 1.653723, loss2 : 1.109967
train_step : 20916, loss1 : 1.021504, loss2 : 1.425494
train_step : 20917, loss1 : 3.161810, loss2 : 1.587961
train_step : 20918, loss1 : 1.225872, loss2 : 0.654254
train_step : 20919, loss1 : 0.962002, loss2 : 1.379134
train_step : 20920, loss1 : 1.865801, loss2 : 1.082224
train_step : 20921, loss1 : 1.538864, loss2 : 1.659379
train_step : 20922, loss1 : 1.999369, loss2 : 1.787390
train_step : 20923, loss1 : 2.414879, loss2 : 1.137408
train_step : 20924, loss1 : 1.414096, loss2 : 1.356518
train_step : 20925, loss1 : 1.344412, loss2 : 1.187941
train_step : 20926, loss1 : 1.138292, loss2 : 1.168808
train_step : 20927, loss1 : 3.816141, loss2 : 0.481685
train_step : 20928, loss1 : 0.678700, loss2 : 0.537593
train_step : 20929, loss1 : 0.922546, loss2 : 1.352477
train_step : 20930, loss1 : 0.768629, loss2 : 1.183701
train_step : 20931, loss1 : 1.425854, loss2 : 1.401636
train_step : 20932, loss1 : 1.329121, loss2 : 0.803156
train_step : 20933, loss1 : 2.073338, loss2 : 1.834813
train_step : 20934, loss1 : 1.191385, loss2 : 1.150348
train_step : 20935, loss1 : 0.972237, loss2 : 1.387249
train_step : 20936, loss1 : 2.743553, loss2 : 1.116556
train_step : 20937, loss1 : 2.212403, loss2 : 1.893515
train_step : 20938, loss1 : 1.339719, loss2 : 1.613515
train_step : 20939, loss1 : 1.150699, loss2 : 1.858665
train_step : 20940, loss1 : 1.755339, loss2 : 1.933765
train_step : 20941, loss1 : 2.113097, loss2 : 3.981219
train_step : 20942, loss1 : 4.095090, loss2 : 2.203630
train_step : 20943, loss1 : 2.616585, loss2 : 3.590194
train_step : 20944, loss1 : 2.079300, loss2 : 3.146662
train_step : 20945, loss1 : 2.934874, loss2 : 2.939631
train_step : 20946, loss1 : 1.513495, loss2 : 1.627570
train_step : 20947, loss1 : 2.178925, loss2 : 1.805550
train_step : 20948, loss1 : 1.507073, loss2 : 1.561894
train_step : 20949, loss1 : 0.970099, loss2 : 0.519434
train_step : 20950, loss1 : 1.900046, loss2 : 1.481532
train_step : 20951, loss1 : 1.123458, loss2 : 1.506440
train_step : 20952, loss1 : 1.055045, loss2 : 2.397321
train_step : 20953, loss1 : 1.778568, loss2 : 0.769272
train_step : 20954, loss1 : 1.894582, loss2 : 2.094220
train_step : 20955, loss1 : 1.012890, loss2 : 1.766918
train_step : 20956, loss1 : 0.794854, loss2 : 0.832729
train_step : 20957, loss1 : 0.934994, loss2 : 1.303409
train_step : 20958, loss1 : 1.530555, loss2 : 1.286995
train_step : 20959, loss1 : 1.114411, loss2 : 1.084573
train_step : 20960, loss1 : 0.896348, loss2 : 2.235360
train_step : 20961, loss1 : 0.946845, loss2 : 1.526938
train_step : 20962, loss1 : 0.964391, loss2 : 1.283274
train_step : 20963, loss1 : 0.707469, loss2 : 0.816849
train_step : 20964, loss1 : 0.879735, loss2 : 1.073691
train_step : 20965, loss1 : 1.276905, loss2 : 0.747131
train_step : 20966, loss1 : 1.657860, loss2 : 1.504088
train_step : 20967, loss1 : 1.387102, loss2 : 1.249507
train_step : 20968, loss1 : 1.127756, loss2 : 1.168961
train_step : 20969, loss1 : 0.748402, loss2 : 0.958554
train_step : 20970, loss1 : 2.080226, loss2 : 1.194665
train_step : 20971, loss1 : 1.148329, loss2 : 0.995346
train_step : 20972, loss1 : 1.313220, loss2 : 0.534832
train_step : 20973, loss1 : 1.912670, loss2 : 0.835439
train_step : 20974, loss1 : 1.132616, loss2 : 1.925099
train_step : 20975, loss1 : 1.466372, loss2 : 0.940394
train_step : 20976, loss1 : 0.775267, loss2 : 1.315618
train_step : 20977, loss1 : 1.079757, loss2 : 0.632524
train_step : 20978, loss1 : 1.199840, loss2 : 1.134352
train_step : 20979, loss1 : 0.852356, loss2 : 1.354358
train_step : 20980, loss1 : 1.473628, loss2 : 1.317815
train_step : 20981, loss1 : 2.107495, loss2 : 0.975277
train_step : 20982, loss1 : 1.634019, loss2 : 2.239510
train_step : 20983, loss1 : 2.010266, loss2 : 2.992500
train_step : 20984, loss1 : 3.029274, loss2 : 3.068899
train_step : 20985, loss1 : 3.064280, loss2 : 3.094463
train_step : 20986, loss1 : 3.216955, loss2 : 4.228701
train_step : 20987, loss1 : 2.673487, loss2 : 3.655780
train_step : 20988, loss1 : 2.722748, loss2 : 3.949290
train_step : 20989, loss1 : 2.659775, loss2 : 2.741475
train_step : 20990, loss1 : 1.761873, loss2 : 1.465809
train_step : 20991, loss1 : 1.175697, loss2 : 1.710535
train_step : 20992, loss1 : 1.704099, loss2 : 1.301939
train_step : 20993, loss1 : 1.698993, loss2 : 2.254993
train_step : 20994, loss1 : 1.784417, loss2 : 3.082455
train_step : 20995, loss1 : 2.088987, loss2 : 1.366146
train_step : 20996, loss1 : 1.335496, loss2 : 2.685657
train_step : 20997, loss1 : 0.986841, loss2 : 1.923009
train_step : 20998, loss1 : 2.619703, loss2 : 1.023085
train_step : 20999, loss1 : 0.642031, loss2 : 0.552709
train_step : 21000, loss1 : 1.019532, loss2 : 1.565273
train_step : 21001, loss1 : 1.128599, loss2 : 1.525538
train_step : 21002, loss1 : 2.180116, loss2 : 1.293715
train_step : 21003, loss1 : 1.913020, loss2 : 0.846067
train_step : 21004, loss1 : 1.399466, loss2 : 1.743498
train_step : 21005, loss1 : 1.116813, loss2 : 1.812109
train_step : 21006, loss1 : 1.644014, loss2 : 1.176708
train_step : 21007, loss1 : 0.818924, loss2 : 1.921840
train_step : 21008, loss1 : 1.857899, loss2 : 1.164443
train_step : 21009, loss1 : 0.588690, loss2 : 0.674308
train_step : 21010, loss1 : 0.513534, loss2 : 0.776038
train_step : 21011, loss1 : 1.189307, loss2 : 1.799172
train_step : 21012, loss1 : 1.222272, loss2 : 0.812697
train_step : 21013, loss1 : 0.859976, loss2 : 1.482256
train_step : 21014, loss1 : 1.345877, loss2 : 1.281742
train_step : 21015, loss1 : 2.344074, loss2 : 1.641280
train_step : 21016, loss1 : 1.013720, loss2 : 3.545468
train_step : 21017, loss1 : 1.502378, loss2 : 2.051083
train_step : 21018, loss1 : 1.391814, loss2 : 1.954199
train_step : 21019, loss1 : 1.843245, loss2 : 1.196361
train_step : 21020, loss1 : 1.684785, loss2 : 1.923529
train_step : 21021, loss1 : 1.216092, loss2 : 1.429738
train_step : 21022, loss1 : 0.938846, loss2 : 0.818868
train_step : 21023, loss1 : 1.345058, loss2 : 0.967515
train_step : 21024, loss1 : 1.022249, loss2 : 0.830641
train_step : 21025, loss1 : 0.771874, loss2 : 1.305394
train_step : 21026, loss1 : 1.147303, loss2 : 0.737342
train_step : 21027, loss1 : 0.549996, loss2 : 1.211319
train_step : 21028, loss1 : 0.780119, loss2 : 0.817180
train_step : 21029, loss1 : 1.024877, loss2 : 0.912066
train_step : 21030, loss1 : 0.528044, loss2 : 1.012862
train_step : 21031, loss1 : 0.857528, loss2 : 1.216225
train_step : 21032, loss1 : 1.558708, loss2 : 1.080730
train_step : 21033, loss1 : 0.950503, loss2 : 1.053096
train_step : 21034, loss1 : 1.458058, loss2 : 0.739499
train_step : 21035, loss1 : 1.825350, loss2 : 1.308954
train_step : 21036, loss1 : 1.656364, loss2 : 1.832186
train_step : 21037, loss1 : 1.451585, loss2 : 1.780625
train_step : 21038, loss1 : 1.525244, loss2 : 1.432231
train_step : 21039, loss1 : 1.149314, loss2 : 1.490384
train_step : 21040, loss1 : 1.366875, loss2 : 1.113389
train_step : 21041, loss1 : 0.500792, loss2 : 1.030488
train_step : 21042, loss1 : 0.688540, loss2 : 0.538572
train_step : 21043, loss1 : 1.089642, loss2 : 0.960026
train_step : 21044, loss1 : 1.069433, loss2 : 1.000439
train_step : 21045, loss1 : 1.633473, loss2 : 1.533835
train_step : 21046, loss1 : 2.174754, loss2 : 1.451995
train_step : 21047, loss1 : 0.979157, loss2 : 1.824908
train_step : 21048, loss1 : 1.005534, loss2 : 1.212362
train_step : 21049, loss1 : 1.658059, loss2 : 1.018969
train_step : 21050, loss1 : 1.476095, loss2 : 1.942093
train_step : 21051, loss1 : 1.648689, loss2 : 1.036452
train_step : 21052, loss1 : 1.621984, loss2 : 1.457348
train_step : 21053, loss1 : 0.891612, loss2 : 1.235743
train_step : 21054, loss1 : 0.980137, loss2 : 0.492901
train_step : 21055, loss1 : 0.652622, loss2 : 0.989446
train_step : 21056, loss1 : 1.264856, loss2 : 0.969882
train_step : 21057, loss1 : 1.120537, loss2 : 0.756034
train_step : 21058, loss1 : 0.960844, loss2 : 0.929997
train_step : 21059, loss1 : 0.933774, loss2 : 1.143782
train_step : 21060, loss1 : 2.969778, loss2 : 1.213568
train_step : 21061, loss1 : 1.136598, loss2 : 1.315428
train_step : 21062, loss1 : 1.457290, loss2 : 1.434939
train_step : 21063, loss1 : 1.294698, loss2 : 1.463268
train_step : 21064, loss1 : 0.994848, loss2 : 0.940716
train_step : 21065, loss1 : 1.081452, loss2 : 0.913142
train_step : 21066, loss1 : 1.438646, loss2 : 0.974831
train_step : 21067, loss1 : 1.212510, loss2 : 1.080844
train_step : 21068, loss1 : 1.325237, loss2 : 0.712410
train_step : 21069, loss1 : 1.196644, loss2 : 1.190426
train_step : 21070, loss1 : 0.881064, loss2 : 1.310786
train_step : 21071, loss1 : 1.467834, loss2 : 1.269143
train_step : 21072, loss1 : 2.031410, loss2 : 1.331971
train_step : 21073, loss1 : 1.843245, loss2 : 1.814456
train_step : 21074, loss1 : 1.550485, loss2 : 2.831942
train_step : 21075, loss1 : 1.545732, loss2 : 2.873593
train_step : 21076, loss1 : 1.360727, loss2 : 1.498692
train_step : 21077, loss1 : 1.331580, loss2 : 1.423006
train_step : 21078, loss1 : 2.125182, loss2 : 2.368650
train_step : 21079, loss1 : 2.375463, loss2 : 0.970768
train_step : 21080, loss1 : 1.058454, loss2 : 2.559363
train_step : 21081, loss1 : 1.623915, loss2 : 0.993596
train_step : 21082, loss1 : 1.079020, loss2 : 1.470189
train_step : 21083, loss1 : 1.549527, loss2 : 1.097204
train_step : 21084, loss1 : 1.378268, loss2 : 0.886959
train_step : 21085, loss1 : 2.134244, loss2 : 1.229854
train_step : 21086, loss1 : 0.602058, loss2 : 1.877939
train_step : 21087, loss1 : 1.630250, loss2 : 1.483185
train_step : 21088, loss1 : 1.663355, loss2 : 1.197084
train_step : 21089, loss1 : 2.049238, loss2 : 1.042318
train_step : 21090, loss1 : 2.454905, loss2 : 1.273547
train_step : 21091, loss1 : 1.687168, loss2 : 1.804268
train_step : 21092, loss1 : 1.602773, loss2 : 2.814040
train_step : 21093, loss1 : 1.843914, loss2 : 1.860480
train_step : 21094, loss1 : 1.002982, loss2 : 0.988580
train_step : 21095, loss1 : 1.036354, loss2 : 1.037553
train_step : 21096, loss1 : 1.377995, loss2 : 0.803325
train_step : 21097, loss1 : 1.174270, loss2 : 1.261952
train_step : 21098, loss1 : 1.098178, loss2 : 0.550379
train_step : 21099, loss1 : 1.440909, loss2 : 1.456462
train_step : 21100, loss1 : 1.373649, loss2 : 2.036198
train_step : 21101, loss1 : 1.268432, loss2 : 1.980358
train_step : 21102, loss1 : 1.855469, loss2 : 0.674169
train_step : 21103, loss1 : 1.309883, loss2 : 1.437813
train_step : 21104, loss1 : 0.696964, loss2 : 3.244619
train_step : 21105, loss1 : 2.972167, loss2 : 2.697600
train_step : 21106, loss1 : 2.765131, loss2 : 2.117389
train_step : 21107, loss1 : 1.658205, loss2 : 4.049335
train_step : 21108, loss1 : 1.226014, loss2 : 1.568967
train_step : 21109, loss1 : 1.705019, loss2 : 1.306147
train_step : 21110, loss1 : 1.105865, loss2 : 0.700007
train_step : 21111, loss1 : 0.692154, loss2 : 0.724249
train_step : 21112, loss1 : 1.427495, loss2 : 0.879537
train_step : 21113, loss1 : 0.894338, loss2 : 0.977801
train_step : 21114, loss1 : 1.058484, loss2 : 0.976824
train_step : 21115, loss1 : 2.028789, loss2 : 1.606292
train_step : 21116, loss1 : 0.829724, loss2 : 1.800628
train_step : 21117, loss1 : 0.854142, loss2 : 0.749194
train_step : 21118, loss1 : 0.645744, loss2 : 1.394405
train_step : 21119, loss1 : 1.468988, loss2 : 1.151684
train_step : 21120, loss1 : 1.100068, loss2 : 2.203724
train_step : 21121, loss1 : 3.073397, loss2 : 2.372478
train_step : 21122, loss1 : 2.441133, loss2 : 2.580125
train_step : 21123, loss1 : 2.788815, loss2 : 3.138335
train_step : 21124, loss1 : 2.561302, loss2 : 2.615216
train_step : 21125, loss1 : 2.416238, loss2 : 2.353667
train_step : 21126, loss1 : 2.335076, loss2 : 1.434350
train_step : 21127, loss1 : 0.892544, loss2 : 2.873851
train_step : 21128, loss1 : 0.615827, loss2 : 1.342844
train_step : 21129, loss1 : 1.416017, loss2 : 1.488644
train_step : 21130, loss1 : 2.438032, loss2 : 1.275620
train_step : 21131, loss1 : 1.433273, loss2 : 1.934861
train_step : 21132, loss1 : 1.430800, loss2 : 0.969680
train_step : 21133, loss1 : 1.166786, loss2 : 0.687272
train_step : 21134, loss1 : 0.812996, loss2 : 0.766614
train_step : 21135, loss1 : 1.239992, loss2 : 0.976552
train_step : 21136, loss1 : 1.548143, loss2 : 1.174684
train_step : 21137, loss1 : 1.036085, loss2 : 1.142469
train_step : 21138, loss1 : 0.725459, loss2 : 1.623928
train_step : 21139, loss1 : 1.416798, loss2 : 1.521862
train_step : 21140, loss1 : 0.684253, loss2 : 1.221755
train_step : 21141, loss1 : 0.697983, loss2 : 1.439274
train_step : 21142, loss1 : 0.852119, loss2 : 0.962669
train_step : 21143, loss1 : 0.675697, loss2 : 0.931773
train_step : 21144, loss1 : 1.457817, loss2 : 0.853696
train_step : 21145, loss1 : 0.759499, loss2 : 0.555854
train_step : 21146, loss1 : 1.131827, loss2 : 0.856535
train_step : 21147, loss1 : 1.252466, loss2 : 0.839271
train_step : 21148, loss1 : 0.934062, loss2 : 1.517820
train_step : 21149, loss1 : 1.148207, loss2 : 0.955287
train_step : 21150, loss1 : 0.858678, loss2 : 0.822916
train_step : 21151, loss1 : 1.261645, loss2 : 1.545287
train_step : 21152, loss1 : 1.083098, loss2 : 3.744611
train_step : 21153, loss1 : 0.823038, loss2 : 0.938449
train_step : 21154, loss1 : 1.272290, loss2 : 1.533236
train_step : 21155, loss1 : 0.948185, loss2 : 0.853722
train_step : 21156, loss1 : 0.908516, loss2 : 1.303726
train_step : 21157, loss1 : 1.266053, loss2 : 2.428380
train_step : 21158, loss1 : 1.393402, loss2 : 0.903262
train_step : 21159, loss1 : 0.794180, loss2 : 0.619647
train_step : 21160, loss1 : 1.262573, loss2 : 1.022273
train_step : 21161, loss1 : 0.966935, loss2 : 0.861457
train_step : 21162, loss1 : 1.953294, loss2 : 1.246863
train_step : 21163, loss1 : 1.653185, loss2 : 1.114190
train_step : 21164, loss1 : 1.210508, loss2 : 2.030798
train_step : 21165, loss1 : 2.445217, loss2 : 1.547501
train_step : 21166, loss1 : 2.255599, loss2 : 1.623702
train_step : 21167, loss1 : 1.888027, loss2 : 2.531812
train_step : 21168, loss1 : 1.137141, loss2 : 1.537115
train_step : 21169, loss1 : 1.662446, loss2 : 1.460515
train_step : 21170, loss1 : 2.221532, loss2 : 3.849018
train_step : 21171, loss1 : 1.380813, loss2 : 1.707260
train_step : 21172, loss1 : 1.335355, loss2 : 1.065139
train_step : 21173, loss1 : 1.371591, loss2 : 1.499076
train_step : 21174, loss1 : 1.327736, loss2 : 1.108521
train_step : 21175, loss1 : 1.055891, loss2 : 1.472950
train_step : 21176, loss1 : 1.647456, loss2 : 1.327116
train_step : 21177, loss1 : 1.139925, loss2 : 0.820549
train_step : 21178, loss1 : 1.682397, loss2 : 1.380661
train_step : 21179, loss1 : 1.931314, loss2 : 1.672978
train_step : 21180, loss1 : 1.251453, loss2 : 2.011932
train_step : 21181, loss1 : 1.433119, loss2 : 1.339899
train_step : 21182, loss1 : 0.854257, loss2 : 1.820519
train_step : 21183, loss1 : 1.017792, loss2 : 1.401409
train_step : 21184, loss1 : 0.787038, loss2 : 0.749731
train_step : 21185, loss1 : 0.678651, loss2 : 1.134909
train_step : 21186, loss1 : 1.216714, loss2 : 0.934501
train_step : 21187, loss1 : 1.154413, loss2 : 1.114725
train_step : 21188, loss1 : 0.805403, loss2 : 1.125603
train_step : 21189, loss1 : 2.262664, loss2 : 0.651796
train_step : 21190, loss1 : 0.959671, loss2 : 0.795518
train_step : 21191, loss1 : 1.152419, loss2 : 1.687395
train_step : 21192, loss1 : 1.158791, loss2 : 1.097128
train_step : 21193, loss1 : 1.701244, loss2 : 0.899969
train_step : 21194, loss1 : 1.092241, loss2 : 1.174448
train_step : 21195, loss1 : 0.944770, loss2 : 1.018506
train_step : 21196, loss1 : 1.899636, loss2 : 1.843760
train_step : 21197, loss1 : 2.253086, loss2 : 1.551202
train_step : 21198, loss1 : 1.075161, loss2 : 1.325896
train_step : 21199, loss1 : 1.028785, loss2 : 0.754521
train_step : 21200, loss1 : 0.995430, loss2 : 1.152705
train_step : 21201, loss1 : 0.591587, loss2 : 0.754647
train_step : 21202, loss1 : 2.206959, loss2 : 1.142077
train_step : 21203, loss1 : 0.837970, loss2 : 1.496392
train_step : 21204, loss1 : 0.962243, loss2 : 1.460753
train_step : 21205, loss1 : 0.919718, loss2 : 1.505292
train_step : 21206, loss1 : 1.147220, loss2 : 1.356119
train_step : 21207, loss1 : 0.578534, loss2 : 1.591684
train_step : 21208, loss1 : 1.894835, loss2 : 1.787703
train_step : 21209, loss1 : 1.934409, loss2 : 2.183739
train_step : 21210, loss1 : 2.902906, loss2 : 0.749077
train_step : 21211, loss1 : 1.441145, loss2 : 1.816613
train_step : 21212, loss1 : 2.453356, loss2 : 1.653651
train_step : 21213, loss1 : 1.870089, loss2 : 3.199674
train_step : 21214, loss1 : 0.565998, loss2 : 0.517606
train_step : 21215, loss1 : 2.223047, loss2 : 0.717713
train_step : 21216, loss1 : 1.237667, loss2 : 1.878322
train_step : 21217, loss1 : 1.536236, loss2 : 2.019394
train_step : 21218, loss1 : 1.302055, loss2 : 0.461444
train_step : 21219, loss1 : 1.227655, loss2 : 0.684565
train_step : 21220, loss1 : 1.061338, loss2 : 0.904908
train_step : 21221, loss1 : 1.293833, loss2 : 0.999082
train_step : 21222, loss1 : 1.107256, loss2 : 0.868112
train_step : 21223, loss1 : 0.857978, loss2 : 1.092862
train_step : 21224, loss1 : 1.109127, loss2 : 0.485724
train_step : 21225, loss1 : 1.508784, loss2 : 0.759733
train_step : 21226, loss1 : 1.590742, loss2 : 1.236016
train_step : 21227, loss1 : 0.997395, loss2 : 2.244658
train_step : 21228, loss1 : 1.221754, loss2 : 1.266240
train_step : 21229, loss1 : 1.030136, loss2 : 0.760067
train_step : 21230, loss1 : 1.225180, loss2 : 1.392109
train_step : 21231, loss1 : 1.082359, loss2 : 1.321368
train_step : 21232, loss1 : 2.101223, loss2 : 1.502463
train_step : 21233, loss1 : 0.799918, loss2 : 0.752843
train_step : 21234, loss1 : 0.803386, loss2 : 1.165333
train_step : 21235, loss1 : 1.223082, loss2 : 1.628747
train_step : 21236, loss1 : 0.831713, loss2 : 1.353167
train_step : 21237, loss1 : 0.982227, loss2 : 1.754014
train_step : 21238, loss1 : 1.013554, loss2 : 1.000374
train_step : 21239, loss1 : 1.097910, loss2 : 1.703734
train_step : 21240, loss1 : 0.894997, loss2 : 1.239824
train_step : 21241, loss1 : 1.406442, loss2 : 1.020214
train_step : 21242, loss1 : 0.797699, loss2 : 2.182043
train_step : 21243, loss1 : 1.167856, loss2 : 1.142940
train_step : 21244, loss1 : 1.174256, loss2 : 0.807198
train_step : 21245, loss1 : 1.678251, loss2 : 1.006598
train_step : 21246, loss1 : 1.060746, loss2 : 0.718366
train_step : 21247, loss1 : 1.836947, loss2 : 0.879815
train_step : 21248, loss1 : 1.667609, loss2 : 0.891097
train_step : 21249, loss1 : 0.727603, loss2 : 1.592162
train_step : 21250, loss1 : 1.166631, loss2 : 0.998903
train_step : 21251, loss1 : 1.626895, loss2 : 0.855226
train_step : 21252, loss1 : 1.561770, loss2 : 1.700073
train_step : 21253, loss1 : 1.112956, loss2 : 1.343279
train_step : 21254, loss1 : 1.251494, loss2 : 0.963393
train_step : 21255, loss1 : 0.899531, loss2 : 0.592530
train_step : 21256, loss1 : 1.005342, loss2 : 1.221265
train_step : 21257, loss1 : 0.996004, loss2 : 1.304691
train_step : 21258, loss1 : 1.056898, loss2 : 1.005845
train_step : 21259, loss1 : 0.957415, loss2 : 1.416074
train_step : 21260, loss1 : 1.128313, loss2 : 1.496861
train_step : 21261, loss1 : 1.645267, loss2 : 0.458389
train_step : 21262, loss1 : 2.133488, loss2 : 0.820394
train_step : 21263, loss1 : 1.226476, loss2 : 1.222800
train_step : 21264, loss1 : 1.106957, loss2 : 1.193446
train_step : 21265, loss1 : 0.892035, loss2 : 1.191435
train_step : 21266, loss1 : 1.222108, loss2 : 0.582168
train_step : 21267, loss1 : 1.084989, loss2 : 0.990712
train_step : 21268, loss1 : 0.940170, loss2 : 0.854588
train_step : 21269, loss1 : 1.284967, loss2 : 1.920819
train_step : 21270, loss1 : 1.143909, loss2 : 1.940160
train_step : 21271, loss1 : 1.848480, loss2 : 1.690782
train_step : 21272, loss1 : 2.289606, loss2 : 1.166582
train_step : 21273, loss1 : 0.843732, loss2 : 1.361489
train_step : 21274, loss1 : 1.194917, loss2 : 0.526793
train_step : 21275, loss1 : 0.783297, loss2 : 1.130138
train_step : 21276, loss1 : 1.072294, loss2 : 0.779132
train_step : 21277, loss1 : 0.764415, loss2 : 0.810405
train_step : 21278, loss1 : 0.951527, loss2 : 1.080722
train_step : 21279, loss1 : 0.938642, loss2 : 0.488720
train_step : 21280, loss1 : 1.103589, loss2 : 1.425721
train_step : 21281, loss1 : 0.766240, loss2 : 2.737259
train_step : 21282, loss1 : 0.872753, loss2 : 1.496270
train_step : 21283, loss1 : 1.189647, loss2 : 1.114450
train_step : 21284, loss1 : 1.011208, loss2 : 1.838512
train_step : 21285, loss1 : 1.742202, loss2 : 1.246168
train_step : 21286, loss1 : 1.097236, loss2 : 0.719774
train_step : 21287, loss1 : 0.678959, loss2 : 1.424932
train_step : 21288, loss1 : 2.471149, loss2 : 1.593372
train_step : 21289, loss1 : 1.235196, loss2 : 1.058546
train_step : 21290, loss1 : 1.038117, loss2 : 1.557688
train_step : 21291, loss1 : 1.368011, loss2 : 1.602566
train_step : 21292, loss1 : 1.410285, loss2 : 1.543057
train_step : 21293, loss1 : 1.009964, loss2 : 1.423406
train_step : 21294, loss1 : 1.026808, loss2 : 1.855844
train_step : 21295, loss1 : 2.564435, loss2 : 1.145211
train_step : 21296, loss1 : 0.883453, loss2 : 1.123271
train_step : 21297, loss1 : 1.337385, loss2 : 0.878599
train_step : 21298, loss1 : 1.351518, loss2 : 1.138970
train_step : 21299, loss1 : 1.795545, loss2 : 1.733748
train_step : 21300, loss1 : 1.340310, loss2 : 1.516497
train_step : 21301, loss1 : 1.482286, loss2 : 1.605510
train_step : 21302, loss1 : 1.228722, loss2 : 1.384982
train_step : 21303, loss1 : 1.464589, loss2 : 2.617644
train_step : 21304, loss1 : 3.226127, loss2 : 1.184252
train_step : 21305, loss1 : 2.097096, loss2 : 0.815786
train_step : 21306, loss1 : 1.927935, loss2 : 1.817772
train_step : 21307, loss1 : 1.045680, loss2 : 0.609986
train_step : 21308, loss1 : 0.812013, loss2 : 0.511269
train_step : 21309, loss1 : 0.651583, loss2 : 0.645893
train_step : 21310, loss1 : 1.168095, loss2 : 1.640752
train_step : 21311, loss1 : 0.762976, loss2 : 1.767484
train_step : 21312, loss1 : 1.330754, loss2 : 1.131628
train_step : 21313, loss1 : 2.089275, loss2 : 0.859098
train_step : 21314, loss1 : 1.789683, loss2 : 1.325999
train_step : 21315, loss1 : 1.003159, loss2 : 1.582551
train_step : 21316, loss1 : 1.012393, loss2 : 1.638337
train_step : 21317, loss1 : 0.590131, loss2 : 1.056837
train_step : 21318, loss1 : 1.404195, loss2 : 0.927154
train_step : 21319, loss1 : 0.758206, loss2 : 1.555701
train_step : 21320, loss1 : 0.500702, loss2 : 1.236670
train_step : 21321, loss1 : 0.680400, loss2 : 1.125418
train_step : 21322, loss1 : 0.611275, loss2 : 0.824348
train_step : 21323, loss1 : 0.957593, loss2 : 0.955740
train_step : 21324, loss1 : 1.035577, loss2 : 1.100665
train_step : 21325, loss1 : 1.718772, loss2 : 1.499648
train_step : 21326, loss1 : 0.756505, loss2 : 1.607346
train_step : 21327, loss1 : 0.487231, loss2 : 1.069681
train_step : 21328, loss1 : 0.707523, loss2 : 1.228518
train_step : 21329, loss1 : 0.781099, loss2 : 1.204514
train_step : 21330, loss1 : 0.933496, loss2 : 1.175950
train_step : 21331, loss1 : 1.089306, loss2 : 1.071157
train_step : 21332, loss1 : 1.491502, loss2 : 1.382445
train_step : 21333, loss1 : 0.917838, loss2 : 2.023703
train_step : 21334, loss1 : 1.296946, loss2 : 1.495445
train_step : 21335, loss1 : 1.360505, loss2 : 1.433758
train_step : 21336, loss1 : 0.966138, loss2 : 0.918391
train_step : 21337, loss1 : 1.044727, loss2 : 1.387514
train_step : 21338, loss1 : 0.869847, loss2 : 0.796062
train_step : 21339, loss1 : 1.708720, loss2 : 1.016038
train_step : 21340, loss1 : 1.328097, loss2 : 2.431489
train_step : 21341, loss1 : 1.066321, loss2 : 1.423952
train_step : 21342, loss1 : 1.010110, loss2 : 0.945964
train_step : 21343, loss1 : 2.243221, loss2 : 1.157894
train_step : 21344, loss1 : 1.116518, loss2 : 0.726544
train_step : 21345, loss1 : 1.637676, loss2 : 2.418229
train_step : 21346, loss1 : 1.090192, loss2 : 1.136411
train_step : 21347, loss1 : 1.646227, loss2 : 0.901779
train_step : 21348, loss1 : 0.666176, loss2 : 1.566470
train_step : 21349, loss1 : 0.997974, loss2 : 0.575344
train_step : 21350, loss1 : 1.708297, loss2 : 0.639752
train_step : 21351, loss1 : 1.255274, loss2 : 0.783838
train_step : 21352, loss1 : 0.827103, loss2 : 1.093178
train_step : 21353, loss1 : 0.866880, loss2 : 1.158042
train_step : 21354, loss1 : 1.300237, loss2 : 1.232637
train_step : 21355, loss1 : 1.528741, loss2 : 0.686888
train_step : 21356, loss1 : 1.246687, loss2 : 0.677823
train_step : 21357, loss1 : 1.245932, loss2 : 1.013988
train_step : 21358, loss1 : 0.765624, loss2 : 1.893354
train_step : 21359, loss1 : 1.370520, loss2 : 0.674641
train_step : 21360, loss1 : 0.858157, loss2 : 1.367993
train_step : 21361, loss1 : 0.816774, loss2 : 1.355318
train_step : 21362, loss1 : 0.946879, loss2 : 1.017849
train_step : 21363, loss1 : 0.957076, loss2 : 1.273979
train_step : 21364, loss1 : 0.872037, loss2 : 1.006696
train_step : 21365, loss1 : 1.424386, loss2 : 0.991808
train_step : 21366, loss1 : 1.342339, loss2 : 0.856612
train_step : 21367, loss1 : 1.577363, loss2 : 1.008194
train_step : 21368, loss1 : 1.700348, loss2 : 1.575598
train_step : 21369, loss1 : 1.692052, loss2 : 1.735928
train_step : 21370, loss1 : 1.004105, loss2 : 1.880515
train_step : 21371, loss1 : 0.552228, loss2 : 1.245910
train_step : 21372, loss1 : 1.306129, loss2 : 0.898779
train_step : 21373, loss1 : 1.021148, loss2 : 0.987043
train_step : 21374, loss1 : 1.226943, loss2 : 1.451077
train_step : 21375, loss1 : 1.152359, loss2 : 0.924248
train_step : 21376, loss1 : 0.743151, loss2 : 1.385139
train_step : 21377, loss1 : 1.640407, loss2 : 1.110211
train_step : 21378, loss1 : 0.727205, loss2 : 1.114613
train_step : 21379, loss1 : 1.082428, loss2 : 0.812394
train_step : 21380, loss1 : 0.658455, loss2 : 0.857715
train_step : 21381, loss1 : 1.337248, loss2 : 0.862945
train_step : 21382, loss1 : 2.030668, loss2 : 1.840832
train_step : 21383, loss1 : 1.121719, loss2 : 0.968824
train_step : 21384, loss1 : 0.884617, loss2 : 1.448010
train_step : 21385, loss1 : 0.911790, loss2 : 1.072645
train_step : 21386, loss1 : 1.337837, loss2 : 2.201685
train_step : 21387, loss1 : 2.552761, loss2 : 1.543003
train_step : 21388, loss1 : 2.734424, loss2 : 1.355877
train_step : 21389, loss1 : 1.083215, loss2 : 2.674396
train_step : 21390, loss1 : 1.612779, loss2 : 0.957333
train_step : 21391, loss1 : 0.768230, loss2 : 1.196867
train_step : 21392, loss1 : 0.893669, loss2 : 0.579310
train_step : 21393, loss1 : 1.719126, loss2 : 2.198846
train_step : 21394, loss1 : 0.928486, loss2 : 1.308213
train_step : 21395, loss1 : 1.291070, loss2 : 1.317449
train_step : 21396, loss1 : 1.480080, loss2 : 1.188680
train_step : 21397, loss1 : 1.186823, loss2 : 1.031756
train_step : 21398, loss1 : 1.301628, loss2 : 1.153507
train_step : 21399, loss1 : 2.758920, loss2 : 2.298045
train_step : 21400, loss1 : 1.112224, loss2 : 2.916153
train_step : 21401, loss1 : 1.526091, loss2 : 1.675153
train_step : 21402, loss1 : 2.287255, loss2 : 1.063906
train_step : 21403, loss1 : 1.556142, loss2 : 2.015517
train_step : 21404, loss1 : 2.447220, loss2 : 2.310056
train_step : 21405, loss1 : 1.913622, loss2 : 1.359170
train_step : 21406, loss1 : 1.159795, loss2 : 1.654382
train_step : 21407, loss1 : 1.697094, loss2 : 1.923124
train_step : 21408, loss1 : 2.086204, loss2 : 0.995213
train_step : 21409, loss1 : 1.260602, loss2 : 1.720393
train_step : 21410, loss1 : 1.101903, loss2 : 1.523148
train_step : 21411, loss1 : 1.845312, loss2 : 1.503921
train_step : 21412, loss1 : 1.217333, loss2 : 2.085226
train_step : 21413, loss1 : 0.952833, loss2 : 2.013393
train_step : 21414, loss1 : 1.292053, loss2 : 1.291347
train_step : 21415, loss1 : 1.337545, loss2 : 0.922590
train_step : 21416, loss1 : 0.750756, loss2 : 1.707281
train_step : 21417, loss1 : 1.724037, loss2 : 1.112761
train_step : 21418, loss1 : 1.261496, loss2 : 0.977003
train_step : 21419, loss1 : 1.482971, loss2 : 1.226230
train_step : 21420, loss1 : 1.190121, loss2 : 1.829391
train_step : 21421, loss1 : 0.811569, loss2 : 1.850873
train_step : 21422, loss1 : 1.170839, loss2 : 0.731672
train_step : 21423, loss1 : 1.052398, loss2 : 1.860236
train_step : 21424, loss1 : 0.679135, loss2 : 0.905027
train_step : 21425, loss1 : 1.145939, loss2 : 0.817548
train_step : 21426, loss1 : 0.742925, loss2 : 1.268836
train_step : 21427, loss1 : 0.695428, loss2 : 2.266579
train_step : 21428, loss1 : 0.879153, loss2 : 1.209641
train_step : 21429, loss1 : 0.470461, loss2 : 1.765006
train_step : 21430, loss1 : 0.922189, loss2 : 1.850786
train_step : 21431, loss1 : 0.831511, loss2 : 1.251236
train_step : 21432, loss1 : 1.116717, loss2 : 0.823639
train_step : 21433, loss1 : 1.211951, loss2 : 1.465044
train_step : 21434, loss1 : 0.846483, loss2 : 1.739526
train_step : 21435, loss1 : 0.817535, loss2 : 1.775736
train_step : 21436, loss1 : 1.157472, loss2 : 1.391397
train_step : 21437, loss1 : 1.498863, loss2 : 0.825634
train_step : 21438, loss1 : 1.258329, loss2 : 1.234358
train_step : 21439, loss1 : 0.972003, loss2 : 0.411857
train_step : 21440, loss1 : 1.486488, loss2 : 1.515541
train_step : 21441, loss1 : 2.303483, loss2 : 1.157133
train_step : 21442, loss1 : 1.194428, loss2 : 1.502297
train_step : 21443, loss1 : 1.285299, loss2 : 0.799998
train_step : 21444, loss1 : 1.166718, loss2 : 1.240445
train_step : 21445, loss1 : 1.643603, loss2 : 1.287211
train_step : 21446, loss1 : 1.302719, loss2 : 1.518786
train_step : 21447, loss1 : 1.462320, loss2 : 1.406117
train_step : 21448, loss1 : 1.734975, loss2 : 2.923409
train_step : 21449, loss1 : 2.591411, loss2 : 3.696056
train_step : 21450, loss1 : 3.380354, loss2 : 1.645131
train_step : 21451, loss1 : 5.095326, loss2 : 2.959970
train_step : 21452, loss1 : 3.493588, loss2 : 3.806623
train_step : 21453, loss1 : 3.624083, loss2 : 5.666989
train_step : 21454, loss1 : 4.170936, loss2 : 3.942386
train_step : 21455, loss1 : 5.879867, loss2 : 5.275197
train_step : 21456, loss1 : 4.645088, loss2 : 6.310199
train_step : 21457, loss1 : 5.728676, loss2 : 4.911192
train_step : 21458, loss1 : 2.311785, loss2 : 2.801266
train_step : 21459, loss1 : 1.587607, loss2 : 1.505763
train_step : 21460, loss1 : 1.350575, loss2 : 1.504663
train_step : 21461, loss1 : 2.149205, loss2 : 1.857334
train_step : 21462, loss1 : 5.732096, loss2 : 2.115139
train_step : 21463, loss1 : 4.066462, loss2 : 2.040286
train_step : 21464, loss1 : 2.296982, loss2 : 1.391101
train_step : 21465, loss1 : 1.095580, loss2 : 0.948631
train_step : 21466, loss1 : 0.818606, loss2 : 1.426132
train_step : 21467, loss1 : 0.628561, loss2 : 1.700692
train_step : 21468, loss1 : 0.300568, loss2 : 1.856152
train_step : 21469, loss1 : 2.344833, loss2 : 1.050367
train_step : 21470, loss1 : 2.270021, loss2 : 1.012965
train_step : 21471, loss1 : 2.748834, loss2 : 1.613366
train_step : 21472, loss1 : 2.458447, loss2 : 1.625388
train_step : 21473, loss1 : 1.890707, loss2 : 1.498272
train_step : 21474, loss1 : 2.255624, loss2 : 2.200732
train_step : 21475, loss1 : 1.838698, loss2 : 4.228137
train_step : 21476, loss1 : 1.791056, loss2 : 1.696882
train_step : 21477, loss1 : 2.663580, loss2 : 1.091460
train_step : 21478, loss1 : 1.014723, loss2 : 1.478336
train_step : 21479, loss1 : 1.013648, loss2 : 0.968632
train_step : 21480, loss1 : 1.539123, loss2 : 0.928185
train_step : 21481, loss1 : 0.680415, loss2 : 0.892460
train_step : 21482, loss1 : 0.532467, loss2 : 0.581949
train_step : 21483, loss1 : 0.564005, loss2 : 1.417228
train_step : 21484, loss1 : 0.900681, loss2 : 0.530353
train_step : 21485, loss1 : 0.965749, loss2 : 0.958439
train_step : 21486, loss1 : 1.923041, loss2 : 1.259249
train_step : 21487, loss1 : 1.257790, loss2 : 0.859755
train_step : 21488, loss1 : 0.708050, loss2 : 0.733114
train_step : 21489, loss1 : 1.416642, loss2 : 1.558771
train_step : 21490, loss1 : 0.932837, loss2 : 0.751067
train_step : 21491, loss1 : 0.797091, loss2 : 0.822840
train_step : 21492, loss1 : 0.623821, loss2 : 1.105893
train_step : 21493, loss1 : 0.660781, loss2 : 1.062246
train_step : 21494, loss1 : 1.823823, loss2 : 1.481378
train_step : 21495, loss1 : 2.205316, loss2 : 1.355536
train_step : 21496, loss1 : 1.831842, loss2 : 2.673063
train_step : 21497, loss1 : 2.269789, loss2 : 0.895991
train_step : 21498, loss1 : 1.590032, loss2 : 1.572192
train_step : 21499, loss1 : 1.474915, loss2 : 1.542737
train_step : 21500, loss1 : 1.726957, loss2 : 1.393775
train_step : 21501, loss1 : 1.303178, loss2 : 0.989186
train_step : 21502, loss1 : 1.151651, loss2 : 1.246789
train_step : 21503, loss1 : 1.624996, loss2 : 2.453792
train_step : 21504, loss1 : 1.737674, loss2 : 2.517449
train_step : 21505, loss1 : 2.438873, loss2 : 1.883398
train_step : 21506, loss1 : 2.456212, loss2 : 1.733060
train_step : 21507, loss1 : 1.553714, loss2 : 1.346964
train_step : 21508, loss1 : 2.021183, loss2 : 1.650606
train_step : 21509, loss1 : 1.734666, loss2 : 0.988401
train_step : 21510, loss1 : 1.679224, loss2 : 0.906834
train_step : 21511, loss1 : 1.565684, loss2 : 1.068026
train_step : 21512, loss1 : 1.292906, loss2 : 0.548694
train_step : 21513, loss1 : 1.130676, loss2 : 1.283237
train_step : 21514, loss1 : 0.785198, loss2 : 1.014223
train_step : 21515, loss1 : 0.890746, loss2 : 0.980967
train_step : 21516, loss1 : 0.472181, loss2 : 1.148482
train_step : 21517, loss1 : 0.844265, loss2 : 1.339420
train_step : 21518, loss1 : 0.870710, loss2 : 0.705137
train_step : 21519, loss1 : 1.137233, loss2 : 1.011061
train_step : 21520, loss1 : 1.604367, loss2 : 1.155611
train_step : 21521, loss1 : 1.442665, loss2 : 0.956885
train_step : 21522, loss1 : 0.662382, loss2 : 1.294298
train_step : 21523, loss1 : 1.038280, loss2 : 1.419140
train_step : 21524, loss1 : 1.929887, loss2 : 1.511580
train_step : 21525, loss1 : 0.960520, loss2 : 1.089465
train_step : 21526, loss1 : 0.391842, loss2 : 0.954957
train_step : 21527, loss1 : 2.157976, loss2 : 1.703752
train_step : 21528, loss1 : 2.025527, loss2 : 2.250554
train_step : 21529, loss1 : 1.474278, loss2 : 1.659267
train_step : 21530, loss1 : 2.114690, loss2 : 1.379724
train_step : 21531, loss1 : 1.839813, loss2 : 2.136414
train_step : 21532, loss1 : 0.869995, loss2 : 1.676798
train_step : 21533, loss1 : 0.679786, loss2 : 1.306501
train_step : 21534, loss1 : 1.149652, loss2 : 0.986487
train_step : 21535, loss1 : 1.515554, loss2 : 1.383415
train_step : 21536, loss1 : 2.461453, loss2 : 1.638864
train_step : 21537, loss1 : 1.327148, loss2 : 3.551129
train_step : 21538, loss1 : 1.476398, loss2 : 1.651048
train_step : 21539, loss1 : 2.028299, loss2 : 1.688112
train_step : 21540, loss1 : 1.138849, loss2 : 1.550288
train_step : 21541, loss1 : 1.009238, loss2 : 0.869717
train_step : 21542, loss1 : 0.969819, loss2 : 1.654381
train_step : 21543, loss1 : 0.580324, loss2 : 1.071197
train_step : 21544, loss1 : 1.016546, loss2 : 1.501652
train_step : 21545, loss1 : 1.766521, loss2 : 1.091654
train_step : 21546, loss1 : 1.374877, loss2 : 0.902149
train_step : 21547, loss1 : 1.148314, loss2 : 1.289890
train_step : 21548, loss1 : 0.951826, loss2 : 1.802779
train_step : 21549, loss1 : 1.450731, loss2 : 1.619027
train_step : 21550, loss1 : 0.732147, loss2 : 1.867975
train_step : 21551, loss1 : 0.868875, loss2 : 0.822730
train_step : 21552, loss1 : 2.223617, loss2 : 0.617481
train_step : 21553, loss1 : 1.054865, loss2 : 1.819369
train_step : 21554, loss1 : 1.062778, loss2 : 0.825822
train_step : 21555, loss1 : 1.054975, loss2 : 1.159605
train_step : 21556, loss1 : 0.701237, loss2 : 1.679354
train_step : 21557, loss1 : 0.738269, loss2 : 0.479427
train_step : 21558, loss1 : 1.284408, loss2 : 0.693491
train_step : 21559, loss1 : 0.648502, loss2 : 1.106849
train_step : 21560, loss1 : 1.096971, loss2 : 1.596568
train_step : 21561, loss1 : 1.891696, loss2 : 3.496308
train_step : 21562, loss1 : 1.532826, loss2 : 2.094238
train_step : 21563, loss1 : 1.506453, loss2 : 0.851414
train_step : 21564, loss1 : 1.295526, loss2 : 1.086864
train_step : 21565, loss1 : 0.999264, loss2 : 2.985560
train_step : 21566, loss1 : 1.464731, loss2 : 1.704700
train_step : 21567, loss1 : 0.809224, loss2 : 1.129563
train_step : 21568, loss1 : 1.129329, loss2 : 0.738405
train_step : 21569, loss1 : 0.882201, loss2 : 1.306068
train_step : 21570, loss1 : 0.716436, loss2 : 0.763727
train_step : 21571, loss1 : 0.588789, loss2 : 1.061347
train_step : 21572, loss1 : 1.758028, loss2 : 1.460259
train_step : 21573, loss1 : 1.071190, loss2 : 1.016479
train_step : 21574, loss1 : 1.664807, loss2 : 0.390132
train_step : 21575, loss1 : 2.029065, loss2 : 1.249324
train_step : 21576, loss1 : 1.199321, loss2 : 0.755180
train_step : 21577, loss1 : 0.489668, loss2 : 0.566048
train_step : 21578, loss1 : 0.406125, loss2 : 0.927342
train_step : 21579, loss1 : 1.251648, loss2 : 1.176705
train_step : 21580, loss1 : 0.991085, loss2 : 1.069015
train_step : 21581, loss1 : 1.303377, loss2 : 0.946962
train_step : 21582, loss1 : 1.913911, loss2 : 1.155690
train_step : 21583, loss1 : 1.868641, loss2 : 2.395995
train_step : 21584, loss1 : 2.377065, loss2 : 2.277849
train_step : 21585, loss1 : 1.959259, loss2 : 1.446452
train_step : 21586, loss1 : 1.915173, loss2 : 0.747929
train_step : 21587, loss1 : 1.188185, loss2 : 1.475451
train_step : 21588, loss1 : 0.878474, loss2 : 0.646564
train_step : 21589, loss1 : 0.830117, loss2 : 1.485062
train_step : 21590, loss1 : 0.957839, loss2 : 1.920409
train_step : 21591, loss1 : 1.492332, loss2 : 2.364515
train_step : 21592, loss1 : 0.950460, loss2 : 0.902389
train_step : 21593, loss1 : 0.753600, loss2 : 0.994433
train_step : 21594, loss1 : 0.882801, loss2 : 1.228968
train_step : 21595, loss1 : 1.168542, loss2 : 0.864627
train_step : 21596, loss1 : 0.973188, loss2 : 1.290034
train_step : 21597, loss1 : 1.409550, loss2 : 0.681828
train_step : 21598, loss1 : 0.964363, loss2 : 1.081913
train_step : 21599, loss1 : 0.884092, loss2 : 1.820800
train_step : 21600, loss1 : 0.912774, loss2 : 1.069061
train_step : 21601, loss1 : 3.365048, loss2 : 0.353720
train_step : 21602, loss1 : 0.745639, loss2 : 1.213356
train_step : 21603, loss1 : 1.929446, loss2 : 0.656614
train_step : 21604, loss1 : 1.030145, loss2 : 0.890390
train_step : 21605, loss1 : 1.020500, loss2 : 1.357552
train_step : 21606, loss1 : 1.484361, loss2 : 1.067759
train_step : 21607, loss1 : 2.479213, loss2 : 2.406102
train_step : 21608, loss1 : 1.131900, loss2 : 2.142688
train_step : 21609, loss1 : 1.712545, loss2 : 1.824867
train_step : 21610, loss1 : 1.305395, loss2 : 1.461350
train_step : 21611, loss1 : 1.958372, loss2 : 1.556774
train_step : 21612, loss1 : 1.759981, loss2 : 1.295345
train_step : 21613, loss1 : 1.364350, loss2 : 0.981571
train_step : 21614, loss1 : 1.808259, loss2 : 2.125435
train_step : 21615, loss1 : 1.058939, loss2 : 1.064260
train_step : 21616, loss1 : 1.214265, loss2 : 0.937277
train_step : 21617, loss1 : 6.126713, loss2 : 0.803656
train_step : 21618, loss1 : 1.501382, loss2 : 1.168984
train_step : 21619, loss1 : 1.183087, loss2 : 1.659639
train_step : 21620, loss1 : 1.757327, loss2 : 1.988326
train_step : 21621, loss1 : 1.525051, loss2 : 1.205696
train_step : 21622, loss1 : 1.626290, loss2 : 1.320569
train_step : 21623, loss1 : 1.379083, loss2 : 2.864152
train_step : 21624, loss1 : 2.975078, loss2 : 3.197442
train_step : 21625, loss1 : 3.977076, loss2 : 3.200055
train_step : 21626, loss1 : 5.023492, loss2 : 4.559598
train_step : 21627, loss1 : 4.109682, loss2 : 4.205081
train_step : 21628, loss1 : 4.647611, loss2 : 6.246850
train_step : 21629, loss1 : 1.847485, loss2 : 3.618921
train_step : 21630, loss1 : 1.689963, loss2 : 1.744118
train_step : 21631, loss1 : 1.678600, loss2 : 2.033888
train_step : 21632, loss1 : 1.259941, loss2 : 1.685441
train_step : 21633, loss1 : 0.842336, loss2 : 1.634207
train_step : 21634, loss1 : 1.805144, loss2 : 0.649431
train_step : 21635, loss1 : 0.893234, loss2 : 1.375348
train_step : 21636, loss1 : 1.635991, loss2 : 0.636095
train_step : 21637, loss1 : 0.719456, loss2 : 1.700284
train_step : 21638, loss1 : 1.237058, loss2 : 1.308018
train_step : 21639, loss1 : 0.655383, loss2 : 0.830740
train_step : 21640, loss1 : 1.543383, loss2 : 1.200164
train_step : 21641, loss1 : 1.715548, loss2 : 1.330347
train_step : 21642, loss1 : 2.056265, loss2 : 1.230006
train_step : 21643, loss1 : 1.660570, loss2 : 1.862087
train_step : 21644, loss1 : 1.468742, loss2 : 2.511707
train_step : 21645, loss1 : 1.452024, loss2 : 2.086784
train_step : 21646, loss1 : 2.217368, loss2 : 1.903891
train_step : 21647, loss1 : 1.998245, loss2 : 1.954555
train_step : 21648, loss1 : 1.465640, loss2 : 1.313542
train_step : 21649, loss1 : 1.060890, loss2 : 1.238242
train_step : 21650, loss1 : 1.403573, loss2 : 1.819966
train_step : 21651, loss1 : 1.778895, loss2 : 1.737379
train_step : 21652, loss1 : 1.601614, loss2 : 1.757260
train_step : 21653, loss1 : 1.850371, loss2 : 1.159993
train_step : 21654, loss1 : 0.918723, loss2 : 4.452893
train_step : 21655, loss1 : 0.472092, loss2 : 1.409694
train_step : 21656, loss1 : 1.365737, loss2 : 0.956531
train_step : 21657, loss1 : 1.290374, loss2 : 1.232818
train_step : 21658, loss1 : 0.636942, loss2 : 0.821060
train_step : 21659, loss1 : 0.701715, loss2 : 1.524402
train_step : 21660, loss1 : 1.038902, loss2 : 1.522461
train_step : 21661, loss1 : 1.233685, loss2 : 0.893432
train_step : 21662, loss1 : 1.057197, loss2 : 0.841454
train_step : 21663, loss1 : 1.535819, loss2 : 1.091660
train_step : 21664, loss1 : 1.850537, loss2 : 1.791954
train_step : 21665, loss1 : 1.263250, loss2 : 1.297035
train_step : 21666, loss1 : 1.476245, loss2 : 1.145736
train_step : 21667, loss1 : 1.822646, loss2 : 1.713049
train_step : 21668, loss1 : 2.550860, loss2 : 1.454876
train_step : 21669, loss1 : 2.314144, loss2 : 2.664385
train_step : 21670, loss1 : 2.467212, loss2 : 2.102362
train_step : 21671, loss1 : 0.939336, loss2 : 2.642176
train_step : 21672, loss1 : 2.264742, loss2 : 2.447452
train_step : 21673, loss1 : 2.581644, loss2 : 2.606727
train_step : 21674, loss1 : 3.487885, loss2 : 2.904013
train_step : 21675, loss1 : 3.253594, loss2 : 1.760599
train_step : 21676, loss1 : 1.686156, loss2 : 1.278630
train_step : 21677, loss1 : 1.145151, loss2 : 1.193886
train_step : 21678, loss1 : 1.467875, loss2 : 1.218244
train_step : 21679, loss1 : 0.865802, loss2 : 0.857896
train_step : 21680, loss1 : 0.398140, loss2 : 0.253943
train_step : 21681, loss1 : 0.848207, loss2 : 1.289742
train_step : 21682, loss1 : 1.968538, loss2 : 1.106892
train_step : 21683, loss1 : 1.635722, loss2 : 2.474530
train_step : 21684, loss1 : 1.482759, loss2 : 1.524915
train_step : 21685, loss1 : 1.547397, loss2 : 3.672584
train_step : 21686, loss1 : 2.845849, loss2 : 2.293213
train_step : 21687, loss1 : 2.640483, loss2 : 2.510397
train_step : 21688, loss1 : 2.790254, loss2 : 2.974532
train_step : 21689, loss1 : 2.613953, loss2 : 2.807122
train_step : 21690, loss1 : 2.297475, loss2 : 2.595781
train_step : 21691, loss1 : 2.331066, loss2 : 1.908231
train_step : 21692, loss1 : 2.653541, loss2 : 1.759604
train_step : 21693, loss1 : 2.662063, loss2 : 2.020185
train_step : 21694, loss1 : 1.220435, loss2 : 2.329962
train_step : 21695, loss1 : 1.328403, loss2 : 1.041885
train_step : 21696, loss1 : 0.761362, loss2 : 0.862282
train_step : 21697, loss1 : 1.067313, loss2 : 1.225305
train_step : 21698, loss1 : 1.458461, loss2 : 1.003226
train_step : 21699, loss1 : 1.735671, loss2 : 2.405154
train_step : 21700, loss1 : 1.454297, loss2 : 2.813527
train_step : 21701, loss1 : 2.779011, loss2 : 2.552094
train_step : 21702, loss1 : 1.773155, loss2 : 2.982506
train_step : 21703, loss1 : 1.089398, loss2 : 2.196688
train_step : 21704, loss1 : 0.963430, loss2 : 1.771133
train_step : 21705, loss1 : 1.568662, loss2 : 0.994947
train_step : 21706, loss1 : 0.962793, loss2 : 1.087367
train_step : 21707, loss1 : 0.930796, loss2 : 0.738378
train_step : 21708, loss1 : 1.851760, loss2 : 1.095349
train_step : 21709, loss1 : 1.109281, loss2 : 1.562605
train_step : 21710, loss1 : 1.358706, loss2 : 1.907593
train_step : 21711, loss1 : 2.951673, loss2 : 1.024355
train_step : 21712, loss1 : 1.916779, loss2 : 2.071731
train_step : 21713, loss1 : 2.489490, loss2 : 1.794715
train_step : 21714, loss1 : 2.434220, loss2 : 2.754549
train_step : 21715, loss1 : 1.062327, loss2 : 2.282670
train_step : 21716, loss1 : 1.514784, loss2 : 1.722956
train_step : 21717, loss1 : 1.302486, loss2 : 1.723519
train_step : 21718, loss1 : 1.427599, loss2 : 1.152829
train_step : 21719, loss1 : 1.694677, loss2 : 0.512531
train_step : 21720, loss1 : 1.263928, loss2 : 1.257764
train_step : 21721, loss1 : 1.673218, loss2 : 0.880021
train_step : 21722, loss1 : 1.068181, loss2 : 2.485399
train_step : 21723, loss1 : 1.435683, loss2 : 1.533073
train_step : 21724, loss1 : 1.116678, loss2 : 2.327739
train_step : 21725, loss1 : 2.025453, loss2 : 1.346548
train_step : 21726, loss1 : 1.038310, loss2 : 0.823435
train_step : 21727, loss1 : 1.269337, loss2 : 1.375133
train_step : 21728, loss1 : 1.328697, loss2 : 0.967598
train_step : 21729, loss1 : 1.458094, loss2 : 0.921760
train_step : 21730, loss1 : 1.202573, loss2 : 0.669605
train_step : 21731, loss1 : 1.293717, loss2 : 1.633004
train_step : 21732, loss1 : 0.768562, loss2 : 1.487885
train_step : 21733, loss1 : 1.270950, loss2 : 0.963934
train_step : 21734, loss1 : 0.846593, loss2 : 0.847513
train_step : 21735, loss1 : 1.361326, loss2 : 1.126909
train_step : 21736, loss1 : 0.830137, loss2 : 2.046762
train_step : 21737, loss1 : 0.987173, loss2 : 1.392586
train_step : 21738, loss1 : 1.413352, loss2 : 0.692703
train_step : 21739, loss1 : 1.797717, loss2 : 0.910206
train_step : 21740, loss1 : 1.226703, loss2 : 1.026345
train_step : 21741, loss1 : 2.085715, loss2 : 0.607126
train_step : 21742, loss1 : 1.990559, loss2 : 1.026383
train_step : 21743, loss1 : 1.231156, loss2 : 0.620748
train_step : 21744, loss1 : 0.561910, loss2 : 0.517474
train_step : 21745, loss1 : 1.086647, loss2 : 0.996944
train_step : 21746, loss1 : 0.529032, loss2 : 0.612020
train_step : 21747, loss1 : 0.967980, loss2 : 1.203920
train_step : 21748, loss1 : 2.600439, loss2 : 1.649522
train_step : 21749, loss1 : 1.356373, loss2 : 1.605413
train_step : 21750, loss1 : 1.101499, loss2 : 1.529994
train_step : 21751, loss1 : 1.450015, loss2 : 1.155222
train_step : 21752, loss1 : 1.141869, loss2 : 1.749022
train_step : 21753, loss1 : 1.499617, loss2 : 1.186420
train_step : 21754, loss1 : 1.512516, loss2 : 1.274607
train_step : 21755, loss1 : 1.862803, loss2 : 1.605023
train_step : 21756, loss1 : 0.887155, loss2 : 1.789252
train_step : 21757, loss1 : 1.697677, loss2 : 1.914458
train_step : 21758, loss1 : 2.024531, loss2 : 1.751217
train_step : 21759, loss1 : 2.654696, loss2 : 0.756245
train_step : 21760, loss1 : 1.283954, loss2 : 1.602311
train_step : 21761, loss1 : 1.248054, loss2 : 2.246502
train_step : 21762, loss1 : 1.496315, loss2 : 0.376320
train_step : 21763, loss1 : 0.987658, loss2 : 1.355264
train_step : 21764, loss1 : 0.653736, loss2 : 0.851403
train_step : 21765, loss1 : 0.658150, loss2 : 0.668242
train_step : 21766, loss1 : 1.060915, loss2 : 1.045056
train_step : 21767, loss1 : 2.118678, loss2 : 1.059430
train_step : 21768, loss1 : 1.001354, loss2 : 0.869820
train_step : 21769, loss1 : 1.656361, loss2 : 1.120282
train_step : 21770, loss1 : 0.820844, loss2 : 1.108853
train_step : 21771, loss1 : 0.766652, loss2 : 1.026843
train_step : 21772, loss1 : 1.252131, loss2 : 1.335653
train_step : 21773, loss1 : 0.875631, loss2 : 0.923279
train_step : 21774, loss1 : 1.004831, loss2 : 1.296938
train_step : 21775, loss1 : 1.284512, loss2 : 1.223721
train_step : 21776, loss1 : 1.517932, loss2 : 1.931922
train_step : 21777, loss1 : 1.087978, loss2 : 2.878516
train_step : 21778, loss1 : 2.980344, loss2 : 2.232208
train_step : 21779, loss1 : 2.819923, loss2 : 2.895779
train_step : 21780, loss1 : 1.687878, loss2 : 2.789640
train_step : 21781, loss1 : 1.482055, loss2 : 1.490087
train_step : 21782, loss1 : 0.736924, loss2 : 1.008223
train_step : 21783, loss1 : 1.263967, loss2 : 1.876506
train_step : 21784, loss1 : 2.049369, loss2 : 2.333841
train_step : 21785, loss1 : 2.623604, loss2 : 2.158825
train_step : 21786, loss1 : 2.711112, loss2 : 1.759784
train_step : 21787, loss1 : 3.666743, loss2 : 4.700424
train_step : 21788, loss1 : 3.793662, loss2 : 4.262600
train_step : 21789, loss1 : 1.681402, loss2 : 0.836071
train_step : 21790, loss1 : 1.353589, loss2 : 1.257828
train_step : 21791, loss1 : 1.677890, loss2 : 1.482589
train_step : 21792, loss1 : 1.873011, loss2 : 1.379192
train_step : 21793, loss1 : 1.345290, loss2 : 1.585080
train_step : 21794, loss1 : 1.271007, loss2 : 1.156616
train_step : 21795, loss1 : 1.069498, loss2 : 0.586317
train_step : 21796, loss1 : 0.959308, loss2 : 1.911414
train_step : 21797, loss1 : 0.894122, loss2 : 1.509566
train_step : 21798, loss1 : 0.817027, loss2 : 1.159315
train_step : 21799, loss1 : 0.627166, loss2 : 1.111318
train_step : 21800, loss1 : 0.914046, loss2 : 1.525979
train_step : 21801, loss1 : 2.014172, loss2 : 1.045009
train_step : 21802, loss1 : 2.025432, loss2 : 1.788121
train_step : 21803, loss1 : 1.442082, loss2 : 1.051226
train_step : 21804, loss1 : 1.586418, loss2 : 1.879560
train_step : 21805, loss1 : 2.171201, loss2 : 0.914822
train_step : 21806, loss1 : 1.628304, loss2 : 1.024853
train_step : 21807, loss1 : 0.803819, loss2 : 1.611156
train_step : 21808, loss1 : 2.581131, loss2 : 1.978954
train_step : 21809, loss1 : 3.071346, loss2 : 2.667720
train_step : 21810, loss1 : 2.309520, loss2 : 2.536092
train_step : 21811, loss1 : 1.359770, loss2 : 1.633366
train_step : 21812, loss1 : 0.981074, loss2 : 1.352433
train_step : 21813, loss1 : 0.607864, loss2 : 2.676718
train_step : 21814, loss1 : 0.910124, loss2 : 1.307580
train_step : 21815, loss1 : 1.195640, loss2 : 0.921560
train_step : 21816, loss1 : 2.307864, loss2 : 1.252223
train_step : 21817, loss1 : 2.706665, loss2 : 1.893943
train_step : 21818, loss1 : 1.548698, loss2 : 3.115316
train_step : 21819, loss1 : 2.684673, loss2 : 1.956589
train_step : 21820, loss1 : 2.386475, loss2 : 2.700817
train_step : 21821, loss1 : 2.406964, loss2 : 2.076600
train_step : 21822, loss1 : 1.357072, loss2 : 0.946859
train_step : 21823, loss1 : 0.956628, loss2 : 1.387206
train_step : 21824, loss1 : 0.939667, loss2 : 1.313750
train_step : 21825, loss1 : 1.108376, loss2 : 0.990641
train_step : 21826, loss1 : 1.195646, loss2 : 0.604827
train_step : 21827, loss1 : 0.738128, loss2 : 1.470612
train_step : 21828, loss1 : 1.257975, loss2 : 1.252217
train_step : 21829, loss1 : 0.734014, loss2 : 0.977225
train_step : 21830, loss1 : 1.134634, loss2 : 1.240854
train_step : 21831, loss1 : 1.393661, loss2 : 1.690615
train_step : 21832, loss1 : 1.554964, loss2 : 0.746020
train_step : 21833, loss1 : 1.688831, loss2 : 2.100496
train_step : 21834, loss1 : 1.564479, loss2 : 1.196625
train_step : 21835, loss1 : 0.683338, loss2 : 1.354478
train_step : 21836, loss1 : 1.222927, loss2 : 0.728087
train_step : 21837, loss1 : 0.867849, loss2 : 0.977219
train_step : 21838, loss1 : 1.457443, loss2 : 1.261777
train_step : 21839, loss1 : 0.718617, loss2 : 1.245945
train_step : 21840, loss1 : 0.936967, loss2 : 1.890516
train_step : 21841, loss1 : 1.088152, loss2 : 0.862494
train_step : 21842, loss1 : 0.863208, loss2 : 1.295802
train_step : 21843, loss1 : 2.342153, loss2 : 1.235278
train_step : 21844, loss1 : 2.304788, loss2 : 0.895162
train_step : 21845, loss1 : 1.607739, loss2 : 0.678992
train_step : 21846, loss1 : 1.224655, loss2 : 1.509748
train_step : 21847, loss1 : 1.341449, loss2 : 0.566122
train_step : 21848, loss1 : 0.840529, loss2 : 1.412559
train_step : 21849, loss1 : 1.037102, loss2 : 0.909059
train_step : 21850, loss1 : 2.183209, loss2 : 0.841507
train_step : 21851, loss1 : 1.413399, loss2 : 1.028396
train_step : 21852, loss1 : 1.104366, loss2 : 0.710487
train_step : 21853, loss1 : 1.432607, loss2 : 1.074721
train_step : 21854, loss1 : 1.869953, loss2 : 0.654252
train_step : 21855, loss1 : 1.896442, loss2 : 1.015126
train_step : 21856, loss1 : 1.255431, loss2 : 1.834907
train_step : 21857, loss1 : 2.595598, loss2 : 2.038897
train_step : 21858, loss1 : 2.074212, loss2 : 3.211759
train_step : 21859, loss1 : 1.697492, loss2 : 2.604598
train_step : 21860, loss1 : 1.535209, loss2 : 2.302093
train_step : 21861, loss1 : 1.071302, loss2 : 1.755136
train_step : 21862, loss1 : 2.182856, loss2 : 0.893073
train_step : 21863, loss1 : 1.781722, loss2 : 1.321008
train_step : 21864, loss1 : 3.474533, loss2 : 1.646649
train_step : 21865, loss1 : 1.404437, loss2 : 2.101276
train_step : 21866, loss1 : 1.190948, loss2 : 1.399398
train_step : 21867, loss1 : 1.164783, loss2 : 1.598633
train_step : 21868, loss1 : 1.675427, loss2 : 0.488169
train_step : 21869, loss1 : 1.262115, loss2 : 0.548541
train_step : 21870, loss1 : 1.265929, loss2 : 0.947076
train_step : 21871, loss1 : 0.861343, loss2 : 1.149032
train_step : 21872, loss1 : 0.955097, loss2 : 1.147832
train_step : 21873, loss1 : 1.720009, loss2 : 0.595584
train_step : 21874, loss1 : 1.239098, loss2 : 1.545621
train_step : 21875, loss1 : 1.187666, loss2 : 1.848575
train_step : 21876, loss1 : 1.395395, loss2 : 1.070733
train_step : 21877, loss1 : 1.019342, loss2 : 0.674006
train_step : 21878, loss1 : 1.139057, loss2 : 0.937201
train_step : 21879, loss1 : 0.933979, loss2 : 1.010149
train_step : 21880, loss1 : 0.858075, loss2 : 1.880368
train_step : 21881, loss1 : 1.546110, loss2 : 1.498700
train_step : 21882, loss1 : 1.440654, loss2 : 1.339102
train_step : 21883, loss1 : 1.645482, loss2 : 1.049018
train_step : 21884, loss1 : 1.247849, loss2 : 2.252006
train_step : 21885, loss1 : 2.403275, loss2 : 2.509426
train_step : 21886, loss1 : 1.403738, loss2 : 2.403526
train_step : 21887, loss1 : 2.156014, loss2 : 1.207400
train_step : 21888, loss1 : 1.405014, loss2 : 1.069939
train_step : 21889, loss1 : 1.169122, loss2 : 1.281313
train_step : 21890, loss1 : 1.187710, loss2 : 1.151085
train_step : 21891, loss1 : 1.248789, loss2 : 1.753723
train_step : 21892, loss1 : 1.158416, loss2 : 1.512175
train_step : 21893, loss1 : 0.807466, loss2 : 1.040431
train_step : 21894, loss1 : 1.220386, loss2 : 1.222223
train_step : 21895, loss1 : 1.514494, loss2 : 1.719605
train_step : 21896, loss1 : 1.429027, loss2 : 1.264542
train_step : 21897, loss1 : 1.603010, loss2 : 1.276404
train_step : 21898, loss1 : 0.723638, loss2 : 1.175946
train_step : 21899, loss1 : 0.846740, loss2 : 0.803302
train_step : 21900, loss1 : 1.821300, loss2 : 1.939715
train_step : 21901, loss1 : 2.611876, loss2 : 2.181205
train_step : 21902, loss1 : 1.978942, loss2 : 3.080695
train_step : 21903, loss1 : 2.746171, loss2 : 3.877369
train_step : 21904, loss1 : 2.202940, loss2 : 3.196079
train_step : 21905, loss1 : 1.895731, loss2 : 2.228065
train_step : 21906, loss1 : 1.226906, loss2 : 0.702006
train_step : 21907, loss1 : 1.042899, loss2 : 1.057056
train_step : 21908, loss1 : 0.934280, loss2 : 1.205744
train_step : 21909, loss1 : 1.649644, loss2 : 1.119142
train_step : 21910, loss1 : 0.893147, loss2 : 1.611082
train_step : 21911, loss1 : 1.375239, loss2 : 1.006352
train_step : 21912, loss1 : 1.039144, loss2 : 1.019300
train_step : 21913, loss1 : 1.416867, loss2 : 1.139046
train_step : 21914, loss1 : 1.387775, loss2 : 0.883097
train_step : 21915, loss1 : 1.539540, loss2 : 1.162773
train_step : 21916, loss1 : 1.422624, loss2 : 1.783796
train_step : 21917, loss1 : 1.441263, loss2 : 0.956420
train_step : 21918, loss1 : 1.154363, loss2 : 1.256175
train_step : 21919, loss1 : 1.723790, loss2 : 1.909182
train_step : 21920, loss1 : 1.032094, loss2 : 0.876849
train_step : 21921, loss1 : 1.639887, loss2 : 1.437940
train_step : 21922, loss1 : 0.913278, loss2 : 0.911335
train_step : 21923, loss1 : 0.978562, loss2 : 1.640514
train_step : 21924, loss1 : 0.862836, loss2 : 0.904204
train_step : 21925, loss1 : 0.901684, loss2 : 1.018430
train_step : 21926, loss1 : 1.475187, loss2 : 0.800264
train_step : 21927, loss1 : 0.926193, loss2 : 0.922658
train_step : 21928, loss1 : 1.453374, loss2 : 1.809950
train_step : 21929, loss1 : 1.163771, loss2 : 1.830673
train_step : 21930, loss1 : 1.729897, loss2 : 1.747470
train_step : 21931, loss1 : 1.122025, loss2 : 2.002350
train_step : 21932, loss1 : 1.091496, loss2 : 1.328911
train_step : 21933, loss1 : 1.362999, loss2 : 1.131815
train_step : 21934, loss1 : 2.991318, loss2 : 1.376520
train_step : 21935, loss1 : 1.906972, loss2 : 1.617301
train_step : 21936, loss1 : 0.753788, loss2 : 1.369558
train_step : 21937, loss1 : 1.095484, loss2 : 0.753986
train_step : 21938, loss1 : 1.378298, loss2 : 0.892460
train_step : 21939, loss1 : 1.448756, loss2 : 1.193323
train_step : 21940, loss1 : 1.813402, loss2 : 1.223860
train_step : 21941, loss1 : 1.050331, loss2 : 0.925841
train_step : 21942, loss1 : 1.157250, loss2 : 1.408606
train_step : 21943, loss1 : 1.483803, loss2 : 1.004466
train_step : 21944, loss1 : 1.205807, loss2 : 0.960333
train_step : 21945, loss1 : 1.451611, loss2 : 2.134369
train_step : 21946, loss1 : 1.115054, loss2 : 3.363793
train_step : 21947, loss1 : 1.347935, loss2 : 1.014310
train_step : 21948, loss1 : 1.138486, loss2 : 2.388303
train_step : 21949, loss1 : 1.197470, loss2 : 0.829103
train_step : 21950, loss1 : 0.947623, loss2 : 1.052797
train_step : 21951, loss1 : 1.585761, loss2 : 1.229355
train_step : 21952, loss1 : 1.038210, loss2 : 0.698212
train_step : 21953, loss1 : 1.559732, loss2 : 0.768162
train_step : 21954, loss1 : 0.763141, loss2 : 1.773718
train_step : 21955, loss1 : 2.032425, loss2 : 0.766179
train_step : 21956, loss1 : 1.388433, loss2 : 1.561039
train_step : 21957, loss1 : 1.631333, loss2 : 1.637457
train_step : 21958, loss1 : 1.717609, loss2 : 1.747386
train_step : 21959, loss1 : 0.645196, loss2 : 1.271536
train_step : 21960, loss1 : 1.226912, loss2 : 0.876312
train_step : 21961, loss1 : 1.278468, loss2 : 1.272148
train_step : 21962, loss1 : 1.023089, loss2 : 1.076282
train_step : 21963, loss1 : 1.013207, loss2 : 2.110027
train_step : 21964, loss1 : 0.771931, loss2 : 1.561691
train_step : 21965, loss1 : 1.314295, loss2 : 1.209061
train_step : 21966, loss1 : 0.667840, loss2 : 1.170380
train_step : 21967, loss1 : 1.234764, loss2 : 0.793605
train_step : 21968, loss1 : 0.950341, loss2 : 2.171446
train_step : 21969, loss1 : 2.069100, loss2 : 1.579189
train_step : 21970, loss1 : 1.211681, loss2 : 0.848327
train_step : 21971, loss1 : 0.593236, loss2 : 2.488448
train_step : 21972, loss1 : 1.995018, loss2 : 1.323802
train_step : 21973, loss1 : 2.855696, loss2 : 2.345664
train_step : 21974, loss1 : 2.510699, loss2 : 2.060827
train_step : 21975, loss1 : 2.432815, loss2 : 1.177302
train_step : 21976, loss1 : 2.004818, loss2 : 1.965072
train_step : 21977, loss1 : 1.262357, loss2 : 0.798666
train_step : 21978, loss1 : 0.622541, loss2 : 1.251501
train_step : 21979, loss1 : 2.134834, loss2 : 0.996423
train_step : 21980, loss1 : 1.325357, loss2 : 0.612208
train_step : 21981, loss1 : 1.120852, loss2 : 1.205825
train_step : 21982, loss1 : 1.319930, loss2 : 1.174745
train_step : 21983, loss1 : 1.099904, loss2 : 1.441937
train_step : 21984, loss1 : 1.773573, loss2 : 0.775178
train_step : 21985, loss1 : 1.304696, loss2 : 1.798801
train_step : 21986, loss1 : 1.016490, loss2 : 2.014650
train_step : 21987, loss1 : 2.047220, loss2 : 1.194526
train_step : 21988, loss1 : 1.449067, loss2 : 0.758654
train_step : 21989, loss1 : 1.406456, loss2 : 1.613501
train_step : 21990, loss1 : 0.890008, loss2 : 2.010811
train_step : 21991, loss1 : 1.189110, loss2 : 1.080820
train_step : 21992, loss1 : 1.823446, loss2 : 0.804826
train_step : 21993, loss1 : 0.691937, loss2 : 1.258039
train_step : 21994, loss1 : 1.506224, loss2 : 2.401963
train_step : 21995, loss1 : 2.715578, loss2 : 1.120583
train_step : 21996, loss1 : 1.473803, loss2 : 1.204398
train_step : 21997, loss1 : 0.797083, loss2 : 0.611226
train_step : 21998, loss1 : 1.471431, loss2 : 1.183098
train_step : 21999, loss1 : 0.836195, loss2 : 1.523013
train_step : 22000, loss1 : 1.417544, loss2 : 0.969686
train_step : 22001, loss1 : 1.038447, loss2 : 0.884417
train_step : 22002, loss1 : 0.707510, loss2 : 2.379466
train_step : 22003, loss1 : 1.986427, loss2 : 2.032680
train_step : 22004, loss1 : 1.626375, loss2 : 1.598184
train_step : 22005, loss1 : 2.038626, loss2 : 1.071685
train_step : 22006, loss1 : 1.527149, loss2 : 2.169483
train_step : 22007, loss1 : 2.480555, loss2 : 1.642337
train_step : 22008, loss1 : 1.495531, loss2 : 2.170328
train_step : 22009, loss1 : 1.591357, loss2 : 2.609205
train_step : 22010, loss1 : 3.478913, loss2 : 2.423263
train_step : 22011, loss1 : 2.156661, loss2 : 2.417366
train_step : 22012, loss1 : 2.707678, loss2 : 2.230392
train_step : 22013, loss1 : 2.512157, loss2 : 2.151344
train_step : 22014, loss1 : 1.616038, loss2 : 2.094679
train_step : 22015, loss1 : 2.394568, loss2 : 1.388856
train_step : 22016, loss1 : 2.650906, loss2 : 2.368281
train_step : 22017, loss1 : 2.264144, loss2 : 2.502850
train_step : 22018, loss1 : 2.441017, loss2 : 2.765677
train_step : 22019, loss1 : 1.268083, loss2 : 0.986738
train_step : 22020, loss1 : 1.127869, loss2 : 0.874432
train_step : 22021, loss1 : 0.745503, loss2 : 1.221368
train_step : 22022, loss1 : 1.208986, loss2 : 1.538559
train_step : 22023, loss1 : 1.663607, loss2 : 1.200405
train_step : 22024, loss1 : 1.093276, loss2 : 1.035053
train_step : 22025, loss1 : 1.191153, loss2 : 1.147707
train_step : 22026, loss1 : 1.720141, loss2 : 1.048152
train_step : 22027, loss1 : 1.317321, loss2 : 1.084956
train_step : 22028, loss1 : 1.444267, loss2 : 0.957238
train_step : 22029, loss1 : 0.975329, loss2 : 0.966739
train_step : 22030, loss1 : 0.775917, loss2 : 0.893947
train_step : 22031, loss1 : 1.316157, loss2 : 1.487320
train_step : 22032, loss1 : 0.652068, loss2 : 1.360074
train_step : 22033, loss1 : 0.750107, loss2 : 2.115859
train_step : 22034, loss1 : 0.664294, loss2 : 1.140790
train_step : 22035, loss1 : 1.083956, loss2 : 1.821763
train_step : 22036, loss1 : 3.118565, loss2 : 2.357440
train_step : 22037, loss1 : 1.631390, loss2 : 1.539616
train_step : 22038, loss1 : 2.857955, loss2 : 2.148302
train_step : 22039, loss1 : 2.373563, loss2 : 2.398752
train_step : 22040, loss1 : 1.293398, loss2 : 1.208986
train_step : 22041, loss1 : 0.889360, loss2 : 0.216998
train_step : 22042, loss1 : 2.774888, loss2 : 0.968629
train_step : 22043, loss1 : 0.659676, loss2 : 0.964506
train_step : 22044, loss1 : 1.605570, loss2 : 1.083469
train_step : 22045, loss1 : 1.106307, loss2 : 0.901468
train_step : 22046, loss1 : 1.249134, loss2 : 1.493543
train_step : 22047, loss1 : 0.783950, loss2 : 2.266026
train_step : 22048, loss1 : 1.458062, loss2 : 1.492143
train_step : 22049, loss1 : 1.686487, loss2 : 1.227443
train_step : 22050, loss1 : 1.422210, loss2 : 0.813105
train_step : 22051, loss1 : 1.235798, loss2 : 1.150347
train_step : 22052, loss1 : 0.709640, loss2 : 1.445202
train_step : 22053, loss1 : 0.707890, loss2 : 3.732830
train_step : 22054, loss1 : 1.034614, loss2 : 1.706256
train_step : 22055, loss1 : 0.755649, loss2 : 1.618043
train_step : 22056, loss1 : 1.816537, loss2 : 1.481358
train_step : 22057, loss1 : 1.461042, loss2 : 1.037411
train_step : 22058, loss1 : 2.452881, loss2 : 0.895672
train_step : 22059, loss1 : 2.229921, loss2 : 1.897424
train_step : 22060, loss1 : 1.702428, loss2 : 2.010503
train_step : 22061, loss1 : 1.062731, loss2 : 1.470480
train_step : 22062, loss1 : 1.430109, loss2 : 1.732935
train_step : 22063, loss1 : 1.252262, loss2 : 1.552989
train_step : 22064, loss1 : 1.544837, loss2 : 2.302323
train_step : 22065, loss1 : 2.064595, loss2 : 1.508970
train_step : 22066, loss1 : 1.109664, loss2 : 1.117274
train_step : 22067, loss1 : 1.189914, loss2 : 1.530911
train_step : 22068, loss1 : 1.253043, loss2 : 1.832204
train_step : 22069, loss1 : 1.140702, loss2 : 1.389879
train_step : 22070, loss1 : 0.804675, loss2 : 1.457326
train_step : 22071, loss1 : 1.408783, loss2 : 1.398773
train_step : 22072, loss1 : 1.149821, loss2 : 0.544170
train_step : 22073, loss1 : 1.205215, loss2 : 0.885927
train_step : 22074, loss1 : 1.100702, loss2 : 0.964507
train_step : 22075, loss1 : 0.880912, loss2 : 1.002323
train_step : 22076, loss1 : 1.949401, loss2 : 0.768729
train_step : 22077, loss1 : 1.235978, loss2 : 1.567647
train_step : 22078, loss1 : 2.441098, loss2 : 1.398592
train_step : 22079, loss1 : 3.354728, loss2 : 2.737023
train_step : 22080, loss1 : 3.209715, loss2 : 3.196742
train_step : 22081, loss1 : 2.201090, loss2 : 2.421002
train_step : 22082, loss1 : 3.376671, loss2 : 2.656763
train_step : 22083, loss1 : 1.633223, loss2 : 4.704475
train_step : 22084, loss1 : 2.943427, loss2 : 2.572301
train_step : 22085, loss1 : 1.135331, loss2 : 2.628105
train_step : 22086, loss1 : 1.321266, loss2 : 2.459462
train_step : 22087, loss1 : 1.728315, loss2 : 1.842312
train_step : 22088, loss1 : 1.062210, loss2 : 2.427544
train_step : 22089, loss1 : 1.775937, loss2 : 1.022536
train_step : 22090, loss1 : 2.048950, loss2 : 1.736504
train_step : 22091, loss1 : 1.514781, loss2 : 1.288145
train_step : 22092, loss1 : 1.593747, loss2 : 1.848478
train_step : 22093, loss1 : 1.308905, loss2 : 1.568137
train_step : 22094, loss1 : 2.097557, loss2 : 1.423244
train_step : 22095, loss1 : 1.013157, loss2 : 4.180120
train_step : 22096, loss1 : 1.902856, loss2 : 1.506401
train_step : 22097, loss1 : 0.978588, loss2 : 2.824677
train_step : 22098, loss1 : 1.222095, loss2 : 1.680817
train_step : 22099, loss1 : 1.501065, loss2 : 1.149980
train_step : 22100, loss1 : 1.164469, loss2 : 1.486503
train_step : 22101, loss1 : 1.093066, loss2 : 1.001537
train_step : 22102, loss1 : 1.337327, loss2 : 1.090935
train_step : 22103, loss1 : 0.503396, loss2 : 1.677261
train_step : 22104, loss1 : 1.930661, loss2 : 2.193640
train_step : 22105, loss1 : 1.860140, loss2 : 1.948989
train_step : 22106, loss1 : 1.508806, loss2 : 2.940035
train_step : 22107, loss1 : 1.289809, loss2 : 1.800066
train_step : 22108, loss1 : 0.617247, loss2 : 1.210441
train_step : 22109, loss1 : 1.308675, loss2 : 1.946649
train_step : 22110, loss1 : 1.383395, loss2 : 0.886364
train_step : 22111, loss1 : 0.993329, loss2 : 1.086389
train_step : 22112, loss1 : 1.219144, loss2 : 1.344794
train_step : 22113, loss1 : 1.608174, loss2 : 1.924704
train_step : 22114, loss1 : 1.227124, loss2 : 0.745580
train_step : 22115, loss1 : 1.076795, loss2 : 1.172994
train_step : 22116, loss1 : 1.017808, loss2 : 0.780963
train_step : 22117, loss1 : 2.079245, loss2 : 0.736312
train_step : 22118, loss1 : 1.640271, loss2 : 1.107221
train_step : 22119, loss1 : 0.890783, loss2 : 1.202343
train_step : 22120, loss1 : 1.501886, loss2 : 1.302572
train_step : 22121, loss1 : 2.043940, loss2 : 2.101456
train_step : 22122, loss1 : 2.371760, loss2 : 4.424083
train_step : 22123, loss1 : 2.722692, loss2 : 3.793047
train_step : 22124, loss1 : 3.182851, loss2 : 2.893081
train_step : 22125, loss1 : 2.511916, loss2 : 1.765554
train_step : 22126, loss1 : 1.643561, loss2 : 1.456400
train_step : 22127, loss1 : 1.843538, loss2 : 1.406686
train_step : 22128, loss1 : 1.338662, loss2 : 1.480404
train_step : 22129, loss1 : 0.431703, loss2 : 0.976312
train_step : 22130, loss1 : 0.716445, loss2 : 0.889673
train_step : 22131, loss1 : 1.247313, loss2 : 1.153663
train_step : 22132, loss1 : 1.468629, loss2 : 1.781181
train_step : 22133, loss1 : 3.181365, loss2 : 1.573566
train_step : 22134, loss1 : 1.172588, loss2 : 0.878735
train_step : 22135, loss1 : 1.251014, loss2 : 0.923062
train_step : 22136, loss1 : 1.983391, loss2 : 1.426512
train_step : 22137, loss1 : 1.539197, loss2 : 1.851751
train_step : 22138, loss1 : 1.006933, loss2 : 1.914071
train_step : 22139, loss1 : 2.115921, loss2 : 0.823709
train_step : 22140, loss1 : 1.454226, loss2 : 1.558331
train_step : 22141, loss1 : 0.764708, loss2 : 1.379630
train_step : 22142, loss1 : 1.857229, loss2 : 1.582044
train_step : 22143, loss1 : 0.779078, loss2 : 1.014294
train_step : 22144, loss1 : 1.095754, loss2 : 1.926237
train_step : 22145, loss1 : 1.029068, loss2 : 1.785098
train_step : 22146, loss1 : 0.696503, loss2 : 1.792765
train_step : 22147, loss1 : 0.924016, loss2 : 1.025681
train_step : 22148, loss1 : 1.005545, loss2 : 1.136151
train_step : 22149, loss1 : 0.679403, loss2 : 0.650642
train_step : 22150, loss1 : 1.401664, loss2 : 0.700509
train_step : 22151, loss1 : 1.050387, loss2 : 0.697465
train_step : 22152, loss1 : 0.886187, loss2 : 1.102586
train_step : 22153, loss1 : 0.766761, loss2 : 0.932742
train_step : 22154, loss1 : 1.277755, loss2 : 1.214077
train_step : 22155, loss1 : 1.266734, loss2 : 0.996584
train_step : 22156, loss1 : 1.770128, loss2 : 1.667748
train_step : 22157, loss1 : 1.968244, loss2 : 2.391721
train_step : 22158, loss1 : 1.527763, loss2 : 2.297236
train_step : 22159, loss1 : 1.656047, loss2 : 1.197865
train_step : 22160, loss1 : 1.235874, loss2 : 1.742959
train_step : 22161, loss1 : 0.772207, loss2 : 2.051958
train_step : 22162, loss1 : 1.589318, loss2 : 1.706864
train_step : 22163, loss1 : 2.198784, loss2 : 2.257219
train_step : 22164, loss1 : 2.080549, loss2 : 1.851731
train_step : 22165, loss1 : 2.437504, loss2 : 1.525939
train_step : 22166, loss1 : 1.467931, loss2 : 2.025969
train_step : 22167, loss1 : 0.684122, loss2 : 1.427409
train_step : 22168, loss1 : 1.057608, loss2 : 1.320493
train_step : 22169, loss1 : 1.818744, loss2 : 1.810014
train_step : 22170, loss1 : 1.959389, loss2 : 2.860547
train_step : 22171, loss1 : 1.566755, loss2 : 2.724971
train_step : 22172, loss1 : 2.120656, loss2 : 1.832738
train_step : 22173, loss1 : 1.834543, loss2 : 1.467131
train_step : 22174, loss1 : 1.542069, loss2 : 1.741841
train_step : 22175, loss1 : 1.780484, loss2 : 0.827016
train_step : 22176, loss1 : 0.990561, loss2 : 0.857427
train_step : 22177, loss1 : 1.146807, loss2 : 1.774265
train_step : 22178, loss1 : 1.943438, loss2 : 1.592884
train_step : 22179, loss1 : 1.111654, loss2 : 1.248055
train_step : 22180, loss1 : 1.239073, loss2 : 1.173083
train_step : 22181, loss1 : 1.088333, loss2 : 2.155704
train_step : 22182, loss1 : 2.236712, loss2 : 3.925918
train_step : 22183, loss1 : 1.723774, loss2 : 2.796345
train_step : 22184, loss1 : 2.161757, loss2 : 2.223593
train_step : 22185, loss1 : 1.091931, loss2 : 1.054792
train_step : 22186, loss1 : 0.838099, loss2 : 1.045413
train_step : 22187, loss1 : 0.646782, loss2 : 0.655196
train_step : 22188, loss1 : 0.720754, loss2 : 1.059859
train_step : 22189, loss1 : 0.752676, loss2 : 1.646677
train_step : 22190, loss1 : 1.209303, loss2 : 0.537362
train_step : 22191, loss1 : 2.208758, loss2 : 1.214846
train_step : 22192, loss1 : 0.986061, loss2 : 1.193276
train_step : 22193, loss1 : 0.583690, loss2 : 1.191834
train_step : 22194, loss1 : 1.341580, loss2 : 0.930784
train_step : 22195, loss1 : 1.218277, loss2 : 1.679008
train_step : 22196, loss1 : 1.267864, loss2 : 1.197533
train_step : 22197, loss1 : 2.373227, loss2 : 0.906425
train_step : 22198, loss1 : 0.977601, loss2 : 1.422283
train_step : 22199, loss1 : 1.326637, loss2 : 0.898812
train_step : 22200, loss1 : 0.923674, loss2 : 0.872753
train_step : 22201, loss1 : 2.192830, loss2 : 0.991286
train_step : 22202, loss1 : 1.327498, loss2 : 1.052165
train_step : 22203, loss1 : 1.204449, loss2 : 1.693248
train_step : 22204, loss1 : 1.246225, loss2 : 1.424410
train_step : 22205, loss1 : 1.128221, loss2 : 0.866276
train_step : 22206, loss1 : 1.093179, loss2 : 1.071557
train_step : 22207, loss1 : 0.669997, loss2 : 0.918245
train_step : 22208, loss1 : 0.752762, loss2 : 0.662423
train_step : 22209, loss1 : 0.563565, loss2 : 1.245193
train_step : 22210, loss1 : 1.447438, loss2 : 1.314972
train_step : 22211, loss1 : 2.746804, loss2 : 3.103782
train_step : 22212, loss1 : 3.863455, loss2 : 1.329975
train_step : 22213, loss1 : 3.173723, loss2 : 1.832637
train_step : 22214, loss1 : 1.720996, loss2 : 1.949972
train_step : 22215, loss1 : 1.178619, loss2 : 1.702158
train_step : 22216, loss1 : 1.380699, loss2 : 1.338583
train_step : 22217, loss1 : 1.230843, loss2 : 1.569654
train_step : 22218, loss1 : 1.390484, loss2 : 0.997565
train_step : 22219, loss1 : 1.705487, loss2 : 1.269034
train_step : 22220, loss1 : 1.699119, loss2 : 1.914651
train_step : 22221, loss1 : 1.471028, loss2 : 2.209926
train_step : 22222, loss1 : 2.526819, loss2 : 1.785794
train_step : 22223, loss1 : 1.684301, loss2 : 0.959898
train_step : 22224, loss1 : 1.975280, loss2 : 0.726457
train_step : 22225, loss1 : 0.790490, loss2 : 1.385269
train_step : 22226, loss1 : 1.164061, loss2 : 1.275816
train_step : 22227, loss1 : 1.611948, loss2 : 1.038120
train_step : 22228, loss1 : 1.063085, loss2 : 0.688431
train_step : 22229, loss1 : 1.488273, loss2 : 1.322021
train_step : 22230, loss1 : 1.957308, loss2 : 1.425937
train_step : 22231, loss1 : 1.082453, loss2 : 1.396056
train_step : 22232, loss1 : 0.956345, loss2 : 1.153227
train_step : 22233, loss1 : 1.278840, loss2 : 1.515854
train_step : 22234, loss1 : 0.979075, loss2 : 1.142712
train_step : 22235, loss1 : 1.547003, loss2 : 1.772635
train_step : 22236, loss1 : 1.436895, loss2 : 0.944054
train_step : 22237, loss1 : 1.436077, loss2 : 1.202603
train_step : 22238, loss1 : 2.413701, loss2 : 2.622939
train_step : 22239, loss1 : 2.180259, loss2 : 2.459811
train_step : 22240, loss1 : 2.171771, loss2 : 2.879307
train_step : 22241, loss1 : 1.624629, loss2 : 3.534401
train_step : 22242, loss1 : 1.232742, loss2 : 1.423532
train_step : 22243, loss1 : 1.507363, loss2 : 0.977766
train_step : 22244, loss1 : 1.639600, loss2 : 0.996225
train_step : 22245, loss1 : 1.302701, loss2 : 0.944777
train_step : 22246, loss1 : 0.947826, loss2 : 1.832768
train_step : 22247, loss1 : 1.027640, loss2 : 1.509532
train_step : 22248, loss1 : 0.916895, loss2 : 1.515894
train_step : 22249, loss1 : 0.968747, loss2 : 1.440549
train_step : 22250, loss1 : 1.431861, loss2 : 1.700212
train_step : 22251, loss1 : 1.131196, loss2 : 0.811638
train_step : 22252, loss1 : 1.057512, loss2 : 0.983330
train_step : 22253, loss1 : 0.930389, loss2 : 0.820620
train_step : 22254, loss1 : 2.528140, loss2 : 1.162344
train_step : 22255, loss1 : 1.126394, loss2 : 1.293901
train_step : 22256, loss1 : 0.824016, loss2 : 1.162814
train_step : 22257, loss1 : 0.867874, loss2 : 2.437536
train_step : 22258, loss1 : 1.433623, loss2 : 0.937247
train_step : 22259, loss1 : 1.317829, loss2 : 1.169707
train_step : 22260, loss1 : 1.126628, loss2 : 1.892969
train_step : 22261, loss1 : 1.061732, loss2 : 1.085464
train_step : 22262, loss1 : 1.003995, loss2 : 1.057255
train_step : 22263, loss1 : 0.848717, loss2 : 1.174101
train_step : 22264, loss1 : 1.281217, loss2 : 0.456811
train_step : 22265, loss1 : 0.659246, loss2 : 1.046568
train_step : 22266, loss1 : 1.828455, loss2 : 1.673339
train_step : 22267, loss1 : 1.211477, loss2 : 1.249935
train_step : 22268, loss1 : 0.654357, loss2 : 1.354381
train_step : 22269, loss1 : 0.909894, loss2 : 1.199107
train_step : 22270, loss1 : 0.716168, loss2 : 0.865161
train_step : 22271, loss1 : 0.969653, loss2 : 1.007112
train_step : 22272, loss1 : 0.945197, loss2 : 0.979043
train_step : 22273, loss1 : 0.778136, loss2 : 1.372854
train_step : 22274, loss1 : 1.546804, loss2 : 1.029233
train_step : 22275, loss1 : 1.083164, loss2 : 0.791081
train_step : 22276, loss1 : 1.548014, loss2 : 0.409119
train_step : 22277, loss1 : 1.018234, loss2 : 1.470066
train_step : 22278, loss1 : 1.000553, loss2 : 0.446723
train_step : 22279, loss1 : 1.568703, loss2 : 0.711526
train_step : 22280, loss1 : 0.865312, loss2 : 1.620296
train_step : 22281, loss1 : 1.012166, loss2 : 0.987142
train_step : 22282, loss1 : 1.062335, loss2 : 1.386659
train_step : 22283, loss1 : 1.686289, loss2 : 0.551406
train_step : 22284, loss1 : 1.214880, loss2 : 1.004708
train_step : 22285, loss1 : 0.752412, loss2 : 0.511938
train_step : 22286, loss1 : 1.697304, loss2 : 1.036420
train_step : 22287, loss1 : 1.042430, loss2 : 1.239205
train_step : 22288, loss1 : 1.315129, loss2 : 1.349238
train_step : 22289, loss1 : 0.736648, loss2 : 0.817703
train_step : 22290, loss1 : 1.911090, loss2 : 1.259230
train_step : 22291, loss1 : 0.832592, loss2 : 1.575743
train_step : 22292, loss1 : 1.264034, loss2 : 1.187674
train_step : 22293, loss1 : 1.098814, loss2 : 1.097743
train_step : 22294, loss1 : 0.877282, loss2 : 0.708436
train_step : 22295, loss1 : 1.028634, loss2 : 1.232504
train_step : 22296, loss1 : 1.715380, loss2 : 1.204654
train_step : 22297, loss1 : 1.259099, loss2 : 1.055883
train_step : 22298, loss1 : 0.505915, loss2 : 0.726560
train_step : 22299, loss1 : 1.181226, loss2 : 1.318576
train_step : 22300, loss1 : 1.512514, loss2 : 0.782147
train_step : 22301, loss1 : 1.120332, loss2 : 0.994400
train_step : 22302, loss1 : 0.839705, loss2 : 1.561010
train_step : 22303, loss1 : 0.856644, loss2 : 0.718068
train_step : 22304, loss1 : 0.840718, loss2 : 0.946198
train_step : 22305, loss1 : 1.034887, loss2 : 0.642017
train_step : 22306, loss1 : 1.755810, loss2 : 0.785530
train_step : 22307, loss1 : 0.600682, loss2 : 1.594991
train_step : 22308, loss1 : 1.348177, loss2 : 0.954373
train_step : 22309, loss1 : 1.015000, loss2 : 1.229946
train_step : 22310, loss1 : 1.458258, loss2 : 0.902024
train_step : 22311, loss1 : 0.867443, loss2 : 0.634801
train_step : 22312, loss1 : 1.150838, loss2 : 1.250362
train_step : 22313, loss1 : 1.504491, loss2 : 1.366407
train_step : 22314, loss1 : 1.522958, loss2 : 1.168511
train_step : 22315, loss1 : 0.786674, loss2 : 1.243884
train_step : 22316, loss1 : 1.519485, loss2 : 1.528186
train_step : 22317, loss1 : 1.225765, loss2 : 1.342464
train_step : 22318, loss1 : 1.306391, loss2 : 0.994031
train_step : 22319, loss1 : 0.513350, loss2 : 0.865488
train_step : 22320, loss1 : 0.868168, loss2 : 1.505644
train_step : 22321, loss1 : 0.591223, loss2 : 0.518365
train_step : 22322, loss1 : 0.671106, loss2 : 0.709841
train_step : 22323, loss1 : 1.304293, loss2 : 1.263351
train_step : 22324, loss1 : 1.557425, loss2 : 2.374127
train_step : 22325, loss1 : 2.389497, loss2 : 1.891665
train_step : 22326, loss1 : 1.397503, loss2 : 1.243994
train_step : 22327, loss1 : 2.002813, loss2 : 1.284641
train_step : 22328, loss1 : 1.060162, loss2 : 0.689265
train_step : 22329, loss1 : 2.122340, loss2 : 0.760474
train_step : 22330, loss1 : 1.024832, loss2 : 1.060634
train_step : 22331, loss1 : 1.370385, loss2 : 1.054454
train_step : 22332, loss1 : 5.012049, loss2 : 1.146337
train_step : 22333, loss1 : 1.043236, loss2 : 0.628909
train_step : 22334, loss1 : 1.648996, loss2 : 1.526335
train_step : 22335, loss1 : 1.095046, loss2 : 1.016414
train_step : 22336, loss1 : 0.897617, loss2 : 0.878471
train_step : 22337, loss1 : 1.012464, loss2 : 1.130949
train_step : 22338, loss1 : 1.090870, loss2 : 1.567535
train_step : 22339, loss1 : 2.021867, loss2 : 1.027128
train_step : 22340, loss1 : 1.268983, loss2 : 2.662992
train_step : 22341, loss1 : 2.213743, loss2 : 2.819133
train_step : 22342, loss1 : 1.708742, loss2 : 1.557512
train_step : 22343, loss1 : 1.617404, loss2 : 2.123790
train_step : 22344, loss1 : 2.206995, loss2 : 3.127017
train_step : 22345, loss1 : 1.138637, loss2 : 2.485197
train_step : 22346, loss1 : 1.031405, loss2 : 0.701423
train_step : 22347, loss1 : 1.168926, loss2 : 0.887502
train_step : 22348, loss1 : 0.889504, loss2 : 1.161581
train_step : 22349, loss1 : 1.039782, loss2 : 1.207128
train_step : 22350, loss1 : 0.512392, loss2 : 0.782100
train_step : 22351, loss1 : 1.315715, loss2 : 1.320422
train_step : 22352, loss1 : 0.607067, loss2 : 1.526474
train_step : 22353, loss1 : 1.457891, loss2 : 1.342797
train_step : 22354, loss1 : 1.499318, loss2 : 1.725577
train_step : 22355, loss1 : 1.064669, loss2 : 1.119220
train_step : 22356, loss1 : 0.446212, loss2 : 1.183382
train_step : 22357, loss1 : 1.517803, loss2 : 1.354835
train_step : 22358, loss1 : 1.318262, loss2 : 1.014852
train_step : 22359, loss1 : 1.053540, loss2 : 0.947636
train_step : 22360, loss1 : 1.577239, loss2 : 1.347172
train_step : 22361, loss1 : 1.458883, loss2 : 1.368494
train_step : 22362, loss1 : 0.754800, loss2 : 1.091646
train_step : 22363, loss1 : 0.800528, loss2 : 0.787675
train_step : 22364, loss1 : 0.637447, loss2 : 0.504584
train_step : 22365, loss1 : 1.907038, loss2 : 1.257990
train_step : 22366, loss1 : 1.245741, loss2 : 1.252169
train_step : 22367, loss1 : 0.433524, loss2 : 0.773688
train_step : 22368, loss1 : 1.265933, loss2 : 1.475161
train_step : 22369, loss1 : 1.158287, loss2 : 1.668564
train_step : 22370, loss1 : 1.019541, loss2 : 1.288237
train_step : 22371, loss1 : 0.952157, loss2 : 1.099647
train_step : 22372, loss1 : 0.926473, loss2 : 1.274895
train_step : 22373, loss1 : 1.526613, loss2 : 1.328476
train_step : 22374, loss1 : 1.530671, loss2 : 1.894908
train_step : 22375, loss1 : 1.034773, loss2 : 1.423923
train_step : 22376, loss1 : 1.249919, loss2 : 1.594396
train_step : 22377, loss1 : 1.188496, loss2 : 1.814780
train_step : 22378, loss1 : 1.553660, loss2 : 0.920187
train_step : 22379, loss1 : 1.030715, loss2 : 1.091350
train_step : 22380, loss1 : 1.463089, loss2 : 1.290517
train_step : 22381, loss1 : 1.548299, loss2 : 1.254340
train_step : 22382, loss1 : 1.740005, loss2 : 1.647417
train_step : 22383, loss1 : 2.952494, loss2 : 1.610196
train_step : 22384, loss1 : 1.415731, loss2 : 1.596108
train_step : 22385, loss1 : 1.601675, loss2 : 2.244332
train_step : 22386, loss1 : 1.326598, loss2 : 2.791468
train_step : 22387, loss1 : 1.980868, loss2 : 2.288072
train_step : 22388, loss1 : 2.872878, loss2 : 2.889687
train_step : 22389, loss1 : 1.432416, loss2 : 1.029585
train_step : 22390, loss1 : 0.979943, loss2 : 1.324103
train_step : 22391, loss1 : 0.861151, loss2 : 1.259831
train_step : 22392, loss1 : 1.111516, loss2 : 1.261293
train_step : 22393, loss1 : 1.111247, loss2 : 1.942701
train_step : 22394, loss1 : 1.428210, loss2 : 1.013368
train_step : 22395, loss1 : 1.079394, loss2 : 1.160428
train_step : 22396, loss1 : 1.236392, loss2 : 1.058096
train_step : 22397, loss1 : 2.292396, loss2 : 1.298181
train_step : 22398, loss1 : 1.814066, loss2 : 2.018440
train_step : 22399, loss1 : 3.634826, loss2 : 1.292571
train_step : 22400, loss1 : 3.185970, loss2 : 2.680136
train_step : 22401, loss1 : 2.985961, loss2 : 2.607103
train_step : 22402, loss1 : 2.372547, loss2 : 2.527626
train_step : 22403, loss1 : 2.840224, loss2 : 2.921292
train_step : 22404, loss1 : 3.263591, loss2 : 4.160459
train_step : 22405, loss1 : 1.820949, loss2 : 2.899128
train_step : 22406, loss1 : 3.308548, loss2 : 2.594182
train_step : 22407, loss1 : 2.230107, loss2 : 1.420670
train_step : 22408, loss1 : 1.377268, loss2 : 1.801224
train_step : 22409, loss1 : 1.455537, loss2 : 1.291359
train_step : 22410, loss1 : 1.707277, loss2 : 1.725037
train_step : 22411, loss1 : 0.903955, loss2 : 1.579321
train_step : 22412, loss1 : 2.046178, loss2 : 2.070908
train_step : 22413, loss1 : 2.395391, loss2 : 2.308771
train_step : 22414, loss1 : 3.222901, loss2 : 2.963774
train_step : 22415, loss1 : 3.717613, loss2 : 3.025997
train_step : 22416, loss1 : 3.815847, loss2 : 4.250613
train_step : 22417, loss1 : 2.087731, loss2 : 1.534916
train_step : 22418, loss1 : 2.560651, loss2 : 1.353884
train_step : 22419, loss1 : 1.488279, loss2 : 1.641578
train_step : 22420, loss1 : 3.351813, loss2 : 1.297528
train_step : 22421, loss1 : 0.691703, loss2 : 1.324106
train_step : 22422, loss1 : 1.177006, loss2 : 0.869917
train_step : 22423, loss1 : 1.327077, loss2 : 0.596515
train_step : 22424, loss1 : 0.678731, loss2 : 1.304682
train_step : 22425, loss1 : 0.534721, loss2 : 0.623022
train_step : 22426, loss1 : 0.664385, loss2 : 0.897373
train_step : 22427, loss1 : 1.362608, loss2 : 0.399275
train_step : 22428, loss1 : 1.220042, loss2 : 1.032509
train_step : 22429, loss1 : 0.610944, loss2 : 1.301025
train_step : 22430, loss1 : 0.769617, loss2 : 1.129281
train_step : 22431, loss1 : 0.985168, loss2 : 0.871207
train_step : 22432, loss1 : 1.581000, loss2 : 1.157396
train_step : 22433, loss1 : 1.341062, loss2 : 1.667185
train_step : 22434, loss1 : 1.267591, loss2 : 1.187531
train_step : 22435, loss1 : 2.070734, loss2 : 2.602517
train_step : 22436, loss1 : 1.042832, loss2 : 1.739702
train_step : 22437, loss1 : 1.893585, loss2 : 1.570149
train_step : 22438, loss1 : 1.437531, loss2 : 2.245655
train_step : 22439, loss1 : 1.882215, loss2 : 0.826975
train_step : 22440, loss1 : 1.275662, loss2 : 1.084608
train_step : 22441, loss1 : 1.110162, loss2 : 0.699308
train_step : 22442, loss1 : 1.172476, loss2 : 0.709275
train_step : 22443, loss1 : 1.269707, loss2 : 1.445456
train_step : 22444, loss1 : 2.103490, loss2 : 1.608433
train_step : 22445, loss1 : 1.362127, loss2 : 1.338440
train_step : 22446, loss1 : 1.225107, loss2 : 1.201614
train_step : 22447, loss1 : 0.950714, loss2 : 0.774596
train_step : 22448, loss1 : 1.420285, loss2 : 0.363172
train_step : 22449, loss1 : 1.086630, loss2 : 0.921429
train_step : 22450, loss1 : 3.390011, loss2 : 3.187764
train_step : 22451, loss1 : 6.154640, loss2 : 5.308831
train_step : 22452, loss1 : 5.656371, loss2 : 3.188593
train_step : 22453, loss1 : 3.467705, loss2 : 5.868052
train_step : 22454, loss1 : 4.793106, loss2 : 1.818008
train_step : 22455, loss1 : 3.700914, loss2 : 4.077915
train_step : 22456, loss1 : 1.996986, loss2 : 3.425351
train_step : 22457, loss1 : 3.745278, loss2 : 2.634483
train_step : 22458, loss1 : 2.012326, loss2 : 2.629852
train_step : 22459, loss1 : 1.957161, loss2 : 2.370080
train_step : 22460, loss1 : 4.046832, loss2 : 1.731868
train_step : 22461, loss1 : 3.940670, loss2 : 3.868514
train_step : 22462, loss1 : 3.406075, loss2 : 2.703964
train_step : 22463, loss1 : 2.319445, loss2 : 3.097621
train_step : 22464, loss1 : 1.692586, loss2 : 1.192231
train_step : 22465, loss1 : 0.450390, loss2 : 1.150843
train_step : 22466, loss1 : 1.132824, loss2 : 1.030557
train_step : 22467, loss1 : 1.282358, loss2 : 1.009497
train_step : 22468, loss1 : 1.098697, loss2 : 1.027399
train_step : 22469, loss1 : 0.945463, loss2 : 0.882309
train_step : 22470, loss1 : 0.980370, loss2 : 0.578524
train_step : 22471, loss1 : 0.893766, loss2 : 1.209884
train_step : 22472, loss1 : 1.022709, loss2 : 0.847446
train_step : 22473, loss1 : 1.686146, loss2 : 1.840825
train_step : 22474, loss1 : 0.918340, loss2 : 1.585892
train_step : 22475, loss1 : 0.971204, loss2 : 2.040403
train_step : 22476, loss1 : 1.112617, loss2 : 1.936828
train_step : 22477, loss1 : 1.679215, loss2 : 1.031624
train_step : 22478, loss1 : 1.111584, loss2 : 0.916128
train_step : 22479, loss1 : 0.839433, loss2 : 0.751970
train_step : 22480, loss1 : 0.708435, loss2 : 1.150897
train_step : 22481, loss1 : 0.993172, loss2 : 1.506406
train_step : 22482, loss1 : 0.849323, loss2 : 0.682756
train_step : 22483, loss1 : 0.778829, loss2 : 0.713690
train_step : 22484, loss1 : 1.031137, loss2 : 1.751055
train_step : 22485, loss1 : 0.677817, loss2 : 0.646789
train_step : 22486, loss1 : 0.884258, loss2 : 1.263010
train_step : 22487, loss1 : 1.078054, loss2 : 0.842430
train_step : 22488, loss1 : 0.747965, loss2 : 1.103145
train_step : 22489, loss1 : 1.650528, loss2 : 0.888291
train_step : 22490, loss1 : 1.534025, loss2 : 1.164828
train_step : 22491, loss1 : 1.149999, loss2 : 1.141493
train_step : 22492, loss1 : 0.667912, loss2 : 0.724685
train_step : 22493, loss1 : 0.914645, loss2 : 1.194536
train_step : 22494, loss1 : 0.930829, loss2 : 1.280496
train_step : 22495, loss1 : 0.494629, loss2 : 1.745357
train_step : 22496, loss1 : 1.499840, loss2 : 1.818602
train_step : 22497, loss1 : 1.750239, loss2 : 1.194214
train_step : 22498, loss1 : 1.427889, loss2 : 1.145761
train_step : 22499, loss1 : 1.133809, loss2 : 1.376788
train_step : 22500, loss1 : 1.170407, loss2 : 1.362036
train_step : 22501, loss1 : 0.972833, loss2 : 0.956006
train_step : 22502, loss1 : 0.910312, loss2 : 1.017029
train_step : 22503, loss1 : 1.130250, loss2 : 0.912278
train_step : 22504, loss1 : 0.785541, loss2 : 1.724281
train_step : 22505, loss1 : 0.726913, loss2 : 1.339777
train_step : 22506, loss1 : 0.917489, loss2 : 2.146997
train_step : 22507, loss1 : 2.540874, loss2 : 1.329987
train_step : 22508, loss1 : 2.244936, loss2 : 1.284454
train_step : 22509, loss1 : 1.781843, loss2 : 2.058101
train_step : 22510, loss1 : 1.107177, loss2 : 2.701100
train_step : 22511, loss1 : 1.035498, loss2 : 1.276245
train_step : 22512, loss1 : 1.598451, loss2 : 1.315034
train_step : 22513, loss1 : 1.103106, loss2 : 1.389186
train_step : 22514, loss1 : 1.309817, loss2 : 0.916767
train_step : 22515, loss1 : 1.362123, loss2 : 0.714452
train_step : 22516, loss1 : 1.022200, loss2 : 1.066360
train_step : 22517, loss1 : 2.327662, loss2 : 1.274161
train_step : 22518, loss1 : 1.589989, loss2 : 5.792210
train_step : 22519, loss1 : 2.756522, loss2 : 2.540132
train_step : 22520, loss1 : 2.238530, loss2 : 2.592753
train_step : 22521, loss1 : 3.647980, loss2 : 2.970489
train_step : 22522, loss1 : 1.943261, loss2 : 1.909802
train_step : 22523, loss1 : 1.257608, loss2 : 1.478543
train_step : 22524, loss1 : 0.924019, loss2 : 1.626804
train_step : 22525, loss1 : 1.710354, loss2 : 1.086881
train_step : 22526, loss1 : 1.629508, loss2 : 0.752486
train_step : 22527, loss1 : 1.541943, loss2 : 1.586828
train_step : 22528, loss1 : 2.205467, loss2 : 1.811780
train_step : 22529, loss1 : 1.474003, loss2 : 1.631197
train_step : 22530, loss1 : 1.042883, loss2 : 0.620906
train_step : 22531, loss1 : 0.954751, loss2 : 1.456685
train_step : 22532, loss1 : 0.887549, loss2 : 2.463952
train_step : 22533, loss1 : 0.975970, loss2 : 1.919442
train_step : 22534, loss1 : 0.634092, loss2 : 0.966836
train_step : 22535, loss1 : 1.007063, loss2 : 0.769679
train_step : 22536, loss1 : 1.673258, loss2 : 0.906262
train_step : 22537, loss1 : 1.357736, loss2 : 1.494627
train_step : 22538, loss1 : 1.667095, loss2 : 0.969408
train_step : 22539, loss1 : 2.068835, loss2 : 1.111653
train_step : 22540, loss1 : 2.186567, loss2 : 0.691066
train_step : 22541, loss1 : 1.069226, loss2 : 0.931121
train_step : 22542, loss1 : 1.168503, loss2 : 0.937803
train_step : 22543, loss1 : 2.174703, loss2 : 0.632188
train_step : 22544, loss1 : 1.308244, loss2 : 1.146558
train_step : 22545, loss1 : 1.439854, loss2 : 1.031831
train_step : 22546, loss1 : 1.231532, loss2 : 1.235968
train_step : 22547, loss1 : 1.309173, loss2 : 0.889064
train_step : 22548, loss1 : 1.197521, loss2 : 1.246210
train_step : 22549, loss1 : 1.154992, loss2 : 1.036630
train_step : 22550, loss1 : 0.998565, loss2 : 1.387977
train_step : 22551, loss1 : 1.225790, loss2 : 1.071946
train_step : 22552, loss1 : 1.189024, loss2 : 0.515020
train_step : 22553, loss1 : 0.609849, loss2 : 1.132180
train_step : 22554, loss1 : 1.782059, loss2 : 1.473997
train_step : 22555, loss1 : 2.077737, loss2 : 0.813881
train_step : 22556, loss1 : 1.182966, loss2 : 1.496020
train_step : 22557, loss1 : 1.163916, loss2 : 2.962790
train_step : 22558, loss1 : 2.308067, loss2 : 2.188789
train_step : 22559, loss1 : 2.463107, loss2 : 0.774178
train_step : 22560, loss1 : 1.193434, loss2 : 1.440043
train_step : 22561, loss1 : 1.102363, loss2 : 1.896343
train_step : 22562, loss1 : 0.862013, loss2 : 1.004628
train_step : 22563, loss1 : 0.929976, loss2 : 0.756711
train_step : 22564, loss1 : 0.600164, loss2 : 0.879592
train_step : 22565, loss1 : 0.484292, loss2 : 1.398120
train_step : 22566, loss1 : 1.487022, loss2 : 0.816355
train_step : 22567, loss1 : 0.692362, loss2 : 0.633898
train_step : 22568, loss1 : 0.822719, loss2 : 0.980088
train_step : 22569, loss1 : 0.872587, loss2 : 0.942155
train_step : 22570, loss1 : 1.091500, loss2 : 0.874565
train_step : 22571, loss1 : 0.533966, loss2 : 0.707179
train_step : 22572, loss1 : 0.773668, loss2 : 1.411527
train_step : 22573, loss1 : 0.930295, loss2 : 0.930768
train_step : 22574, loss1 : 1.208755, loss2 : 1.596097
train_step : 22575, loss1 : 0.657456, loss2 : 1.627914
train_step : 22576, loss1 : 0.968077, loss2 : 1.236227
train_step : 22577, loss1 : 1.337644, loss2 : 1.593441
train_step : 22578, loss1 : 1.052675, loss2 : 1.277874
train_step : 22579, loss1 : 0.988889, loss2 : 1.144235
train_step : 22580, loss1 : 1.017665, loss2 : 1.077340
train_step : 22581, loss1 : 0.982779, loss2 : 0.667680
train_step : 22582, loss1 : 0.888023, loss2 : 0.894029
train_step : 22583, loss1 : 1.324774, loss2 : 1.448508
train_step : 22584, loss1 : 1.521221, loss2 : 1.223824
train_step : 22585, loss1 : 1.590942, loss2 : 1.822341
train_step : 22586, loss1 : 2.071839, loss2 : 2.007594
train_step : 22587, loss1 : 2.052576, loss2 : 2.500408
train_step : 22588, loss1 : 1.640823, loss2 : 1.767819
train_step : 22589, loss1 : 2.053110, loss2 : 2.501629
train_step : 22590, loss1 : 1.390293, loss2 : 1.024188
train_step : 22591, loss1 : 1.463067, loss2 : 0.952774
train_step : 22592, loss1 : 0.778073, loss2 : 1.269730
train_step : 22593, loss1 : 1.267347, loss2 : 0.725834
train_step : 22594, loss1 : 0.474075, loss2 : 0.910086
train_step : 22595, loss1 : 1.734898, loss2 : 1.307015
train_step : 22596, loss1 : 1.003628, loss2 : 1.107056
train_step : 22597, loss1 : 0.944159, loss2 : 1.860398
train_step : 22598, loss1 : 1.339625, loss2 : 1.312935
train_step : 22599, loss1 : 0.909657, loss2 : 1.935364
train_step : 22600, loss1 : 1.158488, loss2 : 1.369127
train_step : 22601, loss1 : 1.358559, loss2 : 2.582397
train_step : 22602, loss1 : 1.632333, loss2 : 2.285191
train_step : 22603, loss1 : 1.221159, loss2 : 1.528545
train_step : 22604, loss1 : 0.806906, loss2 : 1.999688
train_step : 22605, loss1 : 1.431059, loss2 : 1.739216
train_step : 22606, loss1 : 2.902354, loss2 : 1.521164
train_step : 22607, loss1 : 1.063970, loss2 : 1.362750
train_step : 22608, loss1 : 1.456405, loss2 : 1.716003
train_step : 22609, loss1 : 1.055438, loss2 : 1.971203
train_step : 22610, loss1 : 1.617200, loss2 : 1.685513
train_step : 22611, loss1 : 2.232140, loss2 : 1.355435
train_step : 22612, loss1 : 2.378053, loss2 : 2.044763
train_step : 22613, loss1 : 1.544842, loss2 : 2.446569
train_step : 22614, loss1 : 1.187480, loss2 : 2.123597
train_step : 22615, loss1 : 2.707174, loss2 : 1.528111
train_step : 22616, loss1 : 1.337919, loss2 : 2.184909
train_step : 22617, loss1 : 0.848680, loss2 : 1.652582
train_step : 22618, loss1 : 0.955336, loss2 : 1.032475
train_step : 22619, loss1 : 1.233407, loss2 : 1.491050
train_step : 22620, loss1 : 1.135323, loss2 : 1.449395
train_step : 22621, loss1 : 1.919953, loss2 : 1.401774
train_step : 22622, loss1 : 1.943572, loss2 : 0.844402
train_step : 22623, loss1 : 1.419709, loss2 : 0.866344
train_step : 22624, loss1 : 0.873187, loss2 : 0.902533
train_step : 22625, loss1 : 1.694508, loss2 : 2.030517
train_step : 22626, loss1 : 2.128100, loss2 : 0.708086
train_step : 22627, loss1 : 1.628641, loss2 : 2.065483
train_step : 22628, loss1 : 1.951952, loss2 : 1.469736
train_step : 22629, loss1 : 1.778953, loss2 : 1.106333
train_step : 22630, loss1 : 1.392787, loss2 : 1.352062
train_step : 22631, loss1 : 1.116006, loss2 : 0.542665
train_step : 22632, loss1 : 1.435696, loss2 : 1.001875
train_step : 22633, loss1 : 1.878096, loss2 : 1.336567
train_step : 22634, loss1 : 1.341344, loss2 : 1.457157
train_step : 22635, loss1 : 1.327845, loss2 : 2.637803
train_step : 22636, loss1 : 0.837957, loss2 : 0.674102
train_step : 22637, loss1 : 1.313702, loss2 : 1.432703
train_step : 22638, loss1 : 1.190132, loss2 : 1.302865
train_step : 22639, loss1 : 1.521210, loss2 : 0.729157
train_step : 22640, loss1 : 1.238211, loss2 : 0.926600
train_step : 22641, loss1 : 0.927753, loss2 : 0.967450
train_step : 22642, loss1 : 1.115879, loss2 : 1.775242
train_step : 22643, loss1 : 1.381554, loss2 : 0.829415
train_step : 22644, loss1 : 1.221670, loss2 : 0.805553
train_step : 22645, loss1 : 1.793087, loss2 : 0.810877
train_step : 22646, loss1 : 1.014653, loss2 : 0.767131
train_step : 22647, loss1 : 1.098275, loss2 : 0.704058
train_step : 22648, loss1 : 1.600552, loss2 : 1.345606
train_step : 22649, loss1 : 1.771318, loss2 : 1.516674
train_step : 22650, loss1 : 0.821910, loss2 : 1.477782
train_step : 22651, loss1 : 1.294737, loss2 : 1.356124
train_step : 22652, loss1 : 1.799459, loss2 : 1.383037
train_step : 22653, loss1 : 0.766300, loss2 : 2.054495
train_step : 22654, loss1 : 1.257166, loss2 : 1.108209
train_step : 22655, loss1 : 1.452476, loss2 : 1.214350
train_step : 22656, loss1 : 1.927948, loss2 : 1.268909
train_step : 22657, loss1 : 0.895332, loss2 : 1.377315
train_step : 22658, loss1 : 0.910503, loss2 : 0.720895
train_step : 22659, loss1 : 0.622540, loss2 : 0.523345
train_step : 22660, loss1 : 0.507756, loss2 : 1.544429
train_step : 22661, loss1 : 1.139511, loss2 : 1.046217
train_step : 22662, loss1 : 0.644191, loss2 : 0.767013
train_step : 22663, loss1 : 1.995967, loss2 : 1.751694
train_step : 22664, loss1 : 1.616407, loss2 : 1.546914
train_step : 22665, loss1 : 1.058592, loss2 : 1.380051
train_step : 22666, loss1 : 1.372113, loss2 : 1.365001
train_step : 22667, loss1 : 1.676769, loss2 : 2.232479
train_step : 22668, loss1 : 2.173958, loss2 : 1.477646
train_step : 22669, loss1 : 1.480289, loss2 : 1.684372
train_step : 22670, loss1 : 2.021022, loss2 : 1.214237
train_step : 22671, loss1 : 2.541629, loss2 : 2.184987
train_step : 22672, loss1 : 1.713924, loss2 : 2.661224
train_step : 22673, loss1 : 3.540600, loss2 : 1.511217
train_step : 22674, loss1 : 1.138788, loss2 : 1.210222
train_step : 22675, loss1 : 1.289886, loss2 : 1.341935
train_step : 22676, loss1 : 1.279566, loss2 : 1.297023
train_step : 22677, loss1 : 1.966480, loss2 : 1.551827
train_step : 22678, loss1 : 2.134936, loss2 : 2.825908
train_step : 22679, loss1 : 2.135544, loss2 : 1.948681
train_step : 22680, loss1 : 1.326943, loss2 : 1.180023
train_step : 22681, loss1 : 1.836492, loss2 : 1.439437
train_step : 22682, loss1 : 1.229250, loss2 : 1.809131
train_step : 22683, loss1 : 1.004081, loss2 : 1.514179
train_step : 22684, loss1 : 1.529371, loss2 : 1.502498
train_step : 22685, loss1 : 1.782232, loss2 : 1.763416
train_step : 22686, loss1 : 1.508577, loss2 : 1.733136
train_step : 22687, loss1 : 2.708185, loss2 : 2.748505
train_step : 22688, loss1 : 4.879164, loss2 : 3.082287
train_step : 22689, loss1 : 2.395108, loss2 : 3.589672
train_step : 22690, loss1 : 2.000912, loss2 : 2.992110
train_step : 22691, loss1 : 1.547174, loss2 : 1.680005
train_step : 22692, loss1 : 1.747470, loss2 : 1.178301
train_step : 22693, loss1 : 2.592865, loss2 : 1.305519
train_step : 22694, loss1 : 3.123703, loss2 : 1.255456
train_step : 22695, loss1 : 1.670605, loss2 : 2.063993
train_step : 22696, loss1 : 1.422775, loss2 : 2.757027
train_step : 22697, loss1 : 1.218658, loss2 : 0.478962
train_step : 22698, loss1 : 1.075411, loss2 : 0.800909
train_step : 22699, loss1 : 1.026144, loss2 : 1.540422
train_step : 22700, loss1 : 1.002273, loss2 : 0.614087
train_step : 22701, loss1 : 1.156834, loss2 : 0.815404
train_step : 22702, loss1 : 0.812173, loss2 : 1.766213
train_step : 22703, loss1 : 0.736857, loss2 : 1.511678
train_step : 22704, loss1 : 1.623847, loss2 : 1.231728
train_step : 22705, loss1 : 1.793358, loss2 : 1.666176
train_step : 22706, loss1 : 1.216410, loss2 : 1.074255
train_step : 22707, loss1 : 0.843354, loss2 : 1.351111
train_step : 22708, loss1 : 0.878559, loss2 : 1.418425
train_step : 22709, loss1 : 1.387167, loss2 : 0.988640
train_step : 22710, loss1 : 1.588418, loss2 : 1.997545
train_step : 22711, loss1 : 0.671187, loss2 : 0.866258
train_step : 22712, loss1 : 1.113843, loss2 : 0.999025
train_step : 22713, loss1 : 1.422482, loss2 : 1.572894
train_step : 22714, loss1 : 1.320076, loss2 : 1.555992
train_step : 22715, loss1 : 1.209501, loss2 : 1.021429
train_step : 22716, loss1 : 1.359940, loss2 : 1.572732
train_step : 22717, loss1 : 1.557847, loss2 : 1.032690
train_step : 22718, loss1 : 1.801141, loss2 : 0.858531
train_step : 22719, loss1 : 0.972152, loss2 : 2.007422
train_step : 22720, loss1 : 1.314939, loss2 : 0.773479
train_step : 22721, loss1 : 1.030668, loss2 : 0.611334
train_step : 22722, loss1 : 0.945739, loss2 : 1.297315
train_step : 22723, loss1 : 1.217441, loss2 : 1.161915
train_step : 22724, loss1 : 0.608010, loss2 : 1.063725
train_step : 22725, loss1 : 1.131414, loss2 : 2.442983
train_step : 22726, loss1 : 1.105570, loss2 : 1.309293
train_step : 22727, loss1 : 1.603973, loss2 : 1.288535
train_step : 22728, loss1 : 2.447615, loss2 : 0.876288
train_step : 22729, loss1 : 0.839914, loss2 : 0.910359
train_step : 22730, loss1 : 1.453854, loss2 : 1.605960
train_step : 22731, loss1 : 2.598682, loss2 : 3.476694
train_step : 22732, loss1 : 2.486682, loss2 : 1.438615
train_step : 22733, loss1 : 1.593316, loss2 : 2.142113
train_step : 22734, loss1 : 2.705463, loss2 : 1.807071
train_step : 22735, loss1 : 1.135690, loss2 : 1.963629
train_step : 22736, loss1 : 0.843746, loss2 : 0.634541
train_step : 22737, loss1 : 1.171132, loss2 : 1.548189
train_step : 22738, loss1 : 1.259403, loss2 : 1.884917
train_step : 22739, loss1 : 1.083847, loss2 : 1.796134
train_step : 22740, loss1 : 1.315080, loss2 : 1.178818
train_step : 22741, loss1 : 1.739903, loss2 : 1.282282
train_step : 22742, loss1 : 1.195766, loss2 : 1.106654
train_step : 22743, loss1 : 1.090062, loss2 : 1.070463
train_step : 22744, loss1 : 1.012301, loss2 : 1.760651
train_step : 22745, loss1 : 0.441993, loss2 : 1.172356
train_step : 22746, loss1 : 0.636019, loss2 : 0.547610
train_step : 22747, loss1 : 0.664236, loss2 : 0.534001
train_step : 22748, loss1 : 0.735109, loss2 : 1.149441
train_step : 22749, loss1 : 1.106758, loss2 : 0.923627
train_step : 22750, loss1 : 1.202760, loss2 : 0.925820
train_step : 22751, loss1 : 1.141562, loss2 : 0.928620
train_step : 22752, loss1 : 3.116891, loss2 : 0.682095
train_step : 22753, loss1 : 0.785583, loss2 : 1.194830
train_step : 22754, loss1 : 2.057127, loss2 : 1.353256
train_step : 22755, loss1 : 1.408242, loss2 : 1.342631
train_step : 22756, loss1 : 2.500347, loss2 : 2.116758
train_step : 22757, loss1 : 1.084241, loss2 : 1.931618
train_step : 22758, loss1 : 1.276785, loss2 : 0.907822
train_step : 22759, loss1 : 1.127941, loss2 : 1.094876
train_step : 22760, loss1 : 1.049253, loss2 : 0.958837
train_step : 22761, loss1 : 1.206833, loss2 : 0.642884
train_step : 22762, loss1 : 1.757996, loss2 : 0.993519
train_step : 22763, loss1 : 1.179487, loss2 : 1.001399
train_step : 22764, loss1 : 1.268779, loss2 : 2.997250
train_step : 22765, loss1 : 0.911456, loss2 : 0.628516
train_step : 22766, loss1 : 1.340130, loss2 : 0.879189
train_step : 22767, loss1 : 1.164007, loss2 : 0.499590
train_step : 22768, loss1 : 1.505545, loss2 : 0.956043
train_step : 22769, loss1 : 0.867182, loss2 : 1.032317
train_step : 22770, loss1 : 0.883102, loss2 : 1.613779
train_step : 22771, loss1 : 1.879581, loss2 : 1.852658
train_step : 22772, loss1 : 3.101127, loss2 : 1.257979
train_step : 22773, loss1 : 1.295884, loss2 : 2.368104
train_step : 22774, loss1 : 0.850006, loss2 : 0.903715
train_step : 22775, loss1 : 0.689588, loss2 : 1.186484
train_step : 22776, loss1 : 1.954877, loss2 : 1.620803
train_step : 22777, loss1 : 1.899734, loss2 : 2.686428
train_step : 22778, loss1 : 1.980009, loss2 : 0.683892
train_step : 22779, loss1 : 2.018055, loss2 : 1.743512
train_step : 22780, loss1 : 0.911025, loss2 : 1.774842
train_step : 22781, loss1 : 1.015383, loss2 : 0.684471
train_step : 22782, loss1 : 1.546981, loss2 : 0.666252
train_step : 22783, loss1 : 1.550214, loss2 : 1.678418
train_step : 22784, loss1 : 1.407518, loss2 : 1.752373
train_step : 22785, loss1 : 1.154662, loss2 : 1.337904
train_step : 22786, loss1 : 1.504951, loss2 : 1.445538
train_step : 22787, loss1 : 1.518031, loss2 : 1.582962
train_step : 22788, loss1 : 0.910885, loss2 : 0.973761
train_step : 22789, loss1 : 1.067607, loss2 : 1.351285
train_step : 22790, loss1 : 1.008641, loss2 : 1.048752
train_step : 22791, loss1 : 1.391416, loss2 : 1.048256
train_step : 22792, loss1 : 1.451073, loss2 : 0.927865
train_step : 22793, loss1 : 1.088638, loss2 : 1.253361
train_step : 22794, loss1 : 0.725879, loss2 : 0.829559
train_step : 22795, loss1 : 1.701297, loss2 : 0.644705
train_step : 22796, loss1 : 1.130721, loss2 : 0.866883
train_step : 22797, loss1 : 1.819451, loss2 : 0.957989
train_step : 22798, loss1 : 0.993822, loss2 : 1.118982
train_step : 22799, loss1 : 1.796034, loss2 : 0.853901
train_step : 22800, loss1 : 1.038977, loss2 : 1.078838
train_step : 22801, loss1 : 2.056239, loss2 : 1.203476
train_step : 22802, loss1 : 0.814264, loss2 : 0.910201
train_step : 22803, loss1 : 1.328600, loss2 : 0.720504
train_step : 22804, loss1 : 1.282025, loss2 : 0.908602
train_step : 22805, loss1 : 0.786442, loss2 : 1.049051
train_step : 22806, loss1 : 0.927151, loss2 : 0.846723
train_step : 22807, loss1 : 0.632560, loss2 : 1.021817
train_step : 22808, loss1 : 1.354809, loss2 : 1.271232
train_step : 22809, loss1 : 1.356516, loss2 : 3.461575
train_step : 22810, loss1 : 3.874509, loss2 : 2.625941
train_step : 22811, loss1 : 3.783488, loss2 : 2.713912
train_step : 22812, loss1 : 4.582666, loss2 : 3.532728
train_step : 22813, loss1 : 5.730905, loss2 : 3.739565
train_step : 22814, loss1 : 3.402400, loss2 : 3.872540
train_step : 22815, loss1 : 3.828474, loss2 : 3.047150
train_step : 22816, loss1 : 2.709697, loss2 : 2.463138
train_step : 22817, loss1 : 4.084123, loss2 : 3.539545
train_step : 22818, loss1 : 2.934709, loss2 : 4.132096
train_step : 22819, loss1 : 3.713836, loss2 : 2.981661
train_step : 22820, loss1 : 2.456485, loss2 : 1.700014
train_step : 22821, loss1 : 1.461840, loss2 : 1.815284
train_step : 22822, loss1 : 1.608746, loss2 : 0.845003
train_step : 22823, loss1 : 1.329540, loss2 : 1.579849
train_step : 22824, loss1 : 1.144526, loss2 : 0.861244
train_step : 22825, loss1 : 0.732881, loss2 : 0.963938
train_step : 22826, loss1 : 1.915637, loss2 : 1.337660
train_step : 22827, loss1 : 1.462889, loss2 : 1.295788
train_step : 22828, loss1 : 0.779344, loss2 : 1.238055
train_step : 22829, loss1 : 1.683566, loss2 : 1.377676
train_step : 22830, loss1 : 1.337092, loss2 : 1.084751
train_step : 22831, loss1 : 1.166504, loss2 : 0.923805
train_step : 22832, loss1 : 0.673022, loss2 : 1.738014
train_step : 22833, loss1 : 0.956028, loss2 : 0.888806
train_step : 22834, loss1 : 0.674368, loss2 : 0.977983
train_step : 22835, loss1 : 1.250399, loss2 : 0.783110
train_step : 22836, loss1 : 0.519858, loss2 : 1.082840
train_step : 22837, loss1 : 0.989060, loss2 : 0.843473
train_step : 22838, loss1 : 1.056275, loss2 : 0.512954
train_step : 22839, loss1 : 1.357872, loss2 : 0.690742
train_step : 22840, loss1 : 1.206727, loss2 : 0.839215
train_step : 22841, loss1 : 1.633044, loss2 : 0.520675
train_step : 22842, loss1 : 1.153152, loss2 : 1.422873
train_step : 22843, loss1 : 0.599239, loss2 : 1.071127
train_step : 22844, loss1 : 0.602645, loss2 : 0.899235
train_step : 22845, loss1 : 1.004440, loss2 : 1.165776
train_step : 22846, loss1 : 1.220631, loss2 : 1.021389
train_step : 22847, loss1 : 1.585170, loss2 : 0.644775
train_step : 22848, loss1 : 1.798548, loss2 : 1.554355
train_step : 22849, loss1 : 2.242570, loss2 : 1.471642
train_step : 22850, loss1 : 3.233193, loss2 : 2.490494
train_step : 22851, loss1 : 3.717125, loss2 : 2.791579
train_step : 22852, loss1 : 2.315205, loss2 : 3.085347
train_step : 22853, loss1 : 2.616115, loss2 : 3.017987
train_step : 22854, loss1 : 2.761479, loss2 : 3.062316
train_step : 22855, loss1 : 2.067073, loss2 : 2.692599
train_step : 22856, loss1 : 2.397719, loss2 : 4.248224
train_step : 22857, loss1 : 0.991967, loss2 : 3.991225
train_step : 22858, loss1 : 2.247262, loss2 : 1.779925
train_step : 22859, loss1 : 1.988335, loss2 : 1.300858
train_step : 22860, loss1 : 2.215788, loss2 : 1.903331
train_step : 22861, loss1 : 1.975235, loss2 : 1.353697
train_step : 22862, loss1 : 0.737805, loss2 : 0.783441
train_step : 22863, loss1 : 1.180805, loss2 : 1.039805
train_step : 22864, loss1 : 1.198111, loss2 : 0.883225
train_step : 22865, loss1 : 1.060124, loss2 : 1.039691
train_step : 22866, loss1 : 0.770468, loss2 : 2.028792
train_step : 22867, loss1 : 0.956821, loss2 : 1.046595
train_step : 22868, loss1 : 0.551412, loss2 : 1.016836
train_step : 22869, loss1 : 0.929016, loss2 : 0.576551
train_step : 22870, loss1 : 1.085442, loss2 : 1.357428
train_step : 22871, loss1 : 1.205125, loss2 : 1.898401
train_step : 22872, loss1 : 1.061453, loss2 : 1.570618
train_step : 22873, loss1 : 2.461403, loss2 : 0.734823
train_step : 22874, loss1 : 1.725578, loss2 : 1.706422
train_step : 22875, loss1 : 1.882651, loss2 : 2.551348
train_step : 22876, loss1 : 1.580195, loss2 : 1.572159
train_step : 22877, loss1 : 1.343909, loss2 : 0.963341
train_step : 22878, loss1 : 1.493995, loss2 : 0.884379
train_step : 22879, loss1 : 1.071461, loss2 : 2.006582
train_step : 22880, loss1 : 0.667229, loss2 : 0.889165
train_step : 22881, loss1 : 1.441926, loss2 : 1.401786
train_step : 22882, loss1 : 2.245392, loss2 : 1.305875
train_step : 22883, loss1 : 2.200080, loss2 : 1.730171
train_step : 22884, loss1 : 1.547121, loss2 : 2.054937
train_step : 22885, loss1 : 2.908607, loss2 : 2.501459
train_step : 22886, loss1 : 1.029045, loss2 : 1.394930
train_step : 22887, loss1 : 1.208061, loss2 : 1.407193
train_step : 22888, loss1 : 1.661463, loss2 : 1.847400
train_step : 22889, loss1 : 1.640580, loss2 : 1.887425
train_step : 22890, loss1 : 1.554799, loss2 : 1.462110
train_step : 22891, loss1 : 1.384625, loss2 : 1.357067
train_step : 22892, loss1 : 1.184908, loss2 : 1.325913
train_step : 22893, loss1 : 1.203234, loss2 : 1.062510
train_step : 22894, loss1 : 0.683283, loss2 : 1.050052
train_step : 22895, loss1 : 0.763324, loss2 : 0.962732
train_step : 22896, loss1 : 0.994225, loss2 : 0.919821
train_step : 22897, loss1 : 2.506637, loss2 : 0.646675
train_step : 22898, loss1 : 1.309248, loss2 : 0.972693
train_step : 22899, loss1 : 0.592300, loss2 : 0.688890
train_step : 22900, loss1 : 1.390445, loss2 : 1.240408
train_step : 22901, loss1 : 0.973236, loss2 : 1.320621
train_step : 22902, loss1 : 0.808535, loss2 : 1.130483
train_step : 22903, loss1 : 1.391190, loss2 : 1.003119
train_step : 22904, loss1 : 1.427602, loss2 : 2.415587
train_step : 22905, loss1 : 2.720552, loss2 : 2.814970
train_step : 22906, loss1 : 3.847539, loss2 : 1.780464
train_step : 22907, loss1 : 2.946355, loss2 : 2.892931
train_step : 22908, loss1 : 1.687294, loss2 : 3.453749
train_step : 22909, loss1 : 3.016693, loss2 : 2.098979
train_step : 22910, loss1 : 2.891521, loss2 : 2.491767
train_step : 22911, loss1 : 3.261516, loss2 : 2.574295
train_step : 22912, loss1 : 3.218292, loss2 : 4.537787
train_step : 22913, loss1 : 3.524231, loss2 : 4.176423
train_step : 22914, loss1 : 3.514274, loss2 : 3.192148
train_step : 22915, loss1 : 4.482404, loss2 : 5.884795
train_step : 22916, loss1 : 1.724429, loss2 : 1.547642
train_step : 22917, loss1 : 2.207626, loss2 : 0.539591
train_step : 22918, loss1 : 1.445725, loss2 : 0.894149
train_step : 22919, loss1 : 1.463200, loss2 : 1.305188
train_step : 22920, loss1 : 1.485741, loss2 : 1.190241
train_step : 22921, loss1 : 1.207531, loss2 : 1.271607
train_step : 22922, loss1 : 1.037049, loss2 : 1.080595
train_step : 22923, loss1 : 1.406383, loss2 : 0.982838
train_step : 22924, loss1 : 2.006436, loss2 : 1.342399
train_step : 22925, loss1 : 1.574479, loss2 : 3.116395
train_step : 22926, loss1 : 2.130761, loss2 : 3.721033
train_step : 22927, loss1 : 4.268852, loss2 : 2.635657
train_step : 22928, loss1 : 2.577695, loss2 : 3.937489
train_step : 22929, loss1 : 3.376800, loss2 : 3.283774
train_step : 22930, loss1 : 2.082484, loss2 : 2.157740
train_step : 22931, loss1 : 2.035142, loss2 : 1.775334
train_step : 22932, loss1 : 0.936020, loss2 : 0.865614
train_step : 22933, loss1 : 1.832214, loss2 : 1.657455
train_step : 22934, loss1 : 2.144443, loss2 : 2.771240
train_step : 22935, loss1 : 1.885283, loss2 : 2.215472
train_step : 22936, loss1 : 1.058517, loss2 : 1.636168
train_step : 22937, loss1 : 0.753789, loss2 : 1.478318
train_step : 22938, loss1 : 0.877050, loss2 : 0.414271
train_step : 22939, loss1 : 1.027821, loss2 : 1.587642
train_step : 22940, loss1 : 0.462816, loss2 : 2.392007
train_step : 22941, loss1 : 0.794645, loss2 : 1.054399
train_step : 22942, loss1 : 0.502048, loss2 : 0.859243
train_step : 22943, loss1 : 0.906379, loss2 : 1.242888
train_step : 22944, loss1 : 1.438766, loss2 : 1.029403
train_step : 22945, loss1 : 1.264419, loss2 : 1.312581
train_step : 22946, loss1 : 1.074162, loss2 : 1.502639
train_step : 22947, loss1 : 1.109066, loss2 : 0.856709
train_step : 22948, loss1 : 1.284382, loss2 : 1.084517
train_step : 22949, loss1 : 1.017891, loss2 : 1.287395
train_step : 22950, loss1 : 0.566842, loss2 : 0.989598
train_step : 22951, loss1 : 1.629198, loss2 : 1.094239
train_step : 22952, loss1 : 1.192427, loss2 : 1.019177
train_step : 22953, loss1 : 1.832543, loss2 : 1.548916
train_step : 22954, loss1 : 1.466622, loss2 : 0.818287
train_step : 22955, loss1 : 1.510380, loss2 : 1.501915
train_step : 22956, loss1 : 0.797366, loss2 : 1.125523
train_step : 22957, loss1 : 0.992558, loss2 : 1.344670
train_step : 22958, loss1 : 1.278997, loss2 : 0.597089
train_step : 22959, loss1 : 0.717955, loss2 : 1.421538
train_step : 22960, loss1 : 1.430623, loss2 : 1.691985
train_step : 22961, loss1 : 2.276858, loss2 : 2.183002
train_step : 22962, loss1 : 1.720325, loss2 : 2.948667
train_step : 22963, loss1 : 2.801000, loss2 : 3.379878
train_step : 22964, loss1 : 3.425696, loss2 : 3.281545
train_step : 22965, loss1 : 3.697271, loss2 : 3.339484
train_step : 22966, loss1 : 1.892914, loss2 : 3.119724
train_step : 22967, loss1 : 2.251315, loss2 : 2.036219
train_step : 22968, loss1 : 1.907288, loss2 : 2.539953
train_step : 22969, loss1 : 2.351787, loss2 : 1.759048
train_step : 22970, loss1 : 1.773889, loss2 : 1.999105
train_step : 22971, loss1 : 1.945927, loss2 : 1.423669
train_step : 22972, loss1 : 1.579736, loss2 : 2.086041
train_step : 22973, loss1 : 2.428332, loss2 : 2.045457
train_step : 22974, loss1 : 1.790807, loss2 : 1.662448
train_step : 22975, loss1 : 1.501754, loss2 : 2.434101
train_step : 22976, loss1 : 1.319545, loss2 : 1.016337
train_step : 22977, loss1 : 1.442389, loss2 : 1.401062
train_step : 22978, loss1 : 1.518735, loss2 : 0.772702
train_step : 22979, loss1 : 1.205175, loss2 : 1.079414
train_step : 22980, loss1 : 1.730655, loss2 : 1.293364
train_step : 22981, loss1 : 1.123749, loss2 : 1.720482
train_step : 22982, loss1 : 0.844739, loss2 : 1.922342
train_step : 22983, loss1 : 2.554986, loss2 : 1.936697
train_step : 22984, loss1 : 2.003342, loss2 : 2.320743
train_step : 22985, loss1 : 2.003981, loss2 : 2.676490
train_step : 22986, loss1 : 2.478572, loss2 : 1.498345
train_step : 22987, loss1 : 2.048189, loss2 : 1.847582
train_step : 22988, loss1 : 3.014608, loss2 : 1.590988
train_step : 22989, loss1 : 2.905097, loss2 : 1.642134
train_step : 22990, loss1 : 2.493346, loss2 : 2.054749
train_step : 22991, loss1 : 1.525629, loss2 : 0.699585
train_step : 22992, loss1 : 1.200951, loss2 : 1.331575
train_step : 22993, loss1 : 0.863680, loss2 : 0.889693
train_step : 22994, loss1 : 0.728847, loss2 : 1.170643
train_step : 22995, loss1 : 0.935123, loss2 : 1.026618
train_step : 22996, loss1 : 1.185440, loss2 : 1.866469
train_step : 22997, loss1 : 1.113733, loss2 : 1.393407
train_step : 22998, loss1 : 0.874394, loss2 : 1.446719
train_step : 22999, loss1 : 0.986005, loss2 : 0.872647
train_step : 23000, loss1 : 0.983554, loss2 : 1.400899
train_step : 23001, loss1 : 1.328100, loss2 : 0.800172
train_step : 23002, loss1 : 0.895602, loss2 : 1.713925
train_step : 23003, loss1 : 1.336107, loss2 : 0.684785
train_step : 23004, loss1 : 0.728017, loss2 : 1.181725
train_step : 23005, loss1 : 2.302436, loss2 : 1.911926
train_step : 23006, loss1 : 0.919000, loss2 : 0.889451
train_step : 23007, loss1 : 1.178038, loss2 : 5.420621
train_step : 23008, loss1 : 1.881919, loss2 : 1.339779
train_step : 23009, loss1 : 1.809012, loss2 : 1.836093
train_step : 23010, loss1 : 0.607340, loss2 : 0.890854
train_step : 23011, loss1 : 1.301543, loss2 : 1.139791
train_step : 23012, loss1 : 0.791869, loss2 : 1.042202
train_step : 23013, loss1 : 0.705108, loss2 : 1.503941
train_step : 23014, loss1 : 1.069253, loss2 : 0.651989
train_step : 23015, loss1 : 1.516411, loss2 : 1.042078
train_step : 23016, loss1 : 0.696521, loss2 : 1.465998
train_step : 23017, loss1 : 1.367048, loss2 : 1.375111
train_step : 23018, loss1 : 1.179929, loss2 : 1.361767
train_step : 23019, loss1 : 1.047805, loss2 : 0.560714
train_step : 23020, loss1 : 1.963012, loss2 : 1.131351
train_step : 23021, loss1 : 1.960863, loss2 : 0.993248
train_step : 23022, loss1 : 0.735672, loss2 : 0.992072
train_step : 23023, loss1 : 2.009736, loss2 : 1.509910
train_step : 23024, loss1 : 0.588013, loss2 : 1.051407
train_step : 23025, loss1 : 1.015716, loss2 : 1.099415
train_step : 23026, loss1 : 2.697359, loss2 : 0.732811
train_step : 23027, loss1 : 1.728117, loss2 : 1.337938
train_step : 23028, loss1 : 1.289521, loss2 : 0.869134
train_step : 23029, loss1 : 2.106649, loss2 : 1.735166
train_step : 23030, loss1 : 0.880535, loss2 : 0.844894
train_step : 23031, loss1 : 0.798332, loss2 : 0.499597
train_step : 23032, loss1 : 0.902057, loss2 : 1.516687
train_step : 23033, loss1 : 1.255362, loss2 : 0.583432
train_step : 23034, loss1 : 0.986172, loss2 : 1.955466
train_step : 23035, loss1 : 0.622899, loss2 : 1.765526
train_step : 23036, loss1 : 0.570018, loss2 : 0.972326
train_step : 23037, loss1 : 0.830611, loss2 : 1.447874
train_step : 23038, loss1 : 0.555482, loss2 : 1.427051
train_step : 23039, loss1 : 0.650823, loss2 : 1.683387
train_step : 23040, loss1 : 1.082235, loss2 : 0.805438
train_step : 23041, loss1 : 1.065363, loss2 : 0.691626
train_step : 23042, loss1 : 0.884709, loss2 : 1.385514
train_step : 23043, loss1 : 1.176602, loss2 : 0.755634
train_step : 23044, loss1 : 0.404443, loss2 : 1.067650
train_step : 23045, loss1 : 0.676823, loss2 : 0.853788
train_step : 23046, loss1 : 0.994743, loss2 : 1.638792
train_step : 23047, loss1 : 1.265125, loss2 : 1.278069
train_step : 23048, loss1 : 0.816752, loss2 : 1.006352
train_step : 23049, loss1 : 0.599762, loss2 : 0.934850
train_step : 23050, loss1 : 0.722881, loss2 : 0.929991
train_step : 23051, loss1 : 1.158383, loss2 : 1.215551
train_step : 23052, loss1 : 1.337108, loss2 : 0.433136
train_step : 23053, loss1 : 1.255072, loss2 : 1.213445
train_step : 23054, loss1 : 1.264194, loss2 : 1.445201
train_step : 23055, loss1 : 0.917159, loss2 : 1.062852
train_step : 23056, loss1 : 1.405329, loss2 : 2.252610
train_step : 23057, loss1 : 1.453932, loss2 : 1.332210
train_step : 23058, loss1 : 1.958907, loss2 : 0.911248
train_step : 23059, loss1 : 1.578135, loss2 : 0.845775
train_step : 23060, loss1 : 1.625355, loss2 : 2.001664
train_step : 23061, loss1 : 3.367123, loss2 : 1.796930
train_step : 23062, loss1 : 1.851182, loss2 : 3.098303
train_step : 23063, loss1 : 2.512598, loss2 : 2.304253
train_step : 23064, loss1 : 2.796750, loss2 : 3.033874
train_step : 23065, loss1 : 3.612016, loss2 : 4.260951
train_step : 23066, loss1 : 2.806877, loss2 : 3.558790
train_step : 23067, loss1 : 2.158779, loss2 : 3.213840
train_step : 23068, loss1 : 1.702298, loss2 : 1.811968
train_step : 23069, loss1 : 2.554345, loss2 : 1.820098
train_step : 23070, loss1 : 2.299958, loss2 : 1.977570
train_step : 23071, loss1 : 2.276576, loss2 : 2.178831
train_step : 23072, loss1 : 1.728602, loss2 : 0.890938
train_step : 23073, loss1 : 1.070604, loss2 : 1.249528
train_step : 23074, loss1 : 0.919286, loss2 : 1.111873
train_step : 23075, loss1 : 1.130651, loss2 : 1.313920
train_step : 23076, loss1 : 0.880604, loss2 : 1.686240
train_step : 23077, loss1 : 1.633456, loss2 : 0.670830
train_step : 23078, loss1 : 0.481383, loss2 : 0.907605
train_step : 23079, loss1 : 1.554757, loss2 : 0.688678
train_step : 23080, loss1 : 0.973476, loss2 : 1.163215
train_step : 23081, loss1 : 0.399982, loss2 : 1.489384
train_step : 23082, loss1 : 1.114098, loss2 : 0.497535
train_step : 23083, loss1 : 1.335512, loss2 : 1.480071
train_step : 23084, loss1 : 1.221373, loss2 : 1.641381
train_step : 23085, loss1 : 1.243218, loss2 : 1.284613
train_step : 23086, loss1 : 1.119697, loss2 : 1.037833
train_step : 23087, loss1 : 2.850749, loss2 : 1.422059
train_step : 23088, loss1 : 1.919157, loss2 : 2.026706
train_step : 23089, loss1 : 1.203812, loss2 : 1.125508
train_step : 23090, loss1 : 0.791169, loss2 : 0.993092
train_step : 23091, loss1 : 1.394734, loss2 : 1.554342
train_step : 23092, loss1 : 1.353800, loss2 : 1.066062
train_step : 23093, loss1 : 1.559436, loss2 : 1.532471
train_step : 23094, loss1 : 1.607996, loss2 : 1.042269
train_step : 23095, loss1 : 1.363551, loss2 : 1.481765
train_step : 23096, loss1 : 2.685673, loss2 : 1.773983
train_step : 23097, loss1 : 1.387311, loss2 : 2.654253
train_step : 23098, loss1 : 2.413105, loss2 : 2.736794
train_step : 23099, loss1 : 4.997171, loss2 : 3.159048
train_step : 23100, loss1 : 3.701398, loss2 : 3.156120
train_step : 23101, loss1 : 2.101944, loss2 : 3.533298
train_step : 23102, loss1 : 2.565249, loss2 : 2.477217
train_step : 23103, loss1 : 2.394243, loss2 : 1.675522
train_step : 23104, loss1 : 1.057295, loss2 : 2.251421
train_step : 23105, loss1 : 1.723900, loss2 : 1.690810
train_step : 23106, loss1 : 1.869694, loss2 : 1.375957
train_step : 23107, loss1 : 1.262848, loss2 : 0.953943
train_step : 23108, loss1 : 0.931100, loss2 : 0.985822
train_step : 23109, loss1 : 0.912317, loss2 : 0.907550
train_step : 23110, loss1 : 0.838405, loss2 : 0.691677
train_step : 23111, loss1 : 1.133889, loss2 : 1.525842
train_step : 23112, loss1 : 1.165273, loss2 : 1.142693
train_step : 23113, loss1 : 2.020761, loss2 : 1.814960
train_step : 23114, loss1 : 1.909347, loss2 : 1.505520
train_step : 23115, loss1 : 1.071338, loss2 : 1.384325
train_step : 23116, loss1 : 1.305427, loss2 : 1.627421
train_step : 23117, loss1 : 1.616216, loss2 : 0.671034
train_step : 23118, loss1 : 1.150200, loss2 : 0.890849
train_step : 23119, loss1 : 1.476956, loss2 : 1.445717
train_step : 23120, loss1 : 0.691641, loss2 : 0.818000
train_step : 23121, loss1 : 1.064120, loss2 : 0.897954
train_step : 23122, loss1 : 1.001960, loss2 : 0.868852
train_step : 23123, loss1 : 0.845825, loss2 : 1.607675
train_step : 23124, loss1 : 1.327107, loss2 : 1.990778
train_step : 23125, loss1 : 2.155369, loss2 : 1.612413
train_step : 23126, loss1 : 1.697025, loss2 : 1.441416
train_step : 23127, loss1 : 2.564229, loss2 : 1.353413
train_step : 23128, loss1 : 1.964082, loss2 : 2.009307
train_step : 23129, loss1 : 1.940855, loss2 : 1.744086
train_step : 23130, loss1 : 0.926569, loss2 : 2.034080
train_step : 23131, loss1 : 1.146826, loss2 : 2.013091
train_step : 23132, loss1 : 1.435689, loss2 : 1.260674
train_step : 23133, loss1 : 1.610600, loss2 : 1.665169
train_step : 23134, loss1 : 1.077416, loss2 : 1.198605
train_step : 23135, loss1 : 0.792894, loss2 : 1.355394
train_step : 23136, loss1 : 1.161433, loss2 : 1.033371
train_step : 23137, loss1 : 0.730311, loss2 : 0.890798
train_step : 23138, loss1 : 2.114518, loss2 : 0.984730
train_step : 23139, loss1 : 1.093727, loss2 : 1.833216
train_step : 23140, loss1 : 1.191171, loss2 : 0.937337
train_step : 23141, loss1 : 0.851034, loss2 : 2.021523
train_step : 23142, loss1 : 0.802318, loss2 : 1.171862
train_step : 23143, loss1 : 1.285163, loss2 : 0.623626
train_step : 23144, loss1 : 2.045048, loss2 : 1.079645
train_step : 23145, loss1 : 1.114702, loss2 : 1.092552
train_step : 23146, loss1 : 0.741885, loss2 : 1.392004
train_step : 23147, loss1 : 1.227137, loss2 : 1.011105
train_step : 23148, loss1 : 2.317542, loss2 : 0.979637
train_step : 23149, loss1 : 1.121252, loss2 : 1.406652
train_step : 23150, loss1 : 1.521872, loss2 : 1.291709
train_step : 23151, loss1 : 1.196875, loss2 : 0.788698
train_step : 23152, loss1 : 1.440595, loss2 : 0.979960
train_step : 23153, loss1 : 1.321946, loss2 : 1.061584
train_step : 23154, loss1 : 0.991335, loss2 : 1.085609
train_step : 23155, loss1 : 0.838661, loss2 : 0.968091
train_step : 23156, loss1 : 1.517952, loss2 : 1.007270
train_step : 23157, loss1 : 0.919545, loss2 : 1.924251
train_step : 23158, loss1 : 1.016690, loss2 : 1.909846
train_step : 23159, loss1 : 1.145100, loss2 : 1.677815
train_step : 23160, loss1 : 1.522623, loss2 : 1.100595
train_step : 23161, loss1 : 1.247056, loss2 : 1.851113
train_step : 23162, loss1 : 2.236910, loss2 : 2.087500
train_step : 23163, loss1 : 2.254288, loss2 : 1.034758
train_step : 23164, loss1 : 1.796940, loss2 : 2.324453
train_step : 23165, loss1 : 1.437547, loss2 : 1.654866
train_step : 23166, loss1 : 1.172766, loss2 : 1.307342
train_step : 23167, loss1 : 1.554877, loss2 : 0.851182
train_step : 23168, loss1 : 1.303917, loss2 : 1.133319
train_step : 23169, loss1 : 2.017578, loss2 : 1.910357
train_step : 23170, loss1 : 6.724339, loss2 : 3.436277
train_step : 23171, loss1 : 4.415470, loss2 : 2.588396
train_step : 23172, loss1 : 2.986948, loss2 : 3.124245
train_step : 23173, loss1 : 2.838874, loss2 : 1.916550
train_step : 23174, loss1 : 2.442770, loss2 : 2.218013
train_step : 23175, loss1 : 1.349019, loss2 : 4.178634
train_step : 23176, loss1 : 2.656031, loss2 : 2.795341
train_step : 23177, loss1 : 2.719937, loss2 : 2.498525
train_step : 23178, loss1 : 3.038788, loss2 : 3.161877
train_step : 23179, loss1 : 2.675832, loss2 : 4.967202
train_step : 23180, loss1 : 3.363701, loss2 : 2.867523
train_step : 23181, loss1 : 1.177901, loss2 : 1.528850
train_step : 23182, loss1 : 1.923380, loss2 : 1.797834
train_step : 23183, loss1 : 1.323280, loss2 : 1.269995
train_step : 23184, loss1 : 0.848049, loss2 : 1.191937
train_step : 23185, loss1 : 1.131797, loss2 : 1.363023
train_step : 23186, loss1 : 1.438242, loss2 : 0.938172
train_step : 23187, loss1 : 1.242480, loss2 : 0.891199
train_step : 23188, loss1 : 0.942548, loss2 : 1.103639
train_step : 23189, loss1 : 0.877676, loss2 : 0.840533
train_step : 23190, loss1 : 1.692141, loss2 : 2.024400
train_step : 23191, loss1 : 0.590776, loss2 : 1.070184
train_step : 23192, loss1 : 1.026230, loss2 : 0.837506
train_step : 23193, loss1 : 2.219783, loss2 : 2.130701
train_step : 23194, loss1 : 0.932119, loss2 : 1.914615
train_step : 23195, loss1 : 1.515605, loss2 : 1.052359
train_step : 23196, loss1 : 1.459045, loss2 : 1.291133
train_step : 23197, loss1 : 1.025060, loss2 : 1.176898
train_step : 23198, loss1 : 1.844633, loss2 : 1.387914
train_step : 23199, loss1 : 1.672424, loss2 : 0.968768
train_step : 23200, loss1 : 0.969892, loss2 : 1.335749
train_step : 23201, loss1 : 0.971713, loss2 : 1.063433
train_step : 23202, loss1 : 1.305331, loss2 : 0.808557
train_step : 23203, loss1 : 0.757322, loss2 : 0.582728
train_step : 23204, loss1 : 1.119619, loss2 : 1.334741
train_step : 23205, loss1 : 0.911508, loss2 : 1.048437
train_step : 23206, loss1 : 0.723726, loss2 : 0.668383
train_step : 23207, loss1 : 1.207856, loss2 : 0.816912
train_step : 23208, loss1 : 1.632796, loss2 : 1.295432
train_step : 23209, loss1 : 1.942993, loss2 : 1.108880
train_step : 23210, loss1 : 1.029862, loss2 : 2.769271
train_step : 23211, loss1 : 1.178769, loss2 : 1.925835
train_step : 23212, loss1 : 1.325117, loss2 : 1.536860
train_step : 23213, loss1 : 1.328060, loss2 : 1.878467
train_step : 23214, loss1 : 1.011683, loss2 : 0.551196
train_step : 23215, loss1 : 0.873820, loss2 : 0.712988
train_step : 23216, loss1 : 1.550199, loss2 : 1.606378
train_step : 23217, loss1 : 0.893490, loss2 : 2.220646
train_step : 23218, loss1 : 1.981230, loss2 : 1.751585
train_step : 23219, loss1 : 1.825117, loss2 : 1.780223
train_step : 23220, loss1 : 0.688651, loss2 : 1.182182
train_step : 23221, loss1 : 0.404958, loss2 : 0.513128
train_step : 23222, loss1 : 1.295717, loss2 : 1.404110
train_step : 23223, loss1 : 0.962712, loss2 : 0.660318
train_step : 23224, loss1 : 1.150069, loss2 : 1.088167
train_step : 23225, loss1 : 0.920639, loss2 : 0.693517
train_step : 23226, loss1 : 1.494207, loss2 : 0.899310
train_step : 23227, loss1 : 1.723151, loss2 : 0.956666
train_step : 23228, loss1 : 1.519738, loss2 : 0.844406
train_step : 23229, loss1 : 0.969996, loss2 : 0.867171
train_step : 23230, loss1 : 1.072048, loss2 : 2.017153
train_step : 23231, loss1 : 2.074111, loss2 : 1.441328
train_step : 23232, loss1 : 1.541902, loss2 : 3.038215
train_step : 23233, loss1 : 2.292522, loss2 : 1.442237
train_step : 23234, loss1 : 3.014499, loss2 : 1.684874
train_step : 23235, loss1 : 3.073547, loss2 : 3.667267
train_step : 23236, loss1 : 4.709353, loss2 : 4.197185
train_step : 23237, loss1 : 2.893972, loss2 : 2.622339
train_step : 23238, loss1 : 1.981411, loss2 : 1.759054
train_step : 23239, loss1 : 1.314865, loss2 : 1.213783
train_step : 23240, loss1 : 2.880480, loss2 : 1.064588
train_step : 23241, loss1 : 1.322035, loss2 : 1.293435
train_step : 23242, loss1 : 1.101667, loss2 : 2.564718
train_step : 23243, loss1 : 1.007220, loss2 : 1.025919
train_step : 23244, loss1 : 1.855384, loss2 : 1.373941
train_step : 23245, loss1 : 2.015801, loss2 : 1.419282
train_step : 23246, loss1 : 0.863993, loss2 : 2.265643
train_step : 23247, loss1 : 0.739398, loss2 : 0.839720
train_step : 23248, loss1 : 0.758112, loss2 : 1.027356
train_step : 23249, loss1 : 1.870661, loss2 : 0.750075
train_step : 23250, loss1 : 0.596754, loss2 : 1.204588
train_step : 23251, loss1 : 1.962419, loss2 : 0.882613
train_step : 23252, loss1 : 2.023298, loss2 : 1.558046
train_step : 23253, loss1 : 0.893160, loss2 : 1.194071
train_step : 23254, loss1 : 1.010032, loss2 : 1.738143
train_step : 23255, loss1 : 1.112471, loss2 : 1.101729
train_step : 23256, loss1 : 1.059655, loss2 : 1.593269
train_step : 23257, loss1 : 0.813207, loss2 : 1.290729
train_step : 23258, loss1 : 0.775550, loss2 : 0.596971
train_step : 23259, loss1 : 0.862732, loss2 : 0.775937
train_step : 23260, loss1 : 0.593851, loss2 : 1.074326
train_step : 23261, loss1 : 1.573005, loss2 : 1.837305
train_step : 23262, loss1 : 1.409043, loss2 : 0.681434
train_step : 23263, loss1 : 0.985260, loss2 : 1.266496
train_step : 23264, loss1 : 1.604338, loss2 : 0.966442
train_step : 23265, loss1 : 0.569856, loss2 : 1.588337
train_step : 23266, loss1 : 0.666996, loss2 : 1.068750
train_step : 23267, loss1 : 0.814185, loss2 : 0.909990
train_step : 23268, loss1 : 1.600856, loss2 : 1.346747
train_step : 23269, loss1 : 1.861363, loss2 : 1.541334
train_step : 23270, loss1 : 2.109651, loss2 : 1.779248
train_step : 23271, loss1 : 0.836695, loss2 : 1.554043
train_step : 23272, loss1 : 1.458067, loss2 : 1.395090
train_step : 23273, loss1 : 1.729111, loss2 : 2.738348
train_step : 23274, loss1 : 1.572160, loss2 : 3.556718
train_step : 23275, loss1 : 1.107423, loss2 : 1.928337
train_step : 23276, loss1 : 1.602187, loss2 : 1.570534
train_step : 23277, loss1 : 1.149811, loss2 : 3.037849
train_step : 23278, loss1 : 1.914620, loss2 : 1.496769
train_step : 23279, loss1 : 0.936282, loss2 : 1.039368
train_step : 23280, loss1 : 0.943013, loss2 : 1.107300
train_step : 23281, loss1 : 0.791369, loss2 : 0.989550
train_step : 23282, loss1 : 1.252291, loss2 : 1.156213
train_step : 23283, loss1 : 0.869967, loss2 : 1.074102
train_step : 23284, loss1 : 1.265899, loss2 : 0.766530
train_step : 23285, loss1 : 0.861292, loss2 : 1.048186
train_step : 23286, loss1 : 0.762781, loss2 : 1.155829
train_step : 23287, loss1 : 1.030174, loss2 : 0.873433
train_step : 23288, loss1 : 1.460071, loss2 : 1.470834
train_step : 23289, loss1 : 1.301137, loss2 : 2.141360
train_step : 23290, loss1 : 2.571794, loss2 : 2.813568
train_step : 23291, loss1 : 0.765955, loss2 : 1.723313
train_step : 23292, loss1 : 0.771507, loss2 : 1.202940
train_step : 23293, loss1 : 1.008283, loss2 : 1.715461
train_step : 23294, loss1 : 1.636770, loss2 : 3.046431
train_step : 23295, loss1 : 1.699838, loss2 : 1.862318
train_step : 23296, loss1 : 2.211862, loss2 : 1.584699
train_step : 23297, loss1 : 1.611694, loss2 : 0.904227
train_step : 23298, loss1 : 1.115398, loss2 : 1.242173
train_step : 23299, loss1 : 1.193928, loss2 : 1.235231
train_step : 23300, loss1 : 0.999706, loss2 : 0.520952
train_step : 23301, loss1 : 0.804429, loss2 : 1.369311
train_step : 23302, loss1 : 1.133988, loss2 : 1.687454
train_step : 23303, loss1 : 1.210199, loss2 : 0.673597
train_step : 23304, loss1 : 0.719699, loss2 : 1.237135
train_step : 23305, loss1 : 0.901296, loss2 : 1.034466
train_step : 23306, loss1 : 1.110785, loss2 : 1.166697
train_step : 23307, loss1 : 2.201809, loss2 : 0.761137
train_step : 23308, loss1 : 0.922680, loss2 : 1.134537
train_step : 23309, loss1 : 1.122213, loss2 : 2.303281
train_step : 23310, loss1 : 1.476016, loss2 : 1.303360
train_step : 23311, loss1 : 1.966255, loss2 : 1.994638
train_step : 23312, loss1 : 1.841407, loss2 : 1.164008
train_step : 23313, loss1 : 1.144323, loss2 : 2.595455
train_step : 23314, loss1 : 1.487844, loss2 : 1.103895
train_step : 23315, loss1 : 1.104115, loss2 : 1.887712
train_step : 23316, loss1 : 1.025893, loss2 : 1.534652
train_step : 23317, loss1 : 0.952557, loss2 : 1.178537
train_step : 23318, loss1 : 0.614099, loss2 : 0.633812
train_step : 23319, loss1 : 0.979315, loss2 : 0.632961
train_step : 23320, loss1 : 1.253895, loss2 : 0.911905
train_step : 23321, loss1 : 1.027976, loss2 : 1.141688
train_step : 23322, loss1 : 1.807117, loss2 : 1.095691
train_step : 23323, loss1 : 0.920180, loss2 : 0.940474
train_step : 23324, loss1 : 0.677351, loss2 : 0.738181
train_step : 23325, loss1 : 1.645141, loss2 : 0.804205
train_step : 23326, loss1 : 0.942858, loss2 : 0.474657
train_step : 23327, loss1 : 1.130304, loss2 : 0.793731
train_step : 23328, loss1 : 0.979765, loss2 : 0.800721
train_step : 23329, loss1 : 1.370453, loss2 : 1.279760
train_step : 23330, loss1 : 0.562130, loss2 : 1.864794
train_step : 23331, loss1 : 1.129053, loss2 : 0.978787
train_step : 23332, loss1 : 1.353104, loss2 : 1.073269
train_step : 23333, loss1 : 1.149236, loss2 : 0.765790
train_step : 23334, loss1 : 1.012048, loss2 : 1.737832
train_step : 23335, loss1 : 1.044815, loss2 : 1.263810
train_step : 23336, loss1 : 2.141286, loss2 : 0.690178
train_step : 23337, loss1 : 0.915185, loss2 : 0.975196
train_step : 23338, loss1 : 1.029238, loss2 : 1.000119
train_step : 23339, loss1 : 1.426341, loss2 : 0.821330
train_step : 23340, loss1 : 1.657352, loss2 : 1.588877
train_step : 23341, loss1 : 1.176170, loss2 : 1.760797
train_step : 23342, loss1 : 1.308846, loss2 : 0.669475
train_step : 23343, loss1 : 1.573646, loss2 : 1.096856
train_step : 23344, loss1 : 1.000313, loss2 : 1.588159
train_step : 23345, loss1 : 1.207693, loss2 : 1.025645
train_step : 23346, loss1 : 0.885806, loss2 : 1.048333
train_step : 23347, loss1 : 0.680222, loss2 : 2.001794
train_step : 23348, loss1 : 0.870841, loss2 : 2.173606
train_step : 23349, loss1 : 0.689575, loss2 : 1.037616
train_step : 23350, loss1 : 0.626587, loss2 : 1.092092
train_step : 23351, loss1 : 1.565944, loss2 : 1.743890
train_step : 23352, loss1 : 0.987060, loss2 : 1.073738
train_step : 23353, loss1 : 0.608707, loss2 : 1.547590
train_step : 23354, loss1 : 0.626463, loss2 : 0.947787
train_step : 23355, loss1 : 1.017569, loss2 : 0.804770
train_step : 23356, loss1 : 1.010651, loss2 : 0.903838
train_step : 23357, loss1 : 0.846040, loss2 : 0.481237
train_step : 23358, loss1 : 1.406949, loss2 : 1.045571
train_step : 23359, loss1 : 1.630031, loss2 : 1.118810
train_step : 23360, loss1 : 0.500130, loss2 : 1.486315
train_step : 23361, loss1 : 1.125095, loss2 : 1.290457
train_step : 23362, loss1 : 1.210953, loss2 : 1.959187
train_step : 23363, loss1 : 1.285201, loss2 : 1.321219
train_step : 23364, loss1 : 0.661406, loss2 : 0.812010
train_step : 23365, loss1 : 1.784563, loss2 : 1.325949
train_step : 23366, loss1 : 1.079152, loss2 : 2.075557
train_step : 23367, loss1 : 0.704236, loss2 : 0.867505
train_step : 23368, loss1 : 0.493210, loss2 : 0.783188
train_step : 23369, loss1 : 1.052174, loss2 : 1.357829
train_step : 23370, loss1 : 1.321678, loss2 : 1.034755
train_step : 23371, loss1 : 0.961442, loss2 : 1.376391
train_step : 23372, loss1 : 1.382953, loss2 : 0.844478
train_step : 23373, loss1 : 0.848389, loss2 : 0.992258
train_step : 23374, loss1 : 1.221901, loss2 : 0.905248
train_step : 23375, loss1 : 1.013117, loss2 : 1.101313
train_step : 23376, loss1 : 0.617585, loss2 : 1.182494
train_step : 23377, loss1 : 1.327332, loss2 : 0.886689
train_step : 23378, loss1 : 2.113492, loss2 : 2.656605
train_step : 23379, loss1 : 1.534383, loss2 : 1.366204
train_step : 23380, loss1 : 1.991560, loss2 : 1.857393
train_step : 23381, loss1 : 1.349691, loss2 : 1.247957
train_step : 23382, loss1 : 1.800840, loss2 : 1.342476
train_step : 23383, loss1 : 1.335009, loss2 : 0.897483
train_step : 23384, loss1 : 1.071579, loss2 : 1.035973
train_step : 23385, loss1 : 1.715707, loss2 : 1.275893
train_step : 23386, loss1 : 0.972946, loss2 : 1.131368
train_step : 23387, loss1 : 0.910086, loss2 : 0.987730
train_step : 23388, loss1 : 0.807395, loss2 : 0.674035
train_step : 23389, loss1 : 1.132622, loss2 : 1.551229
train_step : 23390, loss1 : 1.540530, loss2 : 1.185584
train_step : 23391, loss1 : 0.850998, loss2 : 1.295950
train_step : 23392, loss1 : 1.166715, loss2 : 1.304327
train_step : 23393, loss1 : 1.175304, loss2 : 1.374643
train_step : 23394, loss1 : 1.628057, loss2 : 1.361819
train_step : 23395, loss1 : 1.780754, loss2 : 0.956877
train_step : 23396, loss1 : 1.844622, loss2 : 1.356412
train_step : 23397, loss1 : 0.813556, loss2 : 1.350432
train_step : 23398, loss1 : 0.959622, loss2 : 0.929178
train_step : 23399, loss1 : 0.884306, loss2 : 1.968048
train_step : 23400, loss1 : 1.219628, loss2 : 1.123488
train_step : 23401, loss1 : 1.416286, loss2 : 0.849190
train_step : 23402, loss1 : 1.769761, loss2 : 2.008129
train_step : 23403, loss1 : 2.326093, loss2 : 1.327981
train_step : 23404, loss1 : 1.402315, loss2 : 2.931348
train_step : 23405, loss1 : 1.338804, loss2 : 2.033026
train_step : 23406, loss1 : 1.749425, loss2 : 2.030544
train_step : 23407, loss1 : 1.496578, loss2 : 1.276678
train_step : 23408, loss1 : 1.542717, loss2 : 1.198906
train_step : 23409, loss1 : 2.688105, loss2 : 1.623042
train_step : 23410, loss1 : 1.035324, loss2 : 2.213309
train_step : 23411, loss1 : 0.958648, loss2 : 1.923090
train_step : 23412, loss1 : 1.911547, loss2 : 1.662966
train_step : 23413, loss1 : 1.301943, loss2 : 2.630806
train_step : 23414, loss1 : 0.744335, loss2 : 1.364032
train_step : 23415, loss1 : 0.951202, loss2 : 0.742802
train_step : 23416, loss1 : 0.819948, loss2 : 0.960241
train_step : 23417, loss1 : 1.375212, loss2 : 1.452160
train_step : 23418, loss1 : 0.651415, loss2 : 0.617726
train_step : 23419, loss1 : 1.320316, loss2 : 1.153142
train_step : 23420, loss1 : 0.590285, loss2 : 1.365687
train_step : 23421, loss1 : 1.183628, loss2 : 0.734930
train_step : 23422, loss1 : 1.318466, loss2 : 1.158202
train_step : 23423, loss1 : 1.044873, loss2 : 1.547918
train_step : 23424, loss1 : 0.880245, loss2 : 0.600424
train_step : 23425, loss1 : 1.019459, loss2 : 0.600182
train_step : 23426, loss1 : 1.554649, loss2 : 0.778745
train_step : 23427, loss1 : 1.390017, loss2 : 1.377929
train_step : 23428, loss1 : 1.003681, loss2 : 1.071170
train_step : 23429, loss1 : 2.037875, loss2 : 1.201778
train_step : 23430, loss1 : 0.800321, loss2 : 1.800148
train_step : 23431, loss1 : 1.330293, loss2 : 1.459168
train_step : 23432, loss1 : 1.454259, loss2 : 1.050412
train_step : 23433, loss1 : 0.537063, loss2 : 1.548617
train_step : 23434, loss1 : 1.026775, loss2 : 1.371930
train_step : 23435, loss1 : 1.530910, loss2 : 1.230991
train_step : 23436, loss1 : 2.594214, loss2 : 1.778807
train_step : 23437, loss1 : 1.566850, loss2 : 1.970853
train_step : 23438, loss1 : 1.268697, loss2 : 1.263448
train_step : 23439, loss1 : 1.097044, loss2 : 0.746189
train_step : 23440, loss1 : 1.341210, loss2 : 1.101244
train_step : 23441, loss1 : 0.757805, loss2 : 1.433373
train_step : 23442, loss1 : 0.521090, loss2 : 0.929908
train_step : 23443, loss1 : 1.584570, loss2 : 1.332181
train_step : 23444, loss1 : 0.936924, loss2 : 0.951239
train_step : 23445, loss1 : 1.327935, loss2 : 1.134682
train_step : 23446, loss1 : 1.279919, loss2 : 1.323196
train_step : 23447, loss1 : 1.871836, loss2 : 1.833318
train_step : 23448, loss1 : 1.387275, loss2 : 1.491135
train_step : 23449, loss1 : 2.232093, loss2 : 0.933533
train_step : 23450, loss1 : 3.848812, loss2 : 2.886745
train_step : 23451, loss1 : 3.855099, loss2 : 3.550520
train_step : 23452, loss1 : 4.089330, loss2 : 2.438743
train_step : 23453, loss1 : 2.930680, loss2 : 2.898661
train_step : 23454, loss1 : 1.553877, loss2 : 3.327700
train_step : 23455, loss1 : 1.154374, loss2 : 1.580697
train_step : 23456, loss1 : 2.015617, loss2 : 1.555814
train_step : 23457, loss1 : 1.545897, loss2 : 1.703986
train_step : 23458, loss1 : 0.881303, loss2 : 2.126953
train_step : 23459, loss1 : 1.193449, loss2 : 1.591698
train_step : 23460, loss1 : 1.278612, loss2 : 1.356146
train_step : 23461, loss1 : 1.276310, loss2 : 1.484602
train_step : 23462, loss1 : 1.229644, loss2 : 1.452273
train_step : 23463, loss1 : 1.607637, loss2 : 1.631296
train_step : 23464, loss1 : 1.427956, loss2 : 1.902438
train_step : 23465, loss1 : 1.277671, loss2 : 1.429868
train_step : 23466, loss1 : 0.803373, loss2 : 1.025758
train_step : 23467, loss1 : 1.425016, loss2 : 1.652570
train_step : 23468, loss1 : 2.824506, loss2 : 7.221870
train_step : 23469, loss1 : 2.691579, loss2 : 2.466505
train_step : 23470, loss1 : 1.408440, loss2 : 2.491402
train_step : 23471, loss1 : 0.916854, loss2 : 1.627380
train_step : 23472, loss1 : 1.206129, loss2 : 1.308881
train_step : 23473, loss1 : 0.648287, loss2 : 1.401279
train_step : 23474, loss1 : 1.066369, loss2 : 1.077363
train_step : 23475, loss1 : 0.695293, loss2 : 0.985829
train_step : 23476, loss1 : 1.281173, loss2 : 0.399708
train_step : 23477, loss1 : 0.663780, loss2 : 1.284838
train_step : 23478, loss1 : 0.624610, loss2 : 1.097996
train_step : 23479, loss1 : 1.729713, loss2 : 1.690814
train_step : 23480, loss1 : 1.822011, loss2 : 1.168992
train_step : 23481, loss1 : 1.475943, loss2 : 1.445704
train_step : 23482, loss1 : 1.341362, loss2 : 0.886520
train_step : 23483, loss1 : 1.093990, loss2 : 1.450697
train_step : 23484, loss1 : 1.155724, loss2 : 1.920678
train_step : 23485, loss1 : 1.369903, loss2 : 1.334085
train_step : 23486, loss1 : 1.940772, loss2 : 1.288503
train_step : 23487, loss1 : 1.486099, loss2 : 1.075652
train_step : 23488, loss1 : 1.705767, loss2 : 1.442399
train_step : 23489, loss1 : 1.396605, loss2 : 1.244100
train_step : 23490, loss1 : 0.812195, loss2 : 1.617385
train_step : 23491, loss1 : 1.121512, loss2 : 1.333860
train_step : 23492, loss1 : 0.992742, loss2 : 1.432903
train_step : 23493, loss1 : 0.790692, loss2 : 0.738065
train_step : 23494, loss1 : 0.703837, loss2 : 2.454950
train_step : 23495, loss1 : 1.330611, loss2 : 0.941329
train_step : 23496, loss1 : 1.533865, loss2 : 1.352108
train_step : 23497, loss1 : 0.923749, loss2 : 1.267808
train_step : 23498, loss1 : 1.137877, loss2 : 1.028142
train_step : 23499, loss1 : 1.583564, loss2 : 1.179893
train_step : 23500, loss1 : 0.623538, loss2 : 1.169256
train_step : 23501, loss1 : 1.337730, loss2 : 1.261936
train_step : 23502, loss1 : 1.494549, loss2 : 1.502124
train_step : 23503, loss1 : 1.385304, loss2 : 1.479907
train_step : 23504, loss1 : 1.526698, loss2 : 0.972841
train_step : 23505, loss1 : 2.349764, loss2 : 1.245695
train_step : 23506, loss1 : 0.923933, loss2 : 1.229199
train_step : 23507, loss1 : 2.258364, loss2 : 0.983765
train_step : 23508, loss1 : 2.965466, loss2 : 1.923288
train_step : 23509, loss1 : 2.188880, loss2 : 1.775258
train_step : 23510, loss1 : 2.602330, loss2 : 2.707934
train_step : 23511, loss1 : 1.629575, loss2 : 1.666179
train_step : 23512, loss1 : 1.004825, loss2 : 1.006639
train_step : 23513, loss1 : 2.392328, loss2 : 1.523109
train_step : 23514, loss1 : 1.781178, loss2 : 1.644171
train_step : 23515, loss1 : 1.324826, loss2 : 0.874390
train_step : 23516, loss1 : 0.822496, loss2 : 1.205414
train_step : 23517, loss1 : 1.453100, loss2 : 1.382138
train_step : 23518, loss1 : 2.431711, loss2 : 0.759976
train_step : 23519, loss1 : 2.077446, loss2 : 1.382802
train_step : 23520, loss1 : 1.591107, loss2 : 1.080387
train_step : 23521, loss1 : 0.827911, loss2 : 1.910193
train_step : 23522, loss1 : 2.079457, loss2 : 1.728245
train_step : 23523, loss1 : 1.080016, loss2 : 1.681421
train_step : 23524, loss1 : 0.843545, loss2 : 1.074839
train_step : 23525, loss1 : 1.874200, loss2 : 1.704599
train_step : 23526, loss1 : 2.082580, loss2 : 2.069059
train_step : 23527, loss1 : 4.421934, loss2 : 2.373290
train_step : 23528, loss1 : 1.694443, loss2 : 2.306891
train_step : 23529, loss1 : 0.869154, loss2 : 0.845668
train_step : 23530, loss1 : 1.334407, loss2 : 0.980112
train_step : 23531, loss1 : 1.733676, loss2 : 1.370086
train_step : 23532, loss1 : 1.953281, loss2 : 3.124706
train_step : 23533, loss1 : 2.023492, loss2 : 1.479888
train_step : 23534, loss1 : 1.642493, loss2 : 2.116686
train_step : 23535, loss1 : 1.736604, loss2 : 1.978605
train_step : 23536, loss1 : 2.961401, loss2 : 1.964550
train_step : 23537, loss1 : 2.337286, loss2 : 1.427491
train_step : 23538, loss1 : 1.896618, loss2 : 2.387042
train_step : 23539, loss1 : 1.610709, loss2 : 3.015065
train_step : 23540, loss1 : 2.812708, loss2 : 2.594914
train_step : 23541, loss1 : 3.186884, loss2 : 2.616007
train_step : 23542, loss1 : 4.227827, loss2 : 3.509105
train_step : 23543, loss1 : 3.718204, loss2 : 5.881231
train_step : 23544, loss1 : 6.700558, loss2 : 6.666368
train_step : 23545, loss1 : 5.595823, loss2 : 6.177632
train_step : 23546, loss1 : 5.504242, loss2 : 6.870090
train_step : 23547, loss1 : 5.788679, loss2 : 2.470724
train_step : 23548, loss1 : 6.005355, loss2 : 4.970286
train_step : 23549, loss1 : 3.228978, loss2 : 3.622880
train_step : 23550, loss1 : 2.841969, loss2 : 1.978992
train_step : 23551, loss1 : 1.951544, loss2 : 1.318436
train_step : 23552, loss1 : 1.239902, loss2 : 1.626608
train_step : 23553, loss1 : 1.567054, loss2 : 1.096085
train_step : 23554, loss1 : 0.427065, loss2 : 0.639197
train_step : 23555, loss1 : 1.154225, loss2 : 0.632364
train_step : 23556, loss1 : 0.528099, loss2 : 0.978641
train_step : 23557, loss1 : 2.742092, loss2 : 0.398241
train_step : 23558, loss1 : 0.746164, loss2 : 0.791463
train_step : 23559, loss1 : 3.185800, loss2 : 0.993752
train_step : 23560, loss1 : 1.908647, loss2 : 2.120575
train_step : 23561, loss1 : 1.681649, loss2 : 2.174428
train_step : 23562, loss1 : 2.196927, loss2 : 2.062593
train_step : 23563, loss1 : 1.282399, loss2 : 1.684160
train_step : 23564, loss1 : 1.476828, loss2 : 1.798646
train_step : 23565, loss1 : 2.451094, loss2 : 2.478211
train_step : 23566, loss1 : 4.831862, loss2 : 2.905187
train_step : 23567, loss1 : 1.572198, loss2 : 1.759292
train_step : 23568, loss1 : 1.528692, loss2 : 2.213916
train_step : 23569, loss1 : 1.615223, loss2 : 1.122620
train_step : 23570, loss1 : 1.358472, loss2 : 1.246247
train_step : 23571, loss1 : 2.134084, loss2 : 0.938126
train_step : 23572, loss1 : 1.855380, loss2 : 1.339890
train_step : 23573, loss1 : 1.010576, loss2 : 1.252886
train_step : 23574, loss1 : 1.483968, loss2 : 0.597947
train_step : 23575, loss1 : 1.381344, loss2 : 1.349735
train_step : 23576, loss1 : 0.824034, loss2 : 1.139278
train_step : 23577, loss1 : 1.332092, loss2 : 0.916428
train_step : 23578, loss1 : 1.217219, loss2 : 0.905358
train_step : 23579, loss1 : 1.279274, loss2 : 1.246214
train_step : 23580, loss1 : 0.838504, loss2 : 0.949427
train_step : 23581, loss1 : 0.990818, loss2 : 0.981078
train_step : 23582, loss1 : 1.301945, loss2 : 1.572794
train_step : 23583, loss1 : 1.685218, loss2 : 1.217787
train_step : 23584, loss1 : 1.241595, loss2 : 1.975601
train_step : 23585, loss1 : 1.578221, loss2 : 1.445922
train_step : 23586, loss1 : 1.028152, loss2 : 1.754519
train_step : 23587, loss1 : 2.289482, loss2 : 1.442469
train_step : 23588, loss1 : 1.510965, loss2 : 1.865219
train_step : 23589, loss1 : 0.999949, loss2 : 1.348691
train_step : 23590, loss1 : 1.372764, loss2 : 1.076406
train_step : 23591, loss1 : 1.128067, loss2 : 0.775137
train_step : 23592, loss1 : 0.942435, loss2 : 0.828902
train_step : 23593, loss1 : 0.941490, loss2 : 0.606628
train_step : 23594, loss1 : 1.366147, loss2 : 0.964245
train_step : 23595, loss1 : 1.591958, loss2 : 1.320105
train_step : 23596, loss1 : 0.656769, loss2 : 1.808537
train_step : 23597, loss1 : 1.592861, loss2 : 1.198255
train_step : 23598, loss1 : 1.473702, loss2 : 1.202252
train_step : 23599, loss1 : 1.083510, loss2 : 0.533114
train_step : 23600, loss1 : 1.737150, loss2 : 0.887655
train_step : 23601, loss1 : 0.648197, loss2 : 1.219370
train_step : 23602, loss1 : 1.322307, loss2 : 0.545163
train_step : 23603, loss1 : 0.929293, loss2 : 0.321786
train_step : 23604, loss1 : 0.855822, loss2 : 1.384313
train_step : 23605, loss1 : 1.431867, loss2 : 0.902331
train_step : 23606, loss1 : 1.645053, loss2 : 2.189771
train_step : 23607, loss1 : 1.567423, loss2 : 1.363120
train_step : 23608, loss1 : 0.959619, loss2 : 1.099458
train_step : 23609, loss1 : 1.673969, loss2 : 1.568728
train_step : 23610, loss1 : 1.795498, loss2 : 1.586806
train_step : 23611, loss1 : 1.463617, loss2 : 2.290616
train_step : 23612, loss1 : 2.394542, loss2 : 2.369635
train_step : 23613, loss1 : 1.788849, loss2 : 1.952386
train_step : 23614, loss1 : 1.776572, loss2 : 1.813976
train_step : 23615, loss1 : 2.072561, loss2 : 2.269637
train_step : 23616, loss1 : 2.665411, loss2 : 1.490112
train_step : 23617, loss1 : 3.121940, loss2 : 2.063260
train_step : 23618, loss1 : 1.290212, loss2 : 1.739118
train_step : 23619, loss1 : 1.022802, loss2 : 0.453919
train_step : 23620, loss1 : 1.066081, loss2 : 0.813710
train_step : 23621, loss1 : 0.677095, loss2 : 0.899669
train_step : 23622, loss1 : 1.925108, loss2 : 1.406626
train_step : 23623, loss1 : 1.730349, loss2 : 1.764525
train_step : 23624, loss1 : 1.086176, loss2 : 1.833014
train_step : 23625, loss1 : 0.813169, loss2 : 0.728600
train_step : 23626, loss1 : 1.479891, loss2 : 0.677153
train_step : 23627, loss1 : 0.793634, loss2 : 0.809237
train_step : 23628, loss1 : 2.321799, loss2 : 1.237903
train_step : 23629, loss1 : 1.959479, loss2 : 1.680301
train_step : 23630, loss1 : 1.184062, loss2 : 1.239618
train_step : 23631, loss1 : 1.936403, loss2 : 1.759715
train_step : 23632, loss1 : 1.161054, loss2 : 1.253989
train_step : 23633, loss1 : 0.874016, loss2 : 1.330062
train_step : 23634, loss1 : 0.967507, loss2 : 1.255556
train_step : 23635, loss1 : 1.820083, loss2 : 1.726204
train_step : 23636, loss1 : 1.125480, loss2 : 1.237690
train_step : 23637, loss1 : 0.861373, loss2 : 2.088881
train_step : 23638, loss1 : 1.513719, loss2 : 1.055182
train_step : 23639, loss1 : 1.414267, loss2 : 1.225270
train_step : 23640, loss1 : 1.565185, loss2 : 0.853920
train_step : 23641, loss1 : 1.373281, loss2 : 2.029757
train_step : 23642, loss1 : 2.083821, loss2 : 1.665907
train_step : 23643, loss1 : 0.966423, loss2 : 0.736210
train_step : 23644, loss1 : 1.031609, loss2 : 1.335975
train_step : 23645, loss1 : 1.111829, loss2 : 0.617747
train_step : 23646, loss1 : 1.463166, loss2 : 1.384773
train_step : 23647, loss1 : 1.399506, loss2 : 2.506175
train_step : 23648, loss1 : 1.388067, loss2 : 1.760353
train_step : 23649, loss1 : 1.686265, loss2 : 1.127911
train_step : 23650, loss1 : 1.079909, loss2 : 4.062634
train_step : 23651, loss1 : 1.348524, loss2 : 1.454317
train_step : 23652, loss1 : 0.651830, loss2 : 1.458421
train_step : 23653, loss1 : 0.735936, loss2 : 1.180869
train_step : 23654, loss1 : 0.943816, loss2 : 0.683269
train_step : 23655, loss1 : 0.745012, loss2 : 0.943292
train_step : 23656, loss1 : 0.577489, loss2 : 0.831439
train_step : 23657, loss1 : 1.019635, loss2 : 0.877931
train_step : 23658, loss1 : 1.626212, loss2 : 1.744681
train_step : 23659, loss1 : 1.749118, loss2 : 0.891088
train_step : 23660, loss1 : 2.979824, loss2 : 0.930219
train_step : 23661, loss1 : 2.039116, loss2 : 1.355396
train_step : 23662, loss1 : 0.834623, loss2 : 1.549474
train_step : 23663, loss1 : 1.091316, loss2 : 0.465949
train_step : 23664, loss1 : 0.924226, loss2 : 0.974131
train_step : 23665, loss1 : 1.163273, loss2 : 1.693250
train_step : 23666, loss1 : 0.945019, loss2 : 1.413015
train_step : 23667, loss1 : 1.732601, loss2 : 0.874649
train_step : 23668, loss1 : 1.865361, loss2 : 1.332685
train_step : 23669, loss1 : 1.492015, loss2 : 2.454950
train_step : 23670, loss1 : 1.524047, loss2 : 1.889935
train_step : 23671, loss1 : 1.784651, loss2 : 1.260321
train_step : 23672, loss1 : 0.924497, loss2 : 1.132339
train_step : 23673, loss1 : 0.847106, loss2 : 0.810717
train_step : 23674, loss1 : 1.543836, loss2 : 1.249637
train_step : 23675, loss1 : 2.130294, loss2 : 1.713266
train_step : 23676, loss1 : 1.032743, loss2 : 1.517782
train_step : 23677, loss1 : 1.386104, loss2 : 1.546405
train_step : 23678, loss1 : 1.412922, loss2 : 2.008795
train_step : 23679, loss1 : 1.636819, loss2 : 1.271947
train_step : 23680, loss1 : 0.712172, loss2 : 1.000915
train_step : 23681, loss1 : 0.881770, loss2 : 1.408201
train_step : 23682, loss1 : 1.302218, loss2 : 0.631436
train_step : 23683, loss1 : 1.405582, loss2 : 1.223394
train_step : 23684, loss1 : 1.519404, loss2 : 1.005639
train_step : 23685, loss1 : 0.682616, loss2 : 0.974122
train_step : 23686, loss1 : 0.899124, loss2 : 0.944322
train_step : 23687, loss1 : 0.643401, loss2 : 1.071512
train_step : 23688, loss1 : 0.744236, loss2 : 0.575419
train_step : 23689, loss1 : 1.029171, loss2 : 1.427901
train_step : 23690, loss1 : 0.892541, loss2 : 0.515217
train_step : 23691, loss1 : 1.097756, loss2 : 0.587086
train_step : 23692, loss1 : 0.979827, loss2 : 1.293276
train_step : 23693, loss1 : 1.083861, loss2 : 1.808657
train_step : 23694, loss1 : 0.736423, loss2 : 1.575130
train_step : 23695, loss1 : 1.208638, loss2 : 2.553541
train_step : 23696, loss1 : 1.475287, loss2 : 1.073771
train_step : 23697, loss1 : 1.522783, loss2 : 1.049601
train_step : 23698, loss1 : 2.099924, loss2 : 0.708625
train_step : 23699, loss1 : 1.827146, loss2 : 1.434548
train_step : 23700, loss1 : 0.915782, loss2 : 1.508161
train_step : 23701, loss1 : 0.900078, loss2 : 0.986136
train_step : 23702, loss1 : 1.056162, loss2 : 0.729789
train_step : 23703, loss1 : 1.396136, loss2 : 0.928179
train_step : 23704, loss1 : 1.621372, loss2 : 2.441667
train_step : 23705, loss1 : 0.695811, loss2 : 2.566751
train_step : 23706, loss1 : 1.312192, loss2 : 0.940390
train_step : 23707, loss1 : 0.979402, loss2 : 2.165666
train_step : 23708, loss1 : 1.081207, loss2 : 1.284333
train_step : 23709, loss1 : 0.953864, loss2 : 1.549941
train_step : 23710, loss1 : 1.160440, loss2 : 1.553611
train_step : 23711, loss1 : 1.597080, loss2 : 1.299813
train_step : 23712, loss1 : 2.027602, loss2 : 1.182175
train_step : 23713, loss1 : 1.748767, loss2 : 1.834643
train_step : 23714, loss1 : 1.385035, loss2 : 2.539757
train_step : 23715, loss1 : 2.629346, loss2 : 1.428197
train_step : 23716, loss1 : 0.976265, loss2 : 2.160651
train_step : 23717, loss1 : 0.883847, loss2 : 1.048058
train_step : 23718, loss1 : 1.036534, loss2 : 1.054372
train_step : 23719, loss1 : 1.068153, loss2 : 0.903882
train_step : 23720, loss1 : 0.755497, loss2 : 0.730765
train_step : 23721, loss1 : 1.215658, loss2 : 0.769480
train_step : 23722, loss1 : 0.745907, loss2 : 1.603968
train_step : 23723, loss1 : 0.603377, loss2 : 1.307695
train_step : 23724, loss1 : 1.511344, loss2 : 1.328189
train_step : 23725, loss1 : 0.722597, loss2 : 0.965873
train_step : 23726, loss1 : 0.708332, loss2 : 2.899785
train_step : 23727, loss1 : 1.099807, loss2 : 2.880487
train_step : 23728, loss1 : 1.355097, loss2 : 1.771918
train_step : 23729, loss1 : 1.135038, loss2 : 1.064821
train_step : 23730, loss1 : 1.182974, loss2 : 1.352909
train_step : 23731, loss1 : 1.002763, loss2 : 1.211725
train_step : 23732, loss1 : 1.149709, loss2 : 1.063435
train_step : 23733, loss1 : 1.059174, loss2 : 1.261251
train_step : 23734, loss1 : 1.710738, loss2 : 0.759879
train_step : 23735, loss1 : 0.764666, loss2 : 1.009198
train_step : 23736, loss1 : 0.831083, loss2 : 1.121508
train_step : 23737, loss1 : 1.019686, loss2 : 1.199453
train_step : 23738, loss1 : 1.554590, loss2 : 1.486821
train_step : 23739, loss1 : 1.397339, loss2 : 0.954906
train_step : 23740, loss1 : 1.475819, loss2 : 1.249792
train_step : 23741, loss1 : 1.685737, loss2 : 2.141715
train_step : 23742, loss1 : 2.057198, loss2 : 1.957735
train_step : 23743, loss1 : 1.811803, loss2 : 1.653078
train_step : 23744, loss1 : 1.374275, loss2 : 2.023274
train_step : 23745, loss1 : 2.282497, loss2 : 2.736385
train_step : 23746, loss1 : 1.506464, loss2 : 1.673619
train_step : 23747, loss1 : 2.554778, loss2 : 1.977067
train_step : 23748, loss1 : 2.609275, loss2 : 2.809875
train_step : 23749, loss1 : 2.883158, loss2 : 2.426874
train_step : 23750, loss1 : 1.876330, loss2 : 2.613758
train_step : 23751, loss1 : 2.334719, loss2 : 3.122513
train_step : 23752, loss1 : 1.701152, loss2 : 2.536671
train_step : 23753, loss1 : 1.996919, loss2 : 2.079864
train_step : 23754, loss1 : 1.406646, loss2 : 0.350379
train_step : 23755, loss1 : 0.917374, loss2 : 1.425954
train_step : 23756, loss1 : 1.277955, loss2 : 0.867347
train_step : 23757, loss1 : 0.933702, loss2 : 1.900248
train_step : 23758, loss1 : 0.439856, loss2 : 2.524552
train_step : 23759, loss1 : 1.203135, loss2 : 0.675751
train_step : 23760, loss1 : 0.961640, loss2 : 0.484571
train_step : 23761, loss1 : 1.128529, loss2 : 0.906383
train_step : 23762, loss1 : 1.427505, loss2 : 2.364330
train_step : 23763, loss1 : 2.109975, loss2 : 2.455705
train_step : 23764, loss1 : 2.642882, loss2 : 1.135408
train_step : 23765, loss1 : 1.233300, loss2 : 2.567302
train_step : 23766, loss1 : 2.050797, loss2 : 1.590128
train_step : 23767, loss1 : 1.736003, loss2 : 1.195073
train_step : 23768, loss1 : 1.593651, loss2 : 0.991386
train_step : 23769, loss1 : 0.752666, loss2 : 1.556882
train_step : 23770, loss1 : 1.209146, loss2 : 1.110616
train_step : 23771, loss1 : 1.383616, loss2 : 1.656999
train_step : 23772, loss1 : 1.793118, loss2 : 0.557861
train_step : 23773, loss1 : 3.006715, loss2 : 0.738495
train_step : 23774, loss1 : 1.236491, loss2 : 1.136472
train_step : 23775, loss1 : 0.814863, loss2 : 1.036880
train_step : 23776, loss1 : 0.593301, loss2 : 0.895634
train_step : 23777, loss1 : 1.025823, loss2 : 1.128147
train_step : 23778, loss1 : 1.634911, loss2 : 0.823580
train_step : 23779, loss1 : 1.327386, loss2 : 1.178832
train_step : 23780, loss1 : 1.386870, loss2 : 0.987401
train_step : 23781, loss1 : 0.513839, loss2 : 1.353166
train_step : 23782, loss1 : 1.384337, loss2 : 1.327592
train_step : 23783, loss1 : 0.838946, loss2 : 1.402856
train_step : 23784, loss1 : 0.989594, loss2 : 0.938206
train_step : 23785, loss1 : 1.132796, loss2 : 1.068364
train_step : 23786, loss1 : 0.964142, loss2 : 2.276011
train_step : 23787, loss1 : 1.444323, loss2 : 1.460965
train_step : 23788, loss1 : 1.149221, loss2 : 1.133633
train_step : 23789, loss1 : 1.674535, loss2 : 0.710331
train_step : 23790, loss1 : 0.862455, loss2 : 0.998631
train_step : 23791, loss1 : 1.053506, loss2 : 1.035894
train_step : 23792, loss1 : 1.201428, loss2 : 1.789786
train_step : 23793, loss1 : 0.841628, loss2 : 1.129473
train_step : 23794, loss1 : 0.841922, loss2 : 1.228311
train_step : 23795, loss1 : 0.900267, loss2 : 1.874795
train_step : 23796, loss1 : 1.342146, loss2 : 1.602987
train_step : 23797, loss1 : 1.470236, loss2 : 1.211175
train_step : 23798, loss1 : 0.801876, loss2 : 1.480899
train_step : 23799, loss1 : 1.656048, loss2 : 1.198623
train_step : 23800, loss1 : 0.981920, loss2 : 1.311028
train_step : 23801, loss1 : 1.553074, loss2 : 1.182891
train_step : 23802, loss1 : 1.076645, loss2 : 1.362004
train_step : 23803, loss1 : 1.166121, loss2 : 0.966740
train_step : 23804, loss1 : 1.643120, loss2 : 0.871522
train_step : 23805, loss1 : 1.033559, loss2 : 1.282887
train_step : 23806, loss1 : 1.643925, loss2 : 1.887464
train_step : 23807, loss1 : 1.090245, loss2 : 2.491640
train_step : 23808, loss1 : 1.240691, loss2 : 0.917978
train_step : 23809, loss1 : 0.594682, loss2 : 1.075062
train_step : 23810, loss1 : 0.673787, loss2 : 1.078243
train_step : 23811, loss1 : 0.730166, loss2 : 1.592427
train_step : 23812, loss1 : 1.156953, loss2 : 1.253784
train_step : 23813, loss1 : 2.051393, loss2 : 1.041998
train_step : 23814, loss1 : 1.493243, loss2 : 1.538929
train_step : 23815, loss1 : 2.197423, loss2 : 2.176480
train_step : 23816, loss1 : 2.323193, loss2 : 2.255307
train_step : 23817, loss1 : 2.662074, loss2 : 1.941768
train_step : 23818, loss1 : 2.183846, loss2 : 1.975911
train_step : 23819, loss1 : 1.586725, loss2 : 2.036285
train_step : 23820, loss1 : 1.203017, loss2 : 0.862312
train_step : 23821, loss1 : 0.799122, loss2 : 0.637771
train_step : 23822, loss1 : 3.181557, loss2 : 0.672407
train_step : 23823, loss1 : 0.929788, loss2 : 1.143803
train_step : 23824, loss1 : 1.621847, loss2 : 0.960865
train_step : 23825, loss1 : 0.402298, loss2 : 0.723158
train_step : 23826, loss1 : 0.566238, loss2 : 1.114193
train_step : 23827, loss1 : 1.202629, loss2 : 1.418204
train_step : 23828, loss1 : 1.271632, loss2 : 0.940791
train_step : 23829, loss1 : 1.103320, loss2 : 0.809886
train_step : 23830, loss1 : 1.204141, loss2 : 0.726895
train_step : 23831, loss1 : 1.362074, loss2 : 0.819187
train_step : 23832, loss1 : 1.490613, loss2 : 0.509634
train_step : 23833, loss1 : 1.210591, loss2 : 0.692091
train_step : 23834, loss1 : 1.212638, loss2 : 0.775851
train_step : 23835, loss1 : 2.053258, loss2 : 1.926767
train_step : 23836, loss1 : 2.137415, loss2 : 1.570013
train_step : 23837, loss1 : 1.635267, loss2 : 1.286015
train_step : 23838, loss1 : 1.976155, loss2 : 1.820735
train_step : 23839, loss1 : 1.513481, loss2 : 1.634913
train_step : 23840, loss1 : 1.389252, loss2 : 1.116606
train_step : 23841, loss1 : 1.361781, loss2 : 1.403005
train_step : 23842, loss1 : 1.720867, loss2 : 0.845153
train_step : 23843, loss1 : 0.958970, loss2 : 2.187850
train_step : 23844, loss1 : 0.903135, loss2 : 0.842416
train_step : 23845, loss1 : 0.915932, loss2 : 2.014023
train_step : 23846, loss1 : 0.951046, loss2 : 1.293677
train_step : 23847, loss1 : 1.907343, loss2 : 2.953087
train_step : 23848, loss1 : 1.906752, loss2 : 1.971306
train_step : 23849, loss1 : 2.453180, loss2 : 1.681739
train_step : 23850, loss1 : 2.394723, loss2 : 2.701262
train_step : 23851, loss1 : 2.106821, loss2 : 1.935363
train_step : 23852, loss1 : 1.381550, loss2 : 1.677683
train_step : 23853, loss1 : 1.338271, loss2 : 1.164725
train_step : 23854, loss1 : 1.517689, loss2 : 1.868278
train_step : 23855, loss1 : 1.652348, loss2 : 2.215067
train_step : 23856, loss1 : 2.603245, loss2 : 2.148878
train_step : 23857, loss1 : 4.274700, loss2 : 3.885583
train_step : 23858, loss1 : 1.983634, loss2 : 2.902369
train_step : 23859, loss1 : 0.792443, loss2 : 1.684316
train_step : 23860, loss1 : 2.095096, loss2 : 2.507623
train_step : 23861, loss1 : 1.736344, loss2 : 0.862985
train_step : 23862, loss1 : 0.988666, loss2 : 0.769274
train_step : 23863, loss1 : 0.887413, loss2 : 0.960511
train_step : 23864, loss1 : 1.277884, loss2 : 0.899015
train_step : 23865, loss1 : 0.277974, loss2 : 0.634935
train_step : 23866, loss1 : 0.645424, loss2 : 1.319791
train_step : 23867, loss1 : 1.666217, loss2 : 1.457036
train_step : 23868, loss1 : 1.375557, loss2 : 0.814238
train_step : 23869, loss1 : 0.779443, loss2 : 1.792441
train_step : 23870, loss1 : 0.918156, loss2 : 1.006083
train_step : 23871, loss1 : 1.101352, loss2 : 1.224963
train_step : 23872, loss1 : 1.167235, loss2 : 1.515912
train_step : 23873, loss1 : 1.036870, loss2 : 0.697793
train_step : 23874, loss1 : 0.778683, loss2 : 2.185926
train_step : 23875, loss1 : 1.163120, loss2 : 1.145202
train_step : 23876, loss1 : 0.773286, loss2 : 1.669683
train_step : 23877, loss1 : 0.981154, loss2 : 0.772339
train_step : 23878, loss1 : 1.416920, loss2 : 0.965578
train_step : 23879, loss1 : 1.004059, loss2 : 0.918717
train_step : 23880, loss1 : 0.650162, loss2 : 0.665992
train_step : 23881, loss1 : 1.298562, loss2 : 0.788129
train_step : 23882, loss1 : 0.390060, loss2 : 1.008910
train_step : 23883, loss1 : 0.817147, loss2 : 0.877191
train_step : 23884, loss1 : 0.922630, loss2 : 1.807792
train_step : 23885, loss1 : 1.243556, loss2 : 1.439569
train_step : 23886, loss1 : 0.938026, loss2 : 0.476171
train_step : 23887, loss1 : 2.012467, loss2 : 1.518539
train_step : 23888, loss1 : 1.512874, loss2 : 1.101833
train_step : 23889, loss1 : 0.972592, loss2 : 1.026928
train_step : 23890, loss1 : 0.813010, loss2 : 2.333464
train_step : 23891, loss1 : 1.778428, loss2 : 1.943614
train_step : 23892, loss1 : 1.462813, loss2 : 1.097376
train_step : 23893, loss1 : 1.599065, loss2 : 1.482673
train_step : 23894, loss1 : 1.335028, loss2 : 2.936338
train_step : 23895, loss1 : 2.085184, loss2 : 1.442525
train_step : 23896, loss1 : 1.241659, loss2 : 1.859774
train_step : 23897, loss1 : 2.572437, loss2 : 2.151193
train_step : 23898, loss1 : 1.253142, loss2 : 3.356342
train_step : 23899, loss1 : 1.041740, loss2 : 0.836913
train_step : 23900, loss1 : 1.700144, loss2 : 1.086619
train_step : 23901, loss1 : 1.727271, loss2 : 0.707603
train_step : 23902, loss1 : 1.174232, loss2 : 1.618786
train_step : 23903, loss1 : 2.205378, loss2 : 1.947569
train_step : 23904, loss1 : 2.130049, loss2 : 1.865643
train_step : 23905, loss1 : 1.311768, loss2 : 3.019064
train_step : 23906, loss1 : 2.995696, loss2 : 3.153084
train_step : 23907, loss1 : 2.890282, loss2 : 2.850668
train_step : 23908, loss1 : 5.095877, loss2 : 3.860188
train_step : 23909, loss1 : 2.584011, loss2 : 2.891957
train_step : 23910, loss1 : 2.880324, loss2 : 2.228068
train_step : 23911, loss1 : 2.130936, loss2 : 1.822420
train_step : 23912, loss1 : 2.918547, loss2 : 2.830118
train_step : 23913, loss1 : 1.950224, loss2 : 1.528045
train_step : 23914, loss1 : 1.421782, loss2 : 1.429716
train_step : 23915, loss1 : 1.924640, loss2 : 0.979759
train_step : 23916, loss1 : 1.954101, loss2 : 1.605509
train_step : 23917, loss1 : 2.269400, loss2 : 1.826395
train_step : 23918, loss1 : 1.490159, loss2 : 3.211282
train_step : 23919, loss1 : 2.300172, loss2 : 1.366207
train_step : 23920, loss1 : 1.589804, loss2 : 0.787173
train_step : 23921, loss1 : 1.302784, loss2 : 1.387969
train_step : 23922, loss1 : 1.282077, loss2 : 1.352950
train_step : 23923, loss1 : 1.389978, loss2 : 1.535241
train_step : 23924, loss1 : 1.679892, loss2 : 1.718681
train_step : 23925, loss1 : 1.043401, loss2 : 0.745681
train_step : 23926, loss1 : 0.982058, loss2 : 1.113382
train_step : 23927, loss1 : 0.908513, loss2 : 1.708548
train_step : 23928, loss1 : 0.651335, loss2 : 1.686518
train_step : 23929, loss1 : 1.519717, loss2 : 1.018368
train_step : 23930, loss1 : 1.072290, loss2 : 0.730473
train_step : 23931, loss1 : 0.838600, loss2 : 1.220890
train_step : 23932, loss1 : 1.199738, loss2 : 1.516728
train_step : 23933, loss1 : 1.266597, loss2 : 1.031069
train_step : 23934, loss1 : 2.135561, loss2 : 1.233965
train_step : 23935, loss1 : 2.210447, loss2 : 1.406397
train_step : 23936, loss1 : 1.854827, loss2 : 1.020703
train_step : 23937, loss1 : 1.957431, loss2 : 1.834480
train_step : 23938, loss1 : 2.763977, loss2 : 1.516022
train_step : 23939, loss1 : 3.066377, loss2 : 2.646061
train_step : 23940, loss1 : 1.426326, loss2 : 1.714281
train_step : 23941, loss1 : 1.859662, loss2 : 1.683938
train_step : 23942, loss1 : 2.042389, loss2 : 1.657321
train_step : 23943, loss1 : 1.324334, loss2 : 2.129717
train_step : 23944, loss1 : 1.665077, loss2 : 1.088637
train_step : 23945, loss1 : 1.996221, loss2 : 2.115497
train_step : 23946, loss1 : 1.624051, loss2 : 2.864790
train_step : 23947, loss1 : 1.759545, loss2 : 1.693005
train_step : 23948, loss1 : 1.315498, loss2 : 2.611356
train_step : 23949, loss1 : 1.062679, loss2 : 1.015220
train_step : 23950, loss1 : 1.364576, loss2 : 1.805974
train_step : 23951, loss1 : 1.701437, loss2 : 1.465523
train_step : 23952, loss1 : 0.809866, loss2 : 1.936806
train_step : 23953, loss1 : 2.163204, loss2 : 1.370558
train_step : 23954, loss1 : 0.707679, loss2 : 0.961586
train_step : 23955, loss1 : 0.798071, loss2 : 1.480414
train_step : 23956, loss1 : 1.708059, loss2 : 1.049745
train_step : 23957, loss1 : 0.894048, loss2 : 1.465701
train_step : 23958, loss1 : 1.022517, loss2 : 1.278009
train_step : 23959, loss1 : 1.651237, loss2 : 1.596307
train_step : 23960, loss1 : 1.847689, loss2 : 1.642144
train_step : 23961, loss1 : 1.815311, loss2 : 1.629787
train_step : 23962, loss1 : 1.281717, loss2 : 0.915629
train_step : 23963, loss1 : 1.032398, loss2 : 1.121713
train_step : 23964, loss1 : 1.770290, loss2 : 0.945115
train_step : 23965, loss1 : 0.703186, loss2 : 0.940886
train_step : 23966, loss1 : 0.974232, loss2 : 0.616278
train_step : 23967, loss1 : 2.168649, loss2 : 1.338409
train_step : 23968, loss1 : 1.056743, loss2 : 1.972849
train_step : 23969, loss1 : 1.460654, loss2 : 2.169894
train_step : 23970, loss1 : 1.151014, loss2 : 1.385538
train_step : 23971, loss1 : 1.385183, loss2 : 1.566831
train_step : 23972, loss1 : 1.026772, loss2 : 1.222669
train_step : 23973, loss1 : 1.336744, loss2 : 1.000834
train_step : 23974, loss1 : 1.304069, loss2 : 1.067068
train_step : 23975, loss1 : 1.493611, loss2 : 0.862422
train_step : 23976, loss1 : 1.133139, loss2 : 0.939385
train_step : 23977, loss1 : 0.769084, loss2 : 0.937743
train_step : 23978, loss1 : 0.625828, loss2 : 1.407995
train_step : 23979, loss1 : 1.827274, loss2 : 1.759746
train_step : 23980, loss1 : 0.625207, loss2 : 1.115889
train_step : 23981, loss1 : 1.423900, loss2 : 0.734931
train_step : 23982, loss1 : 0.992657, loss2 : 1.182741
train_step : 23983, loss1 : 0.835517, loss2 : 1.317088
train_step : 23984, loss1 : 1.557667, loss2 : 0.679126
train_step : 23985, loss1 : 0.937099, loss2 : 1.214038
train_step : 23986, loss1 : 1.206141, loss2 : 1.061718
train_step : 23987, loss1 : 2.127859, loss2 : 1.846184
train_step : 23988, loss1 : 0.983090, loss2 : 1.524600
train_step : 23989, loss1 : 0.899566, loss2 : 1.718313
train_step : 23990, loss1 : 0.720512, loss2 : 1.282017
train_step : 23991, loss1 : 1.173815, loss2 : 1.104818
train_step : 23992, loss1 : 0.991250, loss2 : 2.477523
train_step : 23993, loss1 : 1.178180, loss2 : 0.952903
train_step : 23994, loss1 : 1.109223, loss2 : 1.111904
train_step : 23995, loss1 : 1.197673, loss2 : 1.736552
train_step : 23996, loss1 : 2.091644, loss2 : 2.300575
train_step : 23997, loss1 : 2.721534, loss2 : 1.782073
train_step : 23998, loss1 : 1.628848, loss2 : 0.847699
train_step : 23999, loss1 : 1.700069, loss2 : 1.697083
train_step : 24000, loss1 : 1.617293, loss2 : 1.545938
train_step : 24001, loss1 : 2.564444, loss2 : 1.216254
train_step : 24002, loss1 : 3.929330, loss2 : 0.720261
train_step : 24003, loss1 : 1.136698, loss2 : 1.383841
train_step : 24004, loss1 : 1.529206, loss2 : 0.653994
train_step : 24005, loss1 : 3.044059, loss2 : 4.730141
train_step : 24006, loss1 : 0.850104, loss2 : 1.331112
train_step : 24007, loss1 : 0.663572, loss2 : 1.348999
train_step : 24008, loss1 : 0.489234, loss2 : 1.587678
train_step : 24009, loss1 : 0.691461, loss2 : 1.165310
train_step : 24010, loss1 : 1.032291, loss2 : 0.946890
train_step : 24011, loss1 : 1.359694, loss2 : 1.339293
train_step : 24012, loss1 : 0.792728, loss2 : 1.056921
train_step : 24013, loss1 : 0.807997, loss2 : 1.267976
train_step : 24014, loss1 : 2.865807, loss2 : 1.253057
train_step : 24015, loss1 : 1.279777, loss2 : 1.230010
train_step : 24016, loss1 : 1.803808, loss2 : 0.583595
train_step : 24017, loss1 : 1.166974, loss2 : 1.040277
train_step : 24018, loss1 : 1.377598, loss2 : 1.273011
train_step : 24019, loss1 : 1.650354, loss2 : 1.226472
train_step : 24020, loss1 : 1.504514, loss2 : 1.301626
train_step : 24021, loss1 : 3.120341, loss2 : 1.144951
train_step : 24022, loss1 : 1.958322, loss2 : 1.027378
train_step : 24023, loss1 : 1.209607, loss2 : 1.502858
train_step : 24024, loss1 : 1.232663, loss2 : 1.511935
train_step : 24025, loss1 : 1.835979, loss2 : 2.103435
train_step : 24026, loss1 : 2.072455, loss2 : 2.452506
train_step : 24027, loss1 : 1.969626, loss2 : 1.331253
train_step : 24028, loss1 : 1.398132, loss2 : 1.031863
train_step : 24029, loss1 : 1.937609, loss2 : 1.842715
train_step : 24030, loss1 : 1.736995, loss2 : 2.469182
train_step : 24031, loss1 : 4.751730, loss2 : 2.014065
train_step : 24032, loss1 : 1.537013, loss2 : 1.869850
train_step : 24033, loss1 : 3.076365, loss2 : 2.041454
train_step : 24034, loss1 : 2.063990, loss2 : 1.056410
train_step : 24035, loss1 : 2.240275, loss2 : 1.801571
train_step : 24036, loss1 : 2.696776, loss2 : 2.387078
train_step : 24037, loss1 : 2.614695, loss2 : 2.215922
train_step : 24038, loss1 : 0.693664, loss2 : 1.440547
train_step : 24039, loss1 : 1.273016, loss2 : 0.839567
train_step : 24040, loss1 : 0.835788, loss2 : 0.828532
train_step : 24041, loss1 : 0.721068, loss2 : 0.761122
train_step : 24042, loss1 : 0.921929, loss2 : 0.948184
train_step : 24043, loss1 : 1.456171, loss2 : 2.081946
train_step : 24044, loss1 : 1.107885, loss2 : 1.557742
train_step : 24045, loss1 : 1.540706, loss2 : 0.906530
train_step : 24046, loss1 : 1.035111, loss2 : 1.016778
train_step : 24047, loss1 : 1.431885, loss2 : 0.975732
train_step : 24048, loss1 : 1.447809, loss2 : 1.255639
train_step : 24049, loss1 : 0.760659, loss2 : 1.227436
train_step : 24050, loss1 : 0.858128, loss2 : 1.238341
train_step : 24051, loss1 : 1.051657, loss2 : 1.124118
train_step : 24052, loss1 : 0.613460, loss2 : 0.906573
train_step : 24053, loss1 : 1.328944, loss2 : 0.982015
train_step : 24054, loss1 : 1.052501, loss2 : 1.183221
train_step : 24055, loss1 : 0.587941, loss2 : 1.237794
train_step : 24056, loss1 : 0.867253, loss2 : 1.438530
train_step : 24057, loss1 : 1.066209, loss2 : 1.211714
train_step : 24058, loss1 : 1.488586, loss2 : 1.762876
train_step : 24059, loss1 : 1.203305, loss2 : 1.737009
train_step : 24060, loss1 : 2.187976, loss2 : 1.191521
train_step : 24061, loss1 : 1.307270, loss2 : 1.071089
train_step : 24062, loss1 : 2.115849, loss2 : 1.210456
train_step : 24063, loss1 : 2.056685, loss2 : 1.096812
train_step : 24064, loss1 : 0.912284, loss2 : 1.688140
train_step : 24065, loss1 : 1.195861, loss2 : 1.700977
train_step : 24066, loss1 : 1.473597, loss2 : 2.404387
train_step : 24067, loss1 : 2.189532, loss2 : 1.673029
train_step : 24068, loss1 : 1.891780, loss2 : 2.360257
train_step : 24069, loss1 : 4.660239, loss2 : 2.319021
train_step : 24070, loss1 : 3.046251, loss2 : 3.014340
train_step : 24071, loss1 : 2.926631, loss2 : 4.905472
train_step : 24072, loss1 : 4.487043, loss2 : 4.730464
train_step : 24073, loss1 : 1.944576, loss2 : 1.489549
train_step : 24074, loss1 : 1.566455, loss2 : 1.704046
train_step : 24075, loss1 : 1.190028, loss2 : 0.809237
train_step : 24076, loss1 : 1.358054, loss2 : 2.090261
train_step : 24077, loss1 : 1.784021, loss2 : 0.651566
train_step : 24078, loss1 : 1.054644, loss2 : 2.062205
train_step : 24079, loss1 : 1.120328, loss2 : 1.306509
train_step : 24080, loss1 : 0.987271, loss2 : 1.758770
train_step : 24081, loss1 : 0.835712, loss2 : 0.395318
train_step : 24082, loss1 : 1.480109, loss2 : 1.184263
train_step : 24083, loss1 : 1.034911, loss2 : 1.511944
train_step : 24084, loss1 : 1.035721, loss2 : 1.343535
train_step : 24085, loss1 : 1.322900, loss2 : 0.594723
train_step : 24086, loss1 : 1.563692, loss2 : 1.426958
train_step : 24087, loss1 : 1.662845, loss2 : 0.639776
train_step : 24088, loss1 : 0.806853, loss2 : 1.072296
train_step : 24089, loss1 : 0.704696, loss2 : 1.240495
train_step : 24090, loss1 : 1.504800, loss2 : 1.117231
train_step : 24091, loss1 : 1.135189, loss2 : 1.745096
train_step : 24092, loss1 : 1.186324, loss2 : 1.104571
train_step : 24093, loss1 : 1.129405, loss2 : 1.577682
train_step : 24094, loss1 : 1.589441, loss2 : 2.512957
train_step : 24095, loss1 : 1.039507, loss2 : 1.267657
train_step : 24096, loss1 : 1.534429, loss2 : 1.416242
train_step : 24097, loss1 : 1.482753, loss2 : 1.771107
train_step : 24098, loss1 : 2.030070, loss2 : 2.327164
train_step : 24099, loss1 : 2.230953, loss2 : 2.205101
train_step : 24100, loss1 : 2.310123, loss2 : 1.809779
train_step : 24101, loss1 : 1.928550, loss2 : 2.169241
train_step : 24102, loss1 : 2.673743, loss2 : 1.295219
train_step : 24103, loss1 : 1.684019, loss2 : 1.460721
train_step : 24104, loss1 : 0.868889, loss2 : 1.231431
train_step : 24105, loss1 : 0.739908, loss2 : 0.769230
train_step : 24106, loss1 : 1.192615, loss2 : 1.742950
train_step : 24107, loss1 : 1.256445, loss2 : 1.315763
train_step : 24108, loss1 : 1.776641, loss2 : 2.102055
train_step : 24109, loss1 : 1.080802, loss2 : 1.435890
train_step : 24110, loss1 : 0.769122, loss2 : 0.965693
train_step : 24111, loss1 : 0.866315, loss2 : 0.730843
train_step : 24112, loss1 : 0.852732, loss2 : 1.386939
train_step : 24113, loss1 : 1.446725, loss2 : 0.951965
train_step : 24114, loss1 : 0.803019, loss2 : 1.141533
train_step : 24115, loss1 : 0.752897, loss2 : 0.794521
train_step : 24116, loss1 : 1.716203, loss2 : 0.574165
train_step : 24117, loss1 : 1.243295, loss2 : 1.426785
train_step : 24118, loss1 : 1.305693, loss2 : 0.965190
train_step : 24119, loss1 : 0.770943, loss2 : 1.066112
train_step : 24120, loss1 : 1.200632, loss2 : 1.127146
train_step : 24121, loss1 : 1.378543, loss2 : 0.708324
train_step : 24122, loss1 : 1.266930, loss2 : 1.437150
train_step : 24123, loss1 : 0.868611, loss2 : 0.816289
train_step : 24124, loss1 : 1.417299, loss2 : 1.286890
train_step : 24125, loss1 : 2.673151, loss2 : 1.659483
train_step : 24126, loss1 : 1.137960, loss2 : 1.625803
train_step : 24127, loss1 : 1.071750, loss2 : 1.504048
train_step : 24128, loss1 : 1.381651, loss2 : 1.145642
train_step : 24129, loss1 : 0.751782, loss2 : 0.749426
train_step : 24130, loss1 : 1.491477, loss2 : 0.934112
train_step : 24131, loss1 : 1.676994, loss2 : 1.022957
train_step : 24132, loss1 : 0.812021, loss2 : 1.738972
train_step : 24133, loss1 : 0.797569, loss2 : 1.958366
train_step : 24134, loss1 : 1.403184, loss2 : 0.872766
train_step : 24135, loss1 : 1.599215, loss2 : 0.805679
train_step : 24136, loss1 : 0.812741, loss2 : 0.826946
train_step : 24137, loss1 : 1.525708, loss2 : 1.525166
train_step : 24138, loss1 : 1.707700, loss2 : 1.597562
train_step : 24139, loss1 : 1.090353, loss2 : 1.789283
train_step : 24140, loss1 : 1.245879, loss2 : 1.172540
train_step : 24141, loss1 : 1.302284, loss2 : 0.647388
train_step : 24142, loss1 : 1.309411, loss2 : 1.231246
train_step : 24143, loss1 : 0.716222, loss2 : 1.293738
train_step : 24144, loss1 : 1.476180, loss2 : 2.024650
train_step : 24145, loss1 : 0.957965, loss2 : 0.847531
train_step : 24146, loss1 : 0.619183, loss2 : 1.145806
train_step : 24147, loss1 : 1.338060, loss2 : 1.033205
train_step : 24148, loss1 : 1.659122, loss2 : 1.027962
train_step : 24149, loss1 : 3.772573, loss2 : 2.097805
train_step : 24150, loss1 : 3.470699, loss2 : 2.697151
train_step : 24151, loss1 : 1.796363, loss2 : 2.778015
train_step : 24152, loss1 : 2.190158, loss2 : 2.727067
train_step : 24153, loss1 : 1.751148, loss2 : 1.527556
train_step : 24154, loss1 : 1.388672, loss2 : 1.660983
train_step : 24155, loss1 : 1.861653, loss2 : 1.386260
train_step : 24156, loss1 : 1.635306, loss2 : 1.404026
train_step : 24157, loss1 : 1.938351, loss2 : 0.685612
train_step : 24158, loss1 : 0.779842, loss2 : 0.931635
train_step : 24159, loss1 : 0.998613, loss2 : 1.564779
train_step : 24160, loss1 : 1.819446, loss2 : 1.000743
train_step : 24161, loss1 : 1.256552, loss2 : 1.353457
train_step : 24162, loss1 : 0.966003, loss2 : 0.885451
train_step : 24163, loss1 : 1.357942, loss2 : 0.465399
train_step : 24164, loss1 : 0.959495, loss2 : 0.874357
train_step : 24165, loss1 : 1.225212, loss2 : 0.923724
train_step : 24166, loss1 : 1.964297, loss2 : 1.930465
train_step : 24167, loss1 : 1.892596, loss2 : 1.164647
train_step : 24168, loss1 : 2.239486, loss2 : 1.722711
train_step : 24169, loss1 : 1.654846, loss2 : 2.178166
train_step : 24170, loss1 : 1.151808, loss2 : 2.396848
train_step : 24171, loss1 : 2.285743, loss2 : 2.783642
train_step : 24172, loss1 : 1.798151, loss2 : 3.635969
train_step : 24173, loss1 : 3.078602, loss2 : 2.181058
train_step : 24174, loss1 : 2.212195, loss2 : 2.533191
train_step : 24175, loss1 : 1.038618, loss2 : 1.111081
train_step : 24176, loss1 : 1.039054, loss2 : 1.151114
train_step : 24177, loss1 : 1.463947, loss2 : 1.115626
train_step : 24178, loss1 : 1.189340, loss2 : 0.604484
train_step : 24179, loss1 : 1.283541, loss2 : 1.124956
train_step : 24180, loss1 : 1.101435, loss2 : 1.329512
train_step : 24181, loss1 : 1.047655, loss2 : 1.315383
train_step : 24182, loss1 : 1.325112, loss2 : 0.829397
train_step : 24183, loss1 : 1.208476, loss2 : 1.289119
train_step : 24184, loss1 : 1.311999, loss2 : 0.985309
train_step : 24185, loss1 : 1.896747, loss2 : 1.692518
train_step : 24186, loss1 : 1.171575, loss2 : 1.258497
train_step : 24187, loss1 : 0.986320, loss2 : 1.163556
train_step : 24188, loss1 : 1.177336, loss2 : 0.542597
train_step : 24189, loss1 : 1.003786, loss2 : 1.187728
train_step : 24190, loss1 : 0.962204, loss2 : 1.554756
train_step : 24191, loss1 : 0.745042, loss2 : 1.371844
train_step : 24192, loss1 : 1.329610, loss2 : 1.170155
train_step : 24193, loss1 : 0.883478, loss2 : 0.902778
train_step : 24194, loss1 : 0.910612, loss2 : 0.955880
train_step : 24195, loss1 : 0.828480, loss2 : 1.462846
train_step : 24196, loss1 : 1.031181, loss2 : 1.430993
train_step : 24197, loss1 : 0.924005, loss2 : 0.730954
train_step : 24198, loss1 : 1.556492, loss2 : 1.358523
train_step : 24199, loss1 : 1.525759, loss2 : 0.823429
train_step : 24200, loss1 : 1.707685, loss2 : 1.920141
train_step : 24201, loss1 : 1.843107, loss2 : 2.225915
train_step : 24202, loss1 : 3.250694, loss2 : 2.654981
train_step : 24203, loss1 : 2.735360, loss2 : 2.649056
train_step : 24204, loss1 : 1.896667, loss2 : 1.907971
train_step : 24205, loss1 : 2.201907, loss2 : 1.879156
train_step : 24206, loss1 : 1.931540, loss2 : 1.196718
train_step : 24207, loss1 : 1.099385, loss2 : 1.675724
train_step : 24208, loss1 : 0.707252, loss2 : 0.829289
train_step : 24209, loss1 : 1.420811, loss2 : 1.001778
train_step : 24210, loss1 : 0.896498, loss2 : 0.744609
train_step : 24211, loss1 : 0.833645, loss2 : 0.953865
train_step : 24212, loss1 : 1.188114, loss2 : 0.636101
train_step : 24213, loss1 : 1.095464, loss2 : 0.803105
train_step : 24214, loss1 : 0.672173, loss2 : 1.061668
train_step : 24215, loss1 : 1.170713, loss2 : 0.833004
train_step : 24216, loss1 : 0.857109, loss2 : 0.798265
train_step : 24217, loss1 : 2.166544, loss2 : 1.243349
train_step : 24218, loss1 : 1.723205, loss2 : 1.479218
train_step : 24219, loss1 : 2.644599, loss2 : 1.712373
train_step : 24220, loss1 : 2.241313, loss2 : 3.238109
train_step : 24221, loss1 : 3.585484, loss2 : 2.861611
train_step : 24222, loss1 : 2.856121, loss2 : 3.112960
train_step : 24223, loss1 : 1.957762, loss2 : 1.408535
train_step : 24224, loss1 : 2.192950, loss2 : 2.228426
train_step : 24225, loss1 : 4.563634, loss2 : 2.841980
train_step : 24226, loss1 : 6.858943, loss2 : 5.815306
train_step : 24227, loss1 : 2.409065, loss2 : 5.973602
train_step : 24228, loss1 : 4.441770, loss2 : 2.477177
train_step : 24229, loss1 : 1.255506, loss2 : 2.104990
train_step : 24230, loss1 : 1.964008, loss2 : 1.867056
train_step : 24231, loss1 : 2.074945, loss2 : 2.235556
train_step : 24232, loss1 : 1.039175, loss2 : 1.139588
train_step : 24233, loss1 : 1.490630, loss2 : 0.770048
train_step : 24234, loss1 : 1.482812, loss2 : 1.114794
train_step : 24235, loss1 : 1.322244, loss2 : 0.695575
train_step : 24236, loss1 : 1.179081, loss2 : 1.322795
train_step : 24237, loss1 : 1.850662, loss2 : 2.147285
train_step : 24238, loss1 : 1.617224, loss2 : 1.710478
train_step : 24239, loss1 : 1.151672, loss2 : 2.870672
train_step : 24240, loss1 : 2.677960, loss2 : 1.764973
train_step : 24241, loss1 : 2.017952, loss2 : 2.084158
train_step : 24242, loss1 : 3.284476, loss2 : 2.518067
train_step : 24243, loss1 : 2.435706, loss2 : 3.032682
train_step : 24244, loss1 : 2.815618, loss2 : 4.228571
train_step : 24245, loss1 : 1.749672, loss2 : 1.866904
train_step : 24246, loss1 : 2.130023, loss2 : 1.994666
train_step : 24247, loss1 : 0.959973, loss2 : 1.085537
train_step : 24248, loss1 : 1.290709, loss2 : 0.482997
train_step : 24249, loss1 : 0.480869, loss2 : 1.308298
train_step : 24250, loss1 : 1.207986, loss2 : 1.489230
train_step : 24251, loss1 : 1.135959, loss2 : 1.351707
train_step : 24252, loss1 : 1.080778, loss2 : 1.677593
train_step : 24253, loss1 : 0.973115, loss2 : 0.578692
train_step : 24254, loss1 : 1.701811, loss2 : 0.739108
train_step : 24255, loss1 : 0.857931, loss2 : 1.073831
train_step : 24256, loss1 : 0.683680, loss2 : 1.964287
train_step : 24257, loss1 : 1.515448, loss2 : 0.805102
train_step : 24258, loss1 : 0.762745, loss2 : 3.363010
train_step : 24259, loss1 : 0.763808, loss2 : 0.734175
train_step : 24260, loss1 : 1.052867, loss2 : 1.239982
train_step : 24261, loss1 : 1.222963, loss2 : 0.850765
train_step : 24262, loss1 : 1.104614, loss2 : 1.058103
train_step : 24263, loss1 : 1.384706, loss2 : 1.743790
train_step : 24264, loss1 : 1.556851, loss2 : 1.693689
train_step : 24265, loss1 : 2.324653, loss2 : 1.378053
train_step : 24266, loss1 : 1.445253, loss2 : 1.330888
train_step : 24267, loss1 : 1.136152, loss2 : 2.912481
train_step : 24268, loss1 : 0.937347, loss2 : 0.998100
train_step : 24269, loss1 : 0.825554, loss2 : 0.572133
train_step : 24270, loss1 : 0.705170, loss2 : 0.996531
train_step : 24271, loss1 : 1.000146, loss2 : 1.207227
train_step : 24272, loss1 : 0.579589, loss2 : 2.058693
train_step : 24273, loss1 : 0.843885, loss2 : 0.923614
train_step : 24274, loss1 : 1.166245, loss2 : 2.118452
train_step : 24275, loss1 : 1.256153, loss2 : 1.855412
train_step : 24276, loss1 : 0.964426, loss2 : 1.586334
train_step : 24277, loss1 : 1.618672, loss2 : 1.934686
train_step : 24278, loss1 : 1.906032, loss2 : 2.101348
train_step : 24279, loss1 : 2.203831, loss2 : 1.670142
train_step : 24280, loss1 : 3.578588, loss2 : 0.871825
train_step : 24281, loss1 : 1.909167, loss2 : 1.791201
train_step : 24282, loss1 : 0.449988, loss2 : 1.391667
train_step : 24283, loss1 : 1.368775, loss2 : 1.407511
train_step : 24284, loss1 : 1.448248, loss2 : 1.616718
train_step : 24285, loss1 : 1.396278, loss2 : 0.881708
train_step : 24286, loss1 : 1.713331, loss2 : 0.710663
train_step : 24287, loss1 : 1.228704, loss2 : 0.692595
train_step : 24288, loss1 : 1.046301, loss2 : 1.802019
train_step : 24289, loss1 : 1.323596, loss2 : 0.989314
train_step : 24290, loss1 : 1.451761, loss2 : 0.544733
train_step : 24291, loss1 : 0.795931, loss2 : 1.353901
train_step : 24292, loss1 : 1.152076, loss2 : 0.663293
train_step : 24293, loss1 : 0.904927, loss2 : 1.164397
train_step : 24294, loss1 : 0.809887, loss2 : 0.891159
train_step : 24295, loss1 : 1.053196, loss2 : 1.519623
train_step : 24296, loss1 : 1.604321, loss2 : 1.063826
train_step : 24297, loss1 : 1.282580, loss2 : 1.400443
train_step : 24298, loss1 : 0.518063, loss2 : 0.869724
train_step : 24299, loss1 : 0.648950, loss2 : 0.789836
train_step : 24300, loss1 : 0.953335, loss2 : 0.995996
train_step : 24301, loss1 : 1.556306, loss2 : 0.779204
train_step : 24302, loss1 : 1.289459, loss2 : 0.602732
train_step : 24303, loss1 : 0.559527, loss2 : 1.705376
train_step : 24304, loss1 : 1.088724, loss2 : 0.923310
train_step : 24305, loss1 : 0.912777, loss2 : 1.409090
train_step : 24306, loss1 : 1.078549, loss2 : 1.039734
train_step : 24307, loss1 : 0.939977, loss2 : 1.660586
train_step : 24308, loss1 : 1.775125, loss2 : 1.272599
train_step : 24309, loss1 : 0.816759, loss2 : 0.530781
train_step : 24310, loss1 : 1.028674, loss2 : 0.829107
train_step : 24311, loss1 : 0.630438, loss2 : 0.855916
train_step : 24312, loss1 : 1.144264, loss2 : 1.173932
train_step : 24313, loss1 : 0.718405, loss2 : 2.162607
train_step : 24314, loss1 : 2.140391, loss2 : 1.438292
train_step : 24315, loss1 : 1.727504, loss2 : 1.691306
train_step : 24316, loss1 : 1.015223, loss2 : 1.316826
train_step : 24317, loss1 : 0.897565, loss2 : 0.951697
train_step : 24318, loss1 : 1.160573, loss2 : 1.119436
train_step : 24319, loss1 : 1.779211, loss2 : 1.785360
train_step : 24320, loss1 : 1.172520, loss2 : 2.243588
train_step : 24321, loss1 : 0.979384, loss2 : 1.500191
train_step : 24322, loss1 : 0.617402, loss2 : 1.173450
train_step : 24323, loss1 : 1.348882, loss2 : 1.235014
train_step : 24324, loss1 : 0.658902, loss2 : 1.306074
train_step : 24325, loss1 : 0.855206, loss2 : 1.294256
train_step : 24326, loss1 : 0.934106, loss2 : 0.752348
train_step : 24327, loss1 : 1.015594, loss2 : 1.099010
train_step : 24328, loss1 : 0.721883, loss2 : 1.279989
train_step : 24329, loss1 : 0.739235, loss2 : 1.075121
train_step : 24330, loss1 : 1.082128, loss2 : 1.042909
train_step : 24331, loss1 : 1.491988, loss2 : 1.100855
train_step : 24332, loss1 : 0.697890, loss2 : 1.680233
train_step : 24333, loss1 : 0.797469, loss2 : 0.992028
train_step : 24334, loss1 : 1.050036, loss2 : 0.901768
train_step : 24335, loss1 : 1.088521, loss2 : 1.062314
train_step : 24336, loss1 : 2.214786, loss2 : 1.176193
train_step : 24337, loss1 : 1.045455, loss2 : 0.669936
train_step : 24338, loss1 : 2.142325, loss2 : 1.794293
train_step : 24339, loss1 : 1.442989, loss2 : 1.246380
train_step : 24340, loss1 : 1.454138, loss2 : 1.252659
train_step : 24341, loss1 : 1.493290, loss2 : 0.613161
train_step : 24342, loss1 : 1.516922, loss2 : 0.865459
train_step : 24343, loss1 : 1.017788, loss2 : 0.779833
train_step : 24344, loss1 : 1.502477, loss2 : 0.606878
train_step : 24345, loss1 : 0.677919, loss2 : 1.180225
train_step : 24346, loss1 : 1.546136, loss2 : 0.997857
train_step : 24347, loss1 : 1.661936, loss2 : 2.013267
train_step : 24348, loss1 : 2.221561, loss2 : 2.269365
train_step : 24349, loss1 : 2.838661, loss2 : 1.400629
train_step : 24350, loss1 : 1.475224, loss2 : 1.905104
train_step : 24351, loss1 : 2.103912, loss2 : 1.605126
train_step : 24352, loss1 : 1.787539, loss2 : 2.983714
train_step : 24353, loss1 : 2.162344, loss2 : 2.088777
train_step : 24354, loss1 : 1.389827, loss2 : 1.927017
train_step : 24355, loss1 : 0.475809, loss2 : 0.750561
train_step : 24356, loss1 : 1.358902, loss2 : 1.318748
train_step : 24357, loss1 : 0.845079, loss2 : 1.277019
train_step : 24358, loss1 : 0.617569, loss2 : 0.679881
train_step : 24359, loss1 : 1.189148, loss2 : 1.638497
train_step : 24360, loss1 : 1.187097, loss2 : 0.906733
train_step : 24361, loss1 : 1.099382, loss2 : 0.788348
train_step : 24362, loss1 : 0.965449, loss2 : 1.217283
train_step : 24363, loss1 : 0.832332, loss2 : 0.932934
train_step : 24364, loss1 : 0.571199, loss2 : 0.789948
train_step : 24365, loss1 : 0.786631, loss2 : 1.362711
train_step : 24366, loss1 : 1.552666, loss2 : 0.903657
train_step : 24367, loss1 : 1.560528, loss2 : 1.622794
train_step : 24368, loss1 : 1.052346, loss2 : 1.154662
train_step : 24369, loss1 : 0.831518, loss2 : 0.728433
train_step : 24370, loss1 : 0.619871, loss2 : 2.169721
train_step : 24371, loss1 : 1.200080, loss2 : 0.807428
train_step : 24372, loss1 : 1.282491, loss2 : 0.686215
train_step : 24373, loss1 : 0.562041, loss2 : 1.743789
train_step : 24374, loss1 : 0.959893, loss2 : 0.762564
train_step : 24375, loss1 : 2.699139, loss2 : 2.559189
train_step : 24376, loss1 : 2.657232, loss2 : 3.708653
train_step : 24377, loss1 : 3.199052, loss2 : 2.023496
train_step : 24378, loss1 : 3.385610, loss2 : 2.759242
train_step : 24379, loss1 : 4.419267, loss2 : 4.033253
train_step : 24380, loss1 : 6.472759, loss2 : 5.989211
train_step : 24381, loss1 : 3.568795, loss2 : 3.281106
train_step : 24382, loss1 : 3.782940, loss2 : 4.045527
train_step : 24383, loss1 : 3.717784, loss2 : 4.497928
train_step : 24384, loss1 : 3.733344, loss2 : 3.108477
train_step : 24385, loss1 : 1.824647, loss2 : 1.198812
train_step : 24386, loss1 : 1.142436, loss2 : 1.662765
train_step : 24387, loss1 : 1.152690, loss2 : 1.001717
train_step : 24388, loss1 : 1.474956, loss2 : 1.209573
train_step : 24389, loss1 : 2.291677, loss2 : 1.758379
train_step : 24390, loss1 : 2.701543, loss2 : 2.091919
train_step : 24391, loss1 : 1.740529, loss2 : 2.186795
train_step : 24392, loss1 : 2.673789, loss2 : 0.897240
train_step : 24393, loss1 : 2.275355, loss2 : 2.033175
train_step : 24394, loss1 : 1.365469, loss2 : 1.706650
train_step : 24395, loss1 : 1.006565, loss2 : 1.094649
train_step : 24396, loss1 : 1.493119, loss2 : 0.724982
train_step : 24397, loss1 : 0.987308, loss2 : 1.643733
train_step : 24398, loss1 : 0.928647, loss2 : 1.082325
train_step : 24399, loss1 : 1.587288, loss2 : 0.904651
train_step : 24400, loss1 : 0.945660, loss2 : 0.851298
train_step : 24401, loss1 : 1.346786, loss2 : 1.604760
train_step : 24402, loss1 : 1.933078, loss2 : 1.955822
train_step : 24403, loss1 : 0.936183, loss2 : 1.644876
train_step : 24404, loss1 : 1.398268, loss2 : 0.580030
train_step : 24405, loss1 : 1.583722, loss2 : 0.836765
train_step : 24406, loss1 : 1.122631, loss2 : 0.947987
train_step : 24407, loss1 : 0.837233, loss2 : 1.079880
train_step : 24408, loss1 : 0.651871, loss2 : 1.747964
train_step : 24409, loss1 : 2.074885, loss2 : 1.829493
train_step : 24410, loss1 : 2.258039, loss2 : 2.031327
train_step : 24411, loss1 : 1.938341, loss2 : 1.373420
train_step : 24412, loss1 : 1.808732, loss2 : 1.491112
train_step : 24413, loss1 : 1.716702, loss2 : 1.710746
train_step : 24414, loss1 : 1.845739, loss2 : 1.660533
train_step : 24415, loss1 : 2.186226, loss2 : 2.165222
train_step : 24416, loss1 : 1.411104, loss2 : 1.707492
train_step : 24417, loss1 : 0.997745, loss2 : 1.415311
train_step : 24418, loss1 : 1.452696, loss2 : 0.452331
train_step : 24419, loss1 : 1.922959, loss2 : 1.038639
train_step : 24420, loss1 : 1.675381, loss2 : 1.320282
train_step : 24421, loss1 : 0.802187, loss2 : 1.224625
train_step : 24422, loss1 : 1.309365, loss2 : 1.012465
train_step : 24423, loss1 : 1.041802, loss2 : 1.338556
train_step : 24424, loss1 : 1.183059, loss2 : 1.742592
train_step : 24425, loss1 : 0.919816, loss2 : 0.977527
train_step : 24426, loss1 : 0.674924, loss2 : 0.827688
train_step : 24427, loss1 : 0.886624, loss2 : 1.569771
train_step : 24428, loss1 : 1.185243, loss2 : 0.820117
train_step : 24429, loss1 : 0.522102, loss2 : 1.150635
train_step : 24430, loss1 : 1.138513, loss2 : 1.167632
train_step : 24431, loss1 : 1.249615, loss2 : 0.494920
train_step : 24432, loss1 : 1.172048, loss2 : 1.091917
train_step : 24433, loss1 : 1.447086, loss2 : 1.082473
train_step : 24434, loss1 : 0.717080, loss2 : 1.178986
train_step : 24435, loss1 : 0.545150, loss2 : 0.892118
train_step : 24436, loss1 : 1.058064, loss2 : 0.651131
train_step : 24437, loss1 : 0.930603, loss2 : 0.748109
train_step : 24438, loss1 : 0.889222, loss2 : 1.836541
train_step : 24439, loss1 : 1.421914, loss2 : 1.018635
train_step : 24440, loss1 : 1.294729, loss2 : 0.922814
train_step : 24441, loss1 : 0.618056, loss2 : 0.695612
train_step : 24442, loss1 : 1.262224, loss2 : 1.991353
train_step : 24443, loss1 : 0.944301, loss2 : 0.946703
train_step : 24444, loss1 : 1.182011, loss2 : 0.823325
train_step : 24445, loss1 : 1.275946, loss2 : 1.548110
train_step : 24446, loss1 : 2.392092, loss2 : 0.971356
train_step : 24447, loss1 : 1.221072, loss2 : 1.557790
train_step : 24448, loss1 : 1.168370, loss2 : 1.297932
train_step : 24449, loss1 : 1.381118, loss2 : 0.649259
train_step : 24450, loss1 : 0.852606, loss2 : 0.974492
train_step : 24451, loss1 : 0.990291, loss2 : 0.884816
train_step : 24452, loss1 : 0.862075, loss2 : 0.866281
train_step : 24453, loss1 : 1.000340, loss2 : 1.330954
train_step : 24454, loss1 : 2.245250, loss2 : 1.414639
train_step : 24455, loss1 : 1.201810, loss2 : 1.592601
train_step : 24456, loss1 : 2.547768, loss2 : 3.766850
train_step : 24457, loss1 : 2.947192, loss2 : 4.504719
train_step : 24458, loss1 : 3.208724, loss2 : 1.984372
train_step : 24459, loss1 : 2.303929, loss2 : 4.239491
train_step : 24460, loss1 : 1.700297, loss2 : 1.402461
train_step : 24461, loss1 : 1.735091, loss2 : 1.887457
train_step : 24462, loss1 : 1.419082, loss2 : 0.658666
train_step : 24463, loss1 : 1.070628, loss2 : 0.892142
train_step : 24464, loss1 : 1.306331, loss2 : 1.057964
train_step : 24465, loss1 : 0.992367, loss2 : 0.995175
train_step : 24466, loss1 : 0.841633, loss2 : 1.126043
train_step : 24467, loss1 : 1.017459, loss2 : 1.366330
train_step : 24468, loss1 : 1.484962, loss2 : 1.551311
train_step : 24469, loss1 : 2.032527, loss2 : 1.301619
train_step : 24470, loss1 : 1.241762, loss2 : 0.975458
train_step : 24471, loss1 : 2.736170, loss2 : 0.950555
train_step : 24472, loss1 : 1.223281, loss2 : 1.315682
train_step : 24473, loss1 : 0.654891, loss2 : 0.894966
train_step : 24474, loss1 : 1.063726, loss2 : 0.756344
train_step : 24475, loss1 : 0.450875, loss2 : 0.785031
train_step : 24476, loss1 : 0.686897, loss2 : 0.977683
train_step : 24477, loss1 : 1.358552, loss2 : 1.470357
train_step : 24478, loss1 : 0.704934, loss2 : 0.972909
train_step : 24479, loss1 : 0.843255, loss2 : 1.184780
train_step : 24480, loss1 : 1.148711, loss2 : 1.197918
train_step : 24481, loss1 : 0.608733, loss2 : 1.576302
train_step : 24482, loss1 : 1.543772, loss2 : 1.262586
train_step : 24483, loss1 : 1.252840, loss2 : 2.029594
train_step : 24484, loss1 : 2.083875, loss2 : 1.155244
train_step : 24485, loss1 : 1.391419, loss2 : 0.929258
train_step : 24486, loss1 : 0.937502, loss2 : 1.020924
train_step : 24487, loss1 : 1.234998, loss2 : 1.220933
train_step : 24488, loss1 : 0.901402, loss2 : 0.992715
train_step : 24489, loss1 : 1.470695, loss2 : 0.923532
train_step : 24490, loss1 : 1.384616, loss2 : 1.208200
train_step : 24491, loss1 : 1.382263, loss2 : 0.659130
train_step : 24492, loss1 : 1.369683, loss2 : 1.045155
train_step : 24493, loss1 : 0.882467, loss2 : 1.025465
train_step : 24494, loss1 : 0.960708, loss2 : 0.705198
train_step : 24495, loss1 : 1.678816, loss2 : 1.046423
train_step : 24496, loss1 : 1.485335, loss2 : 1.050563
train_step : 24497, loss1 : 1.105999, loss2 : 0.877850
train_step : 24498, loss1 : 1.157341, loss2 : 1.149910
train_step : 24499, loss1 : 0.933836, loss2 : 0.981155
train_step : 24500, loss1 : 1.654584, loss2 : 0.825444
train_step : 24501, loss1 : 1.111733, loss2 : 1.172982
train_step : 24502, loss1 : 0.915980, loss2 : 1.266220
train_step : 24503, loss1 : 1.133050, loss2 : 1.328270
train_step : 24504, loss1 : 1.778553, loss2 : 0.823391
train_step : 24505, loss1 : 0.711048, loss2 : 0.898654
train_step : 24506, loss1 : 0.459652, loss2 : 1.002176
train_step : 24507, loss1 : 1.298787, loss2 : 1.251105
train_step : 24508, loss1 : 1.713878, loss2 : 1.363606
train_step : 24509, loss1 : 1.981992, loss2 : 1.784859
train_step : 24510, loss1 : 1.321642, loss2 : 2.771712
train_step : 24511, loss1 : 1.934613, loss2 : 2.437534
train_step : 24512, loss1 : 2.416231, loss2 : 1.807628
train_step : 24513, loss1 : 0.660275, loss2 : 1.937191
train_step : 24514, loss1 : 1.685195, loss2 : 1.982512
train_step : 24515, loss1 : 0.824171, loss2 : 0.963110
train_step : 24516, loss1 : 0.661186, loss2 : 1.386163
train_step : 24517, loss1 : 1.277523, loss2 : 1.160542
train_step : 24518, loss1 : 1.451926, loss2 : 0.846938
train_step : 24519, loss1 : 0.633729, loss2 : 1.745707
train_step : 24520, loss1 : 1.637936, loss2 : 1.334047
train_step : 24521, loss1 : 1.250130, loss2 : 1.586647
train_step : 24522, loss1 : 2.105514, loss2 : 1.806852
train_step : 24523, loss1 : 1.306852, loss2 : 1.702188
train_step : 24524, loss1 : 1.693195, loss2 : 1.272340
train_step : 24525, loss1 : 0.476567, loss2 : 0.949529
train_step : 24526, loss1 : 1.244235, loss2 : 0.622216
train_step : 24527, loss1 : 1.595509, loss2 : 1.032423
train_step : 24528, loss1 : 1.052015, loss2 : 1.495595
train_step : 24529, loss1 : 0.796609, loss2 : 0.788503
train_step : 24530, loss1 : 0.752753, loss2 : 0.605446
train_step : 24531, loss1 : 0.741436, loss2 : 1.213374
train_step : 24532, loss1 : 0.831935, loss2 : 0.954600
train_step : 24533, loss1 : 1.139663, loss2 : 1.967435
train_step : 24534, loss1 : 0.939728, loss2 : 0.741387
train_step : 24535, loss1 : 0.966890, loss2 : 0.961378
train_step : 24536, loss1 : 1.294077, loss2 : 1.513455
train_step : 24537, loss1 : 1.384765, loss2 : 0.831709
train_step : 24538, loss1 : 1.149474, loss2 : 0.640911
train_step : 24539, loss1 : 1.152123, loss2 : 1.054481
train_step : 24540, loss1 : 1.086606, loss2 : 1.540649
train_step : 24541, loss1 : 1.051274, loss2 : 1.206427
train_step : 24542, loss1 : 1.205602, loss2 : 2.307375
train_step : 24543, loss1 : 0.834697, loss2 : 1.233648
train_step : 24544, loss1 : 1.424910, loss2 : 1.091125
train_step : 24545, loss1 : 0.654051, loss2 : 1.755905
train_step : 24546, loss1 : 1.474637, loss2 : 1.050172
train_step : 24547, loss1 : 7.541252, loss2 : 0.865112
train_step : 24548, loss1 : 1.119717, loss2 : 1.247842
train_step : 24549, loss1 : 0.805265, loss2 : 1.254995
train_step : 24550, loss1 : 1.045673, loss2 : 1.233271
train_step : 24551, loss1 : 0.795554, loss2 : 1.673932
train_step : 24552, loss1 : 1.038615, loss2 : 0.667448
train_step : 24553, loss1 : 1.231097, loss2 : 0.966315
train_step : 24554, loss1 : 1.103264, loss2 : 0.762757
train_step : 24555, loss1 : 1.498593, loss2 : 2.033732
train_step : 24556, loss1 : 2.014952, loss2 : 1.724283
train_step : 24557, loss1 : 0.563532, loss2 : 1.207107
train_step : 24558, loss1 : 0.634062, loss2 : 1.509698
train_step : 24559, loss1 : 0.588754, loss2 : 2.168116
train_step : 24560, loss1 : 0.544564, loss2 : 1.245540
train_step : 24561, loss1 : 1.300887, loss2 : 1.554306
train_step : 24562, loss1 : 1.329100, loss2 : 0.961670
train_step : 24563, loss1 : 0.979539, loss2 : 0.944739
train_step : 24564, loss1 : 1.183601, loss2 : 0.709408
train_step : 24565, loss1 : 3.929121, loss2 : 1.324189
train_step : 24566, loss1 : 0.965851, loss2 : 0.685077
train_step : 24567, loss1 : 2.569411, loss2 : 1.313031
train_step : 24568, loss1 : 1.301505, loss2 : 1.741969
train_step : 24569, loss1 : 2.271733, loss2 : 1.695987
train_step : 24570, loss1 : 1.049031, loss2 : 1.650753
train_step : 24571, loss1 : 1.347224, loss2 : 0.540064
train_step : 24572, loss1 : 1.293998, loss2 : 1.184368
train_step : 24573, loss1 : 0.797165, loss2 : 1.489580
train_step : 24574, loss1 : 1.822531, loss2 : 1.195128
train_step : 24575, loss1 : 1.893114, loss2 : 1.162593
train_step : 24576, loss1 : 1.968556, loss2 : 2.737558
train_step : 24577, loss1 : 3.169955, loss2 : 2.195648
train_step : 24578, loss1 : 2.348458, loss2 : 1.235159
train_step : 24579, loss1 : 1.978931, loss2 : 2.674621
train_step : 24580, loss1 : 0.971571, loss2 : 1.893110
train_step : 24581, loss1 : 1.418005, loss2 : 1.395937
train_step : 24582, loss1 : 1.957103, loss2 : 2.015351
train_step : 24583, loss1 : 1.574803, loss2 : 1.742423
train_step : 24584, loss1 : 1.733559, loss2 : 0.906553
train_step : 24585, loss1 : 1.115889, loss2 : 1.119216
train_step : 24586, loss1 : 1.339404, loss2 : 0.888645
train_step : 24587, loss1 : 0.872618, loss2 : 0.885985
train_step : 24588, loss1 : 0.781433, loss2 : 0.726393
train_step : 24589, loss1 : 1.145572, loss2 : 0.379746
train_step : 24590, loss1 : 1.178912, loss2 : 0.733123
train_step : 24591, loss1 : 1.330295, loss2 : 2.312894
train_step : 24592, loss1 : 1.879964, loss2 : 1.493549
train_step : 24593, loss1 : 1.233014, loss2 : 1.688591
train_step : 24594, loss1 : 2.053226, loss2 : 1.161036
train_step : 24595, loss1 : 1.022952, loss2 : 0.956556
train_step : 24596, loss1 : 1.487119, loss2 : 1.561191
train_step : 24597, loss1 : 0.689802, loss2 : 1.448563
train_step : 24598, loss1 : 0.556329, loss2 : 1.112039
train_step : 24599, loss1 : 1.145647, loss2 : 1.424201
train_step : 24600, loss1 : 1.232290, loss2 : 1.079738
train_step : 24601, loss1 : 2.380009, loss2 : 0.833580
train_step : 24602, loss1 : 1.499859, loss2 : 1.336576
train_step : 24603, loss1 : 2.260723, loss2 : 0.992814
train_step : 24604, loss1 : 2.296300, loss2 : 2.124521
train_step : 24605, loss1 : 2.654675, loss2 : 1.692652
train_step : 24606, loss1 : 1.818667, loss2 : 2.607233
train_step : 24607, loss1 : 1.127311, loss2 : 1.557580
train_step : 24608, loss1 : 1.145945, loss2 : 1.117910
train_step : 24609, loss1 : 1.337726, loss2 : 1.144202
train_step : 24610, loss1 : 1.160943, loss2 : 1.442360
train_step : 24611, loss1 : 1.231661, loss2 : 0.984994
train_step : 24612, loss1 : 1.203669, loss2 : 1.506987
train_step : 24613, loss1 : 0.967373, loss2 : 0.930545
train_step : 24614, loss1 : 1.341386, loss2 : 1.087694
train_step : 24615, loss1 : 1.903794, loss2 : 0.723429
train_step : 24616, loss1 : 1.431355, loss2 : 0.965319
train_step : 24617, loss1 : 1.029821, loss2 : 1.000915
train_step : 24618, loss1 : 0.583760, loss2 : 0.863417
train_step : 24619, loss1 : 1.195917, loss2 : 1.841889
train_step : 24620, loss1 : 1.037872, loss2 : 1.578445
train_step : 24621, loss1 : 1.658174, loss2 : 1.326616
train_step : 24622, loss1 : 2.044137, loss2 : 2.408820
train_step : 24623, loss1 : 1.108825, loss2 : 1.434845
train_step : 24624, loss1 : 0.876774, loss2 : 1.336304
train_step : 24625, loss1 : 0.987023, loss2 : 0.873971
train_step : 24626, loss1 : 1.863772, loss2 : 1.162264
train_step : 24627, loss1 : 1.711980, loss2 : 1.388074
train_step : 24628, loss1 : 1.581429, loss2 : 1.369096
train_step : 24629, loss1 : 2.300594, loss2 : 1.499863
train_step : 24630, loss1 : 0.689973, loss2 : 1.524303
train_step : 24631, loss1 : 1.500684, loss2 : 2.363779
train_step : 24632, loss1 : 0.568355, loss2 : 1.372161
train_step : 24633, loss1 : 1.465047, loss2 : 1.006164
train_step : 24634, loss1 : 0.772335, loss2 : 0.625947
train_step : 24635, loss1 : 1.084986, loss2 : 1.150576
train_step : 24636, loss1 : 0.951075, loss2 : 3.079678
train_step : 24637, loss1 : 1.209215, loss2 : 0.802271
train_step : 24638, loss1 : 0.721289, loss2 : 1.886254
train_step : 24639, loss1 : 0.731589, loss2 : 0.750397
train_step : 24640, loss1 : 1.649721, loss2 : 0.556301
train_step : 24641, loss1 : 1.162781, loss2 : 1.447176
train_step : 24642, loss1 : 1.665003, loss2 : 1.465277
train_step : 24643, loss1 : 1.175143, loss2 : 0.935751
train_step : 24644, loss1 : 0.911682, loss2 : 2.247941
train_step : 24645, loss1 : 0.926033, loss2 : 1.074878
train_step : 24646, loss1 : 1.072649, loss2 : 0.917495
train_step : 24647, loss1 : 1.083552, loss2 : 1.788392
train_step : 24648, loss1 : 1.222149, loss2 : 1.706155
train_step : 24649, loss1 : 1.944856, loss2 : 1.681030
train_step : 24650, loss1 : 1.970644, loss2 : 1.791223
train_step : 24651, loss1 : 1.309012, loss2 : 0.815313
train_step : 24652, loss1 : 1.190539, loss2 : 1.752146
train_step : 24653, loss1 : 0.689593, loss2 : 1.207272
train_step : 24654, loss1 : 1.081859, loss2 : 1.116853
train_step : 24655, loss1 : 0.774976, loss2 : 1.210358
train_step : 24656, loss1 : 2.239685, loss2 : 0.742427
train_step : 24657, loss1 : 0.811021, loss2 : 1.634173
train_step : 24658, loss1 : 1.297450, loss2 : 0.827098
train_step : 24659, loss1 : 1.381333, loss2 : 0.927189
train_step : 24660, loss1 : 0.984440, loss2 : 1.339187
train_step : 24661, loss1 : 1.616276, loss2 : 1.281925
train_step : 24662, loss1 : 1.169170, loss2 : 1.875496
train_step : 24663, loss1 : 1.755032, loss2 : 1.760890
train_step : 24664, loss1 : 1.689085, loss2 : 1.547996
train_step : 24665, loss1 : 1.136570, loss2 : 1.171106
train_step : 24666, loss1 : 2.147046, loss2 : 1.722622
train_step : 24667, loss1 : 3.190923, loss2 : 2.778722
train_step : 24668, loss1 : 2.639167, loss2 : 1.949355
train_step : 24669, loss1 : 2.505012, loss2 : 1.926553
train_step : 24670, loss1 : 2.992943, loss2 : 2.513700
train_step : 24671, loss1 : 3.482712, loss2 : 2.227524
train_step : 24672, loss1 : 3.337549, loss2 : 2.045507
train_step : 24673, loss1 : 3.210604, loss2 : 3.895567
train_step : 24674, loss1 : 2.270316, loss2 : 2.056660
train_step : 24675, loss1 : 3.160213, loss2 : 1.865504
train_step : 24676, loss1 : 1.915880, loss2 : 1.163269
train_step : 24677, loss1 : 1.361680, loss2 : 0.792639
train_step : 24678, loss1 : 1.399764, loss2 : 1.258953
train_step : 24679, loss1 : 1.709284, loss2 : 1.429684
train_step : 24680, loss1 : 0.730649, loss2 : 0.799492
train_step : 24681, loss1 : 0.855620, loss2 : 1.150304
train_step : 24682, loss1 : 0.769143, loss2 : 0.677298
train_step : 24683, loss1 : 1.170372, loss2 : 1.230827
train_step : 24684, loss1 : 1.810693, loss2 : 1.862998
train_step : 24685, loss1 : 1.809554, loss2 : 1.818352
train_step : 24686, loss1 : 1.993846, loss2 : 1.315113
train_step : 24687, loss1 : 0.530901, loss2 : 1.597201
train_step : 24688, loss1 : 1.577063, loss2 : 2.140768
train_step : 24689, loss1 : 1.420951, loss2 : 2.121076
train_step : 24690, loss1 : 1.654387, loss2 : 1.607279
train_step : 24691, loss1 : 1.598130, loss2 : 2.059490
train_step : 24692, loss1 : 1.323566, loss2 : 1.748976
train_step : 24693, loss1 : 1.192257, loss2 : 0.852380
train_step : 24694, loss1 : 1.432594, loss2 : 1.894478
train_step : 24695, loss1 : 1.915846, loss2 : 2.072789
train_step : 24696, loss1 : 2.420041, loss2 : 1.850093
train_step : 24697, loss1 : 2.380068, loss2 : 2.655627
train_step : 24698, loss1 : 2.545259, loss2 : 2.826470
train_step : 24699, loss1 : 1.707755, loss2 : 1.259010
train_step : 24700, loss1 : 1.549954, loss2 : 1.814759
train_step : 24701, loss1 : 1.164330, loss2 : 1.193539
train_step : 24702, loss1 : 1.259851, loss2 : 0.804522
train_step : 24703, loss1 : 0.572092, loss2 : 1.823312
train_step : 24704, loss1 : 1.606892, loss2 : 1.856035
train_step : 24705, loss1 : 0.976363, loss2 : 1.002451
train_step : 24706, loss1 : 0.697328, loss2 : 0.914322
train_step : 24707, loss1 : 1.416407, loss2 : 1.233234
train_step : 24708, loss1 : 3.032912, loss2 : 1.000974
train_step : 24709, loss1 : 1.114981, loss2 : 2.192018
train_step : 24710, loss1 : 1.508575, loss2 : 1.435010
train_step : 24711, loss1 : 2.004400, loss2 : 1.844615
train_step : 24712, loss1 : 1.448414, loss2 : 1.062207
train_step : 24713, loss1 : 1.421522, loss2 : 1.032895
train_step : 24714, loss1 : 0.873257, loss2 : 0.906999
train_step : 24715, loss1 : 1.915794, loss2 : 1.560805
train_step : 24716, loss1 : 1.843820, loss2 : 1.432129
train_step : 24717, loss1 : 0.713734, loss2 : 0.976501
train_step : 24718, loss1 : 1.361154, loss2 : 0.883726
train_step : 24719, loss1 : 1.656328, loss2 : 1.202312
train_step : 24720, loss1 : 1.142158, loss2 : 1.976953
train_step : 24721, loss1 : 1.000439, loss2 : 1.032467
train_step : 24722, loss1 : 1.088516, loss2 : 1.717094
train_step : 24723, loss1 : 0.918824, loss2 : 0.774815
train_step : 24724, loss1 : 0.915645, loss2 : 0.878177
train_step : 24725, loss1 : 0.929444, loss2 : 1.022888
train_step : 24726, loss1 : 1.168052, loss2 : 0.446242
train_step : 24727, loss1 : 0.879707, loss2 : 1.277201
train_step : 24728, loss1 : 1.195775, loss2 : 1.110182
train_step : 24729, loss1 : 1.637072, loss2 : 1.530297
train_step : 24730, loss1 : 0.962601, loss2 : 0.595303
train_step : 24731, loss1 : 1.097027, loss2 : 1.134179
train_step : 24732, loss1 : 1.053530, loss2 : 0.905764
train_step : 24733, loss1 : 0.535154, loss2 : 0.511234
train_step : 24734, loss1 : 1.201457, loss2 : 1.340861
train_step : 24735, loss1 : 1.474073, loss2 : 1.501815
train_step : 24736, loss1 : 1.289395, loss2 : 0.737318
train_step : 24737, loss1 : 0.892669, loss2 : 1.158248
train_step : 24738, loss1 : 1.007507, loss2 : 1.005981
train_step : 24739, loss1 : 1.893910, loss2 : 1.532666
train_step : 24740, loss1 : 2.794052, loss2 : 2.152272
train_step : 24741, loss1 : 1.462906, loss2 : 1.425894
train_step : 24742, loss1 : 1.909443, loss2 : 1.774179
train_step : 24743, loss1 : 1.113223, loss2 : 1.459447
train_step : 24744, loss1 : 0.892385, loss2 : 1.038153
train_step : 24745, loss1 : 1.474194, loss2 : 1.011927
train_step : 24746, loss1 : 1.806792, loss2 : 2.056771
train_step : 24747, loss1 : 1.254136, loss2 : 0.989568
train_step : 24748, loss1 : 1.957973, loss2 : 0.780657
train_step : 24749, loss1 : 1.578854, loss2 : 0.985520
train_step : 24750, loss1 : 1.663633, loss2 : 2.091409
train_step : 24751, loss1 : 1.884141, loss2 : 2.092780
train_step : 24752, loss1 : 1.080209, loss2 : 1.381124
train_step : 24753, loss1 : 1.582202, loss2 : 1.059980
train_step : 24754, loss1 : 0.604227, loss2 : 1.041020
train_step : 24755, loss1 : 1.140234, loss2 : 1.098693
train_step : 24756, loss1 : 1.036816, loss2 : 0.868487
train_step : 24757, loss1 : 0.727087, loss2 : 1.164166
train_step : 24758, loss1 : 0.897373, loss2 : 0.834420
train_step : 24759, loss1 : 1.254210, loss2 : 0.882572
train_step : 24760, loss1 : 1.550044, loss2 : 0.960703
train_step : 24761, loss1 : 0.982081, loss2 : 1.044413
train_step : 24762, loss1 : 1.814405, loss2 : 1.363084
train_step : 24763, loss1 : 1.477687, loss2 : 2.799946
train_step : 24764, loss1 : 1.414711, loss2 : 1.838978
train_step : 24765, loss1 : 2.102839, loss2 : 1.458445
train_step : 24766, loss1 : 1.931139, loss2 : 2.102055
train_step : 24767, loss1 : 1.855547, loss2 : 1.894285
train_step : 24768, loss1 : 2.655142, loss2 : 2.099236
train_step : 24769, loss1 : 1.425983, loss2 : 0.865838
train_step : 24770, loss1 : 1.722227, loss2 : 1.177676
train_step : 24771, loss1 : 1.356662, loss2 : 0.695573
train_step : 24772, loss1 : 0.547745, loss2 : 1.628406
train_step : 24773, loss1 : 1.083459, loss2 : 1.328200
train_step : 24774, loss1 : 1.770144, loss2 : 1.287496
train_step : 24775, loss1 : 2.404575, loss2 : 0.478641
train_step : 24776, loss1 : 1.098201, loss2 : 0.887880
train_step : 24777, loss1 : 1.006674, loss2 : 1.539310
train_step : 24778, loss1 : 1.959696, loss2 : 1.878055
train_step : 24779, loss1 : 2.388327, loss2 : 1.473974
train_step : 24780, loss1 : 0.566286, loss2 : 1.081463
train_step : 24781, loss1 : 1.145411, loss2 : 1.061247
train_step : 24782, loss1 : 1.468416, loss2 : 1.496830
train_step : 24783, loss1 : 1.123253, loss2 : 1.744684
train_step : 24784, loss1 : 2.258811, loss2 : 2.181019
train_step : 24785, loss1 : 1.992016, loss2 : 1.807150
train_step : 24786, loss1 : 2.115139, loss2 : 1.391323
train_step : 24787, loss1 : 1.347337, loss2 : 1.486852
train_step : 24788, loss1 : 1.444297, loss2 : 2.287424
train_step : 24789, loss1 : 1.049346, loss2 : 1.785061
train_step : 24790, loss1 : 1.328767, loss2 : 1.873798
train_step : 24791, loss1 : 0.808783, loss2 : 1.113612
train_step : 24792, loss1 : 0.847592, loss2 : 0.856257
train_step : 24793, loss1 : 1.230804, loss2 : 0.997217
train_step : 24794, loss1 : 3.425645, loss2 : 1.358625
train_step : 24795, loss1 : 1.408512, loss2 : 0.918680
train_step : 24796, loss1 : 1.349068, loss2 : 4.123455
train_step : 24797, loss1 : 0.918185, loss2 : 1.110919
train_step : 24798, loss1 : 0.822293, loss2 : 1.038301
train_step : 24799, loss1 : 1.777099, loss2 : 1.370505
train_step : 24800, loss1 : 1.236399, loss2 : 1.514517
train_step : 24801, loss1 : 1.132557, loss2 : 1.868928
train_step : 24802, loss1 : 1.185809, loss2 : 0.870843
train_step : 24803, loss1 : 0.969051, loss2 : 0.775742
train_step : 24804, loss1 : 0.981322, loss2 : 0.908274
train_step : 24805, loss1 : 1.725234, loss2 : 1.424888
train_step : 24806, loss1 : 3.106985, loss2 : 1.269681
train_step : 24807, loss1 : 1.412013, loss2 : 0.867520
train_step : 24808, loss1 : 2.145576, loss2 : 1.333577
train_step : 24809, loss1 : 2.375282, loss2 : 2.412746
train_step : 24810, loss1 : 0.805121, loss2 : 1.833439
train_step : 24811, loss1 : 0.934613, loss2 : 0.896433
train_step : 24812, loss1 : 0.948651, loss2 : 0.744232
train_step : 24813, loss1 : 0.964629, loss2 : 0.849069
train_step : 24814, loss1 : 1.955219, loss2 : 0.878847
train_step : 24815, loss1 : 1.846994, loss2 : 0.965331
train_step : 24816, loss1 : 1.576412, loss2 : 1.300545
train_step : 24817, loss1 : 0.735537, loss2 : 0.749087
train_step : 24818, loss1 : 1.113037, loss2 : 1.782883
train_step : 24819, loss1 : 1.308753, loss2 : 1.705181
train_step : 24820, loss1 : 0.704409, loss2 : 0.981237
train_step : 24821, loss1 : 0.737412, loss2 : 1.074309
train_step : 24822, loss1 : 0.786195, loss2 : 1.003055
train_step : 24823, loss1 : 0.602410, loss2 : 1.353455
train_step : 24824, loss1 : 0.603396, loss2 : 1.316846
train_step : 24825, loss1 : 1.217002, loss2 : 1.559515
train_step : 24826, loss1 : 1.353294, loss2 : 0.443365
train_step : 24827, loss1 : 0.934758, loss2 : 1.293985
train_step : 24828, loss1 : 1.137506, loss2 : 0.668415
train_step : 24829, loss1 : 0.915575, loss2 : 2.204688
train_step : 24830, loss1 : 1.581263, loss2 : 0.733507
train_step : 24831, loss1 : 1.698574, loss2 : 0.609551
train_step : 24832, loss1 : 1.171521, loss2 : 0.998409
train_step : 24833, loss1 : 1.372836, loss2 : 1.747276
train_step : 24834, loss1 : 3.281736, loss2 : 2.305216
train_step : 24835, loss1 : 2.462938, loss2 : 3.417839
train_step : 24836, loss1 : 1.515924, loss2 : 1.542038
train_step : 24837, loss1 : 0.478297, loss2 : 1.179021
train_step : 24838, loss1 : 1.085709, loss2 : 0.778504
train_step : 24839, loss1 : 0.540360, loss2 : 0.927686
train_step : 24840, loss1 : 1.390724, loss2 : 1.852075
train_step : 24841, loss1 : 1.214544, loss2 : 1.685771
train_step : 24842, loss1 : 0.982585, loss2 : 1.010494
train_step : 24843, loss1 : 0.940394, loss2 : 1.035165
train_step : 24844, loss1 : 1.514732, loss2 : 0.985573
train_step : 24845, loss1 : 1.063849, loss2 : 1.671483
train_step : 24846, loss1 : 1.051487, loss2 : 0.961769
train_step : 24847, loss1 : 1.281627, loss2 : 0.777874
train_step : 24848, loss1 : 0.650928, loss2 : 1.128405
train_step : 24849, loss1 : 0.822345, loss2 : 0.817228
train_step : 24850, loss1 : 1.612618, loss2 : 0.858932
train_step : 24851, loss1 : 1.132994, loss2 : 0.413892
train_step : 24852, loss1 : 2.067320, loss2 : 1.084381
train_step : 24853, loss1 : 1.373268, loss2 : 1.414503
train_step : 24854, loss1 : 1.129734, loss2 : 1.263406
train_step : 24855, loss1 : 1.455851, loss2 : 0.771016
train_step : 24856, loss1 : 0.709266, loss2 : 0.966679
train_step : 24857, loss1 : 0.891684, loss2 : 1.292686
train_step : 24858, loss1 : 1.332952, loss2 : 0.673904
train_step : 24859, loss1 : 1.021723, loss2 : 0.902198
train_step : 24860, loss1 : 2.177066, loss2 : 0.765027
train_step : 24861, loss1 : 2.051767, loss2 : 1.093866
train_step : 24862, loss1 : 1.586164, loss2 : 2.061233
train_step : 24863, loss1 : 1.214481, loss2 : 1.332239
train_step : 24864, loss1 : 1.416079, loss2 : 0.549075
train_step : 24865, loss1 : 1.522926, loss2 : 1.403832
train_step : 24866, loss1 : 1.757824, loss2 : 2.164628
train_step : 24867, loss1 : 2.508577, loss2 : 2.743290
train_step : 24868, loss1 : 2.338682, loss2 : 2.500779
train_step : 24869, loss1 : 2.940337, loss2 : 2.161587
train_step : 24870, loss1 : 1.514971, loss2 : 1.428496
train_step : 24871, loss1 : 1.789678, loss2 : 1.596585
train_step : 24872, loss1 : 2.968559, loss2 : 2.496826
train_step : 24873, loss1 : 2.864392, loss2 : 3.138228
train_step : 24874, loss1 : 1.544004, loss2 : 1.206321
train_step : 24875, loss1 : 1.130056, loss2 : 0.581670
train_step : 24876, loss1 : 0.640246, loss2 : 2.431448
train_step : 24877, loss1 : 0.789441, loss2 : 0.764623
train_step : 24878, loss1 : 1.438138, loss2 : 1.434537
train_step : 24879, loss1 : 1.432285, loss2 : 1.060623
train_step : 24880, loss1 : 0.863228, loss2 : 0.483119
train_step : 24881, loss1 : 1.198616, loss2 : 1.362725
train_step : 24882, loss1 : 1.742130, loss2 : 1.347713
train_step : 24883, loss1 : 1.770068, loss2 : 3.181443
train_step : 24884, loss1 : 1.602628, loss2 : 1.629416
train_step : 24885, loss1 : 1.324000, loss2 : 2.004046
train_step : 24886, loss1 : 1.463464, loss2 : 2.444015
train_step : 24887, loss1 : 1.579197, loss2 : 2.789236
train_step : 24888, loss1 : 1.887699, loss2 : 1.843905
train_step : 24889, loss1 : 1.822101, loss2 : 2.717323
train_step : 24890, loss1 : 2.044632, loss2 : 1.695465
train_step : 24891, loss1 : 1.674600, loss2 : 1.713578
train_step : 24892, loss1 : 3.239022, loss2 : 1.395093
train_step : 24893, loss1 : 1.027807, loss2 : 1.106167
train_step : 24894, loss1 : 0.767794, loss2 : 1.285927
train_step : 24895, loss1 : 0.915314, loss2 : 1.079251
train_step : 24896, loss1 : 1.270902, loss2 : 1.363821
train_step : 24897, loss1 : 1.108695, loss2 : 1.580858
train_step : 24898, loss1 : 1.631896, loss2 : 1.302666
train_step : 24899, loss1 : 1.244991, loss2 : 1.714363
train_step : 24900, loss1 : 1.389839, loss2 : 1.068833
train_step : 24901, loss1 : 1.149883, loss2 : 1.383487
train_step : 24902, loss1 : 1.922448, loss2 : 1.594757
train_step : 24903, loss1 : 0.948097, loss2 : 0.922704
train_step : 24904, loss1 : 0.969688, loss2 : 0.799700
train_step : 24905, loss1 : 0.795981, loss2 : 1.492712
train_step : 24906, loss1 : 2.049204, loss2 : 1.994122
train_step : 24907, loss1 : 1.290589, loss2 : 1.758890
train_step : 24908, loss1 : 0.680073, loss2 : 1.127392
train_step : 24909, loss1 : 0.873450, loss2 : 1.108816
train_step : 24910, loss1 : 0.700679, loss2 : 1.554002
train_step : 24911, loss1 : 1.703330, loss2 : 1.318997
train_step : 24912, loss1 : 1.638056, loss2 : 1.697757
train_step : 24913, loss1 : 1.671002, loss2 : 2.866607
train_step : 24914, loss1 : 1.004775, loss2 : 1.510066
train_step : 24915, loss1 : 1.976138, loss2 : 1.197182
train_step : 24916, loss1 : 1.470994, loss2 : 2.131077
train_step : 24917, loss1 : 2.021533, loss2 : 2.953269
train_step : 24918, loss1 : 0.964798, loss2 : 1.628762
train_step : 24919, loss1 : 1.855259, loss2 : 1.988633
train_step : 24920, loss1 : 2.091418, loss2 : 2.241668
train_step : 24921, loss1 : 1.987419, loss2 : 3.104483
train_step : 24922, loss1 : 2.138478, loss2 : 2.822401
train_step : 24923, loss1 : 1.375531, loss2 : 3.133801
train_step : 24924, loss1 : 1.850184, loss2 : 0.943319
train_step : 24925, loss1 : 0.682466, loss2 : 0.555315
train_step : 24926, loss1 : 1.350187, loss2 : 1.509045
train_step : 24927, loss1 : 2.000635, loss2 : 2.059210
train_step : 24928, loss1 : 2.010236, loss2 : 0.988902
train_step : 24929, loss1 : 1.899874, loss2 : 2.315462
train_step : 24930, loss1 : 1.528227, loss2 : 2.521584
train_step : 24931, loss1 : 2.951851, loss2 : 1.605799
train_step : 24932, loss1 : 2.337507, loss2 : 2.229936
train_step : 24933, loss1 : 1.272950, loss2 : 1.219493
train_step : 24934, loss1 : 1.842752, loss2 : 2.498921
train_step : 24935, loss1 : 1.819708, loss2 : 2.662870
train_step : 24936, loss1 : 1.247123, loss2 : 2.384996
train_step : 24937, loss1 : 1.366174, loss2 : 1.226860
train_step : 24938, loss1 : 0.770702, loss2 : 0.526537
train_step : 24939, loss1 : 0.957159, loss2 : 0.844969
train_step : 24940, loss1 : 1.811722, loss2 : 0.961627
train_step : 24941, loss1 : 1.118869, loss2 : 1.125486
train_step : 24942, loss1 : 1.558618, loss2 : 0.899119
train_step : 24943, loss1 : 0.984864, loss2 : 0.900564
train_step : 24944, loss1 : 1.110239, loss2 : 0.952641
train_step : 24945, loss1 : 1.103040, loss2 : 1.284709
train_step : 24946, loss1 : 0.810031, loss2 : 1.206529
train_step : 24947, loss1 : 0.637982, loss2 : 1.420116
train_step : 24948, loss1 : 1.250674, loss2 : 0.998214
train_step : 24949, loss1 : 1.002239, loss2 : 0.405906
train_step : 24950, loss1 : 1.352513, loss2 : 0.621410
train_step : 24951, loss1 : 0.690245, loss2 : 0.962112
train_step : 24952, loss1 : 1.385222, loss2 : 0.915764
train_step : 24953, loss1 : 0.851061, loss2 : 1.276060
train_step : 24954, loss1 : 0.978265, loss2 : 1.191098
train_step : 24955, loss1 : 1.791094, loss2 : 1.775575
train_step : 24956, loss1 : 0.734733, loss2 : 1.513961
train_step : 24957, loss1 : 1.001474, loss2 : 1.699655
train_step : 24958, loss1 : 0.921943, loss2 : 2.172622
train_step : 24959, loss1 : 0.965148, loss2 : 1.310091
train_step : 24960, loss1 : 1.494400, loss2 : 1.005205
train_step : 24961, loss1 : 1.749863, loss2 : 1.127313
train_step : 24962, loss1 : 2.367815, loss2 : 1.304769
train_step : 24963, loss1 : 1.085568, loss2 : 0.979737
train_step : 24964, loss1 : 0.762787, loss2 : 0.879101
train_step : 24965, loss1 : 0.947615, loss2 : 0.943422
train_step : 24966, loss1 : 1.478270, loss2 : 0.777786
train_step : 24967, loss1 : 1.413812, loss2 : 1.133088
train_step : 24968, loss1 : 0.644810, loss2 : 1.226900
train_step : 24969, loss1 : 1.414862, loss2 : 1.012071
train_step : 24970, loss1 : 1.270664, loss2 : 0.982255
train_step : 24971, loss1 : 1.082059, loss2 : 1.539871
train_step : 24972, loss1 : 1.626862, loss2 : 1.046888
train_step : 24973, loss1 : 1.052245, loss2 : 0.989953
train_step : 24974, loss1 : 0.604028, loss2 : 1.413546
train_step : 24975, loss1 : 1.394290, loss2 : 1.329470
train_step : 24976, loss1 : 1.174541, loss2 : 1.322865
train_step : 24977, loss1 : 1.093633, loss2 : 1.926659
train_step : 24978, loss1 : 0.498246, loss2 : 0.734167
train_step : 24979, loss1 : 1.014203, loss2 : 0.828062
train_step : 24980, loss1 : 1.101492, loss2 : 0.779723
train_step : 24981, loss1 : 1.654356, loss2 : 1.979188
train_step : 24982, loss1 : 1.544833, loss2 : 1.128854
train_step : 24983, loss1 : 1.453464, loss2 : 1.142721
train_step : 24984, loss1 : 0.864160, loss2 : 0.680845
train_step : 24985, loss1 : 1.011835, loss2 : 1.318090
train_step : 24986, loss1 : 0.795301, loss2 : 1.059631
train_step : 24987, loss1 : 1.493226, loss2 : 0.454797
train_step : 24988, loss1 : 0.555019, loss2 : 1.036665
train_step : 24989, loss1 : 0.923601, loss2 : 1.042353
train_step : 24990, loss1 : 2.315983, loss2 : 1.017599
train_step : 24991, loss1 : 1.147845, loss2 : 1.836191
train_step : 24992, loss1 : 0.946847, loss2 : 0.588492
train_step : 24993, loss1 : 1.196362, loss2 : 0.936135
train_step : 24994, loss1 : 0.840291, loss2 : 1.734836
train_step : 24995, loss1 : 1.653398, loss2 : 0.931850
train_step : 24996, loss1 : 2.201368, loss2 : 2.094244
train_step : 24997, loss1 : 3.629116, loss2 : 1.853495
train_step : 24998, loss1 : 1.813861, loss2 : 2.402201
train_step : 24999, loss1 : 1.015235, loss2 : 1.558488
train_step : 25000, loss1 : 1.880899, loss2 : 1.087587
